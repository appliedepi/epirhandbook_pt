---
knit: "bookdown::render_book"
title: "Manual de R para Epidemiologistas"  
description: "The Epi R Handbook is a R reference manual for applied epidemiology and public health."
author: "the handbook team"
date: "`r Sys.Date()`"
#url: 'https://github.com/nsbatra/Epi_R_handbook'
#twitter-handle: 
#cover-image: images/R_Handbook_Logo.png
site: bookdown::bookdown_site
# output: bookdown::gitbook:
#      config:
#           sharing:
#                twitter: yes
#                facebook: yes
#                whatsapp: yes
#                github: yes
documentclass: book
---

#  {.unnumbered}

```{r, out.width = "100%", fig.align = "center", echo=F}
knitr::include_graphics(here::here("images", "Epi R Handbook Banner Portuguese 1500 x 500.png"))
# library(knitr)
# opts_chunk$set(list(echo = FALSE, eval = FALSE))
```

<meta name="description" content="The Epi R Handbook is an R reference manual for applied epidemiology and public health.">

<meta http-equiv="Content-Type" content="text/html; charset=utf-8">

<!-- <span style="color: red;">**THIS IS A DRAFT.  REVIEWERS GIVE FEEDBACK AT THIS [LINK](https://forms.gle/4RNdRRLGx67xW9yq9)**.</span> -->

<!-- <span style="color: darkgreen;">**DO YOU LIKE THIS HANDBOOK? SHOULD SOMETHING BE CHANGED? PLEASE TELL US!**</span> -->

<!-- <form target="_blank" action="https://forms.gle/A5SnRVws7tPD15Js9"> -->

<!--     <input type="submit" value="FEEDBACK" /> -->

<!-- </form> -->

<!-- ======================================================= -->

<!-- ## An R reference manual for applied epidemiology and public health {.unnumbered} -->

<!-- <span style="color: brown;">**The Epi R Handbook is an R reference manual for applied epidemiology and public health.**</span> -->

<!-- ## About this handbook   -->

## R para epidemiologia aplicada e saúde pública {.unnumbered}

**Uso**: Esse manual já foi utilizado mais de **1 milhão de vezes por 450,000 pessoas** ao redor do mundo.

**Objetivo:** Servir como um guia de referência rápido para escrever código em R (online e [**offline**](#data-used)) com exemplos centrados em exercícios que abordam problemas epidemiológicos comuns.

**Você está começando a aprender R agora?** Conheça nossos [**tutoriais interativos gratuitos**](https://www.appliedepi.org/tutorial/) ou o [**curso introdutório**](https://www.appliedepi.org/live/) síncrono e virtual utilizado pelo CDC dos EUA, pela OMS, e mais de 75 outras agências de saúde e programas de treinamento em Epidemiologia de Campo.

**Idiomas:** [Inglês (English)](https://www.epirhandbook.com/en), [Francês (Français)](https://epirhandbook.com/fr), [Espanhol (Español)](https://epirhandbook.com/es/), [Vietnamita (Tiếng Việt)](https://epirhandbook.com/vn/), [Japonês (日本)](https://epirhandbook.com/jp/), [Turco (Türkçe)](https://epirhandbook.com/tr/)  

Esta é uma versão traduzida para Português. Se você quer colaborar em melhorá-la, corrigindo algum erro, ou traduzir para outro idoma, por favor, nos contate!

<br> [**Escrito por epidemiologistas, para epidemiologistas**]{style="color: black;"}

::: {style="display: flex;"}
<div>

```{r, out.width = "100%", fig.align = "center", echo=F}
knitr::include_graphics(here::here("images", "Applied_Epi_logo.png"))
```

</div>

::: {.col data-latex="{0.05\\textwidth}"}
  <!-- an empty Div (with a white space), serving as
a column separator -->
:::

<div>

[**Applied Epi**](http://www.appliedepi.org) é uma organização sem fins lucrativos e um movimento de base composto por profissionais epidemiologistas que atuam na linha de frente de todo o mundo. Escrevemos em nosso tempo livre para oferecer este recurso à comunidade. Seu incentivo e feedback são muito bem-vindos:

-   Visite nosso [**website**](http://www.appliedepi.org) e [**junte-se a nossa lista de contatos**](https://forms.gle/9awNd8syypTSYUsn7)\
-   [**contact\@appliedepi.org**](mailto:contact@appliedepi.org){.email}, tweet [**\@appliedepi**](https://twitter.com/appliedepi), ou [**LinkedIn**](www.linkedin.com/company/appliedepi)\
-   Envie problemas para o nosso [**repositório Github**](https://github.com/appliedepi/epiRhandbook_eng)

**Oferecemos treinamento em R ao vivo** ministrado por instrutores com décadas de experiência em epidemiologia aplicada - envie-nos um e-mail para discutir.

</div>
:::

<form target="_blank" action="https://www.paypal.com/donate" method="post" target="_top">

<input type="hidden" name="hosted_button_id" value="YTEZELC8VBXV6" /> <input type="image" src="https://github.com/appliedepi/epiRhandbook_eng/raw/master/images/donate_button_long.png" border="0" name="submit" title="PayPal - The safer, easier way to pay online!" alt="Donate with PayPal button" /> <img src="https://www.paypal.com/en_US/i/scr/pixel.gif" border="0"/>

</form>

<!-- ======================================================= -->

## Como usar este manual {.unnumbered}

-   Navegue pelas páginas do Índice, ou use a caixa de busca
-   Clique nos ícones "copiar" para copiar o código\
-   Você pode seguir - junto com [os dados do exemplo](#data-used).\
-   Consulte a seção "Recursos" de cada página para obter mais material

**Versão off-line**

Veja as instruções na página [Fazer o Download do manual e dos dados](#data-used).



<!-- ======================================================= -->

## Agradecimentos {.unnumbered}

Este manual é produzido por uma colaboração de epidemiologistas de todo o mundo, aproveitando a experiência de organizações que incluem agências de saúde locais, estaduais, provinciais e nacionais, a Organização Mundial da Saúde (OMS), Médicos Sem Fronteiras / Médicos sem Fronteiras (MSF), sistemas hospitalares e instituições acadêmicas.

Este manual **não** é um produto aprovado de qualquer organização específica. Embora nos esforcemos para ser precisos, não damos nenhuma garantia do conteúdo deste livro.

### Colaboradores {.unnumbered}

**Editor:** [Neale Batra](https://www.linkedin.com/in/neale-batra/)

**Autores**: [Neale Batra](https://www.linkedin.com/in/neale-batra/), [Alex Spina](https://github.com/aspina7), [Paula Blomquist](https://www.linkedin.com/in/paula-bianca-blomquist-53188186/), [Finlay Campbell](https://github.com/finlaycampbell), [Henry Laurenson-Schafer](https://github.com/henryls1), [Isaac Florence](www.Twitter.com/isaacatflorence), [Natalie Fischer](https://www.linkedin.com/in/nataliefischer211/), [Aminata Ndiaye](https://twitter.com/aminata_fadl), [Liza Coyer](https://www.linkedin.com/in/liza-coyer-86022040/), [Jonathan Polonsky](https://twitter.com/jonny_polonsky), [Yurie Izawa](https://ch.linkedin.com/in/yurie-izawa-a1590319), [Chris Bailey](https://twitter.com/cbailey_58?lang=en), [Daniel Molling](https://www.linkedin.com/in/daniel-molling-4005716a/), [Isha Berry](https://twitter.com/ishaberry2), [Emma Buajitti](https://twitter.com/buajitti), [Mathilde Mousset](https://mathildemousset.wordpress.com/research/), [Sara Hollis](https://www.linkedin.com/in/saramhollis/), Wen Lin

**Revisores**: Pat Keating, Annick Lenglet, Margot Charette, Danielly Xavier, Esther Kukielka, Michelle Sloan, Aybüke Koyuncu, Rachel Burke, Kate Kelsey, [Berhe Etsay](https://www.linkedin.com/in/berhe-etsay-5752b1154/), John Rossow, Mackenzie Zendt, James Wright, Laura Haskins, [Flavio Finger](ffinger.github.io), Tim Taylor, [Jae Hyoung Tim Lee](https://www.linkedin.com/in/jaehyoungtlee/), [Brianna Bradley](https://www.linkedin.com/in/brianna-bradley-bb8658155), [Wayne Enanoria](https://www.linkedin.com/in/wenanoria), Manual Albela Miranda, [Molly Mantus](https://www.linkedin.com/in/molly-mantus-174550150/), Pattama Ulrich, Joseph Timothy, Adam Vaughan, Olivia Varsaneux, Lionel Monteiro, Joao Muianga

**Ilustradores**: Calder Fong

**Tradutores da versão em língua portuguesa (Brasil)**: [Carolina Musso](https://www.linkedin.com/in/carolina-musso-29b627128/), [César Augusto Galvão](https://www.linkedin.com/mwlite/in/cesaraspgalvao) , [Halian Vilela](https://www.linkedin.com/in/halian/), [Laís Relvas](https://www.linkedin.com/in/laís-relvas-35429a5b/), [Felipe Cardoso](https://br.linkedin.com/in/felipe-daniel-cardoso-b7015ba1), [Rafaela Tadei](https://www.linkedin.com/in/rafaela-tadei-1aaa9b142/), [Pauliana Galvão](https://www.linkedin.com/in/pauliana-galvão-2462ab48/), [Nathalia Zini](https://www.linkedin.com/in/nathalia-zini-b12a58196/), [Paula Maçaira](https://www.linkedin.com/in/paulamacaira/), [João Pedro Angelici](https://www.linkedin.com/in/joão-pedro-angelici-4b2701193/), [Ademar Barbosa Dantas Junior](https://www.linkedin.com/in/ademar-dantas-junior/), [Eucilene Santana](https://www.linkedin.com/in/eucilene-santana-92856234/), [Hudson Gabriel Virtuoso Fontenele](https://www.linkedin.com/in/hudson-fontenele-04b148180/), [Lucca Nielsen](https://www.linkedin.com/in/lucca-nielsen-53b2a9181/)

Os tradutores agradecem [ProEpi](https://proepi.org.br) pelo apoio para tradução e contato com a Applied Epi.

<!-- **Editor-in-Chief:** Neale Batra  -->

<!-- **Project core team:** Neale Batra, Alex Spina, Amrish Baidjoe, Pat Keating, Henry Laurenson-Schafer, Finlay Campbell   -->

<!-- **Authors**: Neale Batra, Alex Spina, Paula Blomquist, Finlay Campbell, Henry Laurenson-Schafer, [Isaac Florence](www.Twitter.com/isaacatflorence), Natalie Fischer, Aminata Ndiaye, Liza Coyer, Jonathan Polonsky, Yurie Izawa, Chris Bailey, Daniel Molling, Isha Berry, Emma Buajitti, Mathilde Mousset, Sara Hollis, Wen Lin   -->

<!-- **Reviewers**: Pat Keating, Mathilde Mousset, Annick Lenglet, Margot Charette, Isha Berry, Paula Blomquist, Natalie Fischer, Daniely Xavier, Esther Kukielka, Michelle Sloan, Aybüke Koyuncu, Rachel Burke, Daniel Molling, Kate Kelsey, Berhe Etsay, John Rossow, Mackenzie Zendt, James Wright, Wayne Enanoria, Laura Haskins, Flavio Finger, Tim Taylor, Jae Hyoung Tim Lee, Brianna Bradley, Manual Albela Miranda, Molly Mantus, Priscilla Spencer, Pattama Ulrich, Joseph Timothy, Adam Vaughan, Olivia Varsaneux, Lionel Monteiro, Joao Muianga   -->

### Financiamento e apoio {.unnumbered}

O manual recebeu financiamento de apoio através de uma subvenção de emergência COVID-19 da [TEPHINET](https://www.tephinet.org/), a rede global de Programas de Treinamento em Epidemiologia de Campo (FETPs).

O apoio administrativo foi fornecido pela EPIET Alumni Network ([EAN](https://epietalumni.net/)), com agradecimentos especiais à Annika Wendland. O EPIET é o Programa Europeu de Treinamento em Epidemiologia de Intervenção.

Agradecimentos especiais aos Médicos Sem Fronteiras (MSF) Centro Operacional Amsterdã (OCA) por seu apoio durante o desenvolvimento deste manual.

*Esta publicação foi apoiada pelo Acordo Cooperativo número NU2GGH001873, financiado pelos Centros de Controle e Prevenção de Doenças através do TEPHINET, um programa da Força Tarefa para a Saúde Global. Seu conteúdo é de responsabilidade exclusiva dos autores e não representa necessariamente a visão oficial dos Centros de Controle e Prevenção de Doenças, do Departamento de Saúde e Serviços Humanos, The Task Force for Global Health, Inc. ou TEPHINET.*

### Inspiração {.unnumbered}

A infinidade de tutoriais e vinhetas que forneceram conhecimento para o desenvolvimento do conteúdo do manual são creditados dentro de suas respectivas páginas.

De modo mais geral, as seguintes fontes forneceram inspiração para este manual:

[The "R4Epis" project](https://r4epis.netlify.app/) (colaboração entre MSF e RECON)\
[R Epidemics Consortium (RECON)](https://www.repidemicsconsortium.org/)\
[R for Data Science book (R4DS)](https://r4ds.had.co.nz/)\
[bookdown: Authoring Books and Technical Documents with R Markdown](https://bookdown.org/yihui/bookdown/)\
[Netlify](https://www.netlify.com) hosts this website

<!-- ### Image credits {-}   -->

<!-- Images in logo from US CDC Public Health Image Library) include [2013 Yemen looking for mosquito breeding sites](https://phil.cdc.gov/Details.aspx?pid=19623), [Ebola virus](https://phil.cdc.gov/Details.aspx?pid=23186), and [Survey in Rajasthan](https://phil.cdc.gov/Details.aspx?pid=19838).   -->

## Termos de Uso e Contribuição {.unnumbered}

### Licença {.unnumbered}

<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" alt="Creative Commons License" style="border-width:0"/></a><br />Esta obra está licenciada sob uma <a rel="license" href= "http://creativecommons.org/licenses/by-nc-sa/4.0/">Licença Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International</a>.

Cursos acadêmicos e programas de treinamento de epidemiologistas são bem-vindos para usar este manual com seus alunos. Se você tiver dúvidas sobre o uso pretendido, envie um e-mail para [**contact\@appliedepi.org**](mailto:contact@appliedepi.org){.email}.

### Citação {.unnumbered}

Batra, Neale, et ai. O Manual do Epidemiologista R. 2021. <a rel="license" href="https://zenodo.org/badge/231610102.svg"><img src="https://zenodo.org/badge/231610102.svg" alt="DOI" style="border-width:0"/></a><br />

### Contribuição {.unnumbered}

Se você quiser fazer uma contribuição de conteúdo, entre em contato conosco primeiro por meio de questões do Github ou por e-mail. Estamos implementando um cronograma de atualizações e criando um guia do contribuidor.

Observe que o projeto epiRhandbook é lançado com um [Código de Conduta do Contribuidor](https://contributor-covenant.org/version/2/0/CODE_OF_CONDUCT.html). Ao contribuir para este projeto, você concorda em respeitar seus termos.
```{r include=FALSE, cache=FALSE}

# clear workspace
rm(list = ls(all = TRUE))

# clear all packages except base
#lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))

# to ensure that tidyverse packages prevail
filter <- dplyr::filter
select <- dplyr::select
summarise <- dplyr::summarise
summary <- base::summary
incidence <- incidence2::incidence

#load core packages
pacman::p_load(
     rio,
     here,
     DT,
     stringr,
     lubridate,
     tidyverse
)

# import the cleaned ebola linelist
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

# import the count data - facility level
#count_data <- rio::import(here::here("data", "facility_count_data.rds"))

# Settings

options(scipen=1, digits=7)

# print only text (not code)
# library(knitr)
# opts_chunk$set(list(echo = FALSE, eval = FALSE))
```

<!--chapter:end:index.Rmd-->

# (PART) Sobre este livro {.unnumbered}
```{r include=FALSE, cache=FALSE}

# clear workspace
rm(list = ls(all = TRUE))

# clear all packages except base
#lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))

# to ensure that tidyverse packages prevail
filter <- dplyr::filter
select <- dplyr::select
summarise <- dplyr::summarise
summary <- base::summary
incidence <- incidence2::incidence

#load core packages
pacman::p_load(
     rio,
     here,
     DT,
     stringr,
     lubridate,
     tidyverse
)

# import the cleaned ebola linelist
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

# import the count data - facility level
#count_data <- rio::import(here::here("data", "facility_count_data.rds"))

# Settings

options(scipen=1, digits=7)

# print only text (not code)
# library(knitr)
# opts_chunk$set(list(echo = FALSE, eval = FALSE))
```

<!--chapter:end:new_pages/cat_about_book.Rmd-->

# Notas editoriais e técnicas {#editorial-style}

Nesta página descrevemos a abordagem filosófica, o estilo e as decisões editoriais específicas tomadas durante a criação deste manual.  


## Abordagem e estilo

O público em potencial para este livro é grande. Ele será certamente utilizado por pessoas muito novas no R, e também por usuários experientes do R que procuram as melhores práticas e dicas. Portanto, deve ser ao mesmo tempo acessível e sucinto. Portanto, a nossa abordagem foi fornecer o *suficiente* no texto para que alguém muito novo no R possa aplicar o código e seguir o que o código está fazendo.  


Alguns outros pontos:  

* Este é um livro de referência de códigos, acompanhado de exemplos relativamente breves - *não* um livro de texto completo sobre R ou sobre ciência de dados  
* Este é um *manual  de R* para utilização no âmbito da epidemiologia aplicada - não um manual sobre os métodos ou a ciência da epidemiologia aplicada  
* Este destina-se a ser um documento "vivo" - os pacotes R que são ideais para uma determinada tarefa tendem a mudar frequentemente, e estamos abertos a discussão sobre qual pacote deveríamos enfatizar neste manual


### Pacotes do R {.unnumbered}

**São tantas escolhas**

Um dos aspectos mais desafiadores da aprendizagem de R é saber qual o pacote R utilizar para uma dada tarefa. É uma ocorrência comum esforçar-se demais em uma tarefa e só mais tarde perceber - ei, há um pacote R que faz tudo isso numa única linha de código!  

Neste manual, tentamos oferecer-lhe pelo menos duas formas de completar cada tarefa: um método experimentado e validado (provavelmente em R **base** ou **tidyverse**) e um pacote especial R que tenha sido construído para esse fim. Queremos que tenham algumas opções caso não consigam fazer o *download* de um determinado pacote ou que este não funcione.  

Ao escolher os pacotes a utilizar, nós demos prioridade aos pacotes R e às abordagens que foram testados e aprovados pela comunidade. Também minimizamos o número de pacotes utilizados numa sessão de trabalho típica, e escolhemos aqueles que são estáveis (não mudam com muita frequência), e que cumprem a tarefa de forma simples e limpa  


Este manual dá, de modo geral,  prioridade aos pacotes e funções R do **tidyverse**.  Tidyverse é uma colecção de pacotes de R concebidos para a ciência de dados que partilham gramática e estruturas de dados em comum. Todos os pacotes do tidyverse podem ser instalados ou carregados através do pacote **tidyverse**. Leia mais em [tidyverse website](https://www.tidyverse.org/).  

Quando aplicável, também oferecemos opções de código usando o R **base** - os pacotes e funções que já vêm com R na sua instalação. Isto porque reconhecemos que parte do público deste livro podem não ter Internet estável para realizar o *download* de pacotes extra.  

**Explicitando os pacotes de origem de cada função**

Geralmente é frustrante quando, nos tutoriais de R, uma função é mostrada em código, mas não se sabe de que pacote ela é! Tentamos evitar esta situação.  

No texto narrativo, os nomes dos pacotes são escritos a negrito (por exemplo **dplyr**) e as funções são escritas desta forma: `mutate()`. Esforçamo-nos por ser explícitos sobre de que pacote vem uma função, seja referenciando o pacote em texto próximo ou especificando o pacote explicitamente no código: `dplyr::mutate()`. Pode parecer redundante, mas estamos fazendo isso de propósito.

Veja a página em [Introdução ao R](#basics) para saber mais sobre pacotes e funções.   


### Estilo do código {.unnumbered}

No manual, nós utilizamos frequentemente "novas linhas", fazendo o nosso código parecer "longo". Fazemos isso por algumas razões:  

* Dessa forma podemos escrever comentários explicativos com `#', colocando-os posicionados de forma adjacente a cada pequena parte do código  
* Geralmente, o código mais longo (vertical) é mais fácil de ler  
* É mais fácil de ler em uma tela estreita (não é necessária rolagem lateral)  
* A partir das indentações, pode ser mais fácil saber que argumentos pertencem a que função  

Como resultado, código que *poderia* ser escrito desta forma:  

```{r, eval=F}
linelist %>% 
  group_by(hospital) %>%  # agrupe as linhas por hospital
  slice_max(date, n = 1, with_ties = F) # se houver um empate (de data), pegue a primeira linha
```

...é escrito assim:  

```{r, eval=F}
linelist %>% 
  group_by(hospital) %>% # agrupe as linhas por hospital
  slice_max(
    date,                # mantenha a linha que contem o valor máximo de data para cada grupo k
    n = 1,               # mantenha unicamente a linha com o valor mais alto
    with_ties = F)       # se houver um empate (de data), pegue a primeira linha
```

O código R não é geralmente afetado por novas linhas ou indentações. Ao escrever o código, se você iniciar uma nova linha após uma vírgula, ele aplicará padrões de recuo automáticamente. 

Também utilizamos muitos espaços (por exemplo `n = 1` em vez de `n=1`) porque é mais fácil de ler. Seja gentil com as pessoas que lêem o seu código!  



### Nomenclatura {.unnumbered}  

Neste manual, referimos geralmente "colunas" e "linhas" em vez de "variáveis" e "observações". Como explicado neste manual em ["tidy data"](https://tidyr.tidyverse.org/articles/tidy-data.html), a maioria dos conjuntos de dados estatísticos epidemiológicos consistem estruturalmente em linhas, colunas e valores.  

*As variáveis* contêm os valores que medem o mesmo atributo subjacente (como grupo etário, resultado, ou data de início). *Observações* contêm todos os valores medidos na mesma unidade (por exemplo, uma pessoa, local, ou amostra de laboratório). Portanto, estes aspectos podem ser mais difíceis de definir de forma tangível.    

Em conjuntos de dados "arrumados" (*tidy*), cada coluna é uma variável, cada linha é uma observação, e cada célula é um valor único. No entanto, alguns conjuntos de dados que encontrarem podem não seguir esse modelo - um conjunto de dados de formato "largo" pode ter uma variável dividida em várias colunas (ver um exemplo na página [Pivoteando Dados ](#pivoting)). Da mesma forma, uma única observação pode estar divididas em várias linhas.  

A maior parte deste manual trata da gestão e transformação de dados, e por isso, se referir às estruturas concretas de dados (linhas e colunas) é mais relevante do que se referir às observações e às variáveis de forma mais abstractas. As exceções ocorrem principalmente em páginas sobre análise de dados, onde se verá mais referências a variáveis e observações.  


### Notas {.unnumbered} 

Aqui estão os tipos de notas que você poderá encontrar neste manual:  

<span style="color: black;">**_NOTA:_** Isso é uma nota</span>  
<span style="color: darkgreen;">**_DICA:_** Isso é uma dica.</span>  
<span style="color: orange;">**_CUIDADO:_** Esta é uma nota de precaução.</span>  
<span style="color: red;">**_PERIGO:_** Isso é uma advertência.</span>  



## Decisões editoriais 

Abaixo, relacionamos decisões editoriais significativas em torno da escolha do pacote e da função. Se discordar ou quiser oferecer uma nova ferramenta para consideração, por favor, junte-se/ inicie uma conversa na nossa [página Github](https://github.com/appliedepi/epirhandbook_eng). 

**Tabela de pacote, função, e outras decisões editoriais***  


Assunto           |     POssibilidades    |   Escolha              |    Breve justificativa   
----------------- | --------------------|------------------------|-----------------------------------------------
Abordagem geral para escrita do código|**tidyverse**, **data.table**, **base**|**tidyverse**, com uma página sobre **data.table**, e menções a alternativas em R **base** para leitores sem internet|A facilidade de leitura proporcionada pelo **tidyverse**, elém da sua universalidade e maior utilização para ensino.
Carregamento de pacotes|`library()`,`install.packages()`, `require()`, **pacman**|**pacman**|Encurta e simplifica o código para a maioria dos casos de instalação/carregamento de vários pacotes
Importar e Exportar|**rio**, muitos outros pacotes|**rio**|Fácil para muitos tipos de arquivo
Agrupamento para estatísticas resumo|**dplyr** `group_by()`, **stats** `aggregate()`|**dplyr** `group_by()`|Compatível com a ênfase em **tidyverse**
Pivotamento (|**tidyr** (funções de pivotamento), **reshape2** (melt/cast), **tidyr** (spread/gather)|**tidyr** (funções de pivotamento)|**reshape2** está em desuso, **tidyr** usa funções de pivotamento desde a versão v1.0.0
Limpar nome das colunas|**linelist**, **janitor**|**janitor**|Consolidação de pacotes enfatizada
Epiweeks |**lubridate**, **aweek**, **tsibble**, **zoo**|**lubridate** de modo geral, os outros em casos específicos| A flexibilidade, consistência e perspectiva de manutenção do pacote **lubridate**  
Rótulos/Legendas do ggplot |`labs()`, `ggtitle()`/`ylab()`/`xlab()` |`labs()` |todos os rótulos em um lugar, simplicidade
Converter para fator |`factor()`, **forcats**|**forcats**|suas várias funções tembém convertem para o formato de fator em um memso comando
Curvas epidêmicas|**incidence**, **ggplot2**, **EpiCurve**|**incidence2** para rapidez, **ggplot2** para detalhamento|fiabilidade
Concatenação|`paste()`, `paste0()`, `str_glue()`, `glue()`|`str_glue()`|Funções com sintaxe mais simples do que as funções *paste*; está contido **stringr**


## Principais revisões


Data           |Principais mudanças        
---------------| ------------------------------------------    
10 Maio 2021   |Lançamento da versão 1.0.0    


## Informação da sessão (R, RStudio, pacotes)  

Abaixo estão as informações sobre as versões dos pacotes R, RStudio, e R utilizados durante esta elaboração deste Manual.  

```{r}
sessioninfo::session_info()
```




```{r include=FALSE, cache=FALSE}

# clear workspace
rm(list = ls(all = TRUE))

# clear all packages except base
#lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))

# to ensure that tidyverse packages prevail
filter <- dplyr::filter
select <- dplyr::select
summarise <- dplyr::summarise
summary <- base::summary
incidence <- incidence2::incidence

#load core packages
pacman::p_load(
     rio,
     here,
     DT,
     stringr,
     lubridate,
     tidyverse
)

# import the cleaned ebola linelist
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

# import the count data - facility level
#count_data <- rio::import(here::here("data", "facility_count_data.rds"))

# Settings

options(scipen=1, digits=7)

# print only text (not code)
# library(knitr)
# opts_chunk$set(list(echo = FALSE, eval = FALSE))
```

<!--chapter:end:new_pages/editorial_style.Rmd-->

# Baixe o livro e os dados {#data-used}


<!-- Nota para si: Se você deseja criar um link de download para o Github, clique com o botão direito do mouse no botão "View Raw" no Github, copie o endereço e use-o no HTML abaixo. -->




## Baixe o livro offline  

Você pode baixar a versão offline deste livro como um arquivo HTML para que você possa ver o arquivo em seu navegador, mesmo se você não tiver mais acesso à Internet. Se você está considerando o uso offline do livro do Epi R, aqui estão algumas coisas a serem consideradas:  

* Quando você abre o arquivo, pode levar um ou dois minutos para as imagens e o índice serem carregados  
* O livro off-line tem um layout ligeiramente diferente - uma página muito longa com Índice à esquerda. Para pesquisar termos específicos, use Ctrl+f (Cmd+f)  
* Consulte a página [Pacotes sugeridos](#packages-suggested) para ajudá-lo a instalar os pacotes R apropriados antes que você perca a conectividade com a Internet  
* Instale nosso pacote R **epirhandbook** que contém todos os dados de exemplo (processo de instalação descrito abaixo)  

**Existem duas maneiras de baixar o livro:**  



### Use o link de download {.unnumbered}  

Para acesso rápido, **clique com o botão direito** [neste link](https://github.com/appliedepi/epirhandbook_eng/raw/master/offline_long/Epi_R_Handbook_offline.html) **e selecione "Salvar link como"**.  

Se estiver em um Mac, use Cmd+clique. Se estiver em um celular, pressione e segure o link e selecione "Salvar link". O livro será baixado para o seu dispositivo. Se uma tela com código HTML bruto for exibida, certifique-se de seguir as instruções acima ou tente a Opção 2.  




### Use nosso pacote R {.unnumbered}  

Oferecemos um pacote R denominado **epirhandbook**. Inclui uma função `download_book ()` que baixa o arquivo do livro de nosso repositório Github para o seu computador.  


Este pacote também contém uma função `get_data()` que baixa todos os dados de exemplo para o seu computador.  

Execute o seguinte código para instalar nosso pacote R **epirhandbook** do [repositório Github *applyepi*](https://github.com/appliedepi/epirhandbook). Este pacote não está no CRAN, então use a função especial `p_install_gh()` para instalá-lo do Github.  


```{r, eval=F}
# instale a última versão do pacote do livro do Epi R
pacman::p_install_gh("appliedepi/epirhandbook")
```

Agora, carregue o pacote para uso em sua sessão R atual:  

```{r, eval=F}
# carregue o pacote para uso
pacman::p_load(epirhandbook)
```

Em seguida, execute a função do pacote `download_book()` (com parênteses vazios) para baixar o livro para o seu computador. Supondo que você esteja no RStudio, uma janela aparecerá permitindo que você selecione um local para salvar.  

```{r, eval=F}
# baixe o livro offline para o seu computador
download_book()
```





## Baixe os dados para acompanhar  

Para acompanhar as páginas do livro, você pode baixar os dados e resultados de exemplo.  

### Use nosso pacote R {.unnumbered}  

A abordagem mais fácil para baixar todos os dados é instalar nosso pacote R **epirhandbook**. Ele contém uma função `get_data()` que salva todos os dados de exemplo em uma pasta de sua escolha em seu computador.  

Para instalar nosso pacote R **epirhandbook**, execute o seguinte código. Este pacote não está no CRAN, então use a função `p_install_gh()` para instalá-lo. A entrada faz referência à nossa organização Github ("*appliedepi*") e o pacote **epirhandbook**.  

```{r, eval=F}
# instale a última versão do pacote do livro do Epi R
pacman::p_install_gh("appliedepi/epirhandbook")
```


Agora, carregue o pacote para uso em sua sessão R atual:  

```{r, eval=F}
# carregue o pacote para uso
pacman::p_load(epirhandbook)
```

A seguir, use a função do pacote `get_data()` para baixar os dados de exemplo para o seu computador. Execute `get_data("all")` para obter *todos* os dados de exemplo ou forneça um nome de arquivo específico e extensão entre aspas para recuperar apenas um arquivo.  

Os dados já foram baixados com o pacote e simplesmente precisam ser transferidos para uma pasta em seu computador. Uma janela pop-up aparecerá, permitindo que você selecione um local para salvar a pasta. Sugerimos que você crie uma nova pasta de "dados", pois há cerca de 30 arquivos (incluindo dados de exemplo e saídas de exemplo).  

```{r, eval=F}
# baixe todos os dados de exemplo em uma pasta em seu computador
get_data("all")

# baixe apenas os dados de exemplo da lista de linha em uma pasta em seu computador
get_data(file = "linelist_cleaned.rds")

```


```{r, eval=F}
# baixe um arquivo específico em uma pasta em seu computador
get_data("linelist_cleaned.rds")
```

Depois de usar `get_data()` para salvar um arquivo em seu computador, você ainda precisará importá-lo para R. Consulte a página [Importar e exportar](#importing) para obter detalhes.  

Se desejar, você pode revisar todos os dados usados neste livro na **[pasta "data"](https://github.com/appliedepi/epirhandbook_eng/tree/master/data)** de nosso repositório Github.  



### Baixe um por um {.unnumbered}  

Esta opção envolve o download dos dados arquivo por arquivo de nosso repositório Github por meio de um link ou de um comando R específico para o arquivo. Alguns tipos de arquivo permitem um botão de download, enquanto outros podem ser baixados por meio de um comando R.  


#### "Linelist" de casos {.unnumbered}

Este é um surto fictício de Ebola, expandido pela equipe do livro a partir do conjunto de dados de prática `ebola_sim` no pacote **outbreaks**.  

* <a href='https://github.com/appliedepi/epirhandbook_eng/raw/master/data/case_linelists/linelist_raw.xlsx' class='download-button'> Clique para baixar a *linelist* "bruta" (.xlsx) </span> </a>. A linelist do caso "bruta" é uma planilha do Excel com dados confusos. Use-o para acompanhar a página [Limpeza de dados e funções principais](#cleaning).  

Se você quiser acompanhar, <a href='https://github.com/appliedepi/epirhandbook_eng/raw/master/data/case_linelists/linelist_cleaned.rds' class='download-button'> clique para baixar o linelist "limpo" (clean) </a> (as .rds file). Use este arquivo para todas as outras páginas deste livro que usam a lista de linha. Um arquivo .rds é um tipo de arquivo específico de R que preserva classes de coluna. Isso garante que você terá apenas uma limpeza mínima para fazer após importar os dados para R.  

*Outros arquivos relacionados:*  

Se você quiser acompanhar, <a href='https://github.com/appliedepi/epirhandbook_eng/raw/master/data/case_linelists/linelist_cleaned.rds' class='download-button'> clique para baixar o linelist "limpo" (clean) </a> (as .rds file).

* Parte da página de limpeza usa um "dicionário de limpeza" (arquivo .csv). Você pode carregá-lo diretamente no R executando os seguintes comandos:   

```{r, eval=F}
pacman::p_load(rio) # instalar / carregar o pacote rio

# importe o arquivo diretamente do Github
cleaning_dict <- import("https://github.com/appliedepi/epirhandbook_eng/raw/master/data/case_linelists/cleaning_dict.csv")
```


#### Dados de contagem de malária {#data_malaria .unnumbered}  

Esses dados são contagens fictícias de casos de malária por faixa etária, serviço e dia. Um arquivo .rds é um tipo de arquivo específico de R que preserva classes de coluna. Isso garante que você terá apenas uma limpeza mínima para fazer após importar os dados para R.  

<a href='https://github.com/appliedepi/epirhandbook_eng/raw/master/data/malaria_facility_count_data.rds' class='download-button'>
	Clique para fazer o download
	<span> os dados de contagem de malária (arquivo .rds) </span>
</a>


#### Dados em escala Likert {.unnumbered}  

Estes são dados fictícios de uma pesquisa no estilo Likert, usados na página [Pirâmides demográficas e escalas Likert](#age-pyramid). Você pode carregar esses dados diretamente no R executando os seguintes comandos:    

```{r, eval=F}
pacman::p_load(rio) # instalar / carregar o pacote rio

# importe o arquivo diretamente do Github
likert_data <- import("https://raw.githubusercontent.com/appliedepi/epirhandbook_eng/master/data/likert_data.csv")
```


#### Painéis com flexdashboard {.unnumbered}  

Abaixo estão os links para o arquivo associado à página em [Painéis (Dashboards) com R Markdown](#flexdashboard):  

* Para baixar o R Markdown para o painel de surto, clique com o botão direito neste [link](https://github.com/appliedepi/epirhandbook_eng/raw/master/data/flexdashboard/outbreak_dashboard.Rmd) (Cmd + clique para Mac) e selecione "Salvar link como".  
* Para baixar o painel HTML, clique com o botão direito neste [link](https://github.com/appliedepi/epirhandbook_eng/raw/master/data/flexdashboard/outbreak_dashboard_test.html) (Cmd + clique para Mac) e selecione "Salvar link como".  

#### Rastreamento de contato {.unnumbered} 

A página [Rastreamento de contato](#contact-tracing) demonstra a análise dos dados de rastreamento de contato, usando dados de exemplo de [Go.Data] (https://github.com/WorldHealthOrganization/godata/tree/master/analytics/r-reporting). Os dados usados na página podem ser baixados como arquivos .rds clicando nos seguintes links:  

<a href='https://github.com/WorldHealthOrganization/godata/blob/master/analytics/r-reporting/data/cases_clean.rds?raw=true' class='download-button'>
	Clique para fazer o download
	<span> os dados de investigação do caso (arquivo .rds) </span>
</a>

<a href='https://github.com/WorldHealthOrganization/godata/blob/master/analytics/r-reporting/data/contacts_clean.rds?raw=true' class='download-button'>
	Clique para fazer o download
	<span> os dados de registro do contato (arquivo .rds) </span>
</a>

<a href='https://github.com/WorldHealthOrganization/godata/blob/master/analytics/r-reporting/data/followups_clean.rds?raw=true' class='download-button'>
	Clique para fazer o download
	<span> os dados de acompanhamento do contato (arquivo .rds) </span>
</a>



<span style = "color: black;"> **_NOTA:_** Dados de rastreamento de contato estruturado de outro software (por exemplo, KoBo, DHIS2 Tracker, CommCare) podem parecer diferentes. Se desejar contribuir com dados de amostra ou conteúdo alternativo para esta página, [entre em contato](# contact_us). </span> 

<span style = "color: darkgreen;"> **_DICA:_** Se você estiver implantando Go.Data e quiser se conectar à API da sua instância, consulte a página Importar e exportar [(seção API)](# import_api) e a [Go.Data Community of Practice](https://community-godata.who.int/). </span>


### Sobre o GIS {.unnumbered}  

Os shapefiles têm muitos arquivos de subcomponentes, cada um com uma extensão de arquivo diferente. Um arquivo terá a extensão ".shp", mas outros podem ter ".dbf", ".prj", etc.  

A página [GIS básico](#gis) fornece links para o site *Humanitarian Data Exchange* onde você pode baixar os shapefiles diretamente como arquivos compactados.  

Por exemplo, os dados dos pontos das unidades de saúde podem ser baixados [aqui](https://data.humdata.org/dataset/hotosm_sierra_leone_health_facilities). Download "hotosm_sierra_leone_health_facilities_points_shp.zip". Depois de salvar em seu computador, "descompacte" a pasta. Você verá vários arquivos com extensões diferentes (por exemplo, ".shp", ".prj", ".shx") - todos eles devem ser salvos na mesma pasta em seu computador. Então, para importar para o R, forneça o caminho do arquivo e o nome do arquivo ".shp" para `st_read()` do pacote **sf** (conforme descrito na página [Introdução ao GIS](#gis)).  

Se você seguir a Opção 1 para baixar todos os dados de exemplo (por meio de nosso pacote R **epirhandbook**), todos os shapefiles serão incluídos.  


Alternativamente, você pode baixar os shapefiles da pasta "data" do R Handbook Github (veja a subpasta "gis"). No entanto, esteja ciente de que você precisará baixar *cada* subarquivo individualmente para o seu computador. No Github, clique em cada arquivo individualmente e baixe-os clicando no botão "Baixar". Abaixo, você pode ver como o arquivo de forma "sle_adm3" consiste em muitos arquivos - cada um dos quais precisaria ser baixado do Github.  

```{r out.height = "50%", fig.align = "center", echo=F}
knitr::include_graphics(here::here("images", "download_shp.png"))
```


#### Árvores filogenéticas {.numeradas}  

Veja a página sobre [Árvores filogenéticas](#phylogenetic-trees). Arquivo Newick da árvore filogenética construída a partir do sequenciamento do genoma completo de 299 amostras de Shigella sonnei e dados de amostra correspondentes (convertidos em um arquivo de texto). As amostras belgas e os dados resultantes são gentilmente fornecidos pelo NRC belga para Salmonella e Shigella no âmbito de um projeto conduzido por um bolsista ECDC EUPHEM, e também serão publicados em um manuscrito. Os dados internacionais estão disponíveis abertamente em bases de dados públicas (NCBI) e foram publicados previamente.  

* Para baixar o arquivo da árvore filogenética "Shigella_tree.txt", clique com o botão direito neste [link](https://github.com/appliedepi/epirhandbook_eng/raw/master/data/phylo/Shigella_tree.txt) (Cmd + clique para Mac) e selecione "Salvar link como".  
* Para baixar o "sample_data_Shigella_tree.csv" com informações adicionais sobre cada amostra, clique com o botão direito neste [link](https://github.com/appliedepi/epirhandbook_eng/raw/master/data/phylo/sample_data_Shigella_tree.csv) (Cmd + clique para Mac) e selecione "Salvar link como".  
* Para ver a nova árvore de subconjunto criada, clique com o botão direito neste [link](https://github.com/appliedepi/epirhandbook_eng/raw/master/data/phylo/Shigella_subtree_2.txt) (Cmd + clique para Mac) e selecione "Salvar link como". O arquivo .txt será baixado para o seu computador.  


Você pode então importar os arquivos .txt com `read.tree()` do pacote **ape**, conforme explicado na página.

```{r, eval=F}
ape::read.tree("Shigella_tree.txt")
```


#### Padronização {.unnumbered}  

Consulte a página sobre [Taxas padronizadas](#standardization). Você pode carregar os dados diretamente de nosso repositório Github na Internet em sua sessão R com os seguintes comandos:  


```{r, eval=F}
# instalar / carregar o pacote rio
pacman::p_load(rio) 

)
# País A
)
# importar dados demográficos para o país A diretamente do Github
A_demo <- import("https://github.com/appliedepi/epirhandbook_eng/raw/master/data/standardization/country_demographics.csv")

# importação de mortes para o país A diretamente do Github
A_deaths <- import("https://github.com/appliedepi/epirhandbook_eng/raw/master/data/standardization/deaths_countryA.csv")

)
# País B
)
# importar dados demográficos para o país B diretamente do Github
B_demo <- import("https://github.com/appliedepi/epirhandbook_eng/raw/master/data/standardization/country_demographics_2.csv")

# importação de mortes para o país B diretamente do Github
B_deaths <- import("https://github.com/appliedepi/epirhandbook_eng/raw/master/data/standardization/deaths_countryB.csv")


)
# População Referência 
)
# importar dados demográficos para o país B diretamente do Github
standard_pop_data <- import("https://github.com/appliedepi/epirhandbook_eng/raw/master/data/standardization/world_standard_population_by_sex.csv")
```



#### Séries temporais e detecção de surto {#data_outbreak .unnumbered}  

Consulte a página em [Séries temporais e detecção de surto](#time-series). Usamos casos de Campylobacter relatados na Alemanha 2002-2011, conforme disponível no pacote **surveillance** R. (*nb.* este conjunto de dados foi adaptado do original, em que 3 meses de dados foram excluídos do final de 2011 para fins de demonstração).

<a href='https://github.com/appliedepi/epirhandbook_eng/raw/master/data/time_series/campylobacter_germany.xlsx' class='download-button'>
	Clique para fazer o download
	<span> Campylobacter na Alemanha (.xlsx) </span>
</a>

Também usamos dados climáticos da Alemanha 2002-2011 (temperatura em graus Celsius e queda de chuva em milímetros). Eles foram baixados do conjunto de dados de reanálise do satélite Copernicus da UE usando o pacote **ecmwfr**. Você precisará baixar tudo isso e importá-los com `stars::read_stars()` conforme explicado na página da série temporal.  

<a href='https://github.com/appliedepi/epirhandbook_eng/raw/master/data/time_series/weather/germany_weather2002.nc' class='download-button'>
	Clique para fazer o download
	<span> Alemanha meteorologia 2002 (arquivo .nc) </span>
</a> 

<a href='https://github.com/appliedepi/epirhandbook_eng/raw/master/data/time_series/weather/germany_weather2003.nc' class='download-button'>
	Clique para fazer o download
	<span> Alemanha meteorologia 2003 (arquivo .nc) </span>
</a> 

<a href='https://github.com/appliedepi/epirhandbook_eng/raw/master/data/time_series/weather/germany_weather2004.nc' class='download-button'>
	Clique para fazer o download
	<span> Alemanha meteorologia 2004 (arquivo .nc) </span>
</a> 

<a href='https://github.com/appliedepi/epirhandbook_eng/raw/master/data/time_series/weather/germany_weather2005.nc' class='download-button'>
	Clique para fazer o download
	<span> Clima Alemanha 2005 (arquivo .nc) </span>
</a> 

<a href='https://github.com/appliedepi/epirhandbook_eng/raw/master/data/time_series/weather/germany_weather2006.nc' class='download-button'>
	Clique para fazer o download
	<span> Clima Alemanha 2006 (arquivo .nc) </span>
</a> 

<a href='https://github.com/appliedepi/epirhandbook_eng/raw/master/data/time_series/weather/germany_weather2007.nc' class='download-button'>
	Clique para fazer o download
	<span> Clima Alemanha 2007 (arquivo .nc) </span>
</a> 

<a href='https://github.com/appliedepi/epirhandbook_eng/raw/master/data/time_series/weather/germany_weather2008.nc' class='download-button'>
	Clique para fazer o download
	<span> Clima Alemanha 2008 (arquivo .nc) </span>
</a> 

<a href='https://github.com/appliedepi/epirhandbook_eng/raw/master/data/time_series/weather/germany_weather2009.nc' class='download-button'>
	Clique para fazer o download
	<span> Clima Alemanha 2009 (arquivo .nc) </span>
</a> 

<a href='https://github.com/appliedepi/epirhandbook_eng/raw/master/data/time_series/weather/germany_weather2010.nc' class='download-button'>
	Clique para fazer o download
	<span> Clima Alemanha 2010 (arquivo .nc) </span>
</a> 

<a href='https://github.com/appliedepi/epirhandbook_eng/raw/master/data/time_series/weather/germany_weather2011.nc' class='download-button'>
	Clique para fazer o download
	<span> Clima Alemanha 2011 (arquivo .nc) </span>
</a>



#### Análise da pesquisa {#data_survey .unnumbered}  

Para a página [análise da pesquisa](https://epirhandbook.com/survey-analysis.html), usamos dados fictícios de pesquisa de mortalidade baseados em modelos de pesquisa OCA do MSF. Esses dados fictícios foram gerados como parte do [projeto "R4Epis"](https://r4epis.netlify.app/).

<a href='https://github.com/appliedepi/epirhandbook_eng/raw/master/data/surveys/survey_data.xlsx' class='download-button'>
	Clique para fazer o download
	<span> Dados de pesquisa fictícios (.xlsx) </span>
</a>

<a href='https://github.com/appliedepi/epirhandbook_eng/raw/master/data/surveys/survey_dict.xlsx' class='download-button'>
	Clique para fazer o download
	<span> Dicionário fictício de dados de pesquisa (.xlsx) </span>
</a>

<a href='https://github.com/appliedepi/epirhandbook_eng/raw/master/data/surveys/population.xlsx' class='download-button'>
	Clique para fazer o download
	<span> Dados fictícios da população de pesquisas (.xlsx) </span>
</a>




#### Shiny {#data_shiny .unnumbered}  

A página em [Painéis com Shiny](#shiny-basics) demonstra a construção de um aplicativo simples para exibir dados da malária.  

Para baixar os arquivos R que produzem o aplicativo Shiny:  

Você pode <a href='https://github.com/appliedepi/epirhandbook_eng/raw/master/data/malaria_app/app.R' class='download-button'>
	clique aqui para baixar o arquivo app.R <span> que contém a IU e o código do servidor para o aplicativo Shiny. </span> </a>

Você pode <a href='https://github.com/appliedepi/epirhandbook_eng/blob/master/data/malaria_app/data/facility_count_data.rds' class='download-button'>
	clique aqui para baixar o arquivo facility_count_data.rds <span> </a> que contém dados de malária para o aplicativo Shiny. Observe que pode ser necessário armazená-lo em uma pasta "data" para que os caminhos de arquivo here() funcionem corretamente.  

Você pode <a href='https://github.com/appliedepi/epirhandbook_eng/blob/master/data/malaria_app/global.R' class='download-button'>
	clique aqui para baixar o arquivo global.R <span> </a> que deve ser executado antes da abertura do aplicativo, conforme explicado na página.
	
Você pode <a href='https://github.com/appliedepi/epirhandbook_eng/raw/master/data/malaria_app/funcs/plot_epicurve.R' class='download-button'>
	clique aqui para baixar o arquivo plot_epicurve.R <span> </a> que é fornecido pela global.R. Observe que pode ser necessário armazená-lo em uma pasta "funcs" para que os caminhos de arquivo here() funcionem corretamente.

```{r include=FALSE, cache=FALSE}

# clear workspace
rm(list = ls(all = TRUE))

# clear all packages except base
#lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))

# to ensure that tidyverse packages prevail
filter <- dplyr::filter
select <- dplyr::select
summarise <- dplyr::summarise
summary <- base::summary
incidence <- incidence2::incidence

#load core packages
pacman::p_load(
     rio,
     here,
     DT,
     stringr,
     lubridate,
     tidyverse
)

# import the cleaned ebola linelist
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

# import the count data - facility level
#count_data <- rio::import(here::here("data", "facility_count_data.rds"))

# Settings

options(scipen=1, digits=7)

# print only text (not code)
# library(knitr)
# opts_chunk$set(list(echo = FALSE, eval = FALSE))
```

<!--chapter:end:new_pages/data_used.Rmd-->

# (PART) Básico {.unnumbered}
```{r include=FALSE, cache=FALSE}

# clear workspace
rm(list = ls(all = TRUE))

# clear all packages except base
#lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))

# to ensure that tidyverse packages prevail
filter <- dplyr::filter
select <- dplyr::select
summarise <- dplyr::summarise
summary <- base::summary
incidence <- incidence2::incidence

#load core packages
pacman::p_load(
     rio,
     here,
     DT,
     stringr,
     lubridate,
     tidyverse
)

# import the cleaned ebola linelist
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

# import the count data - facility level
#count_data <- rio::import(here::here("data", "facility_count_data.rds"))

# Settings

options(scipen=1, digits=7)

# print only text (not code)
# library(knitr)
# opts_chunk$set(list(echo = FALSE, eval = FALSE))
```

<!--chapter:end:new_pages/cat_basics.Rmd-->

# Introdução ao R {#basics}

```{r out.width = "100%", fig.align = "center", echo=F}
knitr::include_graphics(here::here("images", "basics_header_close.png"))
```

Bem-vindo!

Esta página analisa o essencial de R. Ela não pretende ser um tutorial abrangente, mas fornece o básico e pode ser útil para refrescar a sua memória. A secção [Recurso para a aprendizagem](#learning) tem links para a tutoriais mais abrangentes.

Partes desta página foram adaptadas com a permissão do [projecto R4Epis](https://r4epis.netlify.app/).

Ver a página em [Transição para R](#transition-to-R) para dicas sobre como mudar para R de STATA, SAS, ou Excel.


```{r, echo=F}
# import the cleaned ebola linelist
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))
pacman::p_load(apyramid)
```

<!-- ======================================================= -->

## Porque usar o R?

Segundo a definição do site [*R project*](https://www.r-project.org/about.html), R é uma linguagem de programação e também um ambiente para computação estatística e gráfica. É altamente versátil, extensível, e orientado para a comunidade.

**Custo**

R é de utilização livre! Há uma política forte na comunidade para que o material seja gratuito e de código aberto.

**Reprodutibilidade**

A prática de conduzir a análise e a gestão dos dados por meio de uma linguagem de programação (em comparação com o Excel ou outra dessas ferramentas que requerem cliques manuais) melhora a **reprodutibilidade**, torna a **detecção de erros** mais fácil e alivia sua carga de trabalho.

**Comunidade**

A comunidade de usuários de R é enorme e colaborativa. Novos pacotes e ferramentas para resolver problemas da vida real são desenvolvidos diariamente e recebe críticas e contribuições da comunidade de utilizadores. Como um exemplo, [R-Ladies](https://rladies.org/) é uma organização mundial cuja missão é promover a diversidade de gênero na comunidade R, e é uma das maiores organizações de utilizadores de R. É provável que tenha uma divisão perto de você!

## Termos chave

**RStudio** - RStudio é uma Interface Gráfica de Utilizador (GUI) para uma utilização mais fácil da linguagem  **R**. Leia mais [na secção RStudio](#rstudio).

**Objetos** - Tudo o que se armazena em R - conjuntos de dados, variáveis, uma lista de nomes de cidades, um número total da população, mesmo saídas como gráficos - são *objetos* aos quais é *atribuído um nome* e *podem ser referenciados* em comandos posteriores. Ler mais [na secção Objectos](#objects).

**Funções** - Uma função é uma operação de código que aceita entradas e devolve uma saída transformada. Leia mais [na secção Funções](#functions).

**Pacotes** - Um pacote R é um pacote partilhável de funções. Leia mais [na secção Pacotes](#packages)

**Scripts/Códigos** - Um script é um arquivo que contém as linhas de comando que escreveu. Leia mais [na secção Scripts](#scripts)

## Recursos para a aprendizagem {#learning}

### Recursos dentro do RStudio {.unnumbered}

**Documentação de ajuda**

Pesquisar na aba "Ajuda" do RStudio pela documentação sobre pacotes do R e funções específicas. Isto está dentro do painel que também contém "Arquivos", "Gráficos" e "Pacotes" (tipicamente no painel inferior direito). Como atalho, também se pode digitar o nome de um pacote ou função no console do R após um ponto de interrogação para abrir a página de Ajuda relevante. Não inclui parênteses.

Por exemplo: `?filter` ou `?diagrammeR`.

**Tutoriais interativos**

Há várias maneiras de aprender R interactivamente *dentro* do RStudio.

O próprio RStudio oferece um painel Tutorial que é alimentado pelo pacote do R [**learnr**](https://blog.rstudio.com/2020/02/25/rstudio-1-3-integrated-tutorials/). Basta instalar este pacote e abrir um tutorial através da nova aba "Tutorial" no painel superior direito do RStudio, que também contém os separadores Environment (Ambiente) e History (Histórico).

O pacote do R [**swirl**](https://swirlstats.com/) oferece cursos interativos no Console do R. Instale e carregue este pacote, depois execute o comando `swirl()` (parênteses vazios) no Console do R. Você verá avisos aparecerem no Console. Responda digitando no Console. Ele irá guiá-lo através de um curso à sua escolha.

### Página de dicas {.unnumbered}

Há várias "cheatsheets" ("colinhas") em pdf disponíveis no [website do RStudio](https://rstudio.com/resources/cheatsheets/), por exemplo:

-   Fatores com o pacote **forcats**
-   Datas e horas com o pacote **lubridate**
-   Caracteres com o pacote **stringr**
-   Operações iterativas com o pacote **purrr**
-   Importação de dados
-   Folha de dica para transformação de dadas com o pacote **dplyr**
-   R Markdown (para criar documentos como PDF, Word, Powerpoint...)
-   Shiny (para construir aplicativos de web interativos)
-   Visualização de dados com o pacote **ggplot2**
-   Cartografia (GIS)
-   Pacote **leaflet** (mapas interativos)
-   Python com R (pacote **reticulate**)

Este é um recurso online do R especificamente para [usuários do Excel](https://jules32.github.io/r-for-excel-users/)

### Twitter {.unnumbered}

R tem uma vibrante comunidade no twitter onde você pode aprender dicas, atalhos e notícias, siga estas contas:

-   Siga nos! [\@epiRhandbook](https://twitter.com/epirhandbook)
-   R Function A Day (Uma função por dia) [\@rfuntionaday](https://twitter.com/rfunctionaday) é um recurso *incrível*
-   R for Data Science (R para Ciência de Dados) [\@rstats4ds](https://twitter.com/rstats4ds?lang=en)
-   RStudio [\@RStudio](https://twitter.com/rstudio?lang=en)
-   Dicas do RStudio[\@rstudiotips](https://twitter.com/rstudiotips)
-   R-Bloggers [\@Rbloggers](https://twitter.com/Rbloggers)
-   R-ladies [\@RLadiesGlobal](https://twitter.com/RLadiesGlobal)
-   Hadley Wickham [\@hadleywickham](https://twitter.com/hadleywickham?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Eauthor)

Também:

**\#epitwitter** e **\#rstats**

### Recursos online gratuitos {.unnumbered}

Um texto definitivo é o livro [R for Data Science](https://r4ds.had.co.nz/) de Garrett Grolemund e Hadley Wickham

O site do projeto [R4Epis](https://r4epis.netlify.app/) tem como objetivo “desenvolver ferramentas padronizadas de limpeza, análise e relatório de dados para cobrir tipos comuns de surtos e pesquisas populacionais que seriam conduzidas em um ambiente de resposta a emergências de MSF”. Você pode encontrar materiais de treinamento básicos do R, modelos para relatórios do RMarkdown sobre surtos e pesquisas e tutoriais para ajudá-lo a configurá-los.

### Idiomas além do inglês {.unnumbered}

[Materiais do RStudio em Espanhol](https://www.rstudio.com/collections/espanol/)

[Introdução ao R e ao tidyverse (Francês)](https://juba.github.io/tidyverse/index.html)

[Ciência de Dados em R (Português)](https://livro.curso-r.com/index.html)

<!-- ======================================================= -->

## Instalação

### R e R Studio {.unnumbered}

**Como instalar o R**

Visite o site <https://www.r-project.org/> e faça o *download* da versão mais recente do R que seja adequada para o seu computador.

**Como instalar o RStudio**

Visite esse website <https://rstudio.com/products/rstudio/download/> e faça o *download* da versão gratuita mais recente para Desktop do RStudio que seja adequada para seu computador.

**Permissões**

Note que você deve instalar R e RStudio em um drive onde você tenha permissões de leitura e escrita. Caso contrário, sua capacidade de instalar pacotes R (um problema de ocorrência freqüente) será impactada. Se você encontrar problemas, tente abrir o RStudio clicando com o botão direito do mouse no ícone e selecionando "Executar como administrador". Outras dicas podem ser encontradas na página [R em unidades de rede](#network-drives).


**Como atualizar o R e o RStudio**

Sua versão de R é exibida ("printada") no o Console R na inicialização. Você também pode executar o `sessionInfo()`.

Para atualizar o R, vá para o site mencionado acima e reinstale o R. Alternativamente, você pode utilizar o pacote **installr** (no Windows) executando `installr::updateR()`. Isto abrirá caixas de diálogo para ajudá-lo a baixar a última versão R e atualizar seus pacotes para a nova versão R. Mais detalhes podem ser encontrados na **installr** [documentação](https://www.r-project.org/nosvn/pandoc/installr.html).

Esteja ciente de que a antiga versão R ainda existirá em seu computador. Você pode executar temporariamente uma versão antiga (antiga "instalação") do R clicando em "Tools" (Ferramentas) -> "Global Options" (Opções Globais)  no RStudio e escolhendo uma versão R. Isto pode ser útil se você quiser usar um pacote que não tenha sido atualizado para funcionar na versão mais nova do R.

Para atualizar o RStudio, você pode ir ao site acima e fazer o download novamente do RStudio. Outra opção é clicar em "Help" (Ajuda) -\> "Check for Updates" (Verificar Atualizações) dentro do RStudio, mas isto pode não mostrar as últimas atualizações.

Para ver quais versões do R, RStudio, ou pacotes foram usados quando este Manual foi feito, veja a página em [Notas editoriais e técnicas](#editorial-style).


### Outros softwares você *pode* precisar instalar {.unnumbered}

-   TinyTeX (*para compilaar documentos de RMarkdown em PDF*)
-   Pandoc (*para compilar documentos de RMarkdown*)
-   RTools (*para construir pacotes em R*)
-   phantomjs (*para salvar imagens ou redes animadas, como redes de transmissão*)

#### TinyTex {.unnumbered}

TinyTex é uma distribuição do LaTeX customizada, útil quando for tentar produzir PDFs no R.
Veja <https://yihui.org/tinytex/> para mais informações.

Para instalar o TinyTex no R:

```{r, eval=F}
install.packages('tinytex')
tinytex::install_tinytex()
# para desisntalar o TinyTeX, corra tinytex::uninstall_tinytex()
```

#### Pandoc {.unnumbered}

Sua versão de R é impressa no o Console R na inicialização. Você também pode executar o Pandoc é um conversor de documentos, um software separado do R. **Ele vem junto com o RStudio , provavelmente não precisará ser baixado.** Ele ajuda no processo de conversão de documentos Rmarkdown para formatos como .pdf e adição de funcionalidades complexas.

#### RTools {.unnumbered}

RTools é uma coleção de softwares para construção de pacotes para R.

Instale desse website: <https://cran.r-project.org/bin/windows/Rtools/>

#### phantomjs {.unnumbered}

Esta ferramenta é freqüentemente usada para tirar "fotografias da tela" de páginas da web. Por exemplo, quando você cria uma cadeia de transmissão com o pacote **epicontacts**,  um arquivo HTML é produzido e ele é interativo e dinâmico. Se você quiser uma imagem estática, pode ser útil usar o pacote [**webshot**](https://wch.github.io/webshot/articles/intro.html) para automatizar este processo. Isto exigirá o programa externo "phantomjs". Você pode instalar o phantomjs através do pacote **webshot** com o comando `webshot::install_phantomjs()`.

<!-- ======================================================= -->

## RStudio {#rstudio}

### Se orientando no RStudio  {.unnumbered}

**Primeiramente, abra o RStudio.** Como os ícones deles podem ser muito parecidos, certifique-se de que você está abrindo mesmo o *RStudio* e não R.

Para que o RStudio funcione, você também deve ter R instalado no computador (veja acima as instruções de instalação).

**RStudio** é uma interface (GUI) para facilitar o uso de **R**. Você pode pensar em R como sendo o motor de um veículo, fazendo o trabalho crucial, e RStudio como a carroceria do veículo (com assentos, acessórios, etc.) que ajuda você realmente a usar o motor para seguir em frente! Você pode ver a ficha completa da interface de usuário do RStudio (PDF) [aqui](https://www.rstudio.com/wp-content/uploads/2016/01/rstudio-IDE-cheatsheet.pdf)

Por padrão, o RStudio exibe quatro painéis retangulares.

```{r out.width = "100%", fig.align = "center", echo=F}
knitr::include_graphics(here::here("images", "RStudio_overview.png"))
```

[***DICA:*** Se o seu RStudio mostrar apenas um painel esquerdo, é porque não há nenhum script aberto ainda]{style="color: black;"}

**O Painel Fonte (Source)**
Este painel, por padrão localizado na parte superior esquerda, é um espaço onde é possível editar, executar e salvar seus [scripts](#scripts). Os scripts contêm os comandos que você deseja executar. Este painel também pode exibir conjuntos de dados (quadros de dados) para visualização.

Para usuários da Stata, este painel é similar às janelas de seu Do-file e Data Editor.

**O Painel do Console R**

O Console R, ou simplesmente Console, é por padrão o painel esquerdo ou inferior esquerdo do RStudio. Ele é a casa do "motor" de R. É aqui que os comandos são realmente executados e as saídas não gráficas e as mensagens de erro/aviso aparecem. Você pode digitar e executar comandos diretamente no Console, mas perceba que estes comandos não são salvos como são ao executar comandos de um script.

Se você está familiarizado com Stata, o Console R é como a Janela de Comando e também a Janela de Resultados.

**O Painel Ambiente (Environment)**

Este painel, por padrão na parte superior direita, é mais freqüentemente usado para ver resumos breves de [objetos](#objetos) no Ambiente R na sessão atual. Estes objetos podem incluir conjuntos de dados importados, modificados ou criados, parâmetros que você definiu (por exemplo, uma semana epidemiológica específica para a análise), ou vetores ou listas que você definiu durante a análise (por exemplo, nomes de regiões). Você pode clicar na seta ao lado de um nome de data frame para ver suas variáveis.

No Stata, isto é mais parecido com a janela Gerenciador de Variáveis.

Este painel também contém a aba *History* onde você pode ver comandos que você pode ver anteriormente. Tem também uma aba "Tutorial" onde você pode completar tutoriais R interativos se você tiver o pacote **learnr** instalado. Tem também um painel "Conections" para conexões externas, e pode ter um painel "Git" se você optar por fazer interface com o Github.

**Paineis: Gráficos (Plots), Visualizador (Viewer), Pacotes (Packages), Ajuda (Help)**

O painel inferior-direito inclui várias abas importantes. Gráficos típicos, incluindo mapas, serão exibidos no painel Plo. Saídas interativas ou HTML serão exibidas no painel do Visualizador (Viewer). O painel de Ajuda (Help) pode exibir documentação e arquivos de ajuda. O painel Arquivos (Files) é um navegador que pode ser usado para abrir ou excluir arquivos. O painel Pacotes (Packages) permite ver, instalar, atualizar, excluir, carregar/descarregar pacotes R, e ver qual versão do pacote você tem. Para saber mais sobre pacotes, veja a [seção pacotes](#packages) abaixo.

Este painel contém os equivalentes Stata das janelas Plots Manager e Project Manager.

### Configurações do RStudio  {.unnumbered}

Altere as configurações e a aparência do RStudio no menu suspenso *Ferramentas* (Tools), selecionando *Opções Globais* (Global Options). Lá você pode alterar as configurações padrão, incluindo a cor da aparência/fundo.

```{r out.width = c('50%'), fig.show='hold', echo=F}
knitr::include_graphics(here::here("images", "RStudio_tools_options_1.png"))

knitr::include_graphics(here::here("images", "RStudio_tools_options.png"))
```

**Restart (Reiniciar)**

Se seu R travar, você pode reiniciar o R indo ao menu Sessão (Session) e clicando em "Reiniciar R" (Restart R). Isto evita o incômodo de fechar e abrir o RStudio. Tudo em seu ambiente R será removido quando você fizer isso.

### Atalhos no teclado {.unnumbered}

Alguns atalhos de teclado muito úteis estão abaixo. Veja todos os atalhos de teclado para Windows, Mac e Linux na segunda página deste RStudio [cheatsheet da interface do usuário](https://www.rstudio.com/wp-content/uploads/2016/01/rstudio-IDE-cheatsheet.pdf).

+----------------------------------+------------------------+--------------------------------------------------------------------------------------------------------------+
| Windows/Linux                    | Mac                    | Ação                                                                                                         |
+==================================+========================+==============================================================================================================+
| Esc                              | Esc                    | Interrompe comando atual <br/>                                                                               |
|                                  |                        | (útil se você acidentalmente executou um comando incompleto e não pode escapar de ver o "+" no console R)    |
+----------------------------------+------------------------+--------------------------------------------------------------------------------------------------------------+
| Ctrl+s                           | Cmd+s                  | Salva (script)                                                                                               |
+----------------------------------+------------------------+--------------------------------------------------------------------------------------------------------------+
| Tab                              | Tab                    | Auto-completa                                                                                                |
+----------------------------------+------------------------+--------------------------------------------------------------------------------------------------------------+
| Ctrl + Enter                     | Cmd + Enter            | Roda a(s) linha(s) atual(is)/seleção de código                                                               |
+----------------------------------+------------------------+--------------------------------------------------------------------------------------------------------------+
| Ctrl + Shift + C                 | Cmd + Shift + c        | comenta/descomenta as linhas selecionadas                                                                    |
+----------------------------------+------------------------+--------------------------------------------------------------------------------------------------------------+
| Alt + -                          | Option + -             | Insere `<-`                                                                                                  |
+----------------------------------+------------------------+--------------------------------------------------------------------------------------------------------------+
| Ctrl + Shift + m                 | Cmd + Shift + m        | Insere `%>%`                                                                                                 |
+----------------------------------+------------------------+--------------------------------------------------------------------------------------------------------------+
| Ctrl + l                         | Cmd + l                | Limpa o console                                                                                              |
+----------------------------------+------------------------+--------------------------------------------------------------------------------------------------------------+
| Ctrl + Alt + b                   | Cmd + Option + b       | Roda do início até a linha atual                                                                             |
+----------------------------------+------------------------+--------------------------------------------------------------------------------------------------------------+
| Ctrl + Alt + t                   | Cmd + Option + t       | Roda a seção de código atual (R Markdown)                                                                    |
+----------------------------------+------------------------+--------------------------------------------------------------------------------------------------------------+
| Ctrl + Alt + i                   | Cmd + Shift + r        | Insere chunk de código (no R Markdown)                                                                       |
+----------------------------------+------------------------+--------------------------------------------------------------------------------------------------------------+
| Ctrl + Alt + c                   | Cmd + Option + c       | Roda o chunk atual (R Markdown)                                                                              |
+----------------------------------+------------------------+--------------------------------------------------------------------------------------------------------------+
| up/down arrows in R console      | Same                   | Alterna entre os comandos executados recentemente                                                            |
+----------------------------------+------------------------+--------------------------------------------------------------------------------------------------------------+
| Shift + up/down arrows in script | Same                   | Seleciona múltiplas linhas de código                                                                         |
+----------------------------------+------------------------+--------------------------------------------------------------------------------------------------------------+
| Ctrl + f                         | Cmd + f                | Procura e substitui no script atual                                                                          |
+----------------------------------+------------------------+--------------------------------------------------------------------------------------------------------------+
| Ctrl + Shift + f                 | Cmd + Shift + f        | Encontra em arquivos (pesquisa/substitui em vários script)                                                   |
+----------------------------------+------------------------+--------------------------------------------------------------------------------------------------------------+
| Alt + l                          | Cmd + Option + l       | Oculta código atual                                                                                          |
+----------------------------------+------------------------+--------------------------------------------------------------------------------------------------------------+
| Shift + Alt + l                  | Cmd + Shift + Option+l | Exibe código sele                                                                                            |
+----------------------------------+------------------------+--------------------------------------------------------------------------------------------------------------+

[***DICA:*** Use sua tecla Tab ao digitar para ativar a funcionalidade de auto-completar do RStudio. Isto pode evitar erros ortográficos. Pressione Tab enquanto digita para produzir um menu suspenso de funções e objetos prováveis, com base no que você digitou até agora. ]{style="color: darkgreen;"}

<!-- ======================================================= -->

## Funções {#functions}

As funções estão no cerne do uso de R. As funções são a forma como você executa tarefas e operações. Muitas funções vêm instaladas com R, muitas mais estão disponíveis para download em *packages* (explicado na seção [pacotes](#packages)), e você pode até mesmo escrever suas próprias funções personalizadas!

Esta seção básica sobre funções explica:

-   O que é uma função e como funcionam
-   O que são os *argumentos/parâmetros* de uma função
-   Como conseguir ajuda para compreender uma função

*Uma nota rápida sobre a sintaxe:* Neste manual, as funções são escritas em texto de código com parênteses abertos, como este: `filter()`. Como explicado na seção [pacotes](#packages), as funções são baixadas dentro de *pacotes*. Neste manual, os nomes dos pacotes são escritos em **negrito**, como **dplyr**. Às vezes, no código de exemplo, você pode ver o nome da função ligado explicitamente ao nome de seu pacote com um par de dois-pontos (`::`) como este: `dplyr::filter()`. O propósito desta ligação é explicado na seção de pacotes.

<!-- ======================================================= -->

### Funções simples {.unnumbered}

**Uma função é como uma máquina que recebe entradas, faz alguma ação com essas entradas e produz uma saída.** O que é a saída depende da função.

**Funções normalmente operam sobre algum objeto colocado dentro dos parênteses da função**. Por exemplo, a função `sqrt()` calcula a raiz quadrada de um número:

```{r basics_function_sqrt}
sqrt(49)
```

O objeto fornecido a uma função também pode ser uma coluna em um conjunto de dados (veja a seção [Objetos](#objetos) para detalhes sobre todos os tipos de objetos). Como R pode armazenar vários conjuntos de dados, será necessário especificar tanto o conjunto de dados quanto a coluna. Uma maneira de fazer isso é utilizar a notação `$` para ligar o nome do conjunto de dados e o nome da coluna (`dataset$coluna`). No exemplo abaixo, a função `summary()` é aplicada à coluna numérica `age` (idade) no conjunto de dados `linelist`, e a saída é um resumo dos valores numéricos e valores ausentes da coluna.

```{r basics_functions_summary}
#Imprimir estatísticas resumidas da coluna 'age' (idade) no conjunto de dados 'linelist'.
summary(linelist$age)
```

[***NOTA:*** Nos bastidores, uma função representa um código adicional complexo que foi condensado para o usuário em um comando fácil.]{style="color: black;"}

<!-- ======================================================= -->

### Funções com argumentos múltiplos {.unnumbered}

As funções frequentemente pedem várias entradas, chamadas ***argumentos***, ou **parâmetros**, localizadas dentro dos parênteses da função, geralmente separadas por vírgulas.

- Alguns argumentos são necessários para que a função funcione corretamente, outros são opcionais
- Argumentos opcionais têm configurações padrão
- Os argumentos podem ter caráter, numérico, lógico (TRUE/FALSE)(*verdadeiro/falso*), e outros inputs

Aqui está uma função ficcional divertida, chamada `oven_bake()` ( do inglês: assar no forno), como um exemplo de uma função típica. Ela pega um objeto de entrada (por exemplo, um conjunto de dados, ou neste exemplo "dough" - massa) e realiza operações sobre ele como especificado por argumentos adicionais (`minutes =` e `temperature =`). A saída pode ser impressa para o console, ou salva como um objeto utilizando o operador de atribuição `<-`.

```{r basics_functions_image, echo=F, out.width = "75%", fig.align = "center"}
knitr::include_graphics(here::here("images", "Function_Bread_Example.png"))
```

**Em um exemplo mais realístico**, o comando `age_pyramid()` abaixo produz uma pirâmide etária baseado em faixas-etárias e uma coluna divisória binária, como `gender` (gênero). A função recebe três argumentos dentro dos parênteses, separados por vírgulas. Os valores fornecidos aos argumentos estabelecem `linelist` como o quadro de dados a utilizar, `age_cat5` como a coluna a contar, e `gender` como a coluna binária a utilizar para dividir a pirâmide por cor.

```{r basics_functions_arguments, include=FALSE, results='hide', message=FALSE, warning=FALSE,}
## crie uma variável de faixa-etária especificando classes categóricas 
linelist$age_group <- cut(linelist$age, breaks = c(0, 5, 10, 15, 20, 30, 45, 60))
```

```{r message=FALSE, warning=FALSE,  out.width = "75%", out.height="75%"}
# Crie uma pirâmide etária
age_pyramid(data = linelist, age_group = "age_cat5", split_by = "gender")
```

O comando acima pode ser escrito de forma equivalente ao abaixo, em um estilo mais longo com uma nova linha para cada argumento. Este estilo pode ser mais fácil de ler, e mais fácil de escrever "comentários" com `#` para explicar cada parte (comentar extensivamente é uma boa prática!). Para executar este comando mais longo, você pode destacar todo o comando e clicar em "Run", ou simplesmente colocar o cursor na primeira linha e, em seguida, pressionar simultaneamente as teclas Ctrl e Enter.

```{r message=FALSE, warning=FALSE,  out.width = "75%", out.height="75%"}
# Crie uma pirâmide etária
age_pyramid(
  data = linelist,        # Use a linelist de casos
  age_group = "age_cat5", # disponibilize a coluna de faixa-etária
  split_by = "gender"     #usee a coluna de gênero para criar dois lados da pirâmide 
  )
```

A primeira metade de uma atribuição de argumentos (por exemplo, `dados =`) não precisa ser especificada se os argumentos forem escritos em uma ordem específica (especificada na documentação da função). O código abaixo produz exatamente a mesma pirâmide que o acima, porque a função espera a ordem dos argumentos: quadro de dados, variável `age_group`, variável `split_by`.

```{r, basics_functions_pyramid2, eval = FALSE, warning=FALSE, message=FALSE, , out.width = "75%", out.height="75%", eval=F}
# Esse comando retorna o mesmo gráfico gerado acima
age_pyramid(linelist, "age_cat5", "gender")
```

**Um comando mais complexo de `age_pyramid()` poderia incluir os argumentos *opcionais* para:**

- Mostrar proporções em vez de contagens (definir `proportional = TRUE` quando o padrão é `FALSE`)
- Especifique as duas cores a serem utilizadas (`pal =` é a abreviação de "paleta" e é fornecido com um vetor de dois nomes de cores. Veja a página [objetos](#objetos) para saber como a função `c()` faz um vetor)

[***NOTA:*** Para argumentos que você especificar com ambas as partes do argumento (por exemplo, `proportional = TRUE`), sua ordem entre todos os argumentos não importa.]{style="color: black;"}

```{r message=FALSE, warning=FALSE, out.width = "75%", out.height="75%"}
age_pyramid(
  linelist,                    # use a linelist de casos
  "age_cat5",                  # coluna de faixa-etária
  "gender",                    # divida por gênero
  proportional = TRUE,         # porcentagem em vez de contagens
  pal = c("orange", "purple")  # cores
  )
```

<!-- ======================================================= -->

### Escrevendo funções {.unnumbered}

R é uma linguagem que é orientada em torno de funções, portanto você deve se sentir capacitado para escrever suas próprias funções. A criação de funções traz várias vantagens:

- Para facilitar a programação modular - a separação do código em peças independentes e gerenciáveis
- Substituir o processo repetitivo de copia e cola, que pode ser propenso a erros.
- Dar nomes memoráveis aos pedaços de código

Como escrever uma função é abordado em profundidade na página [Escrevendo funções](#writing-functions).

<!-- A function is given a name and defined with the assignment operator `<-` to a special **base** R function called `function()`. Within the parentheses, the arguments that the function will accept are defined. This is followed by curly brackets `{ }`, within which the actual code of the function is written.     -->

```{r, eval=F, echo=F}
my_function <- function( ARGUMENTS HERE ){ CODE HERE }
```

<!-- The arguments should be provided in the syntax `argument = default`, separated by commas.   -->

<!-- Here is an example where we create a function `staff_calc()` to serve as a staffing calculator for COVID-19 case investigation and contact tracing calls.   -->

<!-- The arguments (inputs) and their default values will be:   -->

<!-- * `daily_cases = NULL` The number of new COVID-19 cases per day   -->

<!-- * `contacts_each = 5` The number contacts enumerated for each case   -->

<!-- * `time_case = 0.5`  Number of hours to complete a case investigaton by phone   -->

<!-- * `time_contact = 0.25`  Number of hours to complete a contact follow-up by phone   -->

<!-- * `time_day = 8` The number of hours one staff works per day   -->

<!-- Below, the function is created. The code ends with the special function `return()`, which is what the function produces.    -->

<!-- ```{r message=FALSE, warning=FALSE, out.width = "75%", out.height="75%"} -->

<!-- staff_calc <- function(daily_cases = NULL, contacts_each = 5, -->

<!--                        time_case = 0.5, time_contact = 0.25, time_day = 8){ -->

<!--   # Define total daily hours for calling cases -->

<!--   case_hours <- daily_cases * time_case  -->

<!--   # Define total daily hours for calling contacts -->

<!--   contact_hours <- daily_cases * contacts_each * time_contact -->

<!--   # Calculate number of staff required -->

<!--   staff_required <- (case_hours + contact_hours)/time_day -->

<!--   return(staff_required) -->

<!-- } -->

<!-- ``` -->

<!-- Once this code is run, the function will be defined and will appear in the R Environment. We can run the function. Below all the default values are used and the `daily_cases = ` is set to 150.   -->

```{r eval=F, echo=F, message=FALSE, warning=FALSE, out.width = "75%", out.height="75%"}
staff_calc(daily_cases = 150)
```

```{r, eval=F, echo=F}
case_incidence <- tibble(
  dates = seq.Date(from = as.Date("2020-05-01"), to = as.Date("2020-05-21"), by = 1),
  projected_incidence = c(102,110,50,37,106,190,146,138,135,111,60,43,189,184,185,80,44,97,254,291,288),
  staff_needed = staff_calc(projected_incidence)
)

ggplot(case_incidence, aes(x = dates))+
  geom_line(aes(y = projected_incidence))+
  geom_line(aes(y = staff_needed))
```

<!-- There are many other nuances to understand when writing functions, as discussed in the page [Writing functions].   -->

<!-- ======================================================= -->

<!-- ======================================================= -->

## Pacotes {#packages}

**Pacotes contém funções.**

Um pacote R é um pacote compartilhável de código e documentação que contém funções pré-definidas. Os usuários da comunidade R desenvolvem pacotes o tempo todo, atendendo a problemas específicos, e é provável que alguém possa ajudar com seu trabalho inclusive! Você com certeza irá instalar e usar centenas de pacotes em seu uso de R.

Na instalação, o R contém pacotes de  **"base"**  e funções que executam tarefas elementares e comuns. Mas muitos usuários do R criam funções especializadas, que são verificadas pela comunidade R e que você pode baixar como um  **package** (pacote) para seu próprio uso. Neste manual, os nomes dos pacotes estão escritos em **negrito**. Um dos aspectos mais desafiadores do R é que muitas vezes há muitas funções ou pacotes a serem escolhidos para complementar uma determinada tarefa.


### Instalar e carregar {.unnumbered}

*As funções* estão contidas nos **pacotes** que podem ser baixados ("instalados") para seu computador a partir da Internet. Uma vez que um pacote é baixado, ele é armazenado em sua "biblioteca" (do inglês, *library*). Você pode então acessar as funções que ele contém durante sua sessão R atual "carregando" este pacote.

*Pense em R como sua biblioteca pessoal*: Quando você baixa um pacote, sua biblioteca ganha um novo livro de funções, mas cada vez que você quiser usar uma função naquele livro, você deve pegar emprestado ("carregar") aquele livro de sua biblioteca.

Em resumo: para usar as funções disponíveis em um pacote R, duas etapas devem ser implementadas:

1)  O pacote precisa ser **instalado** (uma vez), *e*  

2)  O pacote precisa ser **carregado** (a cada sessão de R que abrir)

#### Sua biblioteca {.unnumbered}

Sua "biblioteca" é na verdade uma pasta em seu computador, contendo uma subpasta para cada pacote que foi instalado. Descubra onde R está instalado em seu computador, e procure uma pasta chamada "win-library". Por exemplo: `R\win-library\4.0` (a 4.0 é a versão R - você terá uma biblioteca diferente para cada versão R que você baixou).

Você pode exibir ("printar") o caminho do arquivo para sua biblioteca digitando `.libPaths()` (parênteses vazios). Isto se torna especialmente importante se você trabalhar com [R em unidades de rede](#network-drives).


#### Instalar do CRAN {.unnumbered}

Na maioria das vezes, os usuários R baixam pacotes da CRAN. CRAN (Comprehensive R Archive Network) é um repositório público on-line de pacotes R que foram publicados por membros da comunidade R.

Você está preocupado com vírus e segurança ao fazer o download de um pacote da CRAN? Leia [este artigo](https://support.rstudio.com/hc/en-us/articles/360042593974-R-and-R-Package-Security) sobre o assunto.


#### Como instalar e carregar {.unnumbered}

Neste manual, sugerimos o uso do pacote **pacman** (abreviação para "package manager" que significa "gerenciador de pacotes" em inglês). Ele oferece uma função conveniente `p_load()` que instalará um pacote se necessário *e* o carregará para utilização na sessão R atual.

A sintaxe é bastante simples. Basta listar os nomes dos pacotes dentro dos parênteses `p_load()`, separados por vírgulas. Este comando instalará os pacotes **rio**, **tidyverse**, e **here** se ainda não estiverem instalados, e os carregará para utilização. Isto torna a abordagem `p_load()` conveniente e concisa se compartilhar scripts com outros. Observe que os nomes dos pacotes são sensíveis a maiúsculas e minúsculas.


```{r}
# Instala (se necessário) e os carrega para o uso
pacman::p_load(rio, tidyverse, here)
```

Note que utilizamos a sintaxe `pacman::p_load()` que escreve explicitamente o nome do pacote (**pacman**) antes do nome da função (`p_load()`), conectado por duas colunas `::`. Esta sintaxe é útil porque também carrega o pacote **pacman** (assumindo que já esteja instalado).

Existem funções alternativas do R **base** que você verá com freqüência. A função do R **base**  para instalar um pacote é `install.packages()`. O nome do pacote a ser instalado deve ser fornecido entre parênteses *em aspas*. Se você quiser instalar vários pacotes em um comando, eles devem ser listados dentro de um vetor de caracteres `c()`.

Nota: este comando *instala* um pacote, mas *não* o carrega para utilização na sessão atual.

```{r, eval=F}
# essa função disponível no R base instala um único pacote 
install.packages("tidyverse")

# install multiple packages with base R
install.packages(c("tidyverse", "rio", "here"))
```

A instalação também pode ser feita clicando e apontando para o painel "Pacotes" do RStudio e clicando em "Instalar" e procurando pelo nome do pacote desejado.

A função do R **base** para **carregar** um pacote para utilização (após ter sido instalado) é `library()`. Ela pode carregar apenas um pacote de cada vez (outro motivo para utilizar `p_load()`). Você pode fornecer o nome do pacote com ou sem aspas.

```{r, eval=F}
# com o R base, você pode carregar os pacotes dessa forma 
library(tidyverse)
library(rio)
library(here)
```

Para verificar se um pacote está instalado e/ou carregado, você pode visualizar o painel de Pacotes no RStudio. Se o pacote estiver instalado, ele é mostrado lá com o número da versão. Se sua caixa for marcada, ela é carregada para a sessão atual.

**Instalar a partir do Github**.

Às vezes, você precisa instalar um pacote que ainda não está disponível na CRAN. Ou talvez o pacote esteja disponível na CRAN, mas você quer a versão *em desenvolvimento* com novos recursos ainda não oferecidos na versão publicada mais estável da CRAN. Estes são frequentemente hospedados no site [github.com](https://github.com/) em um "repositório" de código gratuito e voltado para o público. Leia mais sobre Github na página do manual [Controle de versão e colaboração com Git e Github](#collaboration).

Para baixar os pacotes R do Github, você pode utilizar a função `p_load_gh()` do **pacman**, que instalará o pacote se necessário, e o carregará para utilização em sua sessão R atual. As alternativas para instalar incluem a utilização dos pacotes **remotes** ou **devtools**. Leia mais sobre todas as funções **pacman** na [documentação do pacote](https://cran.r-project.org/web/packages/pacman/pacman.pdf).

Para instalar a partir do Github, você precisa fornecer mais informações. Você tem que fornecer:

1) A identificação do proprietário do repositório Github  

2) O nome do repositório que contém o pacote  

3)  *(opcional) O nome do "ramo" (o "branch" da versão de desenvolvimento específico) que você deseja baixar*  

Nos exemplos abaixo, a primeira palavra entre aspas representa a ID do Github do proprietário do repositório, após a barra é o nome do repositório (o nome do pacote).  

```{r, eval=F}
# instala/carrega o pacote epicontacts do seu repositório Github 
p_load_gh("reconhub/epicontacts")
```

Se você quiser instalar de um "branch" (versão) diferente da principal, adicione o nome do "branch" após um "\@", após o nome do repositório.

```{r, eval=F}
# instale o "branch"(ramo) "timeline" do pacte epicontacts do Github
p_load_gh("reconhub/epicontacts@timeline")
```

Se não houver diferença entre a versão do Github e a versão em seu computador, nenhuma ação será tomada. Você pode "forçar" uma reinstalação utilizando `p_load_current_gh()` com o argumento `update = TRUE`. Leia mais sobre **pacman** nesta [vinheta online](http://trinker.github.io/pacman/vignettes/Introduction_to_pacman.html)

**Instale a partir de ZIP ou TAR**

Você poderia instalar um pacote de um endereço URL:

```{r, eval=F}
packageurl <- "https://cran.r-project.org/src/contrib/Archive/dsr/dsr_0.2.2.tar.gz"
install.packages(packageurl, repos=NULL, type="source")
```

Ou, faça o download dele para seu computador em um arquivo comprimido ("zipado"):

Opção 1: usando`install_local()` do pacote **remotes** 

```{r, eval=F}
remotes::install_local("~/Downloads/dplyr-master.zip")
```

Opção 2: usando `install.packages()` do R **base**, fornecendo o caminho do arquivo comprimido e configurando os parâmetros `type = "source` e `repos = NULL`.

```{r, eval=F}
install.packages("~/Downloads/dplyr-master.zip", repos=NULL, type="source")
```

### Sintaxe do código {.unnumbered}

For clarity in this handbook, functions are sometimes preceded by the name of their package using the `::` symbol in the following way: `package_name::function_name()`

Once a package is loaded for a session, this explicit style is not necessary. One can just use `function_name()`. However writing the package name is useful when a function name is common and may exist in multiple packages (e.g. `plot()`). Writing the package name will also load the package if it is not already loaded.

```{r eval=FALSE}
# Este comando usa o pacote "rio" e sua função   "import()" para importar uma base de dados.
linelist <- rio::import("linelist.xlsx", which = "Sheet1")
```

### Auxílio para as funções {.unnumbered}

Para maior clareza neste manual, as funções são algumas vezes precedidas pelo nome de seu pacote utilizando o símbolo `::` da seguinte forma: `nome_do_pacote::nome_da_função()`

Uma vez carregado um pacote para uma sessão, este estilo explícito não é mais necessário. Pode-se simplesmente utilizar `nome_da_função()`. Entretanto, escrever o nome do pacote é útil quando um nome de função é muito comum e pode existir em vários pacotes (por exemplo, `plot()`). Escrever o nome do pacote também irá carregar o pacote se ele ainda não estiver carregado.

### Atualizando pacotes {.unnumbered}

Você pode atualizar os pacotes, reinstalando-os. Você também pode clicar no botão verde "Atualizar" em seu painel de Pacotes RStudio para ver quais pacotes têm novas versões para instalar. Esteja ciente de que seu código antigo pode precisar ser atualizado se houver uma grande revisão de como uma função funciona!

### Apagar pacotes {.unnumbered}

Utilize `p_delete()` de **pacman**, ou `remove.packages()` do R **base**. Alternativamente, procure a pasta que contém sua biblioteca e exclua manualmente a pasta.

### Dependências {.unnumbered}

Os pacotes muitas vezes dependem de outros pacotes para funcionar. Estes são chamados de dependências. Se uma dependência falhar na instalação, então o pacote dependendo dela também pode falhar na instalação.

Veja as dependências de um pacote com `p_depends()`, e veja quais pacotes dependem dele com `p_depends_reverse()`.

### Funções mascaradas {.unnumbered}

Não é raro que dois ou mais pacotes contenham o mesmo nome de função. Por exemplo, o pacote **dplyr** tem uma função `filter()`, mas o pacote **stats** também. A função padrão `filter()` depende da ordem em que estes pacotes são carregados primeiro na sessão R - a última será o padrão para o comando `filter()`.

Você pode verificar a ordem em seu painel Environment (Ambiente) do R Studio - clique no menu suspenso para Global Environment ("Ambiente Global") e veja a ordem dos pacotes. Funções de pacotes *mais abaixo* nessa lista suspensa mascararão funções com o mesmo nome em pacotes que aparecem mais altos na lista suspensa. Ao carregar um pacote pela primeira vez, R avisará no console se estiver ocorrendo mascaramento, mas isto pode ser fácil de perder.  

```{r out.width = "50%", fig.align = "center", echo=F}
knitr::include_graphics(here::here("images", "masking_functions.png"))
```

1) Especifique o nome do pacote no comando. Por exemplo, utilize `dplyr::filter()` 
2) Reorganize a ordem na qual os pacotes são carregados (por exemplo, dentro de `p_load()`), e *inicie uma nova sessão R*.

### Desprender / descarregar {.unnumbered}

Para separar (descarregar) um pacote, use este comando, com o nome correto do pacote e apenas um "dois pontos". Note que isto pode não resolver o mascaramento.


```{r, eval=F}
detach(package:PACKAGE_NAME_HERE, unload=TRUE)
```

### Instalar uma versão mais antiga {.unnumbered}

Veja este [guia](https://support.rstudio.com/hc/en-us/articles/219949047-Installing-older-versions-of-packages) para instalar uma versão mais antiga de um pacote em particular.

### Pacotes sugeridos{.unnumbered}

Veja a página em [Pacotes sugeridos](#packages-suggested) para uma listagem de pacotes que recomendamos para o dia-a-dia em epidemiologia.

<!-- ======================================================= -->

## Scripts {#scripts}

Os scripts (que significa "roteiro" em inglês) são uma parte fundamental da programação. Eles são documentos que contêm seus comandos (por exemplo, funções para criar e modificar conjuntos de dados, visualizações de impressão, etc.). Você pode salvar um script e executá-lo novamente mais tarde. Há muitas vantagens em armazenar e executar seus comandos a partir de um script (versus digitar comandos um a um na "linha de comando" do console R):

- Portabilidade - você pode compartilhar seu trabalho com outros enviando-lhes seus scripts\
- Reprodutibilidade - para que você e outros saibam exatamente o que você fez
- Controle de versão - para que você possa acompanhar as mudanças feitas por você ou colegas\
- Comentando/anotando - para explicar a seus colegas o que você tem feito

### Comentando {.unnumbered}

Em um script você também pode anotar ("fazer comentários") ao longo do seu código R. Comentar é útil para explicar a si mesmo e aos outros leitores o que você está fazendo. Você pode adicionar um comentário digitando o símbolo "hashtag" (\#) e escrevendo seu comentário depois dele. O texto comentado aparecerá em uma cor diferente da do código R.

Qualquer código escrito após o \# não será executado. Portanto, colocar um \# antes do código também é uma maneira útil de bloquear temporariamente uma linha de código ("comentar fora") se você não quiser apagá-lo). Você pode fazer isso em várias linhas ao mesmo tempo, selecionando-as e pressionando Ctrl+Shift+c (Cmd+Shift+c no Mac).

```{r, eval = F}
# Um comentário pode ser uma linha por si só
# importar dados
linelist <- import("linelist_raw.xlsx") %>%   # também pode ser após o código
# filter(age > 50)                          # também pode ser usado para desativar uma linha de código
  count()

```

- Comente sobre *o que* você está fazendo e sobre **por que** você está fazendo.
- Divida seu código em seções lógicas...
- Acompanhe seu código com uma descrição passo a passo em texto do que você está fazendo (por exemplo, passos numerados)

### Estilo {.unnumbered}

É importante estar consciente de seu estilo de codificação - especialmente se estiver trabalhando em equipe. Defendemos o uso do **tidyverse** [guia de estilo](https://style.tidyverse.org/). Há também pacotes como **styler** e **lintr** que o ajudam a se adequar a este estilo.

Alguns pontos muito básicos para tornar seu código legível para outros:

\* Ao nomear objetos, utilize apenas letras minúsculas, números e sublinhados `_`, por exemplo `my_data`.
\* Utilize espaços frequentes, inclusive ao redor dos operadores, por exemplo `n = 1` e `age_new <- age_old + 3`

### Exemplo de Script {.unnumbered}

Abaixo está um exemplo de um pequeno script R. Lembre-se, quanto melhor você explicar sucintamente seu código nos comentários, mais seus colegas vão gostar de você!

```{r out.width = "100%", fig.align = "center", echo=F}
knitr::include_graphics(here::here("images", "example_script.png"))
```

<!-- ======================================================= -->

### R markdown {.unnumbered}

Um script R markdown é um tipo de script R no qual o script em si *resulta* um documento de saída (PDF, Word, HTML, Powerpoint, etc.). Estas são ferramentas incrivelmente úteis e versáteis, freqüentemente usadas para criar relatórios dinâmicos e automatizados. Mesmo este website e manual são produzidos com um script  R markdown!

Vale a pena notar que usuários iniciantes de R também podem usar R Markdown - não se intimidem! Para saber mais, consulte a página do manual nos documentos [Relatórios com R Markdown](#reportfactory).

<!-- ======================================================= -->

### Notebooks R {.unnumbered}

Não há diferença entre escrever em um Rmarkdown versus um caderno R. Entretanto, a execução do documento difere ligeiramente. Consulte este [site](http://uc-r.github.io/r_notebook) para obter mais detalhes.

<!-- ======================================================= -->

### Shiny

Os aplicativos/websites shiny estão contidas em um script, que deve ser chamado de `app.R`. Este arquivo tem três componentes:

1) Uma interface de usuário (ui)  \
2) Uma função de servidor  \
3) Uma chamada para a função `shinyApp`.  

Veja a página do manual em [Dashboards com Shiny](#shiny-basics), ou este tutorial online: [Tutorial com shiny](https://shiny.rstudio.com/tutorial/written-tutorial/lesson1/)

*Nos tempos mais antigos, o arquivo acima era dividido em dois arquivos (`ui.R`  e `server.R`)*

### Código dobrável {.unnumbered}

Você pode colapsar/dobrar (do inglês *folding*) porções de código para facilitar a leitura de seu roteiro.

Para isso, crie um cabeçalho de texto com \#, escreva seu cabeçalho, e siga-o com pelo menos 4 traços (-), hashes (\#) ou igual a (=). Quando você tiver feito isto, uma pequena seta aparecerá na "sarjeta" à esquerda (pelo número da linha). Você pode clicar nesta seta e o código abaixo até o próximo cabeçalho cair e um ícone de seta dupla aparecerá em seu lugar.

Para expandir o código, clique novamente na seta na sarjeta, ou no ícone de duas fileiras. Há também atalhos de teclado como explicado na seção [RStudio](#rstudio) desta página.

Ao criar cabeçalhos com \#, você também ativará o Índice na parte inferior de seu script (veja abaixo) que você pode usar para navegar em seu script. Você pode criar subtítulos adicionando mais \# símbolos, por exemplo, \#  para primário, \# \# para secundário e \#\#\# para terciário.

Abaixo estão duas versões de um script de exemplo. À esquerda está o original com os cabeçalhos comentados. À direita, quatro traços foram escritos após cada cabeçalho, tornando-os colapsáveis. Dois deles foram colapsados, e você pode ver que a Tabela de Conteúdos na parte inferior agora mostra cada seção.

```{r, out.width = c('50%'), fig.show='hold', echo=F}
knitr::include_graphics(here::here("images", "code_folding1.png"))
knitr::include_graphics(here::here("images", "code_folding2.png"))
```

Outras áreas de código que são automaticamente elegíveis para fazer esse "dobramento" incluem as regiões entre chaves `{ }` tais como definições de funções ou blocos condicionais ( declarações "if else"). Pode ler mais sobre dobramento de código no RStudio [site](https://support.rstudio.com/hc/en-us/articles/200484568-Code-Folding-and-Sections).

<!-- ======================================================= -->

<!-- ======================================================= -->

<!-- ======================================================= -->

## Diretório de trabalho

O diretório de trabalho é o local da pasta raiz usada por R para seu trabalho - onde R procura e salva arquivos por padrão. Por padrão, ele salvará novos arquivos e saídas para este local, e procurará por arquivos para importar (por exemplo, conjuntos de dados) também aqui.

O diretório de trabalho aparece em texto cinza na parte superior do painel do RStudio Console. Você também pode imprimir o diretório de trabalho atual executando `getwd()` (deixe os parênteses vazios).


```{r out.width = "100%", fig.align = "center", echo=F}
knitr::include_graphics(here::here("images", "working_directory_1.png"))
```

### Abordagem recomendada {.unnumbered}

**Veja a página sobre [ projetos R](#r-projects) para obter detalhes sobre nossa abordagem recomendada para gerenciar seu diretório de trabalho.**
Uma maneira comum, eficiente e sem problemas para gerenciar seu diretório de trabalho e caminhos de arquivos é combinar estes 3 elementos em um fluxo de trabalho orientado segundo [projeto R](r-projects)

1) Um projeto R para armazenar todos os seus arquivos (ver página em [projetos R](#r-projects))\
2) O pacote **here** para localização de arquivos (ver página em [Importação e exportação](#importing))\
3) O pacote **rio** para arquivos de importação/exportação (ver página em [Importação e exportação](#importing))


<!-- ======================================================= -->

### Definido por comando {.unnumbered}

Até recentemente, muitas pessoas aprendendo R eram ensinadas a começar seus roteiros com um comando `setwd()`. Em vez disso, considere a utilização de um fluxo de trabalho orientados segundo [projeto R](#r-projects) e leia as [razões para não utilizar `setwd()`](https://www.tidyverse.org/blog/2017/12/workflow-vs-script/). Em resumo, seu trabalho torna-se específico para seu computador, os caminhos de arquivos utilizados para importar e exportar arquivos tornam-se " frágeis", e isso dificulta seriamente a colaboração e a utilização de seu código em qualquer outro computador. Existem alternativas fáceis!

Como observado acima, embora não recomendamos esta abordagem na maioria das circunstâncias, você pode utilizar o comando `setwd()` com o caminho do arquivo da pasta desejada escrito entre aspas, como no exemplo abaixo:


```{r, eval=F}
setwd("C:/Documents/R Files/My analysis")
```

[***PERIGO:*** Definir um diretório de trabalho com `setwd()` *pode* ser "frágil" se o caminho do arquivo for específico para um computador. Em vez disso, use caminhos de arquivo relativos a um diretório raiz do R Project (com o pacote **here**).]{style="color: red;"}

<!-- ======================================================= -->

### Definindo manualmente {.unnumbered}

Para definir o diretório de trabalho manualmente (que seria o equivalente de apontar e clicar de `setwd()`), clique no menu suspenso Sessão (*Session*) e vá para "Definir diretório de trabalho" (*Set Workig Directory*) e depois "Escolher diretório" (*Choose Directory*). Isso definirá o diretório de trabalho para essa sessão específica do R. Nota: se estiver usando esta abordagem, você terá que fazer isso manualmente toda vez que abrir o RStudio.

<!-- ======================================================= -->

### Dentro de um projeto R {.unnumbered}

Se estiver usando um projeto R, o diretório de trabalho será padronizado para a pasta raiz do projeto R que contém o arquivo ".rproj". Isso se aplicará se você abrir o RStudio clicando em abrir o Projeto R (o arquivo com extensão ".rproj").

<!-- ======================================================= -->

### Diretório de trabalho em R markdown {.unnumbered}

Em um script R markdown, o diretório de trabalho padrão é a pasta na qual o arquivo Rmarkdown (`.Rmd`) é salvo. Se estiver usando um projeto R e um pacote **here**, isso não se aplica e o diretório de trabalho será `here()` conforme explicado na página [projetos R](#r-projects).

Se você quiser alterar o diretório de trabalho de um  R markdown autônomo (não em um projeto R), se você usar `setwd()`, isso se aplicará apenas a esse trecho de código específico. Para fazer a alteração para todos os trechos de código em um markdown R, edite o trecho de configuração para adicionar o parâmetro `root.dir =`, como abaixo:

```{r, eval=F}
knitr::opts_knit$set(root.dir = 'desired/directorypath')
```

É muito mais fácil usar apenas o markdown do R dentro de um projeto R e usar o pacote **here**.

<!-- ======================================================= -->

### Fornecendo o caminho dos arquivos {.unnumbered}

Talvez a fonte mais comum de frustração para um iniciante em R (pelo menos em uma máquina Windows) seja digitar um caminho de arquivo para importar ou exportar dados. Há uma explicação completa de como melhor inserir caminhos de arquivo na página [Importar e exportar](#importing), mas aqui estão alguns pontos-chave:

**Caminhos quebrados**

Abaixo está um exemplo de um caminho de arquivo "absoluto" ou "endereço completo". Eles provavelmente quebrarão se forem usados por outro computador. Uma exceção é se você estiver usando uma unidade compartilhada/de rede.

    C:/Users/Name/Document/Analytic Software/R/Projects/Analysis2019/data/March2019.csv  

**Direção da barra**

*Se digitar um caminho de arquivo, observe a direção das barras.* Use *barras normais* (`/`) para separar os componentes ("data/provincial.csv"). Para usuários do Windows, a maneira padrão de exibição dos caminhos de arquivo é com *barras invertidas* (ou contra-barra) (\\) - portanto, você precisará alterar a direção de cada barra. Se você usar o pacote **here** conforme descrito na página [projetos R](#r-projects), a direção da barra não será um problema.

**Caminhos relativos**

Geralmente, recomendamos fornecer caminhos de arquivo "relativos" - ou seja, o caminho *relativo* à raiz do seu projeto R. Você pode fazer isso usando o pacote **here** conforme explicado na página [projetos R](#r-projects). Um caminho de arquivo relativo pode ser assim:

```{r, eval=F}
# Import csv linelist from the data/linelist/clean/ sub-folders of an R project
linelist <- import(here("data", "clean", "linelists", "marin_country.csv"))
```

Mesmo usando caminhos de arquivo relativos em um projeto R, você ainda pode usar caminhos absolutos para importar/exportar dados fora do seu projeto R.

<!-- ======================================================= -->

## Objetos{#objects}

Tudo em R é um objeto, e R é uma linguagem "orientada a objetos". Estas seções explicarão:

- Como criar objetos (`<-`)
- Tipos de objetos (por exemplo, quadros de dados, vetores..)\
- Como acessar subpartes de objetos (por exemplo, variáveis em um conjunto de dados)\
- Classes de objetos (por exemplo, numérico, lógico, inteiro, duplo, caractere, fator)

<!-- ======================================================= -->

### Tudo é um objeto {.unnumbered}

*Esta seção é adaptada do [projeto R4Epis](https://r4epis.netlify.app/training/r_basics/objects/).*\
Tudo o que você armazena no R - conjuntos de dados, variáveis, uma lista de nomes de vilarejos, um número total da população, até saídas como gráficos - são **objetos** que recebem um **nome** e **podem ser referenciados** em comandos posteriores.

Um objeto existe quando você atribui um valor a ele (consulte a seção de atribuição abaixo). Quando lhe é atribuído um valor, o objeto aparece no Ambiente (*Environment*) (veja o painel superior direito do RStudio). Ele pode então ser operado, manipulado, alterado e redefinido.

<!-- ======================================================= -->

### Definindo objetos (`<-`) {.unnumbered}

**Crie objetos *atribuindo-lhes um valor* com o operador \<-.**\
Você pode pensar no operador de atribuição `<-` como as palavras "é definido como". Os comandos de atribuição geralmente seguem uma ordem padrão:

**nome_do_objeto** \<- **valor** (ou processo/cálculo que produz um valor)

Por exemplo, você pode querer registrar a semana do relatório epidemiológico atual como um objeto para referência no código posterior. Neste exemplo, o objeto `semana_atual` é criado quando é atribuído o valor `"2018-W10"` (as aspas fazem disso um valor de caractere). O objeto `semana_atual` aparecerá no painel RStudio Environment (canto superior direito) e poderá ser referenciado em comandos posteriores.

Veja os comandos R e sua saída nas caixas abaixo.

```{r basics_objects_assignment}
semana_atual <- "2018-W10"   # esse comando cria o objeto semana_atual ao atribuir a ele um valor 
semana_atual                # esse comento exibe ("printa") o valor atual do objeto semana_atual no Console 
```

[***NOTA:*** Observe que o `[1]` na saída do console R está simplesmente indicando que você está visualizando o primeiro item da saída]{style="color: black;"}

[***CUIDADO:*** **O valor de um objeto pode ser sobrescrito** a qualquer momento executando um comando de atribuição para redefinir seu valor. Assim, a **ordem dos comandos executados é muito importante**..]{style="color: orange;"}

O comando a seguir irá redefinir o valor de `semana_atual`:

```{r basics_objects_reassignment}
semana_atual <- "2018-W51"   # atribui um NOVO valor para o objeto semana_atual 
semana_atual                # Exibe ("printa") o valor atual do objeto semana_atual no console 
```

**Sinal de igual `=`**

Você também verá sinais de igual no código R:

- Um sinal de igual duplo `==` entre dois objetos ou valores faz uma *pergunta* lógica: "isso é igual a isso?".\
- Você também verá sinais de igual dentro de funções usadas para especificar valores de argumentos de função (leia sobre isso nas seções abaixo), por exemplo `max(age, na.rm = TRUE)`.\
- Você *pode* usar um único sinal de igual `=` no lugar de `<-` para criar e definir objetos, mas isso é desencorajado. Você pode ler sobre por que isso é desencorajado [aqui](https://renkun.me/2014/01/28/difference-between-assignment-operators-in-r/).

**Bases de dados**


Os conjuntos de dados também são objetos (geralmente "dataframes") e devem receber nomes quando são importados. No código abaixo, o objeto `linelist` é criado e atribuído o valor de um arquivo CSV importado com o pacote **rio** e sua função `import()`.

```{r basics_objects_dataframes, eval=FALSE}
# o objeto linelist é criado e a ele é atribuído o valor do arquivo CSV importado
linelist <- import("my_linelist.csv")
```

Você pode ler mais sobre como importar e exportar conjuntos de dados na seção [Importar e exportar](#importing.

[***CUIDADO:*** Uma nota rápida sobre a nomeação de objetos:]{style="color: orange;"}

- Os nomes dos objetos não devem conter espaços, mas você deve usar sublinhado (\_) ou um ponto (.) em vez de um espaço.\
- Os nomes dos objetos diferenciam maiúsculas de minúsculas (o que significa que Dataset_A é diferente de dataset_A).
- Os nomes dos objetos devem começar com uma letra (não pode começar com um número como 1, 2 ou 3).

**Saídas (Outputs)**

Saídas como tabelas e gráficos fornecem um exemplo de como as saídas podem ser salvas como objetos ou apenas exibidas ("printadas" no console) sem serem salvas. Uma tabulação cruzada de gênero e resultado usando a função do R **base** `table()` pode ser exibida diretamente no console R (*sem* ser salva).

```{r}
# exibe apenas no console R
table(linelist$gender, linelist$outcome)
```

Mas a mesma tabela pode ser salva como um objeto nomeado. Então, opcionalmente, pode ser printado.

```{r}
# salvar
gen_out_table <- table(linelist$gender, linelist$outcome)

# printar
gen_out_table
```

**Colunas**

As colunas em um conjunto de dados também são objetos e podem ser definidas, sobrescritas e criadas conforme descrito abaixo na seção Colunas.

Você pode usar o operador de atribuição do R **base** para criar uma nova coluna. Abaixo, a nova coluna `bmi` (IMC - Índice de Massa Corporal, do inglês *Body Mass Index*) é criada, e para cada linha o novo valor é resultado de uma operação matemática sobre o valor da linha nas colunas `wt_kg` e `ht_cm`.


```{r, eval=F}
# criar uma nova colna bmi (que é o valor de IMC) usando a sintaxe do R base
linelist$bmi <- linelist$wt_kg / (linelist$ht_cm/100)^2
```

No entanto, neste manual, enfatizamos uma abordagem diferente para definir colunas, que usa a função `mutate()` do pacote **dplyr** e *piping* com o operador pipe (`%>%`). A sintaxe é mais fácil de ler e há outras vantagens explicadas na página em [Limpeza de dados e principais funções](#cleaning). Você pode ler mais sobre *tubulação* na seção Tubulação abaixo.

```{r, eval=F}
# criar uma nova colna bmi (que é o valor de IMC) usando a sintaxe do dplyr
linelist <- linelist %>% 
  mutate(bmi = wt_kg / (ht_cm/100)^2)
```

<!-- ======================================================= -->

### Estrutura de um objeto {.unnumbered}

**Os objetos podem ser um único dado (por exemplo, `meu_numero <- 24`) ou podem consistir em dados estruturados.**

O gráfico abaixo é emprestado de [este tutorial R online](http://venus.ifca.unican.es/Rintro/dataStruct.html). Ele mostra algumas estruturas de dados comuns e seus nomes. Não estão incluídos nesta imagem os dados espaciais, que são discutidos na página [Noções básicas de GIS](#gis).

```{r basics_objects_structures, echo=F, out.width = "75%", out.height="50%", fig.align = "center"}
knitr::include_graphics(here::here("images", "R_data_structures.png"))
```

Em epidemiologia (e particularmente epidemiologia de campo), você encontrará *mais comumente* dataframes e vetores:

+------------------+--------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------+
| Estrutura comum  | Explicação                                                                                             | Exemplo                                                                             |
+==================+========================================================================================================+=====================================================================================+
| Vetores          | Um conteiner para uma sequência de objetos singulares, de uma mesma classe  (es: numérico, caractere). | **"Variáveis" (colunas) em data frames são vetores** (ex: a coluna `age_years`).    |
+------------------+--------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------+
| Data Frames      | Vetores (ex: colunas) que estão unidas e têm todas o mesmo número de linhas.                          | `linelist` é data frame.                                                             |
+------------------+--------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------+

Observe que para criar um vetor que "independente" (não faz parte de um data frame) a função `c()` é usada para combinar os diferentes elementos. Por exemplo, se estiver criando um vetor de cores para uma paleta de cores de um gráfico: `vector_de_cores <- c("blue", "red2", "orange", "grey")`

<!-- ======================================================= -->

### Classe de objetos {.unnumbered}

Todos os objetos armazenados em R possuem uma *classe* que informa ao R como lidar com o objeto. Existem muitas classes possíveis, mas as mais comuns incluem:

+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------+
| Classe     | Explicação                                                                                                                                                                       | Exemplos                                                                                              |
+============+==================================================================================================================================================================================+=======================================================================================================+
| Character  | Caracteres, esses são textos/palavras/frases **"dentro de aspas"**. Nenhuma operação matemática pode ser realizada com esses objetos.                                            | "Objetos do tipo caractere ficam entre aspas"                                                         |
+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------+
| Integer    | Números **inteiros** (sem decimais)                                                                                                                                              | -5, 14, or 2000                                                                                       |
+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------+
| Numeric    | Números que **podem incluir decimais**. Se estiverem dentro de aspas, serão considerados como caractere                                                                          | 23.1 or 14                                                                                            |
+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------+
| Factor     | Fatores, são vatores que tem uma **ordem específica** ou hierarquia de valores                                                                                                   | Uma variável de status econômico com valores ordenados                                                |
+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------+
| Date       | **Uma vez que o R é informado que um certo grupo de dados corresponde a Data**, esses valores só podem ser apresentados e manipulados de algumas maneiras especiais.             | 2018-04-12 ou 15/3/1954 ou Qua 4 Jan 1980                                                             |
|            | Veja a página sobre [Trabalhando com datas](#dates) para mais informações                                                                                                        |                                                                                                       |
+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------+
| Logical    | Valores lógicos que precisam um dos dois valores especiais TRUE (verdadeiro) ou FALSE (note que eles **não** não "TRUE" e "FALSE" entre aspas)                                   | `TRUE` ou `FALSE`                                                                                     |
+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------+
| data.frame | Uma data frame é como o R armazena uma **base de dados típica**. Consiste de vetores (colunas) de dados unidos, que tenha o mesmo número de observações (linhas).               | O exemplo AJS nomeado `linelist_raw` contém 68 variáveis com 300 observações (linhas) cada.      |
+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------+
| tibble     | tibble é uma variação do data frame, a principal diferença operacional é que eles printam melhor no console (exibem as primeiras 10 linhas e apenas as colunas que cabem na tela)| Qualquer data frame, lista ou matriz pode ser convertido em um tibble com `as_tibble()`               |
+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------+
| list       | Uma lista é como um vetor, mas contém outros objetos que podem ser de outras classes diferentes                                                                                  | Uma lista pode conter um único número, um dataframe, um vetor e até outra lista dentro dele!          |
+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------+

**Você pode testar a classe de um objeto fornecendo seu nome para a função `class()`**. Nota: você pode fazer referência a uma coluna específica dentro de um conjunto de dados utilizando a notação `$` para separar o nome do conjunto de dados e o nome da coluna.

```{r, echo=TRUE,}
class(linelist)         # a classe deve ser uma data frame ou tibble

class(linelist$age)     # classe deve ser numérica 

class(linelist$gender)  # classe deve ser caractere 
```

Às vezes, uma coluna será convertida automaticamente para uma classe diferente pelo R. Cuidado com isso! Por exemplo, se você tiver um vetor ou coluna de números, mas um valor de caractere for inserido... a coluna inteira mudará para caractere de classe.

```{r}
num_vector <- c(1,2,3,4,5) # define um vetor só de números
class(num_vector)          # este vetor é da classe numérico
num_vector[3] <- "three"   # converte o terceiro elemento para um caractere
class(num_vector)          # o vetor agora é classe caractere
```

Um exemplo comum disso é quando se manipula um data frame para exibir uma tabela - se você fizer uma linha total e tentar colar/colar porcentagens na mesma célula dos números (por exemplo, `23 (40%)`), toda a coluna numérica acima será convertida em caractere e não poderá mais ser utilizada para cálculos matemáticos.** Algumas vezes, será necessário converter objetos ou colunas em outra classe.**

+------------------+--------------------------------------------------------------------------------------------+
| Função           | Ação                                                                                       |
+==================+============================================================================================+
| `as.character()` | Converte para a classe caractere                                                           |
+------------------+--------------------------------------------------------------------------------------------+
| `as.numeric()`   | Converte para a classe numérica                                                            |
+------------------+--------------------------------------------------------------------------------------------+
| `as.integer()`   |Converte para a classe inteiro                                                              |
+------------------+--------------------------------------------------------------------------------------------+
| `as.Date()`      | Converte para a classe Data - Nota: Veja a seção sobre [datas](#dates) para detalhes       |
+------------------+--------------------------------------------------------------------------------------------+
| `factor()`       | Converte para a classe fator - Nota: Redefinir a ordem dos níveis requer argumentos extras |
+------------------+--------------------------------------------------------------------------------------------+

Da mesma forma, existem as funções do R **base** para verificar se um objeto é de uma classe específica, como `is.numeric()`, `is.character()`, `is.double()`, `is.factor()`, `is.integer()`

Aqui está [mais material on-line sobre classes e estruturas de dados em R](https://swcarpentry.github.io/r-novice-inflammation/13-supp-data-structures/).

<!-- ======================================================= -->

### Colunas/Variáveis (`$`) {.unnumbered}

**Uma coluna em um data frame é tecnicamente um "vetor" (ver tabela acima)** - uma série de valores que devem ser todos da mesma classe (tanto caracter, numérico, lógico, etc.).

Um vetor pode existir independentemente de um data frame, por exemplo, um vetor de nomes de colunas que você deseja incluir como variáveis explicativas em um modelo. Para criar um vetor  independente, utilize a função `c()` como abaixo:

```{r, warning=F, message=F}
# define o vetor independente de entradas dp tipo caractere 
explanatory_vars <- c("gender", "fever", "chills", "cough", "aches", "vomit")

# printa os valores desse vetor nomeado  
explanatory_vars
```

**As colunas em uma data frame também são vetores e podem ser chamadas, referenciadas, extraídas ou criadas utilizando o símbolo `$`.** O símbolo `$` liga o nome da coluna ao nome de sua moldura de dados. Neste manual, tentamos utilizar a palavra "coluna" em vez de "variável".

```{r basics_objects_call, eval=F}
# Obter o comprimento do vetor age
length(linelist$age) # (age é uma coluna no data frame linelist)

```

Ao digitar o nome do data frame seguido de `$` você verá também um menu suspenso de todas as colunas  data frame. Você pode percorrê-las usando sua tecla de seta, selecionar uma com sua tecla Enter e evitar erros ortográficos!

```{r echo=F, out.width = "100%", fig.align = "center"}
knitr::include_graphics(here::here("images", "Calling_Names.gif"))
```

[***DICA AVANÇADA:*** Alguns objetos mais complexos (por exemplo, uma lista, ou um objeto 'epicontacts') podem ter múltiplos níveis que podem ser acessados através de múltiplos sinais de dólar. Por exemplo `epicontacts$linelist$date_onset`]{style="color: darkgreen;"}

<!-- ======================================================= -->

### Accessar/indexar com colchetes (`[ ]`) {.unnumbered}

Talvez seja necessário visualizar partes de objetos, também chamadas de "indexação", o que muitas vezes é feito utilizando os colchetes `[ ]`. Utilizar `$` em um data frame para acessar uma coluna é também um tipo de indexação.

```{r}
my_vector <- c("a", "b", "c", "d", "e", "f")  # define o vetor
my_vector[5]                                  # printa o quinto elemento
```

Os colchetes também funcionam para retornar partes específicas de uma saída retornada, tais como a saída de uma função summary():

```{r}
# Todo o resumo
summary(linelist$age)

# Apenas o segundo elemento,sem nome, usando colchetes simples
summary(linelist$age)[2]

# Apenas o segundo elemento,sem nome, usando colchetes duplos

# Extrais um elemento pelo nome, sem mostrar o nome aparecer no console
summary(linelist$age)[["Median"]]

```

Os colchetes também trabalham em data frames para visualizar linhas e colunas específicas. Você pode fazer isso utilizando a sintaxe `dataframe[linhas, colunas]`:

```{r basics_objects_access, eval=F}
# Visualizar uma linha específica (2) de uma base de dados, com todas as colunas (não esqueça a vírgula!) 
linelist[2,]

# Vert todas as linhas, mas só uma coluna
linelist[, "date_onset"]

# Ver valores da linha 2, e as colunas 5 a 10
linelist[2, 5:10] 

# VVer valores da linha 2, e as colunas 5 a 10 e a 18
linelist[2, c(5:10, 18)] 

# Ver valores da linha 2 a 20 , e colunas específicas
linelist[2:20, c("date_onset", "outcome", "age")]

#Ver linhas e colunas baseado em critérios
# *** Noque que o dataframe precira ainda ser nomeado no critério!  
linelist[linelist$age > 25 , c("date_onset", "outcome", "age")]

# Use View() para ver as saídas no Painel Visualizador do RStudio Viewer (mais fácil de ler)
# *** Note o  "V" maúsculo na função View() 
View(linelist[2:20, "date_onset"])

# Salve como um novo objeto
new_table <- linelist[2:20, c("date_onset")] 
```

Observe que você também pode alcançar a indexação de linha/coluna acima em dataframes e tibbles utilizando **dplyr** sintaxe (funções `filter()` para linhas, e `select()` para colunas). Leia mais sobre estas funções centrais na página [Dados de limpeza e principais funções](#cleaning).

Para filtrar com base no "número da linha", você pode utilizar a função **dplyr** `row_number()` com parênteses abertos como parte de uma instrução de filtragem lógica. Muitas vezes você utilizará o operador `%in%` e uma faixa de números como parte dessa declaração lógica, como mostrado abaixo. Para ver as *primeiras* N fileiras , você também pode utilizar a função especial **dplyr** `head()`.

```{r, eval=F}
# Visualizar as primeiras 100 linhas
linelist %>% head(100)

# Show row 5 only
linelist %>% filter(row_number() == 5)

# View rows 2 through 20, and three specific columns (note no quotes necessary on column names)
linelist %>% filter(row_number() %in% 2:20) %>% select(date_onset, outcome, age)
```

Ao indexar um objeto de classe **lista**, parênteses simples sempre retornam coma classe lista, mesmo que apenas um único objeto seja retornado. Entretanto, colchetes duplos podem ser usados para acessar um único elemento e retornar uma classe diferente da lista.\
Os parênteses também podem ser escritos um após o outro, como demonstrado abaixo.

Esta [explicação visual da indexação de listas, com pimenteiros](https://r4ds.had.co.nz/vectors.html#lists-of-condiments) é bem-humorada e útil.


```{r}
# define uma lista demo
my_list <- list(
  # Primeiro elemento na lista é um vetor do tipo caractere 
  hospitals = c("Central", "Empire", "Santa Anna"),
  
  # segundo elemento na lista é um dataframe com endereços  
  addresses   = data.frame(
    street = c("145 Medical Way", "1048 Brown Ave", "999 El Camino"),
    city   = c("Andover", "Hamilton", "El Paso")
    )
  )
```

Veja como fica a lista quando exibida no console. Veja como há dois elementos nomeados:

- `hospitals`,, um vetor de caracteres.
- `addresses`, um quadro de dados de endereços

```{r}
my_list
```

Agora nos extraímos usando vários métodos:

```{r}
my_list[1] # esse retorna o elemanto da classe "lista" - o nome do elemento ainda é exibido 

my_list[[1]] # este retorna apenas o vetor de caracter (sem nome) 

my_list[["hospitals"]] # você também pode indexar pelo nome do elemento da lista  

my_list[[1]][3] # Isto retorna o terceiro elemento do vetor de caracteres "hospitals" 

my_list[[2]][1] # Isto retorna a primeira coluna  ("street") da data frame de endereços

```

<!-- ======================================================= -->

### Remover objetos {.unnumbered}

Você pode remover objetos individuais de seu ambiente R colocando o nome na função `rm()` (sem aspas):

```{r, eval=F}
rm(object_name)
```

Você pode reomver todos os objetos (limpar o ambiente de trabalho) ao executar:

```{r, eval=F}
rm(list = ls(all = TRUE))
```

<!-- ======================================================= -->

<!-- ======================================================= -->

<!-- ======================================================= -->

## Piping (Encadeamento, `%>%`)

**Duas abordagens gerais para trabalhar com objetos são:**

1)  **Pipes/tidyverse** - pipes send an object from function to function - emphasis is on the *action*, not the object\
2)  **Definir objetos intermediários** - um objeto é redefinido repetidamente - a ênfase está no objeto.

<!-- ======================================================= -->

### **Pipes** {.unnumbered}

**Explicado de forma simples, o operador do pipe (`%>%`) passa uma saída intermediária de uma função para a próxima.**\
Você pode pensar nisso como dizendo "então". Muitas funções podem ser ligadas com `%>%`.

- **Piping enfatiza uma seqüência de ações, não o objeto sobre o qual as ações estão sendo realizadas**\
- Pipes são melhores quando uma seqüência de ações deve ser executada em um único objeto.\
- Os pipes vêm do pacote **magrittr**, que é automaticamente incluído nos pacotes **dplyr** e **tidyverse**
- Os pipes podem tornar o código mais limpo e fácil de ler, mais intuitivo

Leia mais sobre esta abordagem no tidyverse [guia de estilo](https://style.tidyverse.org/pipes.html)

Aqui está um exemplo falso para comparação, usando funções fictícias para "assar um bolo". Primeiro, o método do pipe:

```{r piping_example_pipe, eval=F}
# Um exemplo falso de como assar um bolo usando a sintaxe do pipe 

cake <- flour %>%       #para definir o bolo, comece com farinha, e então ...
  add(eggs) %>%   # adicione ovos
  add(oil) %>%    # adicione óleo
  add(water) %>%  # adicione água
  mix_together(         # misture
    utensil = spoon,
    minutes = 2) %>%    
  bake(degrees = 350,   # asse
       system = "fahrenheit",
       minutes = 35) %>%  
  let_cool()            # deixe esfriar
```

Aqui está outro [link](https://cfss.uchicago.edu/notes/pipes/#:~:text=Pipes%20are%20an%20extremamente%20useful,code%20and%20combine%20multiple%20operations) descrevendo a utilidade dos pipes.

O pipe não é uma função do R **base**. Para utilizar o pipe, o pacote **magrittr** deve ser instalado e carregado (isto é normalmente feito carregando os pacotes **tidyverse** ou **dplyr** que o inclui). Você pode [ler mais sobre pipe na documentação magrittr](https://magrittr.tidyverse.org/).

Observe que, assim como outros comandos R, os pipes podem ser utilizados apenas para exibir o resultado, ou para salvar/reservar um objeto, dependendo se o operador de atribuição `<-` está envolvido. Veja os dois abaixo:

```{r, eval=F}
# Criar ou sobrescrever um objeto, definindo como contagens agregadas por faixa-etária  (não "printado")
linelist_summary <- linelist %>% 
  count(age_cat)
```

```{r}
# Printa a tabela de contagens no console, mas nao a salva  
linelist %>% 
  count(age_cat)
```

**`%<>%`**\
Este é um "tubo de atribuição" do pacote **magrittr**, que *encadeia um objeto para frente e também re-define o objeto*. Deve ser o primeiro operador pipe da cadeia. É um "atalho". Os dois comandos abaixo são equivalentes:

```{r, eval=F}
linelist <- linelist %>%
  filter(age > 50)

linelist %<>% filter(age > 50)
```

<!-- ======================================================= -->

### Definir objetos intermediários {.unnumbered}

Esta abordagem para mudar objetos/dataframes pode ser melhor se:

- Você precisa manipular vários objetos...
- Há etapas intermediárias que são significativas e merecem nomes de objetos separados

**Riscos:**

- Criar novos objetos para cada etapa significa criar muitos objetos. Se você usar o errado, talvez não se dê conta disso!
- Nomear todos os objetos pode ser confuso...
- Os erros podem não ser facilmente detectáveis

Ou nomear cada objeto intermediário, ou sobrescrever o original, ou combinar todas as funções em conjunto. Todos vêm com seus próprios riscos.

Abaixo está o mesmo exemplo falso de "bolo" como acima, mas usando este estilo:

```{r piping_example_redefine, eval=F}
# um exemplo falso de como assar um bolo usado este método (definindo objetos intermediários) 
batter_1 <- left_join(flour, eggs)
batter_2 <- left_join(batter_1, oil)
batter_3 <- left_join(batter_2, water)

batter_4 <- mix_together(object = batter_3, utensil = spoon, minutes = 2)

cake <- bake(batter_4, degrees = 350, system = "fahrenheit", minutes = 35)

cake <- let_cool(cake)
```

Combine todas as funções em uma só - isso dificulta a leitura):

```{r eval=F}
# um exemplo de combinação/aninhamento de múltiplas funções  juntas - difícil de ler
cake <- let_cool(bake(mix_together(batter_3, utensil = spoon, minutes = 2), degrees = 350, system = "fahrenheit", minutes = 35))
```

<!-- ======================================================= -->

## Principais operadores e funções {#operadores}

Esta seção detalha os operadores em R, como por exemplo:

- Operadores de definição\
- Operadores relacionais (menos do que, igual a...)
- Operadores lógicos (e, ou...)\
- Lidando com valores faltantes...
- Operadores matemáticos e funções (+/-, \>, sum(), median(), ...)\
- O operador `%in%`


<!-- ======================================================= -->

### Operador de atribuição  {.unnumbered}

**`<-`**

O operador de atribuição básica em R é `<-`. De tal forma que `nome_objeto <- valor`.\
Este operador de atribuição também pode ser escrito como `=`. Aconselhamos o uso de `<-` para uso geral em R. \
Aconselhamos também o uso de `<-` para uso geral em R. Aconselhamos também o uso de espaços em torno de tais operadores, para facilitar a leitura.

**`<<-`**

Se você estiver [Escrevendo funções](#writing-functions), ou utilizando R de forma interativa com scripts de origem, então você pode precisar utilizar este operador de atribuição `<<-` (do R **base**). Este operador é utilizado para definir um objeto em um ambiente R 'pai' superior. Veja isto [referência on-line](https://stat.ethz.ch/R-manual/R-devel/library/base/html/assignOps.html).

**`%<>%`**

Este é um "pipe de atribuição" do pacote **magrittr**, que canaliza um objeto para frente e *também re-define o objeto*. Deve ser o primeiro operador pipe da cadeia. É a abreviação, como mostrado abaixo em dois exemplos equivalentes:

```{r, eval=F}
linelist <- linelist %>% 
  mutate(age_months = age_years * 12)
```

O código acima é equivalente ao abaixo: 

```{r, eval=F}
linelist %<>% mutate(age_months = age_years * 12)
```

**`%<+%`**

Isso é usado para adicionar dados a árvores filogenéticas com o pacote **ggtree**. Veja a página em [Árvores Filogenéticas](#phylogenetic-trees) ou este [livro de recursos online ](https://yulab-smu.top/treedata-book/).

<!-- ======================================================= -->

### Operadores relacionais e lógicos  {.unnumbered}

Os operadores relacionais comparam valores e são freqüentemente utilizados na definição de novas variáveis e subconjuntos de conjuntos de dados. Aqui estão os operadores relacionais comuns em R:

+----------------------------+------------+--------------+-------------------------------------------------------------------------------------------------------------------------+
| Significado                | Operador   | Examplo      | Resultado do exemplo                                                                                                    |
+============================+============+==============+=========================================================================================================================+
| Igual a                    | `==`       | `"A" == "a"` | `FALSE` (porque o R é sensível a letras maiúscula/minúsculas) <br/>                                                     |
|                            |            |              | *Note que == (iguais duplos) é diferente de = (símbolo de igual normal), que age como o operador de atribuição `<-`*    |
+----------------------------+------------+--------------+-------------------------------------------------------------------------------------------------------------------------+
| Não igual (diferente)      | `!=`       |  `2 != 0`    | `TRUE`                                                                                                                  |
+----------------------------+------------+--------------+-------------------------------------------------------------------------------------------------------------------------+
| Maior que                  | `>`        | `4 > 2`      | `TRUE`                                                                                                                  |
+----------------------------+------------+--------------+-------------------------------------------------------------------------------------------------------------------------+
| Menor que                  | `<`        | `4 < 2`      | `FALSE`                                                                                                                 |
+----------------------------+------------+--------------+-------------------------------------------------------------------------------------------------------------------------+
| Maior ou igual a           | `>=`       | `6 >= 4`     | `TRUE`                                                                                                                  |
+----------------------------+------------+--------------+-------------------------------------------------------------------------------------------------------------------------+
| Menor ou igual a           | `<=`       | `6 <= 4`     | `FALSE`                                                                                                                 |
+----------------------------+------------+--------------+-------------------------------------------------------------------------------------------------------------------------+
| Valor está faltante        | `is.na()`  | `is.na(7)`   | `FALSE` (veja página em [Dados faltantes](#missing-data))                                                               |
+----------------------------+------------+--------------+-------------------------------------------------------------------------------------------------------------------------+
| Valor não faltante         | `!is.na()` | `!is.na(7)`  | `TRUE`                                                                                                                  |
+----------------------------+------------+--------------+-------------------------------------------------------------------------------------------------------------------------+

Operadores lógicos, como AND e OR, geralmente são usados para conectar operadores relacionais e criar critérios mais complicados. Instruções complexas podem exigir parênteses ( ) para agrupamento e ordem de aplicação.

+-------------+-----------------------------------------------------------------------+
| Significado | Operador                                                              |
+=============+=======================================================================+
| AND         | `&`                                                                   |
+-------------+-----------------------------------------------------------------------+
| OR          | `|` (barra vertical)                                                  |
+-------------+-----------------------------------------------------------------------+
| Parentheses | `( )` Usado para agrupar critérios e clarificar a ordem das operações |
+-------------+-----------------------------------------------------------------------+

Por exemplo, abaixo, temos uma linelist com duas variáveis que queremos utilizar para criar nossa definição de caso, `hep_e_rdt`, um resultado de teste e `other_cases_in_hh`, que nos dirá se há outros casos na casa. O comando abaixo utiliza a função `case_when()` para criar a nova variável `case_def` de tal forma que:

```{r eval=FALSE}
linelist_cleaned <- linelist %>%
  mutate(case_def = case_when(
    is.na(rdt_result) & is.na(other_case_in_home)            ~ NA_character_,
    rdt_result == "Positive"                                 ~ "Confirmed",
    rdt_result != "Positive" & other_cases_in_home == "Yes"  ~ "Probable",
    TRUE                                                     ~ "Suspected"
  ))
```

+------------------------------------------------------------------------------------------------+--------------------------------------------+
| Critérios no exemplo acima                                                                     | Valor da nova variável  "case_def"         |
+================================================================================================+============================================+
| Se o valor das variáveis `rdt_result` e `other_cases_in_home` estiverem faltando               | `NA` (faltante)                            |
+------------------------------------------------------------------------------------------------+--------------------------------------------+
| Se o valor em `rdt_result` for "Positive"                                                      | `Confirmed`                                |
+------------------------------------------------------------------------------------------------+--------------------------------------------+
| If the value in `rdt_result` is NOT "Positive" AND the value in `other_cases_in_home` is "Yes" | `Probable`                                 |
+------------------------------------------------------------------------------------------------+--------------------------------------------+
| If one of the above criteria are not met                                                       | `Suspected`                                |
+------------------------------------------------------------------------------------------------+--------------------------------------------+

*Note that R is case-sensitive, so "Positive" is different than "positive"...*

<!-- ======================================================= -->

### Valores faltantes {.unnumbered}

Em R, os valores ausentes são representados pelo valor especial `NA` (um valor "reservado") (letras maiúsculas N e A - não entre aspas). Se você importar dados que registram dados ausentes de outra maneira (por exemplo, 99, "Missing" ou .), convém recodificar esses valores para `NA`. Como fazer isso é abordado na página [Importação e exportação](#importing).

**Para testar se um valor é `NA`, use a função especial `is.na()`**, que retorna `TRUE` ou `FALSE`.

```{r basics_operators_missing}
rdt_result <- c("Positive", "Suspected", "Positive", NA)   # dois casos positivos, um suspeito e um desconhecido 
is.na(rdt_result)  # Testa se o valor de  rdt_result é NA
```


Leia mais sobre valores ausentes, infinitos, `NULL` e impossíveis na página em [Campos em branco/faltantes](#missing-data). Saiba como converter valores ausentes ao importar dados na página em [Importação e exportação](#importing).

<!-- ======================================================= -->

### Matemática e estatística {.unnumbered}

Todos os operadores e funções nesta página estão disponíveis automaticamente usando o pacote R **base**.

#### Operadores mmatemáticos {.unnumbered}

Estes são frequentemente usados para realizar adição, divisão, para criar novas colunas, etc. Abaixo estão os operadores matemáticos comuns em R. Colocar ou não os espaços ao redor dos operadores não é importante.

| Propósito           | Exemplo no R   |
|---------------------|----------------|
| adição              | `2 + 3`        |
| subtração           | `2 - 3`        |
| multiplicação       | `2 \* 3`       |
| divisão             | `30 / 5`       |
| potência            | `2\^3`         |
| ordem das operações | `( )`          |

#### Funções matemáticas {.unnumbered}

| Propósito                   | Função                                  |
|-----------------------------|-----------------------------------------|
| arredondamento              | `round(x, digits = n)`                  |
| arredondamento              | `janitor::round_half_up(x, digits = n)` |
| teto (arredondar para cima) | `ceiling(x)`                            |
| chão (arredondar para baixo)| `floor(x)`                              |
| valor obsoluto (módulo)     | `abs(x)`                                |
| raiz quadrada               | `sqrt(x)`                               |
| exponencial                 | `exponent(x)`                           |
| logaritmo natural/neperiano | `log(x)`                                |
| logaritmo na base 10        | `log10(x)`                              |
| logaritmo na base 2         | `log2(x)`                               |

Nota: para `round()` o `digits =` especifica o número de casas decimais colocadas. Use `signif()` para arredondar para um número de algarismos significativos.

#### Notação científica {.unnumbered}

A probabilidade de notação científica ser usada depende do valor da opção `scipen`.

Da documentação de `?options`: scipen é uma penalidade a ser aplicada ao decidir imprimir valores numéricos em notação fixa ou exponencial. Os valores positivos tendem para a notação fixa e os negativos para a notação científica: a notação fixa será preferida, a menos que seja mais do que os dígitos 'scipen' mais largos.

Se estiver definido para um número baixo (por exemplo, 0), ele estará sempre "ligado". Para "desativar" a notação científica em sua sessão R, defina-a como um número muito alto, por exemplo:

```{r, eval=F}
# desligar a notação científica
options(scipen=999)
```

#### Arredondando {.unnumbered}

[***PERIGO:*** A função `round()` usa "arredondamento do banqueiro" que arredonda de .5 somente se o número superior for par. Use `round_half_up()` do **janitor** para arredondar consistentemente metades para o número inteiro mais próximo. Veja [esta explicação](https://cran.r-project.org/web/packages/janitor/vignettes/janitor.html#explore-records-with-duplicated-values-for-specific-combinations-of-variables-with-get_dupes)]{style="color: red;"}

```{r}
# use a função de arredondamento adequanda para o seu trabalho 
round(c(2.5, 3.5))

janitor::round_half_up(c(2.5, 3.5))
```

#### Funções estatísticas {.unnumbered}

[***CUIDADO:*** As funções abaixo incluirão, por padrão, valores ausentes nos cálculos. Valores ausentes resultarão em uma saída de `NA`, a menos que o argumento `na.rm = TRUE` seja especificado. Isso pode ser escrito de forma abreviada como `na.rm = T`.]{style="color: orange;"}

| Objetivo                   | Função               |
|----------------------------|----------------------|
| média aritmética           | `mean(x, na.rm=T)`   |
| mediana                    | `median(x, na.rm=T)` |
| desvio padrão              | `sd(x, na.rm=T)`     |
| quantis\*                  | `quantile(x, probs)` |
| soma                       | `sum(x, na.rm=T)`    |
| valor mínimo               | `min(x, na.rm=T)`    |
| valor máximo               | `max(x, na.rm=T)`    |
| range de valores numéricos | `range(x, na.rm=T)`  |
| resumo\*\*                 | `summary(x)`         |

Notas:

- \* `quantile()`: `x` é o vetor numérico a ser examinado e `probs =` é um vetor numérico com probabilidades entre 0 e 1,0, por exemplo, `c(0.5 , 0.8 , 0,.85)`
- \*\* `summary()`: fornece um resumo em um vetor numérico incluindo média, mediana e percentis comuns

[***PERIGO:*** Ao fornecer um vetor de números para uma das funções acima, certifique-se de concatenar os números dentro de `c()` .]{style="color: red;"}

```{r}
# Se fornecer números brutos para uma função, concatene-os antes com c()
mean(1, 6, 12, 10, 5, 0)    # !!! INCORRETO !!!  

mean(c(1, 6, 12, 10, 5, 0)) # CORRETO
```

#### Outras funções úteis {.unnumbered}

+--------------------------------+-------------------+-------------------------------------------------+
| Objetivo                       | Função            | Examplo                                         |
+================================+===================+=================================================+
| criar uma sequência de números | seq(from, to, by) | `seq(1, 10, 2)`                                 |
+--------------------------------+-------------------+-------------------------------------------------+
| repetir x, n vezes             | rep(x, ntimes)    | `rep(1:3, 2)` or `rep(c("a", "b", "c"), 3)`     |
+--------------------------------+-------------------+-------------------------------------------------+
| subdividir um vetor numérico   | cut(x, n)         | `cut(linelist$age, 5)`                          |
+--------------------------------+-------------------+-------------------------------------------------+
| pegar uma amostra aleatória    | sample(x, size)   | `sample(linelist$id, size = 5, replace = TRUE)` |
+--------------------------------+-------------------+-------------------------------------------------+

<!-- ======================================================= -->

### `%in%` {.unnumbered}

Um operador muito útil para combinar valores e avaliar rapidamente se um valor está dentro de um vetor ou dataframe.

```{r}
meu_vetor <- c("a", "b", "c", "d")
```

```{r}
"a" %in% meu_vetor
"h" %in% meu_vetor
```

Para perguntar se um valor **não** está em (`%in%`) é um vetor, coloque um ponto de exclamação (!) **na frente** da instrução lógica:

```{r}
# para negar, coloque a exclamação na frente 
!"a" %in% meu_vetor
!"h" %in% meu_vetor
```

`%in%` é muito útil ao usar a função **dplyr** `case_when()`. Você pode definir um vetor anteriormente e depois referenciá-lo. Por exemplo:

```{r eval=F}
affirmative <- c("1", "Yes", "YES", "yes", "y", "Y", "oui", "Oui", "Si")

linelist <- linelist %>% 
  mutate(child_hospitaled = case_when(
    hospitalized %in% affirmative & age < 18 ~ "Hospitalized Child",
    TRUE                                      ~ "Not"))
```

Note: If you want to detect a partial string, perhaps using `str_detect()` from **stringr**, it will not accept a character vector like `c("1", "Yes", "yes", "y")`. Instead, it must be given a *regular expression* - one condensed string with OR bars, such as "1\|Yes\|yes\|y". For example, `str_detect(hospitalized, "1|Yes|yes|y")`. See the page on [Caracteres e strings](#characters-strings) for more information.

You can convert a character vector to a named regular expression with this command:

```{r}
affirmative <- c("1", "Yes", "YES", "yes", "y", "Y", "oui", "Oui", "Si")
affirmative

# condensar
affirmative_str_search <- paste0(affirmative, collapse = "|")  # opção com R base
affirmative_str_search <- str_c(affirmative, collapse = "|")   # opção co pacote stringr

affirmative_str_search
```

<!-- ======================================================= -->

<!-- ======================================================= -->

<!-- ======================================================= -->

## Erros & avisos

Esta seção explica:

- A diferença entre erros e avisos\
- Dicas gerais de sintaxe para escrever código R\
- Ajudas para o código.

Erros e avisos comuns e dicas de solução de problemas podem ser encontrados na página em [Erros e ajuda](#errors).

<!-- ======================================================= -->

### Erros versus Avisos {.unnumbered}

Quando um comando é executado, o Console R pode mostrar mensagens de aviso ou erro em texto vermelho.

- Um **aviso** significa que o R concluiu seu comando, mas teve que executar etapas adicionais ou produziu uma saída incomum da qual você deve estar ciente.

- Um **erro** significa que o R não conseguiu completar seu comando.

Procurar pistas:

- A mensagem de erro/aviso geralmente inclui um número de linha para o problema.

- Se um objeto "é desconhecido" ou "não encontrado", talvez você o tenha escrito incorretamente, esquecido de chamar um pacote com library() ou esquecido de executar novamente seu script após fazer alterações.

Se tudo mais falhar, copie a mensagem de erro no Google junto com alguns termos-chave: é provável que alguém já tenha trabalhado com isso!

<!-- ======================================================= -->

### Dicas gerais de sintaxe {.unnumbered}

Algumas coisas para lembrar ao escrever comandos em R, para evitar erros e avisos:

- Sempre feche os parênteses - dica: conte o número de abertura "(" e fechamento de parênteses ")" para cada pedaço de código
- Evite espaços em nomes de colunas e objetos. Use sublinhado ( \_ ) ou pontos ( . )
- Acompanhe e lembre-se de separar os argumentos de uma função com vírgulas
- R diferencia maiúsculas de minúsculas, o que significa que `Variable_A` é *diferente* de `variable_A`

<!-- ======================================================= -->

### Ajudas de código {.unnumbered}

Qualquer script (RMarkdown ou outro) dará pistas quando você cometer um erro. Por exemplo, se você esqueceu de escrever uma vírgula onde for necessário, ou de fechar um parêntese, o RStudio irá levantar uma bandeira nessa linha, no lado direito do script, para avisá-lo.
```{r include=FALSE, cache=FALSE}

# clear workspace
rm(list = ls(all = TRUE))

# clear all packages except base
#lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))

# to ensure that tidyverse packages prevail
filter <- dplyr::filter
select <- dplyr::select
summarise <- dplyr::summarise
summary <- base::summary
incidence <- incidence2::incidence

#load core packages
pacman::p_load(
     rio,
     here,
     DT,
     stringr,
     lubridate,
     tidyverse
)

# import the cleaned ebola linelist
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

# import the count data - facility level
#count_data <- rio::import(here::here("data", "facility_count_data.rds"))

# Settings

options(scipen=1, digits=7)

# print only text (not code)
# library(knitr)
# opts_chunk$set(list(echo = FALSE, eval = FALSE))
```

<!--chapter:end:new_pages/basics.Rmd-->


<!-- ======================================================= -->
<!-- ======================================================= -->
<!-- ======================================================= -->
# Transição para o R {#transition-to-R}  

Abaixo, fornecemos alguns conselhos e recursos se você estiver fazendo a transição para o R.  

O R foi lançado no final dos anos 90 e desde então, seu escopo tem crescido dramaticamente. Suas capacidades são tão amplas que programas alternativos comerciais reagiram ao surgimento do R para se manterem competitivas! ([leia este artigo comparando R, SPSS, SAS, STATA, e Python](https://www.inwt-statistics.com/read-blog/comparison-of-r-python-sas-spss-and-stata.html)).  

Além disso, o R é muito mais fácil de aprender do que era há 10 anos. Anteriormente, o R tinha a reputação de ser difícil para os iniciantes. Agora é muito mais fácil de aprender, com interfaces de usuário amigáveis como RStudio, código intuitivo como o **tidyverse**, e muitos recursos tutoriais.  


<span style="color: darkgreen;">**Não se sinta intimidado - venha descobrir o mundo do R!**</span>  

  

```{r, echo=F, out.width = "75%", out.height="75%", fig.align = "center"}
knitr::include_graphics(here::here("images", "transition_door.png"))
```



## Partindo do Excel

A transição do Excel diretamente para R é uma meta muito viável. Pode parecer assustador, mas você consegue fazer isso!  

É verdade que alguém com fortes habilidades no Excel pode fazer atividades muito avançadas somente no Excel - até mesmo usando ferramentas de programação em código como VBA. O Excel é usado em todo o mundo e é uma ferramenta essencial para um epidemiologista. Entretanto, complementá-lo com R pode melhorar drasticamente e expandir seus fluxos de trabalho.  


### Benefícios{.unnumbered}  

Você descobrirá que o uso de R oferece imensos benefícios, desde tempo economizado, análises mais consistentes e precisas, reprodutibilidade, compartilhabilidade e correção mais rápida de erros. Como qualquer software novo, há uma "curva" de aprendizado que reflete o tempo que você deve investir para se familiarizar em ele. Os dividendos serão significativos e um imenso escopo de novas possibilidades se abrirá para você com o R.  

Excel é um software bem conhecido que pode ser fácil para um iniciante usar para produzir análises e visualizações simples com o "apontar e clicar". Em comparação, pode levar algumas semanas para se tornar confortável com as funções e a interface do R. No entanto, o R evoluiu nos últimos anos para se tornar muito mais amigável para iniciantes.  

Muitos fluxos de trabalho do Excel dependem da memória e da repetição - portanto, há muitas oportunidades de erro. Além disso, geralmente a limpeza de dados, a metodologia de análise e as equações utilizadas são ocultadas da vista. Pode ser necessário um tempo substancial para que um novo colega aprenda o que uma pasta de trabalho Excel está fazendo e como resolvê-la. Com R, todas as etapas são explicitamente escritas no script e podem ser facilmente visualizadas, editadas, corrigidas e aplicadas a outros conjuntos de dados. 


**Para iniciar sua transição do Excel para o R, você deve ajustar sua mentalidade de algumas maneiras importantes:**  


### Dados bem arrumados (*tidy data*) {.unnumbered}  

Use dados "arrumados" (*tidy*), isto é, que sejam legíveis para a máquina em vez de dados bagunçados, que são apenas "legíveis para humanos". Estes são os três principais requisitos para dados do tipo "*tidy*", como explicado neste tutorial sobre [dados "tidy" em R](https://r4ds.had.co.nz/tidy-data.html):  

* Cada variável deve ter sua própria coluna  
* Cada observação deve ter sua própria linha
* Cada valor deve ter sua própria célula  

Para os usuários do Excel - pense no papel que [as "tabelas" Excel](https://exceljet.net/excel-tables) desempenham na padronização dos dados e na maior previsibilidade do formato.  

Um exemplo de dados "*tidy*" seria a lista (*linelist*) de casos utilizada ao longo deste manual - cada variável está contida dentro de uma coluna, cada observação (um caso) tem sua própria linha, e cada valor está em apenas uma célula. Abaixo você pode ver as primeiras 50 linhas desta *linelist*: 

```{r, echo=F}
# importar a linelist para o R
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))
```

```{r, message=FALSE, echo=F}
# mostra os dados da linelist como uma tabela
DT::datatable(head(linelist, 50), rownames = FALSE, filter="top", options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```

*O principal motivo pelo qual entramos dados não-arrumados por aí (*non-tidy*) se deve ao fato de muitas planilhas Excel serem projetadas para priorizar a leitura fácil por humanos, não a leitura fácil por máquinas/software.*  

Para ajudá-lo a ver a diferença, abaixo estão alguns exemplos fictícios de **dados não-arrumados** que priorizam leitura por *humanos* em vez de leitura por *máquina*:  

```{r, echo=F, out.width = "100%", out.height="75%", fig.align = "center"}
knitr::include_graphics(here::here("images", "Excel_nonTidy_1.png"))
```


*Problemas:* Na planilha acima, há *células mescladas* que não são facilmente digeridas pelo R. Qual linha deve ser considerada o "cabeçalho" não está totalmente clara. Um dicionário baseado em cores está do lado direito e os valores das células são representados por cores - o que também não é facilmente interpretado pelo R (nem por humanos daltônicos!). Além disso, diferentes pedaços de informação são combinados em uma célula (múltiplas organizações parceiras trabalhando em uma área, ou o status "TBC" na mesma célula que "Parceiro (*partner*) D").     


```{r, echo=F, out.width = "100%", out.height="100%", fig.align = "center"}
knitr::include_graphics(here::here("images", "Excel_nonTidy_2.png"))
```


*Problemas:* Na planilha acima, há numerosas linhas e colunas vazias extras dentro do conjunto de dados - isto causará dores de cabeça para a limpeza do banco no R. Além disso, as coordenadas GPS estão espalhadas por duas linhas para um determinado centro de tratamento. Como nota lateral - as coordenadas GPS estão em dois formatos diferentes!  

Os conjuntos de dados "tidy" podem não ser tão legíveis a um olho humano, mas tornam a limpeza e análise dos dados muito mais fácil! Dados "tidy" podem ser armazenados em vários formatos, por exemplo "longo/comprido" (*long*)  ou "largo/amplo" (*wide*) (ver página em [Pivotando dados](#pivoting)), mas os princípios acima serão sempre observados.


### Funções {.unnumbered}  

A palavra "função" em R pode ser nova, mas o conceito também existe no Excel como *fórmulas*. As fórmulas no Excel também requerem sintaxe precisa (por exemplo, colocação de ponto-e-vírgula e parênteses). Tudo o que você precisa fazer é aprender algumas novas funções e como elas funcionam juntas em R.  

### Scripts {.unnumbered}  

Em vez de clicar nos botões e arrastar as células, você estará escrevendo *todos* os passos e procedimentos em um "roteiro" (daqui em diante referido como *script*). 
Os usuários do Excel podem estar familiarizados com "macros VBA" que também empregam uma abordagem de códigos de programação.  

*O script R consiste de instruções passo a passo.* Isto permite que qualquer colega leia o script e veja facilmente os passos que você deu. Isto também ajuda a eliminar erros ou cálculos imprecisos. Veja a seção [Introdução ao R](#basics) sobre scripts para exemplos.  

Aqui está um exemplo de um script em R:  

```{r, echo=F, out.width = "75%", out.height="75%", fig.align = "center"}
knitr::include_graphics(here::here("images", "example_script.png"))
```




### Do Excel-para-R: recursos {.unnumbered}


* [R vs. Excel](https://www.northeastern.edu/graduate/blog/r-vs-excel/)  
* [curso RStudio em R para usuários do Excel](https://rstudio-conf-2020.github.io/r-for-excel/)  


### Interação R-Excel {.unnumbered}  

R tem formas robustas de importar pastas de trabalho do Excel, trabalhar com os dados, exportar/guardar arquivos Excel e trabalhar com as nuances das planilhas Excel.  

É verdade que algumas das formatações mais estéticas do Excel podem se perder na tradução (por exemplo, itálico, texto lateral, etc.). Se seu fluxo de trabalho exigir a passagem de documentos entre R e Excel enquanto mantém a formatação original do Excel, tente pacotes como **openxlsx***.  


## Partindo do Stata 
<!-- ======================================================= -->

**Vindo do Stata para R***  

Muitos epidemiologistas são ensinados primeiro a usar Stata, e pode parecer assustador mudar para R. Entretanto, se você é um usuário confortável de Stata, então o salto para R é certamente mais manejável do que você possa pensar. Embora existam algumas diferenças chave entre Stata e R em como os dados podem ser criados e modificados, bem como a maneira que as funções de análise são implementadas - após aprender estas diferenças chave você será capaz de adaptar suas habilidades.

Abaixo estão algumas traduções chave entre Stata e R, que podem ser úteis como sua revisão deste guia.


**Notas gerais**

**STATA**                    | **R**  
---------------------------- | ---------------------------------------------    
Você só pode visualizar e manipular um conjunto de dados de cada vez | Você pode visualizar e manipular vários conjuntos de dados ao mesmo tempo, portanto você terá que especificar freqüentemente seu conjunto de dados dentro do código
Comunidade online disponível por meio de [https://www.statalist.org/](https://www.statalist.org/) | Comunidade online disponível por meio de [RStudio](https://community.rstudio.com/), [StackOverFlow](https://stackoverflow.com/questions/tagged/r), e [R-bloggers](https://www.r-bloggers.com/)
Funcionalidade "apontar e clicar" como opção | Funcionalidade "apontar e clicar" mínima
Ajuda para comandos disponíveis por `help [comando]` | Ajuda disponível por `?função` ou busca no painel de Ajuda
Comentar código usando * ou /// ou /* TEXTO */ | Comentar código usando #
Quase todos os comandos são nativos ao Stata. Funções novas/escritas pelo usuário podem ser instaladas como arquivos **ado*** usando **ssc install** [pacote] | A instalação do R vem com funções **base** , mas o uso típico envolve a instalação de outros pacotes do CRAN (veja página em [Introdução ao R](#basics))
A análise é geralmente escrita em um arquivo **do** | Análise escrita em um script R no painel de fontes do RStudio. Scripts em R Markdown são uma alternativa.


**Diretório de trabalho**  

**STATA**                        | **R**  
-------------------------------- | ---------------------------------------------
Os diretórios de trabalho envolvem caminhos de arquivo absolutos (por exemplo, "C:/ nome do usuário/documentos/projetos/dados/")| Os diretórios de trabalho podem ser absolutos, ou relativos a uma pasta raiz do projeto usando o pacote **here** (ver [Importar e exportar](#importing)) 
Ver diretório de trabalho atual com **pwd** | Utilize `getwd()` ou `here()` (se utilizar o pacote **here**), com parênteses vazios 
Definir diretório de trabalho com **cd** "localização de pasta" | Utilize `setwd("localização de pasta")`, ou `set_here("localização de pasta")` (se estiver utilizando **here*** pacote)

**Importando e visualizando dados**  

**STATA**                    | **R**  
-------------------------------- | ---------------------------------------------
Comandos específicos por tipo de arquivo | Utilize `import()` do pacote **rio** para quase todos os tipos de arquivo. Existem funções específicas como alternativas (ver [Importar e exportar](#importing))
A leitura em arquivos csv é feita por **importar delimited** "filename.csv". | Use `import("nomedoarquivo.csv")`
A leitura em arquivos xslx é feita por **import excel** "filename.xlsx" | Use `import("nomedoarquivo.xlsx")`
Navegue seus dados em uma nova janela utilizando o comando **browse** | Visualize um conjunto de dados no painel de origem do RStudio utilizando `View(conjunto de dados)`. *Você precisa especificar o nome de seu conjunto de dados para a função em R porque vários conjuntos de dados podem ser mantidos ao mesmo tempo. Note "V" maiúsculo nesta função*.
Obtenha uma visão geral do seu conjunto de dados utilizando **summarize**, que fornece os nomes das variáveis e informações básicas | Obtenha uma visão geral do seu conjunto de dados utilizando `summary(conjunto de dados)`.

**Manipulações básicas de dados**  

**STATA**                    | **R**  
-------------------------------- | ---------------------------------------------
As colunas do conjunto de dados são frequentemente referidas como "variáveis" | Mais frequentemente referidas como "colunas" ou às vezes como "vetores" ou "variáveis".
Não é necessário especificar o conjunto de dados | Em cada um dos comandos abaixo, você precisa especificar o conjunto de dados - veja a página em [Limpeza de dados e principais funções](#cleaning) para exemplos
Novas variáveis são criadas utilizando o comando **generate** *nome_var* = | Gerar novas variáveis utilizando a função `mutate(nome_var = )`. Consulte a página [Limpeza de dados e principais funções](#cleaning) para obter detalhes sobre todas as funções abaixo **dplyr***.
As variáveis são renomeadas utilizando **rename** *nome_antigo nome_novo* | Colunas podem ser renomeadas utilizando a função `rename(novo_nome = nome_antigo)`
As variáveis são descartadas utilizando **drop** *nome_var* | As colunas podem ser removidas utilizando a função `select()` com o nome da coluna entre parênteses, seguindo um sinal de subtração
As variáveis fatoriais podem ser etiquetadas usando uma série de comandos como **label define** | Os valores de etiquetagem podem ser feitos convertendo a coluna para a classe fator e especificando níveis. Veja a página em [Fatores](#factors). Os nomes das colunas não são tipicamente etiquetados como estão na Stata.

**Análise descritiva**  

**STATA**                    | **R**  
-------------------------------- | ---------------------------------------------
Tabula contagens de uma variável utilizando **tab** *nome_var* | Forneça o conjunto de dados e nome da coluna para `table()` tal como `table(dataset$nome_da_coluna)`. Alternativamente, utilize `count(nome_var)` do pacote **dplyr**, como explicado em [Agrupando dados](#grouping).
Uma tabela de contingência de duas variáveis em uma tabela 2x2 é feito com **tab** *nome_var1 nome_var2* | Use `table(dataset$nome_var1, dataset$nome_var2` ou `count(nome_var1, nome_var2)`


Embora esta lista dê uma visão geral dos conceitos básicos na tradução dos comandos Stata em R, ela não é completa. Há muitos outros grandes recursos para os usuários da Stata em transição para R que poderiam ser de interesse:  

* https://dss.princeton.edu/training/RStata.pdf  
* https://clanfear.github.io/Stata_R_Equivalency/docs/r_stata_commands.html  
* http://r4stats.com/books/r4stata/  




## Partindo do SAS  
<!-- ======================================================= -->

**Vindo da SAS para R***  

O SAS é comumente usado em agências de saúde pública e campos de pesquisa acadêmica. Embora a transição para um novo idioma raramente seja um processo simples, compreender as diferenças-chave entre SAS e R pode ajudá-lo a começar a navegar no novo idioma usando seu idioma nativo. 
A seguir, descrevemos as principais traduções no gerenciamento de dados e análise descritiva entre a SAS e o R.   

**Notas gerais**  

**SAS**                          | **R**  
-------------------------------- | ---------------------------------------------
Comunidade online disponível em [SAS Customer Support](https://support.sas.com/en/support-home.html)|Comunidade online disponível em RStudio, StackOverFlow, e R-bloggers
Ajuda para os comandos disponíveis por `help [comando]`| Ajuda disponível por `?função` ou busca no painel de Ajuda
Comentar código utilizando `* TEXT ;` ou `/* TEXT */` | Comentar código utilizando #
Quase todos os comandos são nativos.  Os usuários podem escrever novas funções utilizando a macro SAS, SAS/IML, SAS Component Language (SCL) e, mais recentemente, procedimentos `Proc Fcmp` e `Proc Proto`|A instalação do R vem com as funções **base**, mas o uso típico envolve a instalação de outros pacotes do CRAN (veja a página em [Introdução ao R](#basics))
A análise é geralmente conduzida escrevendo um programa SAS na janela do Editor. |Análise escrita em um script R no painel fonte do RStudio. Scripts em R Markdown são uma alternativa.

**Diretório de trabalho**  

**SAS**                          | **R**  
-------------------------------- | ---------------------------------------------
Os diretórios de trabalho podem ser absolutos ou relativos a uma pasta raiz do projeto, definindo a pasta raiz utilizando `%let rootdir=/root path; %include "&rootdir/subfoldername/nome_arqquivo"`|Os diretórios de trabalho podem ser absolutos ou relativos a uma pasta raiz do projeto utilizando o pacote **here** (ver [Importar e exportar](#importing))
Veja o diretório de trabalho atual com `% de produção %sysfunc(getoption(work));`|Use `getwd()` ou `here()` (se utilizar o pacote **here**), com parênteses vazios
Definir diretório de trabalho com `libname "localização de pasta"` | Use `setwd("localização de pasta")`, ou `set_here("localização de pasta)` se utilizar o pacote **here**.


**Importando e visualizando dados**  

**SAS**                          | **R**  
-------------------------------- | ---------------------------------------------
Utilize o procedimento `Proc Importar' ou utilize a declaração `Data Step Infile'.|Utilize a função `import()` do pacote **rio** para quase todos os tipos de arquivos. Existem funções específicas como alternativas (ver [Importar e exportar](#importing)).
A leitura em arquivos csv é feita utilizando `Proc Import datafile="nome_arqquivo.csv" out=work.nome_arqquivo dbms=CSV; run;` ou usando [Data Step Infile statement](http://support.sas.com/techsup/technote/ts673.pdf)|Use `import("nome_arqquivo.csv")`
A leitura em arquivos xslx é feita utilizando `Proc Import datafile="nome_arqquivo.xlsx" out=work.nome_arqquivo dbms=xlsx; run;` ou usando [Data Step Infile statement](http://support.sas.com/techsup/technote/ts673.pdf)|Use import("nome_arqquivo.xlsx")
Navegue pelos seus dados em uma nova janela abrindo a janela do Explorer e selecione a biblioteca desejada e o conjunto de dados|Veja um conjunto de dados no painel de fontes do RStudio usando View(dataset). Você precisa especificar o nome de seu conjunto de dados para a função em R porque vários conjuntos de dados podem ser mantidos ao mesmo tempo. atenção para "V" maiúsculo nesta função

**Manipulações básicas de dados**  

**SAS**                          | **R**  
-------------------------------- | ---------------------------------------------
As colunas do conjunto de dados são frequentemente referidas como "variáveis"|Mais frequentemente referidas como "colunas" ou às vezes como "vetores" ou "variáveis".
Não são necessários procedimentos especiais para criar uma variável. Novas variáveis são criadas simplesmente digitando o novo nome da variável, seguido por um sinal de igual e, em seguida, uma expressão para o valor|Gere novas variáveis utilizando a função `mutate()`. Consulte a página [Limpeza de dadps e principais funções](#cleaning) para obter detalhes sobre todas as funções abaixo **dplyr**.
As variáveis são renomeadas utilizando `renome *nome_antigo=nome_novo*`| As colunas podem ser renomeadas utilizando a função `rename(novo_nome = nome_antigo)`
As variáveis são mantidas utilizando `**keep**=nome_var`|Colunas podem ser selecionadas utilizando a função `select()` com o nome da coluna entre parênteses
As variáveis são descartadas utilizando `**drop**=nome da coluna` | As colunas podem ser removidas utilizando a função `select()` com o nome da coluna entre parênteses, seguindo um sinal de subtração
As variáveis do tipo fator podem ser etiquetadas na Etapa de Dados, utilizando a declaração de 'Label' | Os valores do rótulo podem ser feitos convertendo a coluna para a classe Fator e especificando níveis. Veja a página em [Fatores](#factors). Os nomes das colunas não são tipicamente rotulados.
Os registros são selecionados utilizando a instrução `Where` ou `If` na Etapa de Dados. As condições de seleção múltipla são separadas utilizando o comando "and".| Os registros são selecionados utilizando a função `filter()` com condições de seleção múltipla separadas por um operador AND (&) ou por uma vírgula  
Os conjuntos de dados são combinados utilizando a declaração `Merge` na Etapa de Dados. Os conjuntos de dados a serem fundidos precisam ser ordenados primeiro utilizando o procedimento `Proc Sort`.|O pacote **dplyr** oferece algumas funções para fundir conjuntos de dados. Consulte a página [Agrupando Dados](#grouping) para obter detalhes.

**Análise descritiva**  

**SAS**                          | **R**  
-------------------------------- | ---------------------------------------------
Obtenha uma visão geral  do seu conjunto de dados utilizando o procedimento "Proc Summary", que fornece os nomes das variáveis e as estatísticas descritivas.| Obtenha uma visão geral do seu conjunto de dados utilizando o "summary(conjunto_de_dados)" ou "skimr(conjunto_de_dados)" do pacote **skimr**.
Tabular contagens de uma variável utilizando `proc freq data=Dataset; Tables varname; Run;`| Ver a página em [Tabelas descritivas](#tables-descriptive). As opções incluem `table()` do R **base**, e `tabyl()` do pacote **janitor** , entre outras. Observe que você precisará especificar o conjunto de dados e o nome da coluna, pois R contém vários conjuntos de dados.
A tabulação cruzada (tabela de contingência) de duas variáveis em uma tabela 2x2 é feita com `proc freq data=Dataset; Tables rowvar*colvar; Run;`|Novamente, você pode utilizar `table()`, `tabyl()` ou outras opções como descritas na página [Tabelas descritivas](#tables-descriptive).   

**Alguns recursos úteis:**  

[R para usuários de SAS e SPSS (2011)](https://www.amazon.com/SAS-SPSS-Users-Statistics-Computing/dp/1461406846/ref=sr_1_1?dchild=1&gclid=EAIaIQobChMIoqLOvf6u7wIVAhLnCh1c9w_DEAMYASAAEgJLIfD_BwE&hvadid=241675955927&hvdev=c&hvlocphy=9032185&hvnetw=g&hvqmt=e&hvrand=16854847287059617468&hvtargid=kwd-44746119007&hydadcr=16374_10302157&keywords=r+for+sas+users&qid=1615698213&sr=8-1)

[SAS e R, Segunda Edição (2014)](https://www.amazon.com/SAS-Management-Statistical-Analysis-Graphics-dp-1466584491/dp/1466584491/ref=dp_ob_title_bk)



## Interoperabilidade de dados   
<!-- ======================================================= -->

Veja a página [Importar e exportar](#importing) para detalhes sobre como o pacote **rio** do R pode importar e exportar arquivos como arquivos STATA .dta, arquivos SAS .xpt e.sas7bdat, arquivos SPSS .por e.sav, e muitos outros.   



```{r include=FALSE, cache=FALSE}

# clear workspace
rm(list = ls(all = TRUE))

# clear all packages except base
#lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))

# to ensure that tidyverse packages prevail
filter <- dplyr::filter
select <- dplyr::select
summarise <- dplyr::summarise
summary <- base::summary
incidence <- incidence2::incidence

#load core packages
pacman::p_load(
     rio,
     here,
     DT,
     stringr,
     lubridate,
     tidyverse
)

# import the cleaned ebola linelist
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

# import the count data - facility level
#count_data <- rio::import(here::here("data", "facility_count_data.rds"))

# Settings

options(scipen=1, digits=7)

# print only text (not code)
# library(knitr)
# opts_chunk$set(list(echo = FALSE, eval = FALSE))
```

<!--chapter:end:new_pages/transition_to_R.Rmd-->

# Pacotes sugeridos {#packages-suggested}

Abaixo está uma longa lista de pacotes sugeridos para trabalho epidemiológico comum em R. Você pode copiar este código, executá-lo, e todos estes pacotes serão instalados a partir de CRAN e carregados para uso na sessão R atual. Se um pacote já estiver instalado, ele será carregado apenas para uso.  

Você pode modificar o código com símbolos `#` para excluir qualquer pacote que não queira.  

Nota:  

* Instale primeiro o pacote **pacman** antes de executar o código abaixo. Você pode fazer isto com `install.packages("pacman")`. Neste manual, enfatizamos `p_load()` de **pacman**, que instala o pacote se necessário *e* o carrega para utilização na sessão R atual. Você também pode carregar pacotes que já estão instalados com `library()` a partir do R **base**.  
* No código abaixo, os pacotes que são incluídos ao instalar/carregar outro pacote são indicados por um travessão e *hashtag*. Por exemplo, como **ggplot2** está listado em **tidyverse**.  
* Se vários pacotes têm funções com o mesmo nome, o mascaramento (*masking*) das funções pode ocorrer entre os pacotes. Ou seja, quando a função do pacote mais recentemente carregado prevalece. Leia mais na página [Introdução ao R](#basics). Considere o uso do pacote **conflicted** para gerenciar tais conflitos.  
* Consulte a seção [Introdução ao R](#basics) sobre pacotes para mais informações sobre **pacman** e mascaramento.  

Para ver as versões dos pacotes R, RStudio e R utilizados durante a produção deste manual, veja a página em [Notas editoriais e técnicas](#editorial-style).  

## Pacotes do CRAN 

```{r, eval=F}

##########################################
# Lista de pscotes úteis para uso em epidemiologia#
##########################################

# Este script usa a função p_load() do pacote R pacman , 
# que  instala se o pacote estiver ausente, e os carrega para uso, se já estiverem instalados


# Garante que o pacman eestá instalado
if (!require("pacman")) install.packages("pacman")


# Pacotes disponíveis no CRAN
##############################
pacman::p_load(
     
     # aprendendo R
     ############
     learnr,   # tutoriais interativos no RStudio 
     swirl,    # tutoriais interetivos no console
        
     # manuseio de projetos e arquivos 
     #############################
     here,     # caminhos relativos de arquivos para a pasta raiz do projeto 
     rio,      # importar/exportar muitos formatos de arquivos
     openxlsx, # importar/exportar planilhas de Excel com várias abas 
     
     # manipulação e instalação de pacotes
     ################################
     pacman,   # instalação e carregamento de pacotes
     renv,     # manipulando versões de pacotes quando trabalhando em grupos 
     remotes,  # instalar pacotes do github 
     
     # Manipulação geral de dados
     #########################
     tidyverse,    # inlcui vários pacotes para arrumação,  manipulação e apresentação de dados. 
          #dplyr,      # manipulação de dados
          #tidyr,      # manipulação de dados
          #ggplot2,    # visualização de dados
          #stringr,    # trabalhar com strings e caracteres
          #forcats,    # trabalhar com fatores
          #lubridate,  # trabalhar com datas
          #purrr       # iteração e trabalhando com listas
     linelist,     # limpando linelists
     naniar,       # assessando valores ausentes
     
     # estatísticas
     ############
     janitor,      # tabelas e limpeza de dados
     gtsummary,    # fazendo tabelas estatísticas e descritivas
     rstatix,      #  fazer estatíticas e resumos rápidos 
     broom,        # arrumar resultados de regressões 
     lmtest,       # testes de razão de likelihood
     easystats,
          # parametros, # alternativa a limpar os resultados de regressões. 
          # see,        # alternativa para vizualizar gráfico de floresta. 
     
     # modelagem de epidemias
     ###################
     epicontacts,  # Analisando rede de transmissão t
     EpiNow2,      # Estimando Rt 
     EpiEstim,     # Estimando Rt 
     projections,  # Projeção de incidencia
     incidence2,   # Fazer epicurvas e manipular dados de incidência. 
     i2extras,     # Funções extra para pacote incidence2 
     epitrix,      # Funções epi úteis
     distcrete,    # Distribuições discretas com delay (atraso)
     
     
     # Gráficos - geral
     #################
     #ggplot2,         # incluso no tidyverse
     cowplot,          # combinando gráficos
     # patchwork,      #combinando gráficos (alternativa)     
     RColorBrewer,     # escala de cores
     ggnewscale,       # adicionar novos esquemas de cores

     
     # Gráficos - tipos específicos
     ########################
     DiagrammeR,       # diagramas utilizando linguagem DOT
     incidence2,       # curvas epidêmicas
     gghighlight,      # highlight um subset
     ggrepel,          # rótulos inteligentes
     plotly,           # gráficos interativos
     gganimate,        # gráficos animados

     
     # gis
     ######
     sf,               # manusear dados espaciais usado o formato Simple Feature 
     tmap,             # produzir mapas simples, funciona tanto com mapas estáticos ou interativos
     OpenStreetMap,    # adicionar base OSM num mapa ggplot
     spdep,            # estatística espacial
     
     # relatórios de rotina
     #################
     rmarkdown,        # produz arquivos em  PDFs, Word, Powerpoint e HTML 
     reportfactory,    # auto-organização de outputs de R Markdown
     officer,          # powerpoint
     
     # dashboards
     ############
     flexdashboard,    # converte um script R Markdown em um dashboard
     shiny,            # web apps interativo
     
     # tabelas para apresentação
     #########################
     knitr,            # Geração de relatório R Markdown e tabelas html 
     flextable,        # Tabelas HTML 
     #DT,              # Tabelas HTML  (alternativa)
     #gt,              # Tabelas HTML  (alternativa)
     #huxtable,        # Tabelas HTML  (alternativa)
     
     # phylogenetics
     ###############
     ggtree,           # visualização e de árvores filogenéticas 
     ape,              # análise e de filogenenia e evolução
     treeio            # visualizar arquivos de filogenia
 
)

```

## Pacotes do Github  

Abaixo estão os comandos para instalar dois pacotes diretamente dos repositórios Github.  

A versão de desenvolvimento de **epicontacts** contém a capacidade de fazer árvores de transmissão com um eixo x temporal  
O pacote **epirhandbook** contém todos os dados de exemplo para este manual e pode ser usado para baixar a versão offline do manual.  


```{r, eval=F}
# Pacotes para baixar do github (não estão disponíveis no CRAN)
##########################################################

# Versão de desenvolvimento de epicontacts (para cadeias de transmissão com tempo no  eixo x)
pacman::p_install_gh("reconhub/epicontacts@timeline")

# O pacote para este manual, que inclui todos os dados usados nos exemplos 
pacman::p_install_gh("appliedepi/epirhandbook")



```

```{r include=FALSE, cache=FALSE}

# clear workspace
rm(list = ls(all = TRUE))

# clear all packages except base
#lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))

# to ensure that tidyverse packages prevail
filter <- dplyr::filter
select <- dplyr::select
summarise <- dplyr::summarise
summary <- base::summary
incidence <- incidence2::incidence

#load core packages
pacman::p_load(
     rio,
     here,
     DT,
     stringr,
     lubridate,
     tidyverse
)

# import the cleaned ebola linelist
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

# import the count data - facility level
#count_data <- rio::import(here::here("data", "facility_count_data.rds"))

# Settings

options(scipen=1, digits=7)

# print only text (not code)
# library(knitr)
# opts_chunk$set(list(echo = FALSE, eval = FALSE))
```

<!--chapter:end:new_pages/packages_suggested.Rmd-->


# R projects {#r-projects}  


Um R project permite que seu trabalho seja agrupado em uma pasta portátil e independente. Dentro do projeto, todos os scripts, arquivos de dados, figuras / saídas e histórico relevantes são armazenados em subpastas e, mais importante, - o *diretório de trabalho* é a pasta raiz do projeto.  


## Uso sugerido  

Uma maneira comum, eficiente e sem problemas de usar R é combinar esses 3 elementos. Um projeto de trabalho discreto é hospedado em um R project. Cada elemento é descrito nas seções abaixo.  

1) Um projeto **R**  
     - Um ambiente de trabalho independente com pastas para dados, scripts, saídas, etc.  
2) O pacote **here** para caminhos de arquivo relativos  
     - Os caminhos de arquivo são gravados em relação à pasta raiz do R project - consulte [Importar e exportar](#importing) para obter mais informações  
3) O pacote **rio** para importação / exportação  
     - `import()` e `export()` manipulam qualquer tipo de arquivo por sua extensão (por exemplo, .csv, .xlsx, .png)  
     
     


<!-- ======================================================= -->
## Criação de um R project {}

Para criar um R project, selecione "Novo Projeto" no menu Arquivo.

* Se deseja criar uma nova pasta para o projeto, selecione "Novo diretório" e indique onde deseja que seja criado.  
* Se deseja criar o projeto dentro de uma pasta existente, clique em "Diretório existente" e indique a pasta.  
* Se você deseja clonar um repositório Github, selecione a terceira opção "Controle de Versão" e depois "Git". Veja a página em [Controle de versão e colaboração com Git e Github](#collaboration) para mais detalhes.  


```{r out.width = "75%", fig.align = "center", echo=F}
knitr::include_graphics(here::here("images", "create_project.png"))
```


O R project que você criar virá na forma de uma pasta contendo um arquivo *.Rproj*. Este arquivo é um atalho e provavelmente a principal maneira de abrir seu projeto. Você também pode abrir um projeto selecionando "Abrir Projeto" no menu Arquivo. Alternativamente, no canto superior direito do RStudio, você verá um ícone de R project e um menu suspenso de R projects disponíveis. 

Para sair de um R project, abra um novo projeto ou feche o projeto (Arquivo - Fechar Projeto).  


### Alternar projetos {.unnumbered}

Para alternar entre os projetos, clique no ícone do R project e no menu suspenso no canto superior direito do RStudio. Você verá opções para Fechar projeto, Abrir projeto e uma lista de projetos recentes.  

```{r out.width = "100%", fig.align = "center", echo=F}
knitr::include_graphics(here::here("images", "Rproject_dropdown.png"))
```


### Configurações {.unnumbered}  

Em geral, é aconselhável iniciar o RStudio a cada vez com uma "lousa em branco" - ou seja, com sua área de trabalho **não** preservada da sessão anterior. Isso significa que seus objetos e resultados não persistirão de sessão para sessão (você deve recriá-los executando seus scripts). Isso é bom, porque o forçará a escrever scripts melhores e evitará erros no longo prazo.  

Para configurar o RStudio para ter uma "lista limpa" a cada vez na inicialização:  

* Selecione "Opções de projeto" no menu Ferramentas.  
* Na guia "Geral", defina o RStudio para **não** restaurar .RData na área de trabalho na inicialização e para **não** salvar a área de trabalho em .RData ao sair.  



### Organização {.unnumbered}  

É comum ter subpastas em seu projeto. Considere ter pastas como "dados", "scripts", "figuras", "apresentações". Você pode adicionar pastas da maneira típica que faria com uma nova pasta para o seu computador. Como alternativa, consulte a página em [Interações de diretório](#directories) para saber como criar novas pastas com comandos R.  


### Controle de versão {.unnumbered}  

Considere um sistema de controle de versão. Pode ser algo tão simples como ter datas nos nomes dos scripts (por exemplo, "transmission_analysis_2020-10-03.R") e uma pasta de "arquivo". Considere também ter um texto de cabeçalho comentado na parte superior de cada script com uma descrição, tags, autores e log de alterações.  

Um método mais complicado envolveria o uso do Github ou uma plataforma semelhante para controle de versão. Veja a página em [Controle de versão e colaboração com Git e Github](#collaboration).  

Uma dica é que você pode pesquisar um projeto ou pasta inteira usando a ferramenta "Localizar nos arquivos" (menu Editar). Ele pode pesquisar e até mesmo substituir strings em vários arquivos.  






## Exemplos  

Abaixo estão alguns exemplos de importação / exportação / salvamento usando `here()` de dentro de um R project. Leia mais sobre como usar o pacote **here** na página [Importar e exportar](#importing).  


*Importando `linelist_raw.xlsx` da pasta" data "em seu R project*  

```{r, eval=F}
linelist <- import(here("data", "linelist_raw.xlsx"))
```

*Exportando o objeto R `linelist` como" my_linelist.rds "para a pasta" clean "dentro da pasta" data "em seu R project.*   

```{r, eval=F}
export(linelist, here("data","clean", "my_linelist.rds"))
```

*Salvar o gráfico impresso mais recentemente como "epicurve_2021-02-15.png" dentro da pasta "epicurves" na pasta "saídas" em seu R project.*  

```{r, eval=F}
ggsave(here("outputs", "epicurves", "epicurve_2021-02-15.png"))
```




<!-- ======================================================= -->
## Recursos {}

Página da web do RStudio em [usando R projects](https://support.rstudio.com/hc/en-us/articles/200526207-Using-Projects)



```{r include=FALSE, cache=FALSE}

# clear workspace
rm(list = ls(all = TRUE))

# clear all packages except base
#lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))

# to ensure that tidyverse packages prevail
filter <- dplyr::filter
select <- dplyr::select
summarise <- dplyr::summarise
summary <- base::summary
incidence <- incidence2::incidence

#load core packages
pacman::p_load(
     rio,
     here,
     DT,
     stringr,
     lubridate,
     tidyverse
)

# import the cleaned ebola linelist
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

# import the count data - facility level
#count_data <- rio::import(here::here("data", "facility_count_data.rds"))

# Settings

options(scipen=1, digits=7)

# print only text (not code)
# library(knitr)
# opts_chunk$set(list(echo = FALSE, eval = FALSE))
```

<!--chapter:end:new_pages/r_projects.Rmd-->

# Importar e exportar {#importing}


```{r, out.width=c('100%'), echo=F, message=F}
knitr::include_graphics(here::here("images", "Import_Export_1500x500.png"))
```



Nesta página descrevemos formas de localizar, importar e exportar arquivos:  

* Utilização do pacote **rio** para flexivelmente `import()` e `export()` muitos tipos de arquivos  
* Uso do pacote **here** para localizar arquivos relativos a uma raiz de projeto R - para evitar complicações de caminhos de arquivos que são específicos de um computador  
* Cenários específicos de importação, como por exemplo:  
  * Planilhas específicas do Excel  
  * Cabeçalhos confusos e linhas para pular  
  * Planilhas do Google  
  * A partir de dados postados em websites  
  * Com APIs  
  * Importação do arquivo *mais recente*  
* Entrada manual de dados  
* Tipos de arquivos específicos de R, como RDS e RData  
* Exportar / salvar arquivos e gráficos



<!-- ======================================================= -->
## Visão geral

Quando você importa um "conjunto de dados" para o R, você geralmente está criando um novo objeto do tipo *data frame* em seu ambiente R e definindo-o como um arquivo importado (por exemplo, Excel, CSV, TSV, RDS) que está localizado em suas pastas em um determinado caminho/endereço de arquivo.  

Você pode importar/exportar muitos tipos de arquivos, inclusive aqueles criados por outros programas estatísticos (SAS, STATA, SPSS). Você também pode se conectar a bancos de dados relacionais.  

R tem até seus próprios formatos de dados:  

* Um arquivo RDS (.rds) armazena um único objeto R, como um data frame. Estes são úteis para armazenar dados limpos, pois eles mantêm as classes de colunas R. Leia mais em [esta seção](#import_rds).    
* Um arquivo RData (.Rdata) pode ser usado para armazenar vários objetos, ou mesmo um espaço de trabalho R completo. Leia mais em [esta seção](#import_rdata).  

<!-- ======================================================= -->
## O pacote **rio** {}  

O pacote R que recomendamos é: **rio**. O nome "rio" é uma abreviação de "R I/O" (input/output ).

Suas funções `import()` e `export()` podem lidar com muitos tipos diferentes de arquivos (por exemplo, .xlsx, .csv, .rds, .tsv). Quando você fornece um caminho de arquivo para qualquer uma destas funções (incluindo a extensão do arquivo como ".csv"), **rio** lerá a extensão e utilizará a ferramenta correta para importar ou exportar o arquivo.  

A alternativa ao uso do **rio** é usar funções de muitos outros pacotes, cada um dos quais é específico para um tipo de arquivo. Por exemplo, `read.csv()` (R **base** ), `read.xlsx()` (**openxlsx** pacote), e `write_csv()` (**readr** pacakge), etc. Estas alternativas podem ser difíceis de lembrar, enquanto que utilizar `import()` e `export()` de **rio*** é fácil.  

As funções do **rio** `import()` e `export()` utilizam o pacote e função apropriados para um determinado arquivo, com base em sua extensão. Veja no final desta página uma tabela completa de quais pacotes/funções **rio** utilizam em segundo plano. Ele também pode ser utilizado para importar arquivos STATA, SAS e SPSS, entre dezenas de outros tipos de arquivos.  

A importação/exportação de *shapefiles* (para mapas) requer outros pacotes, conforme detalhado na página sobre [GIS básico](#gis).   


## O pacote **here** {#here}

O pacote **here** e sua função `here()` tornam fácil dizer a R onde encontrar e salvar seus arquivos - em essência, ele constrói os caminhos dos arquivos.  

Utilizado em conjunto com um projeto R, **here** permite descrever a localização dos arquivos em seu projeto R em relação ao diretório *root do projeto R* (a pasta de nível superior). Isto é útil quando o projeto R pode ser compartilhado ou acessado por várias pessoas/computadores. Ele evita complicações devido aos caminhos exclusivos dos arquivos em diferentes computadores (por exemplo, `"C:/Users/Laura/Documents...'', "iniciando" o caminho do arquivo em um lugar comum a todos os usuários (a raiz do projeto R).  

É assim como `here()` funciona dentro de um projeto R:  

* Quando o pacote **here** é carregado pela primeira vez dentro do projeto R, ele coloca um pequeno arquivo chamado ".here" na pasta raiz de seu projeto R como um "*benchmark*" ou "âncora".  
* Em seus scripts, para referenciar um arquivo nas subpastas do projeto R, você utiliza a função `here()` para construir o caminho do arquivo *em relação a essa âncora*.
* Para construir o caminho do arquivo, escreva os nomes das pastas além da raiz, entre aspas, separados por vírgulas, finalmente terminando com o nome do arquivo e a extensão do arquivo, como mostrado abaixo  
* Caminhos de arquivos com a função 'here()`  podem ser utilizados tanto para importação quanto para exportação  

Por exemplo, abaixo, a função `import()` está sendo fornecida um caminho de arquivo construído com `here()`.   

```{r, eval=F}
linelist <- import(here("data", "linelists", "ebola_linelist.xlsx"))
```

O comando `here("data", "linelists", "ebola_linelist.xlsx")` está na verdade fornecendo o caminho completo do arquivo que é *único para o computador do usuário*:  

```
"C:/Users/Laura/Documents/my_R_project/data/linelists/ebola_linelist.xlsx"
```

A beleza é que o comando R utilizando `here()` pode ser executado com sucesso em qualquer computador que acesse o projeto R.  


<span style="color: darkgreen;">**_DICA:_**  Se você não tiver certeza de onde a raiz ".here" está definida, execute a função `here()` com parênteses vazios.</span>  

Leia mais sobre o pacote **here** [neste link](https://here.r-lib.org/).  



<!-- ======================================================= -->
## Caminhos dos arquivos

Ao importar ou exportar dados, você deve fornecer um caminho para o arquivo. Você pode fazer isso de três maneiras:  

1) *Recomendado:* fornecer um caminho de arquivo "relativo" com o pacote **here**
2) Fornecer o caminho "completo" / "absoluto" do arquivo  
3) Seleção manual do arquivo  



### Caminhos 'relativo' dos arquivos {.unnumbered}

No R, os caminhos de arquivo "relativos" consistem no caminho de arquivo *relativo à* raiz de um projeto R. Eles permitem caminhos de arquivo mais simples que podem funcionar em computadores diferentes (por exemplo, se o projeto R estiver em um drive compartilhado ou for enviado por e-mail). Como descrito [acima](#here), os caminhos de arquivo relativos são facilitados pelo uso do pacote **here**.  

Um exemplo de um caminho de arquivo relativo construído com `here()` está abaixo. Supomos que o trabalho esteja em um projeto R que contém uma subpasta "dados" e dentro dela uma subpasta "linelists", na qual há o arquivo .xlsx de interesse.    

```{r, eval=F}
linelist <- import(here("dados", "linelists", "ebola_linelist.xlsx"))
```



### Caminhos 'absoluto' dos arquivos {.unnumbered}  

Caminhos de arquivo absolutos ou "completos" podem ser fornecidos para funções como `import()` mas são "frágeis", pois são exclusivos para o computador específico do usuário e portanto *não são recomendados*. 

Abaixo está um exemplo de um caminho de arquivo absoluto, onde no computador de Laura há uma pasta "analises", uma subpasta "dados" e dentro dela uma subpasta "linelists", na qual há o arquivo .xlsx de interesse.  

```{r, eval=F}
linelist <- import("C:/Users/Laura/Documents/analises/dados/linelists/ebola_linelist.xlsx")
```

Algumas coisas a serem observadas sobre os caminhos absolutos dos arquivos:  

* **Evite o uso de caminhos de arquivo absolutos**, pois eles quebrarão se o script for executado em um computador diferente.
* Utilize barras normais (`/`), como no exemplo acima (nota: este é *NÃO* o padrão para caminhos de arquivos do Windows)  
* Os caminhos de arquivos que começam com barras duplas (por exemplo, "//...") provavelmente **não serão reconhecidos por R** e produzirão um erro. Considere mover seu trabalho para uma unidade  "nomeado" ou " com letras" que comece com uma letra (por exemplo, "J:" ou "C:"). Consulte a página em [Interações do diretório](#directories) para obter mais detalhes sobre este assunto.  

Um cenário onde caminhos de arquivo absolutos podem ser apropriados é quando você deseja importar um arquivo de um drive compartilhado que tenha o mesmo caminho de arquivo completo para todos os usuários.  

<span style="color: darkgreen;">**_DICA:_** Para converter rapidemente todas as barras invertidas `\` em barras normais `/`, destaque o código de interesse, use Ctrl+f (no Windows), selecione a caixa de opção "Em seleção" (*In selection*), e depois usar a funcionalidade de substituição para convertê-los.</span>  



<!-- ======================================================= -->
### Selecionando um arquivo manualmente {.unnumbered}

Você pode importar dados manualmente por meio de um destes métodos:  

1) Painel Ambiente (*Environment*) do RStudio, clique em "Importar Dados"  (*Import Dataset*), e selecione o tipo de dado
2) Clique em File / Import Dataset / (selecione o tipo de dados)  
3) Para seleção manual por código, utilize o comando do R *base* `file.choose()` (deixando os parênteses vazios) para acionar a aparência de uma janela **pop-up** que permite ao usuário selecionar manualmente o arquivo de seu computador. Por exemplo:  

```{r import_choose, eval=F}
# Seleção manual de um arquivo. Quando este comando for executado, uma janela POP-UP aparecerá. 
# O caminho do arquivo selecionado será fornecido ao comando import().

my_data <- import(file.choose())
```

<span style="color: darkgreen;">**_DICA:_** A **janela pop-up window** pode aparecer ATRÁS di seu RStudio.</span>



## Importar dados

Utilizar `import()` para importar um conjunto de dados é bastante simples. Basta fornecer o caminho para o arquivo (incluindo o nome do arquivo e a extensão do arquivo) entre aspas. Se utilizar `here()` para construir o caminho do arquivo, siga as instruções acima. Abaixo estão alguns exemplos:  

Importar um arquivo csv que está localizado em seu "diretório de trabalho" ou na pasta raiz do projeto R:  

```{r, eval=F}
linelist <- import("linelist_cleaned.csv")
```


Importação da primeira planilha de uma pasta de trabalho do Excel que está localizada nas subpastas "dados" e "linelists" do projeto R (o caminho do arquivo construído utilizando `here()`):  

```{r, eval=F}
linelist <- import(here("dados", "linelists", "linelist_cleaned.xlsx"))
```

Importação de um  "quadro de dados" ( referido nesse livro como *data frame*)(um arquivo .rds) usando um caminho de arquivo absoluto:  

```{r, eval=F}
linelist <- import("C:/Users/Laura/Documents/tuberculosis/data/linelists/linelist_cleaned.rds")
```



### Planilhas específicas do Excel {.unnumbered}

Por padrão, se você fornecer uma pasta de trabalho Excel (.xlsx) para a função `import()`, a primeira planilha da pasta de trabalho será importada. Se você quiser importar uma **aba** (*sheet*) específica, inclua o nome da planilha ao `which = ` argument. Por exemplo:  

```{r eval=F}
my_data <- import("my_excel_file.xlsx", which = "Sheetname")
```

Se utilizar o método `here()` para fornecer um caminho relativo para `import()`, você ainda pode indicar uma aba específica adicionando o `which = ` argumento depois dos parênteses de fechamento da função `here()`.      

```{r import_sheet_here, eval=F}
# Demonstração: importação de uma planilha específica do Excel ao utilizar caminhos relativos com o pacote 'here'.  

linelist_raw <- import(here("data", "linelist.xlsx"), which = "Sheet1")`  
```

Para *exportar* um *data frame* do R para uma planilha específica do Excel e ter o resto da pasta de trabalho do Excel inalterado, você terá que importar, editar e exportar com um pacote alternativo criado para este propósito, como **openxlsx***. Veja mais informações na página em [Interações do diretório](#directories) ou [nesta página do github](https://ycphs.github.io/openxlsx/).

Se sua pasta de trabalho Excel for .xlsb (pasta de trabalho Excel em formato binário) você talvez não consiga importá-la usando **rio**. Considere a possibilidade de salvá-la como .xlsx, ou usando um pacote como **readxlsb*** que é construído para [este propósito](https://cran.r-project.org/web/packages/readxlsb/vignettes/read-xlsb-workbook.html).  


<!-- ======================================================= -->
### Valores faltantes {#import_missing .unnumbered} 

Você pode querer designar que valor(es) em seu conjunto de dados que deve(m) ser considerado(s) como ausente(s)/faltante(s). Como explicado na página em [Dados faltantes](#missing-data), o valor em R para dados ausentes é `NA`, mas talvez o conjunto de dados que você deseja importar utilize 99, "Ausente", ou apenas espaço vazio de caracteres "" em vez disso.  

Utilize o `na = ` argumento para `import()` e forneça o(s) valor(es) entre aspas (mesmo que sejam números). Você pode especificar múltiplos valores incluindo-os dentro de um vetor, utilizando `c()` como mostrado abaixo.  

Aqui, o valor "99" no conjunto de dados importados é considerado ausente e convertido para `NA` em R.

```{r, eval=F}
linelist <- import(here("data", "my_linelist.xlsx"), na = "99")
```

Qualquer um dos valores "Missing", "" (célula vazia), ou "" (espaço único) no conjunto de dados importados são convertidos para `NA` no R.  

```{r, eval=F}
linelist <- import(here("data", "my_linelist.csv"), na = c("Missing", "", " "))
```


<!-- ======================================================= -->
### Pular linhas {.unnumbered} 

Às vezes, você pode querer evitar a importação de uma linha específica de dados. Você pode fazer isso com o argumento `skip = ` se utilizar `import()` de **rio** em um arquivo .xlsx ou .csv. Forneça o número de linhas que você deseja pular. 

```{r, eval=F}
linelist_raw <- import("linelist_raw.xlsx", skip = 1)  # Não importa a linha de cabeçalho
```

Infelizmente 'skip = 'aceita apenas um valor inteiro, *não* um intervalo (por exemplo, "2:10" não funciona). Para pular a importação de linhas específicas que não são consecutivas do topo, considere importar várias vezes e utilizar `bind_rows()` a partir de **dplyr***. Veja o exemplo abaixo de pular apenas a linha 2.  


### Como lidar com uma segunda linha de cabeçalho {.unnumbered}  

Às vezes, seus dados podem ter uma *segunda* linha de cabeçalho, por exemplo, se for uma linha de "dicionário de dados", como mostrado abaixo. Esta situação pode ser problemática porque pode resultar na importação de todas as colunas como a classe "caractere".

```{r, echo=F}
# HIDDEN FROM READER
####################
# Create second header row of "data dictionary" and insert into row 2. Save as new dataframe.
linelist_2headers <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds")) %>%         
        mutate(across(everything(), as.character)) %>% 
        add_row(.before = 1,
                #row_num = "000",
                case_id = "case identification number assigned by MOH",
                generation = "transmission chain generation number",
                date_infection = "estimated date of infection, mm/dd/yyyy",
                date_onset = "date of symptom onset, YYYY-MM-DD",
                date_hospitalisation = "date of initial hospitalization, mm/dd/yyyy",
                date_outcome = "date of outcome status determination",
                outcome = "either 'Death' or 'Recovered' or 'Unknown'",
                gender = "either 'm' or 'f' or 'unknown'",
                hospital = "Name of hospital of first admission",
                lon = "longitude of residence, approx",
                lat = "latitude of residence, approx",
                infector = "case_id of infector",
                source = "context of known transmission event",
                age = "age number",
                age_unit = "age unit, either 'years' or 'months' or 'days'",
                fever = "presence of fever on admission, either 'yes' or 'no'",
                chills = "presence of chills on admission, either 'yes' or 'no'",
                cough = "presence of cough on admission, either 'yes' or 'no'",
                aches = "presence of aches on admission, either 'yes' or 'no'",
                vomit = "presence of vomiting on admission, either 'yes' or 'no'",
                time_admission = "time of hospital admission HH:MM")
```

Abaixo está um exemplo deste tipo de conjunto de dados (sendo a primeira linha o dicionário de dados).  

```{r message=FALSE, echo=F}
# Exibe a linelist como uma tabela
DT::datatable(head(linelist_2headers, 5), rownames = FALSE, filter="top", options = list(pageLength = 4, scrollX=T), class = 'white-space: nowrap' )
```

#### Remover uma segunda linha de cabeçalho {.unnumbered}  

Para ignorar a segunda linha de cabeçalho, você provavelmente precisará importar os dados duas vezes.  

1) Importar os dados para armazenar os nomes corretos das colunas  
2) Importar os dados novamente, pulando as primeiras *duas* fileiras (cabeçalho e segunda fileira)  
3) Ligar os nomes corretos no campo de dados reduzido

O argumento exato usado para ligar os nomes corretos das colunas depende do tipo de arquivo de dados (.csv, .tsv, .xlsx, etc.). Isto porque **rio** está usando uma função diferente para os diferentes tipos de arquivo (ver tabela acima).  

**Para arquivos Excel:** (`col_names = `)  

```{r, eval=F}
# importe a primeira vez; salve o nome das colunas
linelist_raw_names <- import("linelist_raw.xlsx") %>% names()  # Salva o nome veradeiro das colunas

# Importe uma segunda vez; pule a segunda linha e designe os nomes das colunas para o argumento col_names =
linelist_raw <- import("linelist_raw.xlsx",
                       skip = 2,
                       col_names = linelist_raw_names
                       ) 
```

**Para arquivos CSV:** (`col.names = `)  

```{r, eval=F}
# importe a primeira vez; salve o nome das colunas
linelist_raw_names <- import("linelist_raw.csv") %>% names() # salve o nome verdadeiro das colunas

# note que o argumento para arquivos csv é 'col.names = '
linelist_raw <- import("linelist_raw.csv",
                       skip = 2,
                       col.names = linelist_raw_names
                       ) 
```

**Opção de Backup ** - atribuir/sobreescrever cabeçalhos usando a função 'colnames()' do base

```{r, eval=F}
# assign/overwrite headers using the base 'colnames()' function
colnames(linelist_raw) <- linelist_raw_names
```


#### Fazendo um dicionário de dados {.unnumbered}  

Bônus! Se você tiver uma segunda linha que seja um dicionário de dados, você pode facilmente criar um dicionário de dados adequado a partir dele. Esta dica é adaptada a partir deste [post](https://alison.rbind.io/post/2018-02-23-read-multiple-header-rows/).    


```{r}
dict <- linelist_2headers %>%             # começa: linelist com um dicionário como a primeira linha
  head(1) %>%                             # mantenha apenas os nomes das colunas e a primeira linha com o dicionário               
  pivot_longer(cols = everything(),       # faça o pivotamento de todas as coluna spara o formato "longo" 
               names_to = "Column",       # nomeie as colunas
               values_to = "Description")
```


```{r message=FALSE, echo=F}
DT::datatable(dict, rownames = FALSE, filter="top", options = list(pageLength = 4, scrollX=T), class = 'white-space: nowrap' )
```



#### Combinar duas linhas de cabeçalho {.unnumbered}  

Em alguns casos, quando seu conjunto de dados brutos tiver *duas* linhas de cabeçalho (ou mais especificamente, a segunda linha de dados é um cabeçalho secundário), você pode querer "combiná-las" ou adicionar os valores da segunda linha de cabeçalho à primeira linha de cabeçalho.  

O comando abaixo definirá os nomes das colunas do *data frame* como a combinação (colando em conjunto) dos primeiros cabeçalhos (verdadeiros) com o valor imediatamente abaixo (na primeira linha). 

```{r, eval=F}
names(my_data) <- paste(names(my_data), my_data[1, ], sep = "_")
```



<!-- ======================================================= -->
### Planilhas do Google {.unnumbered}

Você pode importar dados de uma planilha on-line do Google com o pacote **googlesheet4** e autenticando seu acesso à planilha.  


```{r, eval=F}
pacman::p_load("googlesheets4")
```

Abaixo, uma planilha de demonstração do Google é importada e salva. Este comando pode solicitar a confirmação da autenticação de sua conta Google. Siga as instruções e pop-ups em seu navegador de internet para conceder permissões aos pacotes Tidyverse API para editar, criar e excluir suas planilhas no Google Drive.  


A planilha abaixo é "visualizável para qualquer pessoa com o link" e você pode tentar importá-la.  

```{r, eval=F}
Gsheets_demo <- read_sheet("https://docs.google.com/spreadsheets/d/1scgtzkVLLHAe5a6_eFQEwkZcc14yFUx1KgOMZ4AKUfY/edit#gid=0")
```

A planilha também pode ser importada usando apenas a identificação da planilha, uma parte mais curta da URL:  

```{r, eval=F}
Gsheets_demo <- read_sheet("1scgtzkVLLHAe5a6_eFQEwkZcc14yFUx1KgOMZ4AKUfY")
```

Outro pacote, **googledrive** oferece funções úteis para escrever, editar e excluir planilhas do Google. Por exemplo, utilizando as funções `gs4_create()` e `sheet_write()` encontradas neste pacote. 

Aqui estão alguns outros tutoriais on-line úteis:  
[tutorial básico de importação de planilhas do Google](https://arbor-analytics.com/post/getting-your-data-into-r-from-google-sheets/)  
[tutorial mais detalhado](https://googlesheets4.tidyverse.org/articles/googlesheets4.html)  
[interação entre as googlesheets4 e tidyverse](https://googlesheets4.tidyverse.org/articles/articles/drive-and-sheets.html)  



## Múltiplos arquivos- importar, exportar, dividir, combinar  

Veja a página em [Iteração, loops e listas](#iteration) para exemplos de como importar e combinar vários arquivos, ou vários arquivos de pastas de trabalho Excel. Essa página também tem exemplos de como dividir um data frame em partes e exportar cada uma separadamente, ou como planilhas nomeadas em uma pasta de trabalho do Excel.  




<!-- ======================================================= -->
## Importar do GitHub {#import_github}

A importação de dados diretamente do Github para R pode ser muito fácil ou pode exigir alguns passos - dependendo do tipo de arquivo. Abaixo estão algumas abordagens:  

### Arquivos CSV {.unnumbered}  

Pode ser fácil importar um arquivo .csv diretamente do Github para R com um comando R.  

1) Vá até o repositório Github, localize o arquivo de interesse e clique sobre ele  
3) Clique no botão "Raw" (você verá então os dados "brutos" do csv, como mostrado abaixo)  
4) Copiar a URL (endereço web)  
5) Colocar a URL entre aspas dentro do comando `import()` no R  

```{r, out.width=c('100%', '100%'), fig.align = "left", echo=F}
knitr::include_graphics(here::here("images", "download_csv_raw.png"))
```

### Arquivo XLSX {.unnumbered}  

Talvez você não consiga visualizar os dados "Raw" de alguns arquivos (por exemplo, .xlsx, .rds, .nwk, .shp)  

1) Vá até o repositório Github, localize o arquivo de interesse e clique sobre ele  
2) Clique no botão "Download", como mostrado abaixo  
3) Salve o arquivo em seu computador, e importe-o para o R  


```{r , out.width=c('100%', '100%'), fig.align = "left", echo=F}
knitr::include_graphics(here::here("images", "download_xlsx.png"))
```

### Shapefiles {.unnumbered} 

Os shapefiles têm muitos sub-componentes, cada um com uma extensão de arquivo diferente. Um arquivo terá a extensão ".shp", mas outros podem ter ".dbf", ".prj", etc.  Para baixar um shapefile do Github, você precisará baixar cada um dos arquivos de subcomponentes individualmente, e salvá-los na *mesma* pasta  em seu computador. No Github, clique em cada arquivo individualmente e faça o download deles clicando no botão "Download".  

Uma vez salvo em seu computador, você pode importar o shapefile como mostrado na página [GIS básico](#gis) utilizando `st_read()` do pacote **sf**. Você só precisa fornecer o caminho do arquivo e o nome do arquivo ".shp" - desde que os outros arquivos relacionados estejam dentro da mesma pasta em seu computador.  

Abaixo, você pode ver como o shapefile "sle_adm3" consiste de muitos arquivos - cada um dos quais deve ser baixado do Github.  

```{r , out.width=c('100%', '100%'), fig.align = "left", echo=F}
knitr::include_graphics(here::here("images", "download_shp.png"))
```





<!-- ======================================================= -->
## Inserir dados munualmente {}

### Inserção por linhas {.unnumbered}  

Utilize a função `tribble` do pacote **tibble** do tidyverse ([referência online tibble](https://tibble.tidyverse.org/reference/tribble.html)).  
  
Observe como os cabeçalhos das colunas começam com um *til* (`~`).  Observe também que cada coluna deve conter apenas uma classe de dados (caractere, numérico, etc.). Você pode utilizar abas, espaçamento e novas linhas para tornar a entrada de dados mais intuitiva e legível. Os espaços não importam entre os valores, mas cada linha é representada por uma nova linha de código. Por exemplo: 

```{r import_manual_row}
# Crie um conjunto de dados manualmente por linha
manual_entry_rows <- tibble::tribble(
  ~colA, ~colB,
  "a",   1,
  "b",   2,
  "c",   3
  )
```

A agora nós exibimos o novo *data frame*::  

```{r, echo=F}
# exibe o novo data frame
DT::datatable(manual_entry_rows)
```


### Inserção por colunas {.unnumbered}  

Como um data frame consiste em vetores (colunas verticais), a abordagem **base** para a criação manual de data frames no R espera que você defina cada coluna e depois as vincule juntas. Isto pode ser contra-intuitivo em epidemiologia, pois geralmente pensamos em nossos dados em linhas (como acima). 

```{r import_manual_col}
# definir cada vetor (coluna vertical) separadamente, cada um com seu próprio nome
PatientID <- c(235, 452, 778, 111)
Treatment <- c("Yes", "No", "Yes", "Yes")
Death     <- c(1, 0, 1, 0)
```

<span style="color: orange;">**_CUIDADO:_** Todos os vetores devem ter o mesmo comprimento (mesmo número de valores).</span>

The vectors can then be bound together using the function `data.frame()`:  

```{r}
# combine as colunas em um *data frame*, referenciando os nomes dos vetores
manual_entry_cols <- data.frame(PatientID, Treatment, Death)
```

E agora vamos vizualizar o novo conjunto de dados:

```{r, echo=F}
# exibe o novo data frame
DT::datatable(manual_entry_cols)
```




### Colando a partir da área de transferência {.unnumbered}  

Se você copiar dados de outro lugar e os tem na "área de transferência" (*clipboard*), você pode tentar uma das duas maneiras abaixo:  

Do pacote **clipr***, você pode utilizar `read_clip_tbl()` para importar como um data frame, ou apenas `read_clip()` para importar como um vetor de caracteres. Em ambos os casos, deixe os parênteses vazios.     

```{r, eval=F}
linelist <- clipr::read_clip_tbl()  # importa a área de transferência atual como uma data frame
linelist <- clipr::read_clip()      # importa como um vetor de caracteres
```
Você também pode exportar facilmente para a área de transferência do seu sistema com **clipr***. Veja a seção abaixo sobre Exportação.  


Alternativamente, você pode utilizar a função `read.table()` do R **base**  com `file = "clipboard")` para importar como um *data frame*:  

```{r, eval=F}
df_from_clipboard <- read.table(
  file = "clipboard",  # specify this as "clipboard"
  sep = "t",           # separator could be tab, or commas, etc.
  header=TRUE)         # if there is a header row
```



## Importar o arquivo mais recente

Muitas vezes você pode receber atualizações diárias de seus conjuntos de dados. Neste caso, você vai querer escrever o código que importa o arquivo mais recente. A seguir, apresentamos duas formas de abordar este assunto:  

* Selecionando o arquivo com base na data no nome do arquivo  
* Seleção do arquivo com base nos metadados do arquivo (última modificação)  


### Datas no nome de um arquivo {.unnumbered}  

Esta abordagem depende de três premissas:  

1) Você confia nas datas nos nomes dos arquivos  
2) As datas são numéricas e aparecem em *geralmente* no mesmo formato (por exemplo, ano, mês e dia)  
3) Não há outros números no nome do arquivo  

Explicaremos cada passo e, no final, mostraremos a combinação deles.  

Primeiro, utilize `dir()` do R **base** para extrair apenas os nomes dos arquivos para cada arquivo na pasta de interesse. Consulte a página em [Interações de diretório](#directories) para obter mais detalhes sobre `dir()`. Neste exemplo, a pasta de interesse é a pasta "linelists" dentro da pasta "exemplo" dentro de "data" dentro do projeto R.

```{r}
linelist_filenames <- dir(here("data", "example", "linelists")) # pega o nome dos arquivos da pasta
linelist_filenames                                              # exibe 
```

Uma vez que você tenha este vetor de nomes, você pode extrair as datas a partir deles aplicando `str_extract()` de **stringr** utilizando esta expressão regular. Ela extrai quaisquer números no nome do arquivo (incluindo quaisquer outros caracteres no meio, tais como traços ou cortes). Você pode ler mais sobre **stringr*** na página [Strings e caracteres](#characters-strings).  

```{r}
linelist_dates_raw <- stringr::str_extract(linelist_filenames, "[0-9].*[0-9]") # extrai números e quaisquer caracteres no meio
linelist_dates_raw  # print
```

Assumindo que as datas são escritas geralmente no mesmo formato (por exemplo, Ano e depois Mês e depois Dia) e os anos têm 4 dígitos, você pode utilizar **lubridate**'s funções flexíveis de conversão (`ymd()`, `dmy()`, ou `mdy()`) para convertê-las em datas. Para estas funções, os traços, espaços ou cortes não importam, apenas a ordem dos números. Leia mais na página [Trabalhando com datas](#dates).  

```{r}
linelist_dates_clean <- lubridate::ymd(linelist_dates_raw)
linelist_dates_clean
```


A função do R **base** `which.max()` pode então ser utilizada para retornar a posição do índice (por exemplo, 1º, 2º, 3º, ...) do valor máximo da data. O último arquivo é corretamente identificado como o 6º arquivo - "case_linelist_2020-10-08.xlsx".  

```{r}
index_latest_file <- which.max(linelist_dates_clean)
index_latest_file
```

Se nós condensarmos todos esses comandos, o cógico compelto deve parecer com o abaixo. Observe que o `.` na ultima linha é um marcador para o objeto pipe naquele ponta da sequência de pipes. Naquele ponto o valor é implesmente o número 6. Isso é colocado entre cochetes para extrair o sexto elemnto do vetor de nomes do arquivo produzido por `dir()`.    

```{r}
# carrega os pacotes
pacman::p_load(
tidyverse,           # manipulação  de dados
  stringr,           # trabalha com strings/caravteres
  lubridate,         # trabalha com datas
  rio,               # importar / exportar
  here,              # caminhos relativos dos arquivos
  fs)                # interações entre diretórios

# extrai o nome do arquivo mais recente
latest_file <- dir(here("data", "example", "linelists")) %>%  # nomes dos aequivos da subpasta "linelists"         
  str_extract("[0-9].*[0-9]") %>%                  # extrai as datas (números)
  ymd() %>%                                        # converte números pra datas (assumindo o formato ano-mês-dia)
  which.max() %>%                                  # pega o índice da maior data (arquivo mais recente) 
  dir(here("data", "example", "linelists"))[[.]]              # retorna o nome do arquivo da linelist mais recente

latest_file  # mostra o nome do arquivo do artigo mais recente
```

Você pode agora usar esse nome para finalizar o caminho relativo do arquivo, com `here()`:  

```{r, eval=F}
here("dados", "example", "linelists", latest_file) 
```

E agora você pode importar o arquivo mais recente:

```{r, eval=F}
# importar
import(here("dados", "example", "linelists", latest_file)) # import 
```

 

### Use as informações do arquivo {.unnumbered}  

Se seus arquivos não tiverem datas em seus nomes (ou se você não confiar nessas datas), você pode tentar extrair a data da última modificação dos metadados do arquivo. Use funções do pacote **fs** para examinar as informações dos metadados de cada arquivo, que incluem o tempo da última modificação e o caminho do arquivo.  

Abaixo, fornecemos a pasta de interesse para **fs**'s `dir_info()`. Neste caso, a pasta de interesse está no projeto R na pasta "dados", na subpasta "exemplo" e em sua subpasta "linelists".  O resultado é um *data frame* com uma linha por arquivo e colunas para `modification_time', `path', etc. Você pode ver um exemplo visual disto na página em [interações de diretório](#directories).    

Podemos ordenar este *data frame* de arquivos pela coluna `modification_time`, e então manter apenas a linha superior/última linha (arquivo) com a função do R **base*** `head()`. Então podemos extrair o caminho do arquivo deste último arquivo somente com a função **dplyr*** `pull()` na coluna `path`. Finalmente, podemos passar este caminho de arquivo para `import()`. O arquivo importado é salvo como `latest_file`.   

```{r, eval=F}
latest_file <- dir_info(here("dados", "examplo", "linelists")) %>%  # coleta dados sobre todos os arquivos no diretório
  arrange(desc(modification_time)) %>%      # classifica por data da última modificação
  head(1) %>%                               # mantém apenas o arquivo modificado por último
  pull(path) %>%                            # extrai apenas o endereço do arquivo
  import()                                  # importa o arquivo

```



<!-- ======================================================= -->
## APIs {#import_api}

Uma "Interface de Programação Automatizada" (API) pode ser usada para solicitar dados diretamente de um website. As APIs são um conjunto de regras que permitem que uma aplicação de software interaja com outra. O cliente (você) envia uma "solicitação" e recebe uma "resposta" contendo o conteúdo. Os pacotes R **httr** e **jsonlite*** podem facilitar este processo. 

Cada website habilitado para API terá sua própria documentação e especificações para se familiarizar. Alguns sites estão disponíveis publicamente e podem ser acessados por qualquer pessoa. Outros, tais como plataformas com IDs de usuário e credenciais, requerem autenticação para acessar seus dados. 

Não é preciso dizer que é necessário ter uma conexão com a Internet para importar dados via API. Daremos breves exemplos de uso de APIs para importar dados e conectá-lo a outros recursos.  

*Note: lembre-se que os dados podem ser *postados* em um website sem API, o que pode ser mais fácil de ser recuperado. Por exemplo, um arquivo CSV postado pode ser acessível simplesmente fornecendo a URL do site para `import()` como descrito na seção sobre [importação de Github](#import_github).*   


### Requisição HTTP {.unnumbered}  

A troca de API é mais comumente feita através de uma solicitação HTTP. HTTP é o Protocolo de Transferência de Hipertexto, e é o formato subjacente de uma solicitação/resposta entre um cliente e um servidor. A entrada e saída exata pode variar dependendo do tipo de API, mas o processo é o mesmo - uma "Solicitação" (geralmente Solicitação HTTP) do usuário, muitas vezes contendo uma consulta, seguida por uma "Resposta", contendo informações de status sobre a solicitação e possivelmente o conteúdo solicitado.  

Aqui estão alguns componentes de uma solicitação *HTTP*:  

* A URL do endpoint da API  
* O "Método" (ou "Verbo")  
* Cabeçalhos  
* Corpo  

O "método" de solicitação HTTP é a ação que você deseja realizar. Os dois métodos HTTP mais comuns são `GET` e `POST`, mas outros poderiam incluir `PUT`, `DELETE`, `PATCH`, etc. Ao importar dados para R, é mais provável que você utilize `GET`.  

Após sua solicitação, seu computador receberá uma "resposta" em um formato similar ao que você enviou, incluindo URL, status HTTP (Status 200 é o que você quer!), tipo de arquivo, tamanho e o conteúdo desejado. Você precisará então analisar esta resposta e transformá-la em um data frame funcional dentro de seu ambiente R.


### Pacotes {.unnumbered}  

O pacote **httr** funciona bem para lidar com solicitações HTTP em R. Ele requer pouco conhecimento prévio de APIs Web e pode ser usado por pessoas menos familiarizadas com a terminologia de desenvolvimento de software. Além disso, se a resposta HTTP for .json, você pode usar **jsonlite** para analisar a resposta.  

```{r, eval=F}
# carrega pacotes
pacman::p_load(httr, jsonlite, tidyverse)
```


### Dados públicos {.unnumbered}  

Abaixo é um exemplo de uma solicitação de HTTP, originalmente de um tutorial do [the Trafford Data Lab](https://www.trafforddatalab.io/open_data_companion/#A_quick_introduction_to_APIs). Esse site têm vários outros recursos para aprender esse tema e exercícios sobre API.

Cenário: nós queremos importar uma lista de restaurantes fast food na cidade de Trafford, Reino Unido. Os dados podem ser acessados pela API da Food Standards Agency, que disponibiliza dados e classificações acerca de hiigiene alimentar no Reino Unido.

OAqui estão os parâmetros para a nossa solicitação:

* HTTP verb: GET  
* API endpoint URL: http://api.ratings.food.gov.uk/Establishments  
* Parâmetros selecionados: name, address, longitude, latitude, businessTypeId, ratingKey, localAuthorityId  
* Cabeçalho: “x-api-version”, 2  
* Formato(s) dos dados: JSON, XML  
* Documentação: http://api.ratings.food.gov.uk/help  

O código no R seria como seguinte:

```{r, eval=F, warning=F, message=F}
# prepare a solicitação
path <- "http://api.ratings.food.gov.uk/Establishments"
request <- GET(url = path,
             query = list(
               localAuthorityId = 188,
               BusinessTypeId = 7844,
               pageNumber = 1,
               pageSize = 5000),
             add_headers("x-api-version" = "2"))

# cheque para algum erro no servidor ("200" é bom!)
request$status_code

# submita a solicitação, separe a resposta, e converta para um data frame  

response <- content(request, as = "text", encoding = "UTF-8") %>%
  fromJSON(flatten = TRUE) %>%
  pluck("establishments") %>%
  as_tibble()
```

Agora você pode limpar e utilizar o *data frame* `resposta` (*response*), que contém uma linha por estabelecimento de fast food.  

### Autenticação necessária {.unnumbered}  

Algumas APIs requerem autenticação - para que você possa provar quem você é, para que possa acessar dados restritos. Para importar estes dados, você pode precisar primeiro usar um método POST para fornecer um nome de usuário, senha, ou código. Isto retornará um token de acesso, que pode ser usado para solicitações posteriores do método GET para recuperar os dados desejados.  

Abaixo está um exemplo de consulta de dados do *Go.Data*, que é uma ferramenta de investigação de surtos. *Go.Data* usa uma API para todas as interações entre o front-end da web e os aplicativos smartphone usados para a coleta de dados. O *Go.Data* é usado em todo o mundo. Como os dados do surto são sensíveis e você só deve ser capaz de acessar os dados para *seu* surto, a autenticação é necessária.  

Abaixo estão alguns exemplos de código R usando **httr** e **jsonlite** para conexão com a API *Go.Data* para importar dados sobre o acompanhamento de contato de seu surto.  


```{r, eval=F}
# configure as credenciais para a autorização 
url <- "https://godatasampleURL.int/"           # instânica url Go.Data válida
username <- "username"                          # nome de usuário do Go.Data válido
password <- "password"                          # senha do Go.Data válida
outbreak_id <- "xxxxxx-xxxx-xxxx-xxxx-xxxxxxx"  # ID do surto do Go.Data outbreak válida

# obtenha o token de acesso
url_request <- paste0(url,"api/oauth/token?access_token=123") # defina a solicitação da url base 

# prepare a solicitação
response <- POST(
  url = url_request,  
  body = list(
    username = username,    # use o nome de usuario e senha salvos acima para autorizar 
    password = password),                                       
    encode = "json")

# execute a rolicitação e separe a resposta 
content <-
  content(response, as = "text") %>%
  fromJSON(flatten = TRUE) %>%          # flatten nested JSON
  glimpse()

# Salve o token de acesso da resposta 
access_token <- content$access_token    #  salve o token de acesso para permitir as chamadas subsequentes abaixo 

# importat os contatos dos surtos 
# Use o token de access 
response_contacts <- GET(
  paste0(url,"api/outbreaks/",outbreak_id,"/contacts"),          # OBTENHA (GET) a solicitação
  add_headers(
    Authorization = paste("Bearer", access_token, sep = " ")))

json_contacts <- content(response_contacts, as = "text")         # converta para texto JSON

contacts <- as_tibble(fromJSON(json_contacts, flatten = TRUE))   # "achate" o JSON para um tibble
```

<span style="color: orange;">**_CUIDADO:_** Se você estiver importando grandes quantidades de dados de um API que requeira autenticação, poderá haver um intervalo de tempo. Para evitar isto, recupere o access_token novamente antes de cada solicitação GET API e tente usar filtros ou limites na consulta.

<span style="color: darkgreen;">**_DICA:_** A função `fromJSON()` no pacote **jsonlite** não desalinha totalmente na primeira vez em que é executada, então você provavelmente ainda terá itens de lista em seu tibble resultante. Você precisará des-nidificar ainda mais para certas variáveis; dependendo de como seu .json está aninhado. Para ver mais informações sobre isto, veja a documentação do pacote **jsonlite**, como a função [`flatten()`](https://rdrr.io/cran/jsonlite/man/flatten.html). </span>


Para mais detalhes, Veja a documentação em [LoopBack Explorer](https://loopback.io/doc/en/lb4/index.html), a página [Rastreamento de Contatos](#contact-tracing) ou dicas de API em [Go.Data Github repository](https://worldhealthorganization.github.io/godata/api-docs)

Você pode ler mais sobre o pacote *httr* [aqui](https://httr.r-lib.org/articles/quickstart.html)  

Esta seção também foi informada por [este tutorial](https://www.dataquest.io/blog/r-api-tutorial/) e [este tutorial](https://medium.com/@traffordDataLab/querying-apis-in-r-39029b73d5f1). 




<!-- ======================================================= -->
## Exportar {}  

### Com  o pacote **rio**  {.não numerado}
Com **rio***, você pode utilizar a função `export()` de uma forma muito semelhante à `import()`. Primeiro dê o nome do objeto R que você deseja salvar (por exemplo, `linelist`) e depois, entre aspas, coloque o caminho do arquivo onde você deseja salvar o arquivo, incluindo o nome do arquivo desejado e a extensão do arquivo. Por exemplo, o nome do objeto R:  

Isto salva o data frame `linelist` como uma pasta de trabalho do Excel para a pasta raiz do diretório de trabalho/R do projeto:  

```{r, eval=F}
export(linelist, "my_linelist.xlsx") # will save to working directory
```

Você poderia salvar o mesmo *data frame* que um arquivo csv, alterando a extensão. Por exemplo, nós também o salvamos em um caminho de arquivo construído com `aqui()`:  

```{r, eval=F}
export(linelist, here("data", "clean", "my_linelist.csv"))
```


### Para a área de transferência {.unnumbered}

Para exportar um data frame para a "área de transferência" do seu computador (para depois colar em outro software como Excel, Google Spreadsheets, etc.) você pode utilizar `write_clip()` do pacote **clipr***.   

```{r, eval=F}
# exporte a linelist para a área de transferência do seu sistema
clipr::write_clip(linelist)
```




## Arquivos RDS  {#import_rds}

Junto com .csv, .xlsx, etc., você também pode exportar/vendar *data frame* R como arquivos .rds. Este é um formato de arquivo específico para R, e é muito útil se você souber que irá trabalhar com os dados exportados novamente em R. 

As classes de colunas são armazenadas, de modo que você não terá que limpar novamente quando for importado (com um arquivo Excel ou mesmo um arquivo CSV isto pode ser uma dor de cabeça!). É também um arquivo menor, que é útil para exportação e importação se seu conjunto de dados for grande.  

Por exemplo, se você trabalha em uma equipe de Epidemiologia e precisa enviar arquivos para uma equipe GIS para mapeamento, e eles usam R também, basta enviar-lhes o arquivo .rds! Então todas as classes de colunas são mantidas e têm menos trabalho a fazer.  

```{r, eval=F}
export(linelist, here("data", "clean", "my_linelist.rds"))
```



<!-- ======================================================= -->
## Arquivos e listas Rdata  {#import_rdata}

Arquivos do tipo `.Rdata`  cpode armazenar múltiplos objetos R - por exemplo, múltiplos *data frames*, resultados de modelos, listas, etc. Isto pode ser muito útil para consolidar ou compartilhar muitos de seus dados para um determinado projeto.  

No exemplo abaixo, múltiplos objetos R são armazenados dentro do arquivo exportado "my_objects.Rdata":  

```{r, eval=F}
rio::export(my_list, my_dataframe, my_vector, "my_objects.Rdata")
```

Nota: se você estiver tentando *importar* uma lista, utilize `import_list()` de **rio** para importá-la com a estrutura e o conteúdo original completo.  

```{r, eval=F}
rio::import_list("my_list.Rdata")
```







<!-- ======================================================= -->
## Salvando gráficos {} 

Instruções em como salvar gráficos, incluindo os criados pelo pacote `ggplot()`, são discutidos com profundidado na página [ggplot basics](#ggplot-basics).  

Em resumo, execute o código `ggsave("my_plot_filepath_and_name.png")` após exibir o seu gráfico. Você pode  prover um objeto de gráfico para o argumento `plot = `, ou especificar o endereço de salvamento (com extensão de arquivo desejada) para salvar o último gráfico exibido. Você pode tamb[ém controlar o tamanho e qualidade por meio dos argumentos: `width = `, `height = `, `units = ` e `dpi = `.  

Como salvar um gráfico de redes, como uma árvore de transmissão, é discutido na página [Cadeias de Transmissão](#transmission-chains). 


<!-- ======================================================= -->
## Recursos{} 

O [Manual de Importação/Exportação de Dados R](https://cran.r-project.org/doc/manuals/r-release/R-data.html)  
[R 4 Capítulo de ciência dos dados sobre importação de dados](https://r4ds.had.co.nz/data-import.html#data-import)  
[documentação ggsave()](https://ggplot2.tidyverse.org/reference/ggsave.html)  


Abaixo está uma tabela, extraída do **rio** online [vinheta](https://cran.r-project.org/web/packages/rio/vignettes/rio.html). Para cada tipo de dado ele mostra: a extensão de arquivo esperada, o pacote **rio*** utilizado para importar ou exportar os dados, e se esta funcionalidade está incluída na versão instalada padrão do **rio**.  




Formato                     | Extensão típica | Pacote de Importação   | Pacote de exportação | Instalado por padrão
---------------------------_|-----------------|------------------------|----------------------|---------------------
Dados separados por vírgulas | .csv | data.table `fread()` | data.table |	Sim
Dados separados por Pipe |	.psv | data.table `fread()` | data.table | Sim
Dados separados por Tab .tsv | data.table `fread()` | data.table | Sim
SAS | .sas7bdat | haven | haven | Sim
SPSS | .sav | haven | haven | Sim
Stata | .dta | haven | haven | Sim
SAS | XPORT | .xpt | haven | haven | Sim
SPSS Portable | .por | haven | | Sim
Excel | .xls | readxl | | Sim
Excel | .xlsx | readxl | openxlsx | Sim
R syntax | .R	| base | base | Sim
Objetos R salvos | .RData, .rda | base | base | Sim
Objetos R seriados | .rds | base | base | Sim
Epiinfo | .rec | foreign | | Sim
Minitab | .mtp | foreign | | Sim
Systat | .syd |	foreign | | Sim
“XBASE” | database files | .dbf | foreign | foreign | Sim
Weka Attribute-Relation File Format | .arff | foreign | foreign | Sim
Dados no formato de intercâmbio| .dif | utils | | Sim
Dados Fortran da | no recognized extension | utils | | Sim
Dados no formato largura fixa | .fwf | utils | utils | Sim
dados separados por vírgulas gzip  | .csv.gz | utils | utils | v
CSVY (CSV + YAML metadata header) | .csvy | csvy | csvy | Não
EViews | .wf1 |hexView | | Não
Formato de intercâmbio Feather R/Python  | .feather | feather | feather | Não
Fast Storage | .fst | fst |	fst | Não
JSON | .json | jsonlite | jsonlite | Não
Matlab | .mat | rmatio | rmatio | Não
Planilhas OpenDocument | .ods | readODS | readODS | Não
Tabelas HTML  | .html | xml2 | xml2 | Não
Documentos Shallow XML  | .xml | xml2 | xml2 | Não
YAML | .yml | yaml | yaml	| Não
Padrão da área de transferência é tsv | |  clipr | clipr | Não



```{r include=FALSE, cache=FALSE}

# clear workspace
rm(list = ls(all = TRUE))

# clear all packages except base
#lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))

# to ensure that tidyverse packages prevail
filter <- dplyr::filter
select <- dplyr::select
summarise <- dplyr::summarise
summary <- base::summary
incidence <- incidence2::incidence

#load core packages
pacman::p_load(
     rio,
     here,
     DT,
     stringr,
     lubridate,
     tidyverse
)

# import the cleaned ebola linelist
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

# import the count data - facility level
#count_data <- rio::import(here::here("data", "facility_count_data.rds"))

# Settings

options(scipen=1, digits=7)

# print only text (not code)
# library(knitr)
# opts_chunk$set(list(echo = FALSE, eval = FALSE))
```

<!--chapter:end:new_pages/importing.Rmd-->

# (PART) Gerenciamento dos Dados {.unnumbered}
```{r include=FALSE, cache=FALSE}

# clear workspace
rm(list = ls(all = TRUE))

# clear all packages except base
#lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))

# to ensure that tidyverse packages prevail
filter <- dplyr::filter
select <- dplyr::select
summarise <- dplyr::summarise
summary <- base::summary
incidence <- incidence2::incidence

#load core packages
pacman::p_load(
     rio,
     here,
     DT,
     stringr,
     lubridate,
     tidyverse
)

# import the cleaned ebola linelist
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

# import the count data - facility level
#count_data <- rio::import(here::here("data", "facility_count_data.rds"))

# Settings

options(scipen=1, digits=7)

# print only text (not code)
# library(knitr)
# opts_chunk$set(list(echo = FALSE, eval = FALSE))
```

<!--chapter:end:new_pages/cat_data_management.Rmd-->

# Limpeza de dados e principais funções {#cleaning}

```{r, out.height = "10%", fig.align = "center", echo=F, message=FALSE, warning=FALSE}
knitr::include_graphics(here::here("images", "cleaning.png"))
```

Esta página demonstra passos comuns usados no processo de "limpeza" de um conjunto de dados, e também explica o uso de muitas funções essenciais de gerenciamento de dados.

Para demonstrar a limpeza de dados, esta página começa por importar um conjunto de dados brutos de uma lista de casos, e realiza passo-a-passo o processo de limpeza. No código R, isto se manifesta com uma cadeia "pipe", a qual faz referência ao operador "pipe" %\>%\` que passa um conjunto de dados de uma operação para a próxima.

### Funções essenciais {.unnumbered}

Este manual emfatiza a utilização das funções da família de pacotes [**tidyverse**](https://www.tidyverse.org/)do R. As funções essenciais do R demonstradas nesta página estão listadas abaixo.

Muitas destas funções pertencem ao pacote do R [**dplyr**](https://dplyr.tidyverse.org/), que fornece funções "verbo" para resolver desafios de manipulação de dados (o nome é uma referência a um "dataframe-[plier](https://www.thefreedictionary.com/plier#:~:text=also%20ply%C2%B7er%20(pl%C4%AB%E2%80%B2,holding%2C%20bending%2C%20or%20cutting.)%22) (N.T.: *plier* significa alicate, fazendo uma analogia da funcionalidade dessa ferramenta sobre um dataframe). O pacote **dplyr** é parte da família de pacotes **tidyverse** do R (os quais também incluem **ggplot2**, **tidyr**, **stringr**, **tibble**, **purrr**, **magrittr**, e **forcats** entre outros).

+-----------------------------------------------------+---------------------------------------------------------------------------+----------------------------+
| Função                                              | Utilidade                                                                 | Pacote                     |
+=====================================================+===========================================================================+============================+
| `%>%`                                               | "pipe" (passar) dados de uma função para a próxima                         | **magrittr**               |
+-----------------------------------------------------+---------------------------------------------------------------------------+----------------------------+
| `mutate()`                                          | criar, transformar, e redefinir colunas                                   | **dplyr**                  |
+-----------------------------------------------------+---------------------------------------------------------------------------+----------------------------+
| `select()`                                          | manter, remover, selecionar, ou renomear colunas                          | **dplyr**                  |
+-----------------------------------------------------+---------------------------------------------------------------------------+----------------------------+
| `rename()`                                          | renomear colunas                                                          | **dplyr**                  |
+-----------------------------------------------------+---------------------------------------------------------------------------+----------------------------+
| `clean_names()`                                     | padronizar a síntaxe de nomes de colunas                                  | **janitor**                |
+-----------------------------------------------------+---------------------------------------------------------------------------+----------------------------+
| `as.character()`, `as.numeric()`, `as.Date()`, etc. | converter a classe de uma coluna                                          | R **base**                 |
+-----------------------------------------------------+---------------------------------------------------------------------------+----------------------------+
| `across()`                                          | transformar múltiplas colunas de uma vez                                  | **dplyr**                  |
+-----------------------------------------------------+---------------------------------------------------------------------------+----------------------------+
| Funções **tidyselect**                              | use lógica para selecionar colunas                                        | **tidyselect**             |
+-----------------------------------------------------+---------------------------------------------------------------------------+----------------------------+
| `filter()`                                          | manter certas linhas                                                      | **dplyr**                  |
+-----------------------------------------------------+---------------------------------------------------------------------------+----------------------------+
| `distinct()`                                        | remover linhas duplicadas (duplicidades)                                  | **dplyr**                  |
+-----------------------------------------------------+---------------------------------------------------------------------------+----------------------------+
| `rowwise()`                                         | operações por/em cada linha                                               | **dplyr**                  |
+-----------------------------------------------------+---------------------------------------------------------------------------+----------------------------+
| `add_row()`                                         | adicionar linhas manualmente                                              | **tibble**                 |
+-----------------------------------------------------+---------------------------------------------------------------------------+----------------------------+
| `arrange()`                                         | ordenar linhas                                                            | **dplyr**                  |
+-----------------------------------------------------+---------------------------------------------------------------------------+----------------------------+
| `recode()`                                          | recodificar valores em uma coluna                                         | **dplyr**                  |
+-----------------------------------------------------+---------------------------------------------------------------------------+----------------------------+
| `case_when()`                                       | recodificar valores em uma coluna usando critérios lógicos mais complexos | **dplyr**                  |
+-----------------------------------------------------+---------------------------------------------------------------------------+----------------------------+
| `replace_na()`, `na_if()`, `coalesce()`             | funções especiais de recodificação                                        | **tidyr**                  |
+-----------------------------------------------------+---------------------------------------------------------------------------+----------------------------+
| `age_categories()` and `cut()`                      | criar grupos categóricos de uma coluna numérica                           | **epikit** e R **base**    |
+-----------------------------------------------------+---------------------------------------------------------------------------+----------------------------+
| `match_df()`                                        | recodificar/limpar valores usando um dicionário de dados                  | **matchmaker**             |
+-----------------------------------------------------+---------------------------------------------------------------------------+----------------------------+
| `which()`                                           | aplicar critérios lógicos; retorna índices                                | R **base**                 |
+-----------------------------------------------------+---------------------------------------------------------------------------+----------------------------+

Se quiser ver como estas funções se comparam aos comandos Stata ou SAS, consulte a página em [Transição para o R](#transition-to-R).

Você poderá encontrar uma estrutura alternativa de gestão de dados a partir do pacote do R **data.table** com operadores como `:=` e utilização frequente de colchetes `[ ]`. Estas abordagem e sintaxe são brevemente explicadas na página [Tabela de dados](#tables-presentation).

### Nomenclatura {.unnumbered}

Neste manual, utilizamos os termos "colunas" e "linhas" em vez de "variáveis" e "observações". Como explicado neste manual sobre ["dados arrumados"](https://tidyr.tidyverse.org/articles/tidy-data.html), a maioria dos conjuntos de dados estatísticos epidemiológicos consistem estruturalmente em linhas, colunas e valores.

*Variáveis* contêm os valores que medem o mesmo atributo subjacente (como o faixa-etária, desfecho, ou data de início). *Observações* contêm todos os valores medidos na mesma unidade (por exemplo, uma pessoa, local, ou amostra de laboratório). Portanto, estes aspectos podem ser mais difíceis de definir de forma tangível.

Em um conjunto de dados "arrumados", cada coluna é uma variável, cada linha é uma observação, e cada célula é um único valor. Contudo, alguns conjuntos de dados que você encontra não se enquadrarão neste molde - um conjunto de dados de formato "amplo" (*wide*) pode ter uma variável dividida em várias colunas (ver um exemplo na página [Pivotando Dados](#pivoting)). Da mesma forma, as observações podem ser divididas em várias linhas.

A maior parte deste manual trata da gestão e transformação de dados, referindo assim à estrutura concreta dos dados de linhas e colunas é mais relevante do que utilizar os termos observações/variáveis, que são mais abstratos. As exceções ocorrem principalmente em páginas sobre análise de dados, onde se verá mais referências a variáveis e observações.

<!-- ======================================================= -->

<!-- ======================================================= -->

<!-- ======================================================= -->

## Conduta de limpeza

**Esta página prossegue através das típicas etapas de limpeza, adicionando-as sequencialmente a uma cadeia de pipe de limpeza.**

Na análise epidemiológica e processamento de dados, as etapas de limpeza são frequentemente executadas sequencialmente, ligadas entre si. No R, isto manifesta-se frequentemente como um "pipeline" de limpeza, onde *o conjunto de dados bruto é passado ou "canalizado" de uma etapa de limpeza para outra*.

Tais cadeias utilizam funções "verbo" **dplyr** e o operador pipe '%\>\%' do **magrittr**. Esta pipe começa com os dados "brutos" ("linelist_raw.xlsx") e termina com um data frame de R "limpo" (`linelist`) que pode ser utilizada, guardada, exportada, etc.

Em uma cadeia de limpeza, a ordem das etapas é importante. As etapas de limpeza podem incluir:

-   Importação de dados\
-   Nomes de colunas limpos ou alterados\
-   Remoção de duplicidades\
-   Criação e transformação de colunas (por exemplo, re-codificação ou normalização de valores)\
-   Linhas filtradas ou adicionadas

<!-- ======================================================= -->

<!-- ======================================================= -->

<!-- ======================================================= -->

## Carregar pacotes

Este pedaço de código mostra o carregamento das pacotes necessários para as análises. Neste manual, damos ênfase a `p_load()` do **pacman**, que instala o pacote se necessário *e* carrega-o para uso. Você pode também carregar pacotes instalados com `library()` do R **base**. Veja a página do [Introdução ao R](#basics) para mais informações do pacotes do R.

```{r, message = F}
pacman::p_load(
  rio,        # importação de dados  
  here,       # caminhos de arquicos relacionados
  janitor,    # limpeza de dados e tabelas
  lubridate,  # trabalhando com datas
  matchmaker, # limpeza baseada no dicionário
  epikit,     # funções de age_categories() 
  tidyverse,  # manejo e visualização de dados
  skimr
)
```

<!-- ======================================================= -->

<!-- ======================================================= -->

<!-- ======================================================= -->

## Importação de dados

### Importação {.unnumbered}

Aqui nós importamos o arquivo de Excel linelist de casos "brutos" usando a função `import()` do pacote **rio**. O pacote **rio** trata de forma flexível muitos tipos de arquivos (por ex. .xlsx, .csv, .tsv, .rds. Ver a página em [Importar e exportar](#importing) para mais informações e dicas sobre situações não usuais (por exemplo, saltar linhas, definir valores em falta, importar Google sheets, etc.)

Se quiser acompanhar, [clique para descarregar a linelist "bruta"](https://github.com/appliedepi/epirhandbook_eng/raw/master/data/case_linelists/linelist_raw.xlsx) (como arquivo .xlsx).

Se o seu conjunto de dados for grande e demorar muito tempo a importar, pode ser útil que o comando de importação seja separado da cadeia pipe e que o "bruto" seja guardado como um arquivo distinto. Isto também permite uma comparação fácil entre a versão original e a versão limpa.

Abaixo, importamos o arquivo bruto do Excel e o salvamos como o dataframe linelist_raw. Presumimos que o arquivo esteja localizado no diretório de trabalho ou na raiz do projeto R e, portanto, nenhuma subpasta é especificada no caminho do arquivo.

```{r, echo=F, message=F}
# ESCONDIDO DO LEITOR
# realmente carregar os dados usando here()
linelist_raw <- rio::import(here::here("data", "case_linelists", "linelist_raw.xlsx"))
```

```{r, eval=F}
linelist_raw <- import("linelist_raw.xlsx")
```

Você pode visualizar as primeiras 50 linhas do quadro de dados abaixo. Nota: a função contida no pacote R **base** `head(n)` permite que você visualize apenas as primeiras `n` linhas no console do R.

```{r message=FALSE, echo=F}
# exibir os dados da linelist como uma tabela
DT::datatable(head(linelist_raw,50), rownames = FALSE, options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```

### Revisão {.unnumbered}

Você pode usar a função `skim()` do pacote **skimr** para obter uma visão geral de todo o dataframe (ver página em [Tabelas descritivas](#tables-descriptive) para mais informações). As colunas são resumidas por classe/tipo, como caractere, numérico. Nota: "POSIXct" é um tipo de classe de data bruta (ver [Trabalhando com datas](#dates)).

```{r}
skimr::skim(linelist_raw)
```

```{r, eval=F, echo=F}
skimr::skim_without_charts(linelist_raw)
```

<!-- ======================================================= -->

<!-- ======================================================= -->

<!-- ======================================================= -->

## Nomes de colunas

No R, os *nomes* das colunas são o "cabeçalho" ou valor do "topo" de uma coluna. Eles são usados para referir a colunas em código, e serve como um rotulo por omissão nas figuras.

Outros softwares estatísticos como SAS e STATA utilizam *"etiquetas "* que coexistem como versões impressas mais longas dos nomes das colunas mais curtas. Embora o R ofereça a possibilidade de adicionar etiquetas de coluna aos dados, isto não é enfatizado na maioria das práticas. Para que os nomes das colunas sejam "amigáveis para impressão" de figuras, normalmente se ajusta sua exibição dentro dos próprios comandos de criação dos gráficos e tabelas (por exemplo, títulos de eixos ou legendas de um gráfico, ou cabeçalhos de coluna em uma tabela impressa - veja a [seção de escalas da página de dicas ggplot](#ggplot_tips_scales) e páginas de [Tabelas para apresentação](#tables-presentation)). Se você quiser atribuir etiquetas de coluna nos dados, leia mais online [aqui](https://cran.r-project.org/web/packages/expss/vignettes/labels-support.html) e [aqui](https://cran.r-project.org/web/packages/labelled/vignettes/intro_labelled.html).

Como os nomes de colunas no R são usados muito frequentemente, então eles devem ter uma sintaxe "limpa". Nós sugerimos o seguinte:

-   Nomes curtos
-   Sem espaços (substituir com sublinhados \_ )
-   Sem caracteres especiais (&, \#, \<, \>, ...)\
-   Nomenclatura de estilo similar (por exemplo, todas as colunas de datas nomeadas como **data_**início, **data\_**relato, **data\_**morte...)

Os nomes das colunas de `linelist_raw` são "printados" abaixo utilizando `names()` do R **base**. Podemos ver isso inicialmente:

-   Alguns nomes contêm espaços (por exemplo a data de infeccção `infecction date` )\
-   Diferentes padrões de nomes são utilizados para datas (data de início vs data de infecção,  `date onset` vs. `infecction date`)\
-   Deve ter havido um *cabeçalho combinado* nas duas últimas colunas no .xlsx. Sabemos disso porque o nome de duas colunas combinadas ("merged_header") foi atribuído pelo R à primeira coluna, e à segunda coluna foi atribuído um nome de espaço reservado "...28" (pois estava então vazia e é a 28ª coluna).

```{r}
names(linelist_raw)
```

[***NOTA:*** Para referenciar um nome de coluna que inclua espaços, rodeie o nome com o acentro grave (N.T. chamado vulgarmente de "crase"), por exemplo: linelist\$`` ` '\x60infection date\x60'` ``. Note que no seu teclado, o acento grave (\`) é diferente das aspas simples/apóstrofe (').]{style="color: black;"}

### Limpeza automática {.unnumbered}

A função `clean_names()` do pacote **janitor** padroniza os nomes das colunas e os torna únicos ao fazer o seguinte:

-   Converte todos os nomes para consistir apenas em sublinhados, números e letras\
-   Os caracteres acentuados são transliterados para ASCII (por exemplo, german o com umlaut torna-se "o", "enye" espanhol torna-se "n")\
-   A preferência de capitalização para os nomes das novas colunas pode ser especificada utilizando o argumento `case =` argumento ("snake" é padrão, as alternativas incluem "sentence", "title", "small_camel"...)\
-   Você pode especificar substituições específicas de nomes fornecendo um vetor para o argumento `replace =` argumento (por exemplo, `replace = c(onset = "date_of_onset")`)\
-   Aqui está uma [vinheta](https://cran.r-project.org/web/packages/janitor/vignettes/janitor.html#cleaning) online.

A seguir, a linha de limpeza começa utilizando `clean_names()` na linelist bruta.

```{r clean_names}
# pipe do conjunto de dados brutos através da função clean_names(), atribuindo o resultado como "linelist"  
linelist <- linelist_raw %>% 
  janitor::clean_names()

# Veja os novos nomes das colunas
names(linelist)
```

[***NOTA:*** O nome da última coluna "...28" foi mudado para "x28".]{style="color: black;"}

### Limpeza manual de nomes {.unnumbered}

A renomeação manual das colunas é frequentemente necessária, mesmo após a etapa de padronização acima. Abaixo, a renomeação é realizada utilizando a função `rename()` do pacote **dplyr**, como parte de uma cadeia pipe. A função `rename()` utiliza o estilo `NOVO = VELHO` - o novo nome da coluna é dado antes do nome da coluna antiga.

Abaixo, um comando de renomeação é adicionado a linha de pipe limpa. Espaços foram adicionados estrategicamente para alinhar o código para facilitar a leitura.

```{r}
# CADEIA 'PIPE' DE LIMPEZA
# (inicia com dados brutos e encadeia funções com o pipe até a limpeza dos dados)
##################################################################################
linelist <- linelist_raw %>%
    
    # padronização da sintaxe do nome de coluna 
    janitor::clean_names() %>% 
    
    # colunas renomeadas manualmente
           # NOVO nome             # nome VELHO
    rename(date_infection       = infection_date,
           date_hospitalisation = hosp_date,
           date_outcome         = date_of_outcome)
```

Agora você pode ver que os nomes das colunas está sendo mudado:

```{r message=FALSE, echo=F}
names(linelist)
```

#### Renomear a posição da coluna {.unnumbered}

Você pode também renomear pela posição da coluna, ao invés do nome da coluna, por exemplo:

```{r, eval=F}
rename(newNameForFirstColumn  = 1,
       newNameForSecondColumn = 2)
```

#### Renomear via `select()` e `summarise()` {.unnumbered}

Como um atalho, você também pode renomear colunas dentro das funções **dplyr** `select()` e `summarise()`. `select()` é utilizada para manter apenas certas colunas (e é abordada mais adiante nesta página). `summarise()` é coberta nas páginas [Agrupamento de dados](#grouping) e [Tabelas descritivas](#tables-descriptive). Estas funções também utilizam o formato `novo_nome = antigo_nome`. Aqui está um exemplo:

```{r, eval=F}
linelist_raw %>% 
  select(# NOVO nome             # nome VELHO
         date_infection       = `infection date`,    # renomear e MANTER APENAS estas colunas
         date_hospitalisation = `hosp date`)
```

### Outros desafios {.unnumbered}

#### Nomes de colunas Excel vazias {.unnumbered}

O R não pode ter colunas de conjuntos de dados que não tenham nomes de colunas (cabeçalhos). Portanto, se você importar um conjunto de dados Excel com dados mas sem cabeçalhos de colunas, o R preencherá os cabeçalhos com nomes como "...1" ou "...2". O número representa o número da coluna (por exemplo, se a 4ª coluna do conjunto de dados não tiver cabeçalho, então R lhe dará o nome "...4").

Você pode limpar estes nomes manualmente referenciando o número de posição (ver exemplo acima), ou seu nome atribuído (`linelist_raw$...1`).

#### Nomes de colunas e células de Excel combinado {.unnumbered}

As células combinadas em um arquivo Excel são uma ocorrência comum no recebimento de dados. Como explicado em [Transição para R](#transition-to-R), células combinadas podem ser agradáveis para a leitura humana de dados, mas não são "dados arrumados" e causam muitos problemas para a leitura de dados pela máquina. O R não pode acomodar células combinadas.

Lembre as pessoas que fazem a entrada de dados que **dados legíveis por humanos não é o mesmo que dados legíveis por máquinas**. Esforce-se para treinar os usuários sobre os princípios de [**dados arrumados**](https://r4ds.had.co.nz/tidy-data.html). Se possível, tente mudar os procedimentos para que os dados cheguem em um formato ordenado sem células combinadas.

-   Cada variável deve ter sua própria coluna.\
-   Cada observação deve ter sua própria linha.\
-   Cada valor deve ter sua própria célula.

Ao utilizar a função  `import()` do **rio**, o valor em uma célula mesclada será atribuído à primeira célula e as células subsequentes estarão vazias.

Uma solução para lidar com células mescladas é importar os dados com a função `readWorkbook()` do pacote **openxlsx**. Defina o argumento `fillMergedCells = TRUE`. Isto dá o valor em uma célula mesclada a todas as células dentro da faixa mesclada.

```{r, eval=F}
linelist_raw <- openxlsx::readWorkbook("linelist_raw.xlsx", fillMergedCells = TRUE)
```

[***ATENÇÃO:*** Se os nomes das colunas forem mesclados com `readWorkbook()`, você terminará com nomes de colunas duplicadas, que você precisará corrigir manualmente - o R não funciona bem com nomes de colunas duplicadas! Você pode renomeá-los referenciando sua posição (por exemplo, coluna 5), como explicado na seção sobre limpeza manual de nomes de colunas]{style="color: red;"}

<!-- ======================================================= -->

<!-- ======================================================= -->

<!-- ======================================================= -->

## Selecionar ou reordenar colunas

Utilize `select()` do **dplyr** para selecionar as colunas que você deseja reter e especificar sua ordem no quadro de dados,

[***CUIDADO:*** Nos exemplos abaixo, o quadro de dados `linelist` é modificado com `select()` e exibido, mas não salvo. Isto é para fins de demonstração. Os nomes das colunas modificadas são exibidos ao fornecer banco de dados com o pipe para função `names()`.]{style="color: orange;"}


**Aqui estão TODOS os nomes que a linelist tem até este ponto da cadeia de limpeza:**

```{r}
names(linelist)
```

### Manter colunas {.unnumbered}

**Selecione apenas as colunas que você quer manter**

Coloque seus nomes no comando `select()`, sem aspas. Eles aparecerão no data frame na ordem que você fornecer. Observe que se você incluir uma coluna que não existe, o R retornará um erro (veja o uso de `any_of()` abaixo se você não quiser nenhum erro nesta situação).

```{r}
# O conjunto de dados linelist é canalisado através do comando select(), e names() "printam" apenas os nomes das colunas
linelist %>% 
  select(case_id, date_onset, date_hospitalisation, fever) %>% 
  names()  # exibir os nomes das colunas
```

### Funções auxiliares "tidyselect" {#clean_tidyselect .unnumbered}

Estas funções de ajuda existem para facilitar a especificação de colunas para manter, descartar ou transformar. Elas são do pacote **tidyselect**, que está incluído no **tidyverse** e está subjacente à forma como as colunas são selecionadas nas funções **dplyr**.

Por exemplo, se você quiser reordenar as colunas, `everything()` é uma função útil para significar "todas as outras colunas ainda não mencionadas". O comando abaixo move as colunas `date_onset` e `date_hospitalisation` para o início (esquerda) do conjunto de dados, mas mantém todas as outras colunas depois. Note que `everything()` é escrito com parênteses vazios:

```{r}
# mova date_onset e date_hospitalisation para o início
linelist %>% 
  select(date_onset, date_hospitalisation, everything()) %>% 
  names()
```

Aqui estão outras funções auxiliares "tidyselect" que também trabalham *dentro* das funções **dplyr** como `select()`, `across()`, e `summarise()`:

-   `everything()` - todas as outras colunas não mencionadas\

-   `last_col()` - a última coluna\

-   `where()` - aplica uma função a todas as colunas e seleciona aquelas para as quais a função retorna TRUE (verdadeiro)\

-   `contains()` - colunas contendo uma cadeia de caracteres

    -   exemplo: `select(contains("time"))`\

-   `starts_with()` - corresponde a um prefixo especificado

    -   exemplo: `select(starts_with("date_"))`\

-   `ends_with()` - corresponde a um sufixo especificado

    -   exemplo: `select(ends_with("_post"))`\

-   `matches()` - para aplicar uma expressão regular (regex)

    -   exemplo: `select(matches("[pt]al"))`\

-   `num_range()` - uma faixa numérica como x01, x02, x03\

-   `any_of()` - faz a correspondência SE a coluna existir, mas não retorna nenhum erro se não for encontrada

    -   exemplo: `select(any_of(date_onset, date_death, cardiac_arrest))`

Além disso, utilizar operadores normais como `c()` para listar várias colunas, `:` para colunas consecutivas, `!` para o oposto, `&` para AND, e `|` para OR.

Utilize `where()` para especificar critérios lógicos para as colunas. Se fornecer uma função dentro de `where()`, não inclua os parênteses vazios da função. O comando abaixo seleciona colunas que são de classe Numérica.

```{r}
# selecione colunas que são a classe numérica
linelist %>% 
  select(where(is.numeric)) %>% 
  names()
```

Utilize `contains()` para selecionar apenas colunas nas quais o nome da coluna contém uma cadeia de caracteres especificada. Os `ends_with()` e `starts_with()` fornecem mais nuances.

```{r}
# selecione colunas contendo certos caracteres
linelist %>% 
  select(contains("date")) %>% 
  names()
```

A função `matches()` funciona de forma semelhante a `contains()` mas pode ser fornecida uma expressão regular (ver página em [Caracteres e strings](#characters-strings)), tais como múltiplos strings separados por "barras de OU" dentro dos parênteses:

```{r}
# procurado por combinações de caracteres múltiplos
linelist %>% 
  select(matches("onset|hosp|fev")) %>%   # note o símbolo OR "|"
  names()
```

[***CUIDADO:*** Se um nome de coluna que você fornecer especificamente não existir nos dados, ele pode retornar um erro e parar seu código. Considere utilizar `any_of()` para citar colunas que podem ou não existir, especialmente úteis em seleções negativas (remoção).]{style="color: orange;"}  

Apenas uma destas colunas existe, mas nenhum erro é produzido e o código continua sem parar sua cadeia de limpeza.

```{r}
linelist %>% 
  select(any_of(c("date_onset", "village_origin", "village_detection", "village_residence", "village_travel"))) %>% 
  names()
```

### Remova colunas {.unnumbered}

**Indicar quais colunas devem ser removidas** colocando um símbolo menos "-" na frente do nome da coluna (por exemplo,`select(-outcome)`), ou um vetor de nomes de colunas (como abaixo). Todas as outras colunas serão retidas.

```{r}
linelist %>% 
  select(-c(date_onset, fever:vomit)) %>% # remova date_onset e todas as colunas de febre a vômito
  names()
```

Você também pode remover uma coluna utilizando a síntaxe do R **base**, definindo-a como `NULL`. Por exemplo:

```{r, eval=F}
linelist$date_onset <- NULL   # elimina a coluna com a síntaxe da base do R 
```

### Autonomia {.unnumbered}

`select()` também pode ser utilizado como um comando independente (não em uma cadeia de pipe). Neste caso, o primeiro argumento é o dataframe original a ser operado.

```{r}
# Criar uma nova linelist com colunas relacionadas a id e idade
linelist_age <- select(linelist, case_id, contains("age"))

# exiba os nomes das colunas
names(linelist_age)
```

#### Acrescente à cadeia de pipes {.unnumbered}

Na `linelist_raw`, há algumas colunas que não precisamos: `row_num`, `merged_header`, e `x28`. Nós as removemos com um comando `select()` na cadeia pipe limpa:

```{r}
# CADEIA 'PIPE' DE LIMPEZA 
#(inicia com dados brutos e encadeia funções com o pipe até a limpeza dos dados)
##################################################################################

# inicie a cadeia pipe de limpeza
###########################
linelist <- linelist_raw %>%
    
    # padronize a sintaxe do nome da coluna
    janitor::clean_names() %>% 
    
    # renomeie manualmente colunas
           # NOVO nome             # nome VELHO
    rename(date_infection       = infection_date,
           date_hospitalisation = hosp_date,
           date_outcome         = date_of_outcome) %>% 
    
    # ACIMA ESTÃO OS PASSOS DE LIMPEZA JÁ DISCUTIDOS
    #####################################################

    # remova coluna
    select(-c(row_num, merged_header, x28))
```

<!-- ======================================================= -->

<!-- ======================================================= -->

<!-- ======================================================= -->

## Eliminação de duplicidades

Consulte a página do manual de [Eliminação de duplicidades](#deduplication) para obter opções extensivas sobre como de-duplicar os dados. Apenas um exemplo muito simples de eliminação de duplicidades é apresentado aqui.

O pacote**dplyr** oferece a função `distinct()` function. Esta função examina cada linha e reduz o data frame para apenas as linhas únicas. Isto é, ele remove as linhas que são 100% duplicadas.

Ao avaliar linhas duplicadas, ela leva em conta uma gama de colunas - por padrão ele considera todas as colunas. Como mostrado na página de desduplicação, é possível ajustar este intervalo de colunas para que a singularidade das linhas só seja avaliada em relação a determinadas colunas.

Neste exemplo simples, basta adicionar o comando vazio `distinct()` para a cadeia de pipe. Isto garante que não haja linhas que sejam 100% duplicatas de outras linhas (avaliadas em todas as colunas).

Começamos com `nrow(linelist)` de linhas em `linelist`.

```{r}
linelist <- linelist %>% 
  distinct()
```

Após a eliminação de duplicidades, existem `nrow(linelist)` linhas. Qualquer linha removida teria sido 100% duplicada de outras linhas.

Abaixo, o comando `distinct()` é adicionado à cadeia de pipe de limpeza:

```{r}
# CADEIA 'PIPE' DE LIMPEZA 
#(inicia com dados brutos e encadeia funções com o pipe até a limpeza dos dados)
##################################################################################

# começa a limpeza da cadeia pipe
###########################
linelist <- linelist_raw %>%
    
    # padronizar a sintaxe do nome da coluna
    janitor::clean_names() %>% 
    
    # re-nomear colunas manualmente
           # NOVO nome             # nome VELHO
    rename(date_infection       = infection_date,
           date_hospitalisation = hosp_date,
           date_outcome         = date_of_outcome) %>% 
    
    # remova a coluna
    select(-c(row_num, merged_header, x28)) %>% 
  
    # ACIMA ESTÃO OS PASSOS DE LIMPEZA JÁ DISCUTIDOS
    #####################################################
    
    # desduplicar
    distinct()
```

<!-- ======================================================= -->

<!-- ======================================================= -->

<!-- ======================================================= -->

## Criação de coluna e transformação

**Nós recomendamos usar a função dplyr `mutate()` para adicionar uma nova coluna, ou para modificar uma existente.**

Abaixo está um exemplo de criação de uma nova coluna com `mutate()`. A sintaxe é: `mutate(novo_nome_de_coluna = valor ou transformação)`

No Stata, isto é similar ao comando `generate`, mas o `mutate()` do R pode também ser usado para modificar uma coluna existente.

### Novas colunas {.unnumbered}

O comando `mutate()` mais básico para criar uma nova coluna deve parecer como este. Ele cria uma nova coluna `nova_coluna` onde o valor em cada linha é 10.

```{r, eval=F}
linelist <- linelist %>% 
  mutate(nova_coluna = 10)
```

Você também pode referenciar valores em outras colunas, para realizar cálculos. Abaixo, uma nova coluna `bmi` é criada para manter o Índice de Massa Corporal (IMC, *Body Mass Index* em inglês) para cada caso - como calculado utilizando a fórmula IMC = kg/m\^2, utilizando coluna `ht_cm` e coluna `wt_kg`.

```{r}
linelist <- linelist %>% 
  mutate(bmi = wt_kg / (ht_cm/100)^2) #bmi = IMC em portugês
```

Se forem criadas várias colunas novas, separe cada uma delas com uma vírgula e uma nova linha. Abaixo estão exemplos de novas colunas, incluindo aquelas que consistem de valores de outras colunas combinadas utilizando `str_glue()` do pacote **stringr** (veja a página em [Caracteres e strings](#characters-strings).

```{r}
new_col_demo <- linelist %>%                       
  mutate(
    new_var_dup    = case_id,             # nova coluna = duplicata/copia outra coluna existente
    new_var_static = 7,                   # nova coluna = todos os valores o mesmo
    new_var_static = new_var_static + 5,  # você pode sobrescrever uma coluna, e ele pode ser um cálculo de outras variáveis
    new_var_paste  = stringr::str_glue("{hospital} on ({date_hospitalisation})") # nova coluna = colando juntos valores de outras colunas
    ) %>% 
  select(case_id, hospital, date_hospitalisation, contains("new"))        # mostra apenas nova coluna, para demonstrar objetivos
```

Revise as novas colunas. Para demonstrar os objetivos, apenas as novas colunas e as colunas usadas para criá-las são mostradas:

```{r message=FALSE, echo=F}
# exibir os dados da linelist como uma tabela
DT::datatable(head(new_col_demo,50), rownames = FALSE, options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```

[***DICA:*** Uma variação de `mutate()` é a função `transmute()`. Esta função adiciona uma nova coluna apenas como `mutate()`, mas também remove todas outras colunas que você não menciona dentro destes parênteses.]{style="color: darkgreen;"}

```{r, eval=F}
# ESCONDIDO DO LEITOR
# remove novas colunas de demonstração criadas acima
# linelist <- linelist %>% 
#   select(-contains("new_var"))
```

### Converter a classe de coluna {.unnumbered}

Colunas contendo valores que são datas, números ou valores lógicos (TRUE/FALSE, ou seja, verdadeiro/falso) só se comportarão como esperado se forem corretamente classificadas. Há uma diferença entre "2" da classe caracteres e 2 da classe numérica!

Há maneiras de definir a classe da coluna durante os comandos de importação, mas isso é muitas vezes complicado. Veja a seção [Introdução ao R](#basics) sobre classes de objetos para saber mais sobre a conversão da classe de objetos e colunas.

Primeiro, vamos fazer algumas verificações em colunas importantes para ver se são a classe correta. Também vimos isso no início, quando corremos `skim()`.

Atualmente, a classe da coluna `age` é caractere. Para realizar análises quantitativas, precisamos que estes números sejam reconhecidos como numéricos!

```{r}
class(linelist$age)
```

A classe da coluna `date_onset` também é caractere! Para realizar análises, estas datas devem ser reconhecidas como datas!

```{r}
class(linelist$date_onset)
```

Para resolver isto, utilize a capacidade de `mutate()` de redefinir uma coluna com uma transformação. Nós definimos a coluna como ela mesma, mas convertida em uma classe diferente. Aqui está um exemplo básico, convertendo ou assegurando que a coluna 'age' seja de classe numérica:

```{r, eval=F}
linelist <- linelist %>% 
  mutate(age = as.numeric(age))
```

Em um modo similar, você pode usar `as.character()` e `as.logical()`. Para converter para a classe Fator, você pode usar `factor()` do R **base** ou `as_factor()` do **forcats**. Leia mais sobre isso na página [Fatores](#factors).

Você deve ter cuidado ao converter para a classe Data. Vários métodos são explicados na página [Trabalhando com datas](#dates). Normalmente, os valores de data bruta devem estar todos no mesmo formato para que a conversão funcione corretamente (por exemplo "MM/DD/YYYY", ou "DD MM YYYY"). Após a conversão para a classe Data, verifique seus dados para confirmar que cada valor foi convertido corretamente.

### Dados agrupados {.unnumbered}

Se o seu dataframe já estiver *agrupado* (veja a página [Dados agrupados](#grouping)), `mutate()` pode se comportar de forma diferente do que se o dataframe não estiver agrupado. Qualquer função resumida, como `mean()`, `median()`, `max()`, etc. será calculada por grupo, não por todas as linhas.

```{r, eval=F}
# idade normalizada pela média de TODAS as linhas
linelist %>% 
  mutate(age_norm = age / mean(age, na.rm=T))

# idade normalizada pela média do grupo do hospital
linelist %>% 
  group_by(hospital) %>% 
  mutate(age_norm = age / mean(age, na.rm=T))
```

Leia mais sobre a utilização de `mutate ()` em dataframes agrupados nesta [documentaçao do mutate tidyverse](https://dplyr.tidyverse.org/reference/mutate.html).

### Transformar múltiplas colunas {#clean_across .unnumbered}

Muitas vezes para escrever um código conciso você quer aplicar a mesma transformação a várias colunas ao mesmo tempo. Uma transformação pode ser aplicada a múltiplas colunas ao mesmo tempo utilizando a função `across()` do pacote **dplyr** (ambém contida no pacote **tidyverse**). `across()` pode ser utilizada com qualquer função **dplyr**, mas é comumente utilizada dentro de  `select()`, `mutate()`, `filter()`, ou `summarise()`. Veja como é aplicado a `summarise()` na página de [Tabelas Descritivas](#tables-descriptive).

Especifique as colunas para o argumento `.cols =` e a(s) função(ões) a ser(em) aplicada(s) a `.fns =`. Quaisquer argumentos adicionais a serem fornecidos à função `.fns' podem ser incluídos após uma vírgula, ainda dentro de `across()`.

#### Seleção de coluna `across()` {.unnumbered}

Especifique as colunas para o argumento `.cols =`. Você pode nomeá-las individualmente, ou usar as funções do helper do "tidyselect". Especifique a função para .fns =`. Observe que utilizando o modo de função demonstrado abaixo, a função é escrita *sem* seus parênteses ( ).

Aqui a transformação `as.character()` é aplicada a colunas específicas nomeadas dentro de `across()`.

```{r, eval=F}
linelist <- linelist %>% 
  mutate(across(.cols = c(temp, ht_cm, wt_kg), .fns = as.character))
```

As funções auxiliares "tidyselect" estão disponíveis para ajudá-lo a especificar colunas. Elas são detalhadas acima na seção sobre Seleção e reordenação de colunas, e eles incluem: `everything()`, `last_col()`, `where()`, `starts_with()`, `ends_with()`, `contains()`, `matches()`, `num_range()` e `any_of()`.

Aqui está um exemplo de como se pode mudar **todas as colunas** para a classe de caracteres:

```{r, eval=F}
# para mudar todas as colunas para a classe caractere
linelist <- linelist %>% 
  mutate(across(.cols = everything(), .fns = as.character))
```

Converter em caracteres todas as colunas onde o nome contém a string "data" (note a colocação de vírgulas e parênteses):

```{r, eval=F}
# para mudar todas as colunas para classe de caracteres
linelist <- linelist %>% 
  mutate(across(.cols = contains("date"), .fns = as.character))
```

Abaixo, um exemplo de transformação de colunas que atualmente são da classe POSIXct (uma classe de data/hora bruta que mostra marcações de hora) - em outras palavras, onde a função `is.POSIXct()` avalia para `TRUE`. Em seguida, queremos aplicar a função `as.Date()` a estas colunas para convertê-las em uma classe normal Date.

```{r, eval=F}
linelist <- linelist %>% 
  mutate(across(.cols = where(is.POSIXct), .fns = as.Date))
```

- Note que dentro de `across()` também utilizamos a função `where()` como `is.POSIXct` está avaliando para TRUE ou FALSE.\
- Note que `is.POSIXct()` é do pacote **lubridate**. Outras funções "is" similares como `is.character()`, `is.numeric()`, e `is.logical()` são do R **base**.


#### Funções`across()` {.unnumbered}

Você pode ler a documentação com `?across' para obter detalhes sobre como fornecer funções para `across()`. Alguns pontos resumidos: há várias maneiras de especificar a(s) função(ões) a ser(em) executada(s) em uma coluna e você pode até mesmo definir suas próprias funções:

-   Você pode fornecer apenas o nome da função (por ex., `mean` ou `as.character`)\

-   Você pode fornecer a função no estilo **purrr** (por ex.,`~ mean(.x, na.rm = TRUE)`) (veja [esta página de Iterações, Listas e Loops](#iteration))\

-   Você pode especificar múltiplas funções fornecendo uma lista (por exemplo, `list(mean = mean, n_miss = ~ sum(is.na(.x))`).

-   Se você fornecer múltiplas funções, múltiplas colunas transformadas serão retornadas por coluna de entrada, com nomes únicos no formato `col_fn`. Você pode ajustar como as novas colunas são nomeadas com o argumento `.names =` usando a sintaxe **glue** (veja a página de [Caracteres e strings](#characters-strings)) onde `{.col}` e `{.fn}` são are abreviaturas para a coluna de entrada e função.

Aqui estão alguns recursos on-line sobre a utilização de `across()`: [creator Hadley Wickham's thoughts/rationale](https://www.tidyverse.org/blog/2020/04/dplyr-1-0-0-colwise/)

### `coalesce()` {.unnumbered}

Esta função **dplyr** encontra o primeiro valor não-faltante em cada posição. Ela "preenche" os valores ausentes com o primeiro valor disponível em uma ordem especificada por você.

Aqui está um exemplo *fora do contexto de um data frame*: Digamos que você tem dois vetores, um contendo a vila de detecção do paciente e outro contendo a vila de residência do paciente. Você pode usar a coalesce para escolher o primeiro valor não-faltante para cada índice:

```{r}
village_detection <- c("a", "b", NA,  NA)
village_residence <- c("a", "c", "a", "d")

village <- coalesce(village_detection, village_residence)
village    # imprima
```

Isto funciona da mesma forma se você fornecer colunas de data frame: para cada linha, a função atribuirá o novo valor de coluna com o primeiro valor não descartado nas colunas que você forneceu (na ordem fornecida).

```{r, eval=F}
linelist <- linelist %>% 
  mutate(village = coalesce(village_detection, village_residence))
```

Este é um exemplo de uma operação "em linha". Para cálculos mais complicados em linha, veja a seção abaixo sobre cálculos em linha.

### Matemática cumulativa {.unnumbered}

Se você quiser que uma coluna reflita a soma cumulativa/média/mínimo/máximo etc para avaliar as linhas em um dataframe até este ponto, usa as seguintes funções:

`cumsum()` retorna a soma cumulativa, como mostrado abaixo:

```{r}
sum(c(2,4,15,10))     # retorna apenas um número
cumsum(c(2,4,15,10))  # retorna a soma cumulativa em cada etapa
```

Isto pode ser usado em um dataframe ao fazer uma nova coluna. Por exemplo, para calcular o número cumulativo de casos por dia em um surto, considere um código como este:

```{r, warning=F, message=F}
cumulative_case_counts <- linelist %>%  # inicia com o caso linelist
  count(date_onset) %>%                 # conta as linhas por dia, como coluna 'n'   
  mutate(cumulative_cases = cumsum(n))  # nova coluna, da soma cumulativa em cada linha
```

Abaixo estão as primeiras 10 linhas:

```{r}
head(cumulative_case_counts, 10)
```

Veja a página sobre [Curvas epidêmicas](#epicurves) para saber como plotar a incidência acumulada com a epicurva.

Veja também:\
`cumsum()`, `cummean()`, `cummin()`, `cummax()`, `cumany()`, `cumall()`

### Usando o R **base**{.unnumbered}

Para definir uma nova coluna (ou redefinir uma coluna) utilizando o R **base**, escreva o nome do data frame, conectado com `$`, para a *nova* coluna (ou a colunas a ser modificada). Use o operador de atribuição `<-` para definir o(s) novo(s) valor(es). Relembre que quando usar o R **base** você deve especificar o nome do data frame antes do nome da coluna toda vez (por ex., `dataframe$column`). Aqui é um exemplo de criação da coluna `bmi` usando o R **base**:

```{r, eval=F}
linelist$bmi = linelist$wt_kg / (linelist$ht_cm / 100) ^ 2)
```

### Adicionar a cadeia pipe {.unnumbered}

**Abaixo, uma nova coluna é adicionada à cadeia pipe e algumas classes são convertidas.**

```{r }
# CADEIA 'PIPE' DE LIMPEZA
#(começa com dados brutos e faz pipes através das etapas de limpeza)
##################################################################################

# inicie a cadeia pipe limpa
###########################
linelist <- linelist_raw %>%
    
    # padronizar a sintaxe do nome da coluna
    janitor::clean_names() %>% 
    
    # re-nomear colunas manualmente
           # NOVO nome             # nome VELHO
    rename(date_infection       = infection_date,
           date_hospitalisation = hosp_date,
           date_outcome         = date_of_outcome) %>% 
    
    # remova coluna
    select(-c(row_num, merged_header, x28)) %>% 
  
    # remova duplicidade
    distinct() %>% 
  
    # ACIMA SÃO PASSOS DE LIMPEZA A MONTANTE JÁ DISCUTIDOS
    ###################################################
    # adicione nova coluna
    mutate(bmi = wt_kg / (ht_cm/100)^2) %>% 
  
    # converta a classe das colunas
    mutate(across(contains("date"), as.Date), 
           generation = as.numeric(generation),
           age        = as.numeric(age)) 
```

## Re-codificar valores

Aqui estão alguns cenários onde você precisa recodificar (mudar) os valores:

-   para editar um valor específico (por exemplo, uma data com um ano ou formato incorreto)\
-   para reconciliar valores não soletrados da mesma forma
-   para criar uma nova coluna de valores categóricos\
-   para criar uma nova coluna de categorias numéricas (por exemplo, categorias de idade)

### Valores específicos {.unnumbered}

Para alterar valores manualmente, você pode utilizar a função `recode()` dentro da função `mutate()`.

Imagine que haja uma data sem sentido nos dados (por exemplo, "2014-14-15"): você poderia fixar a data manualmente nos dados da fonte bruta, ou, você poderia escrever a alteração no pipe de limpeza via `mutate()` e `recode()`. Esta última é mais transparente e reprodutível para qualquer outra pessoa que procure entender ou repetir sua análise.

```{r, eval=F}
# corrigir valores incorretos          # valor velho       # valor novo
linelist <- linelist %>% 
  mutate(date_onset = recode(date_onset, "2014-14-15" = "2014-04-15"))
```

A linha `mutate()` acima pode ser lida como: "mude a coluna `date_onset` para igualar a coluna `date_onset` re-codificada para que o VALOR VELHO seja alterado para o NOVO VALOR". Note que este padrão (VELHO = NOVO) para `recode()` é o oposto da maioria dos padrões de R (novo = velho). A comunidade de desenvolvedores do R está trabalhando na revisão deste padrão.

**Aqui está outro exemplo de recodificação de múltiplos valores dentro de uma coluna.**

Na `linelist` os valores dna coluna "hospital" devem ser limpos. Há várias grafias diferentes e muitos valores em falta.

```{r}
table(linelist$hospital, useNA = "always")  # imprimir tabela de todos os valores únicos, incluindo os que faltam
```

O comando `recode()` abaixo re-define a coluna "hospital" como a coluna atual "hospital", mas com a recodificação especificada muda. Não esqueça as vírgulas depois de cada uma!

```{r}
linelist <- linelist %>% 
  mutate(hospital = recode(hospital,
                     # for reference: OLD = NEW
                      "Mitylira Hopital"  = "Military Hospital",
                      "Mitylira Hospital" = "Military Hospital",
                      "Military Hopital"  = "Military Hospital",
                      "Port Hopital"      = "Port Hospital",
                      "Central Hopital"   = "Central Hospital",
                      "other"             = "Other",
                      "St. Marks Maternity Hopital (SMMH)" = "St. Mark's Maternity Hospital (SMMH)"
                      ))
```

Agora vemos que as grafias na coluna 'hospitalar' foram corrigidas e consolidadas:

```{r}
table(linelist$hospital, useNA = "always")
```

[***DICA:*** O número de espaços antes e depois de um sinal de igual não importa. Torne seu código mais fácil de ler, alinhando-o = para todas ou para a maioria das linhas. Além disso, considere acrescentar uma linha de comentários em destaque para esclarecer aos futuros leitores qual lado é VELHO e qual lado é NOVO.] {style="color: darkgreen;"}

[***DICA:*** Às vezes existe um valor de caractere *em branco* em um conjunto de dados (não reconhecido como o valor de R por ausente - `NA`). Você pode referenciar este valor com duas aspas sem espaço intermediário ]{style="color: darkgreen;"}

### Pela lógica {.unnumbered}

A seguir demonstramos como recodificar valores em uma coluna usando lógica e condições:

- Utilizando `replace()`, `ifelse()` e `if_else()` para uma lógica simples
- Utilizando `case_when()` para uma lógica mais complexa

### Lógica simples {.unnumbered}

#### `replace()` {.unnumbered}

Para re-codificar com critérios lógicos simples, você pode utilizar `replace()` dentro de `mutate()`. `replace()` é uma função do R **base**. Utilize uma condição lógica para especificar as linhas a serem alteradas . A sintaxe geral é:

`mutate(col_to_change = replace(col_to_change, critério para linhas, new value))`.

Uma situação comum para utilizar `replace()` é **alterar apenas um valor em uma linha, utilizando um identificador único de linha**. Abaixo, o gênero é alterado para "Female" (Feminino) na linha onde a coluna `case_id` é "2195".

```{r, eval=F}
#  Exemplo: mudar o gênero de uma observação específica para  "Female" (Feminino).  
linelist <- linelist %>% 
  mutate(gender = replace(gender, case_id == "2195", "Female"))
```

O comando equivalente utilizando a síntaxe do R **base** e colchetes indexadores `[ ]` está abaixo. Ele é lido como "Alterar o valor da coluna `gender` do dataframe `linelist` (para as linhas onde a coluna `case_id` do `linelist` tem o valor de '2195') para 'Female' ".

```{r, eval=F}
linelist$gender[linelist$case_id == "2195"] <- "Female"
```

#### `ifelse()` e `if_else()` {.unnumbered}

Outra ferramenta de lógica simples é `ifelse()` e seu parceiro `if_else()`. Entretanto, na maioria dos casos para re-codificação é mais claro utilizar `case_when()` (detalhado abaixo). Estes comandos "if else" são versões simplificadas de uma declaração de programação `if` e `else`. A sintaxe geral é:\
`ifelse(condição, valor para retornar se a condição avlia se  TRUE, valor para retornar se a condição avaliada é FALSE)`

Abaixo, a coluna definida `source_known` é definida. Seu valor em uma determinada linha é definido como "conhecido" se o valor da linha na coluna `source` *não* estiver faltando. Se o valor em `source` *está* faltando, então o valor em `source_known` está definido como "desconhecido".

```{r, eval=F}
linelist <- linelist %>% 
  mutate(source_known = ifelse(!is.na(source), "known", "unknown"))
```

`if_else()` é uma versão especial de **dplyr** que manipula  datas. Observe que se o valor 'verdadeiro' é uma data, o valor 'falso' também deve qualificar uma data, portanto, utilizando o valor especial `NA_real_` em vez de apenas `NA`.

```{r, eval=F}
#  Criar uma coluna de data de morte, que é NA, se o paciente não tiver morrido.
linelist <- linelist %>% 
  mutate(date_death = if_else(outcome == "Death", date_outcome, NA_real_))
```

**Evitar a junção de muitos comandos ifelse... use `case_when()` ao invés disso!** `case_when()` é muito mais fácil de ler e você cometerá menos erros.

```{r, fig.align = "center", out.width = "100%", echo=F}
knitr::include_graphics(here::here("images", "ifelse bad.png"))
```

Fora do contexto de um data frame, se você quiser que um objeto utilizado em seu código mude seu valor, considere utilizar `switch()` do R **base**.
 
### Lógica complexa {#clean_case_when .unnumbered}

Use o`case_when()` do **dplyr** se você estiver recodificando em muitos grupos novos, ou se você precisar utilizar declarações lógicas complexas para recodificar valores. Esta função avalia cada linha no data frame, avalia se as linhas atendem aos critérios especificados e atribui o novo valor correto.

Os comandos `case_when()` consistem de declarações que têm um Lado Direito (RHS, de Right-Hand Side em inglês) e um Lado Esquerdo (LHS, Left-Hand Side em inglês) separados por um "til" `~`. Os critérios lógicos estão no lado esquerdo e os valores de ajuste estão no lado direito de cada afirmação. As afirmações são separadas por vírgulas.

Por exemplo, aqui utilizamos as colunas `age` e `age_unit` para criar uma coluna `age_years`:

```{r}
linelist <- linelist %>% 
  mutate(age_years = case_when(
            age_unit == "years"  ~ age,       # se a idade for dada em anos
            age_unit == "months" ~ age/12,    # se a idade for dada em meses
            is.na(age_unit)      ~ age))       # se falta a unidade de idade, suponha anos) 
                                             # qualquer outra circunstância, atribui NA (falta)
```

Como cada linha dos dados é avaliado, os critérios são aplicados/avaliados na ordem em que as declaraçõe `case_when()` são escritos - de cima para baixo. Se o critério de cima avaliar `TRUE` para uma dada linha, o valor RHS é atribuído, e os critérios restantes não são sequer testados para essa linha. Assim, é melhor escrever primeiro os critérios mais específicos, e por último os mais gerais.

Nesta linha, em sua declaração final, coloque `TRUE` no lado esquerdo, que captará qualquer linha que não atenda a nenhum dos critérios anteriores. Ao lado direito desta declaração pode ser atribuído um valor como "checar!" ou perda.

[***PERIGO:*** **Valores no lado direito devem ser todos na mesma classe** - seja numérico, caractere, data, lógico, etc. Para atribuir valores em falta (`NA`), você talvez necessite usar as variações especiais de `NA` como `NA_character_`, `NA_real_` (para numérico ou POSIX), e `as.Date(NA)`. Leia mais em [Trabalhando com datas](#dates).]{style="color: red;"}

### Valores faltantes {.unnumbered}

Abaixo estão as funções especiais para manipular valores ausentes no contexto da limpeza de dados.

Veja a página em [Campos em branco/faltantes](#missing-data) para dicas mais detahadas sobre como identificas e tratar os valores ausentes. Por exemplo, a função `is.na()`que logicamente testa  a falta de dados.

**`replace_na()`**

Para alterar valores ausentes (`NA`) para um valor específico, como "Ausente", use a função **dplyr** `replace_na()` dentro de `mutate()`. Observe que isto é utilizado da mesma forma que a `recode` acima - o nome da variável deve ser repetida dentro de `replace_na()`.

```{r}
linelist <- linelist %>% 
  mutate(hospital = replace_na(hospital, "Ausente"))
```

**fct_explicit_na()**

Esta é uma função do pacote **forcats**. O pacote **forcats** manipula colunas de classe Fator. Fatores são a forma do R manipular valores *ordenados* tais como `c("Primeiro", "Segundo", "Terceiro")` ou para definir a ordem em que os valores (por exemplo, hospitais) aparecem em tabelas e gráficos. Veja a página de [Fatores](#factors).

Se seus dados forem de classe Fator e você tentar converter `NA` para "Ausente" utilizando `replace_na()`, você receberá este erro: `invalid factor level, NA generated`. Você tentou adicionar "Ausente" como um valor, quando este não foi definido como um nível possível do fator, e ele foi rejeitado.

A maneira mais fácil de resolver isto é utilizar a função de **forcats** `fct_explicit_na()` que converte uma coluna para a classe fator, e converte os valores `NA` para o caractere "(Missing)" (Ausente/Faltante).

```{r, eval=F}
linelist %>% 
  mutate(hospital = fct_explicit_na(hospital))
```

Uma alternativa mais lenta seria adicionar o nível do fator utilizando `fct_expand()` e então converter os valores ausentes.

**`na_if()`**

Para converter um *valor específico para* `NA`, use `na_if()` do **dplyr**. O  comando abaixo executa a operação oposta de `replace_na()`.  No exemplo abaixo, quaisquer valores de "Ausente" na coluna `hospital` são convertidas para `NA`.

```{r}
linelist <- linelist %>% 
  mutate(hospital = na_if(hospital, "Missing"))
```

Observe: `na_if()` **não pode ser usado para critérios lógicos** (por ex., "todos os valores \> 99") - use `replace()` ou `case_when()` para isso:

```{r, eval=F}
# Converta temperaturas acima de 40 para NA 
linelist <- linelist %>% 
  mutate(temp = replace(temp, temp > 40, NA))

# Converta as datas de início antes de 1 de janeiro de 2000 em ausente
linelist <- linelist %>% 
  mutate(date_onset = replace(date_onset, date_onset > as.Date("2000-01-01"), NA))
```

### Dicionário de limpeza {.unnumbered}

Utilize o pacote **matchmaker** do R e sua função `match_df()` para limpar um data frame com um *dicionário de limpeza*. 

1)  Criar um dicionário  de limpeza com 3 colunas:

    -   Uma coluna "de" (o valor incorreto)\
    -   Uma coluna "para" (o valor correto)\
    -   Uma coluna especificando a coluna para as mudanças a serem aplicadas (ou ".global" para aplicar a todas as colunas)

Note: As entradas do dicionário .global serão substituídas por entradas de dicionário específicas de coluna

```{r, fig.align = "center", out.width = "100%", echo=F}
knitr::include_graphics(here::here("images", "cleaning_dict.png"))
```

2)  Importar o arquivo do dicionário para R. Este exemplo pode ser baixado através das instruções na página [Baixar manual e dados](#data-used).

```{r, echo=F}
cleaning_dict <- rio::import(here("data", "case_linelists", "cleaning_dict.csv"))
```

```{r, eval=F}
cleaning_dict <- import("cleaning_dict.csv")
```

3)  Passe a linelist bruta para `match_df()`, especificando para `dictionary = ` o data frame do dicionário de limpeza. O argumento `from = ` deve ter o nome da coluna que ontem os valores "antigos", o argumento `by = ` deve ser a coluna do dicionário que contem os valores "novos", e o terceiro argumento lista a coluna sobre a qual fazer a mudança.  

Leia mais sobre em  [package documentation](https://cran.r-project.org/web/packages/matchmaker/vignettes/intro.html) digitando `?match_df` no console. Note que essa função pode demorar um tempo longo de execução em uma base de dados grande. 

```{r}
linelist <- linelist %>%     # sua base de dados
     matchmaker::match_df(
          dictionary = cleaning_dict,  # nome do dicionário
          from = "from",               # coluna com as variáveis a serem substituidas (o padrão é a col 1)
          to = "to",                   # coluna ocm os valores finais (padrão é col 2)
          by = "col"                   # coluna com nome de colunas (padrão é col 3)
  )
```

Agora role para a direita para ver como os valores mudaram - particularmente `gender` (de minúsculas para maiúsculas), e todas as colunas de sintomas foram transformadas de sim/não para 1/0.

```{r message=FALSE, echo=F}
# mostre os dados da linelist como uma tabela
DT::datatable(head(linelist,50), rownames = FALSE, filter="top", options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```

Observe que os nomes das colunas no dicionário de limpeza devem corresponder aos nomes *neste ponto* do seu script de limpeza. Veja esta [referência online para o pacote linelist ](https://www.repidemicsconsortium.org/linelist/reference/clean_data.html) para obter mais detalhes.

#### Adicione a cadeia pipe {.unnumbered}

**Abaixo, algumas novas colunas e transformações de colunas são adicionadas à cadeia pipe.** 

```{r}
# CADEIA 'PIPE' DE LIMPEZA
# inicia com dados brutos e canaliza-os através de etapas de limpeza)
##################################################################################

# inicie a cadeia pipe de limpeza
###########################
linelist <- linelist_raw %>%
    
    # padronize a sintaxe do nome da coluna
    janitor::clean_names() %>% 
    
    # renomeie as colunas manualmente
           # NOVO nome             # nome VELHO
    rename(date_infection       = infection_date,
           date_hospitalisation = hosp_date,
           date_outcome         = date_of_outcome) %>% 
    
    # remova coluna
    select(-c(row_num, merged_header, x28)) %>% 
  
    # remova duplicidade
    distinct() %>% 
  
    # adicione colunas
    mutate(bmi = wt_kg / (ht_cm/100)^2) %>%     

    # converta classe de colunas
    mutate(across(contains("date"), as.Date), 
           generation = as.numeric(generation),
           age        = as.numeric(age)) %>% 
    
    # adicione coluna: demora para internação
    mutate(days_onset_hosp = as.numeric(date_hospitalisation - date_onset)) %>% 
    
   # ACIMA ESTÃO AS ETAPAS DE LIMPEZA A MONTANTE JÁ DISCUTIDAS
   ###################################################

    # limpe valores da coluna do hospital
    mutate(hospital = recode(hospital,
                      # OLD = NEW
                      "Mitylira Hopital"  = "Military Hospital",
                      "Mitylira Hospital" = "Military Hospital",
                      "Military Hopital"  = "Military Hospital",
                      "Port Hopital"      = "Port Hospital",
                      "Central Hopital"   = "Central Hospital",
                      "other"             = "Other",
                      "St. Marks Maternity Hopital (SMMH)" = "St. Mark's Maternity Hospital (SMMH)"
                      )) %>% 
    
    mutate(hospital = replace_na(hospital, "Missing")) %>% 

    # crie a coluna age_years (de age e age_unit)
    mutate(age_years = case_when(
          age_unit == "years" ~ age,
          age_unit == "months" ~ age/12,
          is.na(age_unit) ~ age,
          TRUE ~ NA_real_))
```

<!-- ======================================================= -->

<!-- ======================================================= -->

<!-- ======================================================= -->

## Categorias numéricas {#num_cats}

Aqui descrevemos algumas abordagens especiais para criar categorias a partir de colunas numéricas. Exemplos comuns incluem categorias de idade, grupos de valores de laboratório, etc. Aqui vamos discutir:

-   `age_categories()`, do pacote **epikit** \
-   `cut()`, do R **base**\
-   `case_when()`\
-   quebras de quantis com `quantile()` e `ntile()`

### Distribuição de comentários {.unnumbered}

Para este exemplo, nós vamos criar uma coluna `age_cat` usando a coluna `age_years`.

```{r}
# Verifique a classe da variável da linelist age
class(linelist$age_years)
```

Primeiro, examine a distribuição de seus dados, para fazer os pontos de corte apropriados. Veja a página sobre [Básico do ggplot](#ggplot-basics).

```{r, out.height='50%'}
# examine a distribuição
hist(linelist$age_years)
```

```{r}
summary(linelist$age_years, na.rm=T)
```

[***CUIDADO:*** Às vezes, variáveis numéricas serão importadas como classe "character". Isso ocorre se houver caracteres não numéricos em alguns dos valores, por exemplo, uma entrada de "2 meses" para idade ou (dependendo das configurações locais do R) se uma vírgula for usada na casa decimal (por exemplo, "4,5" para significar quatro anos e meio)..]{style="color: orange;"}

<!-- ======================================================= -->

### `age_categories()` {.unnumbered}

Com o pacote **epikit**, você pode usar a função  `age_categories()` fpara categorizar e rotular facilmente colunas numéricas (observação: esta função também pode ser aplicada a variáveis numéricas que não sejam de idade). Como bônus, a coluna de saída é automaticamente um fator ordenado.

Aqui estão as entradas necessárias:

- Um vetor numérico (coluna)\
- O argumento `breakers =` - fornece um vetor numérico de pontos de interrupção para os novos grupos

Primeiro, o exemplo mais simples:

```{r}
# Exemplo simples
################
pacman::p_load(epikit)                    # carregue pacote

linelist <- linelist %>% 
  mutate(
    age_cat = age_categories(             # crie nova coluna
      age_years,                            # coluna numérica para fazer grupos de
      breakers = c(0, 5, 10, 15, 20,        # pontos de quebra
                   30, 40, 50, 60, 70)))

# show table
table(linelist$age_cat, useNA = "always")
```

Os valores de quebra que você especifica são, por padrão, os limites inferiores - ou seja, eles são incluídos no grupo "superior" / os grupos são "abertos" no lado inferior/esquerdo. Conforme mostrado abaixo, você pode adicionar 1 a cada valor de quebra para obter grupos abertos na parte superior/direita.

```{r}
# Incluir extremidades superiores para as mesmas categorias
############################################
linelist <- linelist %>% 
  mutate(
    age_cat = age_categories(
      age_years, 
      breakers = c(0, 6, 11, 16, 21, 31, 41, 51, 61, 71)))

# Mostre tabela
table(linelist$age_cat, useNA = "always")
```

Você pode ajustar como os rótulos são exibidos com `separator =`. O padrão é "-"

Você pode ajustar como os números superiores são tratados, com o argumento `ceiling =`. Para definir um limite superior, defina `ceiling = TRUE`. Neste uso, o valor de quebra mais alto fornecido é um "teto" e uma categoria "XX+" não é criada. Quaisquer valores acima do valor de quebra mais alto (ou para `upper =`, se definido) são categorizados como `NA`. Abaixo está um exemplo com `ceiling = TRUE`, para que não haja categoria de XX+ e valores acima de 70 (o maior valor de quebra) sejam atribuídos como NA.

```{r}
# Com teto definido para TRUE
##########################
linelist <- linelist %>% 
  mutate(
    age_cat = age_categories(
      age_years, 
      breakers = c(0, 5, 10, 15, 20, 30, 40, 50, 60, 70),
      ceiling = TRUE)) # 70 is ceiling, all above become NA

# Mostre a tabela
table(linelist$age_cat, useNA = "always")
```

Alternativamente, em vez de `breakers =`, você pode fornecer todos de `lower =`, `upper =`, e `by =`:

-   `lower =` O número mais baixo que você quer considerar - o padrão é 0\
-   `upper =` O número mais alto que você quer considerar\
-   `by =` O número de anos entre grupos

```{r}
linelist <- linelist %>% 
  mutate(
    age_cat = age_categories(
      age_years, 
      lower = 0,
      upper = 100,
      by = 10))

# Mostre a tabela
table(linelist$age_cat, useNA = "always")
```

Veja a página de Ajuda da função para mais detalhes (digite `?age_categories` no console do R).

<!-- ======================================================= -->

### `cut()` {.unnumbered}

`cut()` é uma alternativa do R **base** para `age_categories()`, mas eu acho que você verá porque `age_categories()` foi desenvolvida para simplificar este processo. Algumas diferenças notáveis da `age_categories()` são:

- Você não precisa instalar/carregar outro pacote\
- Você pode especificar se os grupos estão abertos/fechados à direita/esquerda\
- Você mesmo deve fornecer etiquetas precisas\
- Se você quiser 0 incluído no grupo mais baixo, você deve especificar isso

A sintaxe básica dentro de `cut()` é fornecer primeiro a coluna numérica a ser cortada (`age_years`), e então o argumento *breaks*, que é um vetor numérico `c()` de pontos de quebra. Usando `cut()`, a coluna resultante é um fator ordenado.

Por padrão, a categorização ocorre de forma que o lado direito/superior seja "aberto" e inclusivo (e o lado esquerdo/inferior seja "fechado" ou exclusivo). Este é o comportamento oposto da função `age_categories()`. Os rótulos padrão usam a notação "(A, B]", o que significa que A não está incluído, mas B sim. **Inverta esse comportamento fornecendo o argumento `right = TRUE`**.

Assim, por padrão, os valores "0" são excluídos do grupo mais baixo e categorizados como `NA`! Os valores "0" podem ser bebês codificados como 0, então tenha cuidado! Para alterar isso, adicione o argumento `include.lowest = TRUE` para que qualquer valor "0" seja incluído no grupo mais baixo. O rótulo gerado automaticamente para a categoria mais baixa será "[A],B]". Observe que se você incluir o argumento `include.lowest = TRUE` **e** `right = TRUE`, a inclusão extrema agora será aplicada ao valor e categoria do ponto de quebra *mais alto*, não ao mais baixo.

Você pode fornecer um vetor de rótulos personalizados usando o argumento `labels =`. Como estes são escritos manualmente, tenha muito cuidado para garantir que eles sejam precisos! Verifique seu trabalho usando tabulação cruzada, conforme descrito abaixo.

Um exemplo de `cut()` aplicado a `age_years` para fazer a nova variável `age_cat` está abaixo:

```{r}
# Crie a nova variável, pelo corte da variável numérica age 
# quebra inferior é excluída, mas quebra superior é incluída em cada categoria
linelist <- linelist %>% 
  mutate(
    age_cat = cut(
      age_years,
      breaks = c(0, 5, 10, 15, 20,
                 30, 50, 70, 100),
      include.lowest = TRUE         # inclua 0 no grupo mais baixo
      ))

# tabule o número de observaçõs por grupo
table(linelist$age_cat, useNA = "always")
```

**Verifique seu trabalho!!!** Verifique se cada valor de idade foi atribuído à categoria correta fazendo uma tabulação cruzada das colunas numéricas e de categoria. Examine a atribuição de valores de limite (por exemplo, 15, se as categorias vizinhas forem 10-15 e 16-20).

```{r}
# Tabulação cruzada das colunas numéricas e de categoria. 
table("Numeric Values" = linelist$age_years,   # nomes especificados na tabela para maior clareza.
      "Categories"     = linelist$age_cat,
      useNA = "always")                        # não esqueça de examinar os valores NA
```

**Rotule novamente os valores `NA`**

Você pode querer atribuir a valores `NA` um rótulo tal como "Ausente". Como a nova coluna é de classe Fator (valores restritos), você não pode simplesmente mudá-la com `replace_na()`, pois este valor será rejeitado. Em vez disso, utilize `fct_explicit_na()` de **forcats**, como explicado na página [Fatores](#factors).

```{r}
linelist <- linelist %>% 
  
  # cut() cria age_cat, automaticamente da classe Fator     
  mutate(age_cat = cut(
    age_years,
    breaks = c(0, 5, 10, 15, 20, 30, 50, 70, 100),          
    right = FALSE,
    include.lowest = TRUE,        
    labels = c("0-4", "5-9", "10-14", "15-19", "20-29", "30-49", "50-69", "70-100")),
         
    # tornar explícitos os valores ausentes
    age_cat = fct_explicit_na(
      age_cat,
      na_level = "Idade Ausente")  # você pode especificar o rótulo
  )    

# tabela para ver contagens
table(linelist$age_cat, useNA = "always")
```

**Fazer quebras e rótulos rapidamente**

Para uma maneira rápida de fazer quebras e rotular vetores, use algo como abaixo. Veja a página [Introdução do R](#basics) para referências em `seq()` e `rep()`.

```{r, eval=F}
# Fazer pontos de quebra de 0 a 90 por 5
age_seq = seq(from = 0, to = 90, by = 5)
age_seq

# Fazer etiquetas para as categorias acima, assumindo as configurações padrão de cut()
age_labels = paste0(age_seq + 1, "-", age_seq + 5)
age_labels

#  verificar se ambos os vetores têm o mesmo comprimento
length(age_seq) == length(age_labels)
```

Leia mais sobre `cut()` em sua página de Ajuda entrando em `?cut` no console R

### Quebrar por quantil {.unnumbered}

No entendimento comum, “quantis” ou “percentis” normalmente se referem a um valor abaixo do qual uma proporção de valores está contida. Por exemplo, o 95º percentil de idades dessa linelist seria a idade abaixo da qual estão 95% dos valores de idade.

No entanto, na fala comum, “quartis” e “decis” também podem se referir aos *grupos de dados* igualmente divididos em 4 ou 10 grupos (observe que haverá mais um ponto de quebra do que grupo).

Para obter pontos de quebra de quantil, você pode usar `quantile()` do pacote **stats** do R **base**. Você fornece um vetor numérico (por exemplo, uma coluna em um conjunto de dados) e um vetor de valores numéricos de probabilidade variando de 0 a 1,0. Os pontos de interrupção são retornados como um vetor numérico. Explore os detalhes das metodologias estatísticas inserindo `?quantile`.

-   Se o seu vetor numérico de entrada tiver algum valor ausente, é melhor definir `na.rm = TRUE`\
-   Defina `names = FALSE` para obter um vetor numérico sem nome

```{r}
quantile(linelist$age_years,               # especifique o vetor numérico para trabalhar nele
  probs = c(0, .25, .50, .75, .90, .95),   # especifique os percentis que você quer
  na.rm = TRUE)                            # ignore os valores ausentes 
```

Você pode usar os resultados de `quantile()` como pontos de quebra em `age_categories()` ou `cut()`. Abaixo nós criamos uma nova coluna `deciles` usando `cut()` onde as quebras são definidas usando `quantiles()` em `age_years`. Abaixo, nós exibimos os resultados usando `tabyl()` do **janitor** para que você possa ver as porcentagens (consulte a página [Tabelas descritivas](#tables-descriptive) ). Observe como eles não são exatamente 10% em cada grupo.

```{r}
linelist %>%                                # inicie com linelist
  mutate(deciles = cut(age_years,           # crie a nova coluna decile como cut() da coluna age_years
    breaks = quantile(                      # defina as quebras usando quantile()
      age_years,                               # opere em age_years
      probs = seq(0, 1, by = 0.1),             # de 0.0 a 1.0 a cada 0.1
      na.rm = TRUE),                           # ignore os valores ausentes
    include.lowest = TRUE)) %>%             # para cut() incluir idade 0
  janitor::tabyl(deciles)                   # pipe para a tabela ser exibida
```

### Grupos de tamanho uniforme {.unnumbered}

Outra ferramenta para fazer grupos numéricos é a função `ntile()` do **dplyr** , que tenta dividir seus dados em n *grupos de tamanho uniforme* - *mas esteja ciente de que diferente com `quantile()` o mesmo valor pode aparecer em mais de um grupo.* Forneça o vetor numérico e, em seguida, o número de grupos. Os valores na nova coluna criada são apenas “números” do grupo (por exemplo, 1 a 10), não o intervalo de valores em si, como ao usar `cut()`.

```{r}
# faça grupos com ntile()
ntile_data <- linelist %>% 
  mutate(even_groups = ntile(age_years, 10))

# faça uma tabela de contagem e proporções por grupo
ntile_table <- ntile_data %>% 
  janitor::tabyl(even_groups)
  
# fixe os valores mín/máx para demonstrar as faixas
ntile_ranges <- ntile_data %>% 
  group_by(even_groups) %>% 
  summarise(
    min = min(age_years, na.rm=T),
    max = max(age_years, na.rm=T)
  )

# combine e "printe" - note que valores estão presentes em múltiplos grupos
left_join(ntile_table, ntile_ranges, by = "even_groups")
```

<!-- ======================================================= -->

### `case_when()` {.unnumbered}

É possível utilizar a função `case_when()` do **dplyr** para criar categorias a partir de uma coluna numérica, mas é mais fácil utilizar `age_categories()` do **epikit** ou `cut()` porque estas criarão automaticamente um fator ordenado.

Se utilizar `case_when()`, por favor, revise o uso apropriado conforme descrito anteriormente na seção recodificar valores desta página. Esteja ciente também que todos os valores do lado direito devem ser da mesma classe. Assim, se você quiser `NA` no lado direito, você deve escrever "Ausente" ou utilizar o valor `NA` especial  `NA_character_`.

### Adicionar à cadeia pipe {.unnumbered} 

Abaixo, é adicionado o código para criar duas colunas de idade categóricas à cadeia pipe de limpeza:

```{r}
# CADEIA DE LIMPEZA 'PIPE' 
# (inicie com dados brutos e canalize-os através de etapas de limpeza)
##################################################################################

# inicie a cadeia pipe de limpeza
###########################
linelist <- linelist_raw %>%
    
    # padronize a sintaxe do nome da coluna
    janitor::clean_names() %>% 
    
    # renomeie as colunas manualmente
           # NOVO nome             # nome VELHO
    rename(date_infection       = infection_date,
           date_hospitalisation = hosp_date,
           date_outcome         = date_of_outcome) %>% 
    
    # remova coluna
    select(-c(row_num, merged_header, x28)) %>% 
  
    # remova as duplicidades
    distinct() %>% 

    # adicione coluna
    mutate(bmi = wt_kg / (ht_cm/100)^2) %>%     

    # converta classe de colunas
    mutate(across(contains("date"), as.Date), 
           generation = as.numeric(generation),
           age        = as.numeric(age)) %>% 
    
    # adicione coluna: demora para internação
    mutate(days_onset_hosp = as.numeric(date_hospitalisation - date_onset)) %>% 
    
    # limpe valores da coluna do hospital
    mutate(hospital = recode(hospital,
                      # VELHO = NOVO
                      "Mitylira Hopital"  = "Military Hospital",
                      "Mitylira Hospital" = "Military Hospital",
                      "Military Hopital"  = "Military Hospital",
                      "Port Hopital"      = "Port Hospital",
                      "Central Hopital"   = "Central Hospital",
                      "other"             = "Other",
                      "St. Marks Maternity Hopital (SMMH)" = "St. Mark's Maternity Hospital (SMMH)"
                      )) %>% 
    
    mutate(hospital = replace_na(hospital, "Ausente")) %>% 

    # crie a coluna age_years (de age e age_unit)
    mutate(age_years = case_when(
          age_unit == "years" ~ age,
          age_unit == "months" ~ age/12,
          is.na(age_unit) ~ age,
          TRUE ~ NA_real_)) %>% 
  
    # ACIMA ESTÃO AS ETAPAS DE LIMPEZA A MONTANTE JÁ DISCUTIDAS
    ###################################################   
    mutate(
          # categorias de idade:personalizado
          age_cat = epikit::age_categories(age_years, breakers = c(0, 5, 10, 15, 20, 30, 50, 70)),
        
          # categorias etárias: 0 a 85 por 5s
          age_cat5 = epikit::age_categories(age_years, breakers = seq(0, 85, 5)))
```

<!-- ======================================================= -->

## Adicionar linhas

### Uma-por-uma {.unnumbered}

Adicionar linhas uma-por-uma manualmente é tediosa mas pode ser feito com `add_row()` do **dplyr**. Relembre que cada coluna deve conter valores de apenas uma classe (seja caracter, numérico, lógico, etc.). Então adicionar uma linha reque detalhes para manter isso.

```{r, eval=F}
linelist <- linelist %>% 
  add_row(row_num = 666,
          case_id = "abc",
          generation = 4,
          `infection date` = as.Date("2020-10-10"),
          .before = 2)
```

Utilize `.before` e `.after.` para especificar a colocação da linha que você deseja adicionar. `.before = 3`colocará a nova linha antes da 3ª linha atual. O comportamento padrão é adicionar a linha ao final. As colunas não especificadas serão deixadas vazias (`NA`).

O novo *número da linha* pode parecer estranho ("...23"), mas os números das linhas preexistentes *mudaram*. Portanto, se utilizar o comando duas vezes, examine/teste a inserção cuidadosamente.

Se uma classe que você fornece estiver desligada, você verá um erro como este:

    Erro: Não é possível combinar ..1$infection date <date> e ..2$infection date <character>. 

(ao inserir uma linha com um valor de data, lembre-se de embrulhar a data na função `as.Date()` como `as.Date("2020-10-10")`).

### Colar linhas {.unnumbered}

Para combinar conjuntos de dados unindo as linhas de um dataframe ao fundo de outro dataframe, pode-se utilizar `bind_rows()` do **dplyr**. Isto é explicado com mais detalhes na página [Juntando dados](#joining-matching).

<!-- ======================================================= -->

<!-- ======================================================= -->

<!-- ======================================================= -->

## Filtrar linhas

Uma etapa típica de limpeza depois de limpar as colunas e recodificar os valores é *filtrar* o dataframe para linhas específicas utilizando o verbo `filter()` do **dplyr**.

Dentro de `filter()`, especificar a lógica que deve ser `TRUE` para que uma linha do conjunto de dados seja mantida. Abaixo mostramos como filtrar linhas com base em condições lógicas simples e complexas.

<!-- ======================================================= -->

### Filtro simples {.unnumbered}

Este exemplo simples redefine o dataframe `linelist` como ela mesma, tendo filtrado as linhas para atender a uma condição lógica. **Apenas as linhas onde a declaração lógica dentro dos parênteses avaliada como`TRUE` são mantidas.**

Neste exemplo, a afirmação lógica é `gender == "f"`, que é perguntar se o valor na coluna`gender` é igual a "f" (sensível a maiúsculas e minúsculas). 

Antes do filtro ser aplicado, o número de linhas da `linelist` é `nrow(linelist)`.

```{r, eval=F}
linelist <- linelist %>% 
  filter(gender == "f")   # mantenha apenas as linhas onde o gênero é igual a  "f"
```

Depois que o filtro é aplicado, o número de linhas da `linelist` é `linelist %>% filter(gender == "f") %>% nrow()`.

### Filtrar valores faltantes {.unnumbered}

É bastante comum querer filtrar as linhas que possuem valores ausentes. Resista à tentação de escrever `filter(!is.na(column) & !is.na(column))` e ao invés disso use a função **tidyr** que é customizada para este propósito: `drop_na()`. Se executado com parênteses vazios, ele remove linhas com *qualquer* valores ausentes. Alternativamente, você pode fornecer nomes de colunas específicas a serem avaliadas quanto à ausência, ou usar as funções auxiliares "tidyselect" descritas [acima](#clean_tidyselect).

```{r, eval=F}
linelist %>% 
  drop_na(case_id, age_years)  # elimila as linhas com valores faltates nas colunas case_id ou age_years
```

Veja a página sobre [Campos em branco/faltantes](#missing-data) para várias técnicas para analisar e manipular valores faltantes nos seus dados. 

### Filtrar pelo número da linha {.unnumbered}

Em um quadro de dados ou tibble, cada linha terá geralmente um "número de linha" que (quando visto no R Viewer) aparece à esquerda da primeira coluna. Não é em si uma coluna verdadeira nos dados, mas pode ser utilizada em uma declaração `filter()`.

Para filtrar com base no "número de linha", é possível utilizar a função **dplyr** com o `row_number()` com parênteses abertos como parte de uma instrução de filtragem lógica. Muitas vezes você utilizará o operador `%in%` e um range de números como parte dessa instrução lógica, como mostrado abaixo. Para ver as *primeiras* N fileiras , você também pode utilizar a função especial `head()`l do pacote **dplyr** .



```{r, eval=F}
# Veja as primeiras 100 linhas
linelist %>% head(100)     # ou use  tail() tvara ver as últimas n linhas

# Mostre apenas 5 linhas
linelist %>% filter(row_number() == 5)

# Veja linha 2 a 20 e especifique 3 colunas 
linelist %>% filter(row_number() %in% 2:20) %>% select(date_onset, outcome, age)
```

Você também pode converter os números das linhas para uma coluna verdadeira, canalizando seu data Frame para a função **tibble** `rownames_to_column()` (não coloque nada entre parênteses).

<!-- ======================================================= -->

### Filtro complexo {.unnumbered}

Sentenças lógicas mais complexas podes ser contruídas usando parênteses  `( )`, OU  os operadores `|`, `!`, `%in%`, e AND `&`. Um exemplo pode ser visto abaixo:

Nota: Você pode utilizar o `!` operador em frente a um critério lógico para negá-lo. Por exemplo, `!is.na(column)` avalia para verdadeiro se o valor da coluna *não* é faltante. Da mesma forma, `!column %in% c("a", "b", "c")` avalia se o valor da coluna *não* está contido no vetor.

#### Examine os dados {.unnumbered}

Abaixo está um simples comando de uma linha para criar um histograma de datas de início. Veja que um segundo surto menor de 2012-2013 também está incluído neste conjunto de dados brutos. **Para nossas análises, queremos remover as entradas deste surto anterior.**

```{r, out.width = "50%"}
hist(linelist$date_onset, breaks = 50)
```

#### Como os filtros lidam com valores numericos e datas faltantes  {.unnumbered}

Podemos simplesmente filtrar por 'date_onset' para as linhas após junho de 2013? **Cuidado! Aplicando o código `filter(date_onset > as.Date("2013-06-01")))` removeria qualquer linha na última epidemia com uma data de início ausente!**

[***PERIGO:*** Filtrar para maior que (\>) ou menor que (\<) uma data ou número pode remover qualquer linha com valores ausentes (`NA`)! Isto porque `NA` é tratado como infinitamente grande e pequeno.]{estilo="cor: vermelho;"}

*(Veja a página em [Trabalhando com datas](#dates) para mais informações sobre como trabalhar com datas e o pacote **lubridate**)*


#### Desenhe o filtro {.unnumbered}

Examine a tabulação cruzada para ter certeza que excluímos somente as linhas corretas:

```{r}
table(Hospital  = linelist$hospital,                     # nome do hospital
      YearOnset = lubridate::year(linelist$date_onset),  # ano de inicio dos sintomas (date_onset)
      useNA     = "always")                              # mostrar valores faltantes
```

Que outros critérios podemos filtrar para remover o primeiro surto (em 2012 e 2013) do conjunto de dados? Vemos isso:

- A primeira epidemia em 2012 & 2013 ocorreu no Hospital A, Hospital B, e que também houve 10 casos no Port Hospital.
- Os Hospitais A e B *não* tiveram casos na segunda epidemia, mas o Port Hospital teve.

Queremos excluir:

- A `nrow(linelist %>% filter(hospital %in% c("Hospital A", "Hospital B") | date_onset < as.Date("2013-06-01")))` filas com início em 2012 e 2013 no hospital A, B, ou no Porto.
    - Excluir `nrow(linelist %>% filter(date_onset < as.Date("2013-06-01")))` filas com início em 2012 e 2013
    - Excluir `nrow(linelist %>% filter(hospital %em% c('Hospital A', 'Hospital B') & is.na(date_onset)))`linhas dos Hospitais A & B com datas de início ausentes\
    - Fazer **não** excluir `nrow(linelist %>% filter(!hospital %in% c('Hospital A', 'Hospital B') & is.na(date_onset)))` outras linhas com datas de início ausentes.

Começamos com uma lineliste de `nrow(linelist){\i1}`. Aqui está nossa declaração de filtro:

```{r}
linelist <- linelist %>% 
  # mantém linhas onde o início é depois de 1 de Junho OU o início dos sintomas está faltante E o hospital é OUTRO que não A nem B 
  filter(date_onset > as.Date("2013-06-01") | (is.na(date_onset) & !hospital %in% c("Hospital A", "Hospital B")))

nrow(linelist)
```

Quando refazemos a tabulação cruzada, vemos que os Hospitais A e B são completamente removidos, e os 10 casos de hospitais portuários de 2012 e 2013 são removidos, e todos os outros valores são os mesmos - exatamente como queríamos.

```{r}
table(Hospital  = linelist$hospital,                     # nome do hospital
      YearOnset = lubridate::year(linelist$date_onset),  # ano de início dos sintomas
      useNA     = "always")                              # mostrar valores faltantes
```

Declarações múltiplas podem ser incluídas dentro de um comando de filtro (separadas por vírgulas), ou você pode sempre encadear com um %>% para um comando filter() separado para maior clareza.

*Nota: alguns leitores podem notar que seria mais fácil filtrar apenas por `date_hospitalisation` porque é 100% completo sem valores ausentes. Isto é verdade. Mas o `date_onset` é utilizado com o propósito didático de demonstrar um filtro complexo.*

### Autônomo/Independente {.unnumbered}

Um filtro também pode ser feito como um comando autônomo (não parte de uma cadeia de pipes (%>%)). Como outros verbos **dplyr**, neste caso o primeiro argumento deve ser o próprio conjunto de dados.

```{r, eval=F}
# dataframe <- filter(dataframe, condition(s) for rows to keep)

linelist <- filter(linelist, !is.na(case_id))
```

Você também pode usar o R **base** para criar um subconjunto dos dados,  usando colchetes que refletem as [linhas, colunas] do  que você deseja reter.

```{r, eval=F}
# dataframe <- dataframe[row conditions, column conditions] (se deixar a entrada em branco significa "todas as linhas ou todas as colunas")

linelist <- linelist[!is.na(case_id), ]
```

### Revisar rapidamente registros {.unnumbered}

Muitas vezes você quer rever rapidamente alguns registros, para apenas algumas colunas. A função do R **base** `View()` exibirá um dataframe para visualização em seu RStudio.

Veja a lineliste no RStudio:

```{r, eval=F}
View(linelist)
```

Aqui estão dois exemplos de visualização de células específicas (linhas específicas, e colunas específicas):

**Com funções dplyr `filter()` e `select()`:**

Dentro de `View()`, encadeie o conjunto de dados com o pipe (%>%) com a função `filter()` para manter certas linhas, e depois com a função `select()` para manter certas colunas. Por exemplo, para rever as datas de início e hospitalização de 3 casos específicos:

```{r, eval=F}
View(linelist %>%
       filter(case_id %in% c("11f8ea", "76b97a", "47a5f5")) %>%
       select(date_onset, date_hospitalisation))
```

Você consegue os mesmos resultados com a seguinte sintaxe do R **base** , usando colchetes `[ ]` para subdividir o que você quer ver.

```{r, eval=F}
View(linelist[linelist$case_id %in% c("11f8ea", "76b97a", "47a5f5"), c("date_onset", "date_hospitalisation")])
```

#### Adiciotar a uma cadeia usando o pipe (%>%) {.unnumbered}

```{r}
#  CADEIA DE LIMPEZA 'PIPE' (inicie com dados brutos e canalize-os através de etapas de limpeza)
##################################################################################

# inicie a cadeia pipe de limpeza
###########################
linelist <- linelist_raw %>%
    
    # padronize a sintaxe do nome da coluna
    janitor::clean_names() %>% 
    
    # renomeie as colunas manualmente
           # NOVO nome             # nome VELHO
    rename(date_infection       = infection_date,
           date_hospitalisation = hosp_date,
           date_outcome         = date_of_outcome) %>% 
    
    # remova coluna
    select(-c(row_num, merged_header, x28)) %>% 
  
    # remova duplicidades
    distinct() %>% 

    # adicione colunas
    mutate(bmi = wt_kg / (ht_cm/100)^2) %>%     

    # converta classe de colunas
    mutate(across(contains("date"), as.Date), 
           generation = as.numeric(generation),
           age        = as.numeric(age)) %>% 
    
    # adicione coluna: demora para internação
    mutate(days_onset_hosp = as.numeric(date_hospitalisation - date_onset)) %>% 
    
    # limpe valores da coluna do hospital
    mutate(hospital = recode(hospital,
                      # VELHO = NOVO
                      "Mitylira Hopital"  = "Military Hospital",
                      "Mitylira Hospital" = "Military Hospital",
                      "Military Hopital"  = "Military Hospital",
                      "Port Hopital"      = "Port Hospital",
                      "Central Hopital"   = "Central Hospital",
                      "other"             = "Other",
                      "St. Marks Maternity Hopital (SMMH)" = "St. Mark's Maternity Hospital (SMMH)"
                      )) %>% 
    
    mutate(hospital = replace_na(hospital, "Ausente")) %>% 

    # crie a coluna age_years (de age e age_unit)
    mutate(age_years = case_when(
          age_unit == "years" ~ age,
          age_unit == "months" ~ age/12,
          is.na(age_unit) ~ age,
          TRUE ~ NA_real_)) %>% 
  
    mutate(
          # categorias de idade: personalizado
          age_cat = epikit::age_categories(age_years, breakers = c(0, 5, 10, 15, 20, 30, 50, 70)),
        
          # categorias de idade: 0 a 85 por 5s
          age_cat5 = epikit::age_categories(age_years, breakers = seq(0, 85, 5))) %>% 
    
    # ACIMA ESTÃO AS ETAPAS DE LIMPEZA A MONTANTE JÁ DISCUTIDAS
    ###################################################
    filter(
          # keep only rows where case_id is not missing
          !is.na(case_id),  
          
          # also filter to keep only the second outbreak
          date_onset > as.Date("2013-06-01") | (is.na(date_onset) & !hospital %in% c("Hospital A", "Hospital B")))
```

<!-- ======================================================= -->

<!-- ======================================================= -->

<!-- ======================================================= -->

## Cálculo por linha

Se você quiser realizar um cálculo dentro de uma linha, você pode utilizar `rowwise()` a partir de **dplyr**. Veja esta vinheta online em [cálculos em linha](https://cran.r-project.org/web/packages/dplyr/vignettes/rowwise.html).\
Por exemplo, este código se aplica `rowwise()` e então cria uma nova coluna que soma o número das colunas de sintomas especificados que têm o valor "yes" (sim), para cada linha da lista de linhas. As colunas são especificadas dentro de `sum()` pelo nome dentro de um vetor `c()`. A coluna `rowwise()` é essencialmente um tipo especial de `group_by()`, portanto é melhor utilizar `ungroup()` quando você terminar (página em [Agrupar dados](#grouping)).

```{r,}
linelist %>%
  rowwise() %>%
  mutate(num_symptoms = sum(c(fever, chills, cough, aches, vomit) == "yes")) %>% 
  ungroup() %>% 
  select(fever, chills, cough, aches, vomit, num_symptoms) # para mostrar
```

Ao especificar a coluna a ser avaliada, talvez você queira utilizar as funções de ajuda "tidyselect" descritas na seção `select()` desta página. Você só tem que fazer um ajuste (porque não está utilizando-as dentro de uma função **dplyr** como `select()` ou `summarise()`).

Coloque o critério de especificação de coluna dentro da função **dplyr** `c_across()`. Isto porque `c_across` ([documentação](https://dplyr.tidyverse.org/reference/c_across.html)) é projetado para trabalhar com `rowwise()` especificamente. Por exemplo, o seguinte código:

- Aplica-se `rowwise()` assim a seguinte operação (`sum()`) é aplicada dentro de cada linha (não somando colunas inteiras)\
- Cria nova coluna `num_NA_dates`, definida para cada linha como o número de colunas (com nome contendo "data") para as quais `is.na()` avaliadas para VERDADEIRO (estão faltando dados).\
- grupo()`ungroup()` para remover os efeitos de `rowwise()` para as etapas subseqüentes.

```{r,}
linelist %>%
  rowwise() %>%
  mutate(num_NA_dates = sum(is.na(c_across(contains("date"))))) %>% 
  ungroup() %>% 
  select(num_NA_dates, contains("date")) # para mostrar
```

Você também poderia fornecer outras funções, tais como `max()` para obter a data mais recente ou mais recente para cada linha:

```{r}
linelist %>%
  rowwise() %>%
  mutate(latest_date = max(c_across(contains("date")), na.rm=T)) %>% 
  ungroup() %>% 
  select(latest_date, contains("date"))  # para mostrar 
```

## Organizar e ordenar

Utilize a função **dplyr** `arrange()` para ordenar ou ordenar as linhas por valores de coluna.

Simplesmente liste as colunas na ordem em que elas devem ser ordenadas. Especifique `.by_group = TRUE` se você quiser que a ordenação ocorra primeiro por quaisquer *grupos* aplicados aos dados (ver página em [Agrupar dados](#grouping)).

Por padrão, a coluna será ordenada em ordem "ascendente" (que se aplica às colunas numéricas e também às colunas de caracteres). Você pode ordenar uma variável em ordem "decrescente", envolvendo-a com `desc()`.

A ordenação de dados com `arrange()` é particularmente útil ao fazer [Tabelas para apresentação](#tables-presentation), utilizando `slice()` para pegar as linhas "top" por grupo, ou definir a ordem de nível de fator por ordem de aparência.

Por exemplo, para ordenar as linhas de nossa linelist por `hospital`, depois por `date_onset` em ordem decrescente, nós utilizaríamos:

```{r, eval=F}
linelist %>% 
   arrange(hospital, desc(date_onset))
```

```{r, echo=F}
# ESCONDIDO
#
# converte uma linha antiga remanescente para faltante para facilitar
linelist <- linelist %>% 
  mutate(
    date_hospitalisation = case_when(
      date_hospitalisation < as.Date("2013-01-01") ~ as.Date(NA),
      TRUE                                         ~ date_hospitalisation),
    date_outcome = case_when(
      date_outcome < as.Date("2013-01-01") ~ as.Date(NA),
      TRUE                                 ~ date_outcome)
    )

#min(linelist$date_hospitalisation, na.rm=T)
#min(linelist$date_outcome, na.rm=T)
```

```{r echo=F}
# REARRANGAR COLUNAS PARA EXPORTAR
linelist <- linelist %>% 
  select(case_id:gender, age, age_unit, age_years, age_cat, age_cat5, everything())
```

```{r echo=F}
# EXPORTAR O ARQUIVO LINELIST LIMPO PARA A PASTA "DATA"
rio::export(linelist, here::here("data", "case_linelists", "linelist_cleaned.xlsx"))
rio::export(linelist, here::here("data", "case_linelists", "linelist_cleaned.rds"))
```
```{r include=FALSE, cache=FALSE}

# clear workspace
rm(list = ls(all = TRUE))

# clear all packages except base
#lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))

# to ensure that tidyverse packages prevail
filter <- dplyr::filter
select <- dplyr::select
summarise <- dplyr::summarise
summary <- base::summary
incidence <- incidence2::incidence

#load core packages
pacman::p_load(
     rio,
     here,
     DT,
     stringr,
     lubridate,
     tidyverse
)

# import the cleaned ebola linelist
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

# import the count data - facility level
#count_data <- rio::import(here::here("data", "facility_count_data.rds"))

# Settings

options(scipen=1, digits=7)

# print only text (not code)
# library(knitr)
# opts_chunk$set(list(echo = FALSE, eval = FALSE))
```

<!--chapter:end:new_pages/cleaning.Rmd-->

# Trabalhando com datas {#dates}

```{r, out.width=c('50%'), fig.align='center', echo=F, message=F}
knitr::include_graphics(here::here("images", "Dates_500x500.png"))
```

Trabalhar com datas no R requer mais atenção do que trabalhar com outras classes de objetos. Abaixo, estão apresentadas algumas ferramentas e exemplos para tornar esse processo menos doloroso. Felizmente, as datas podem ser alteradas facilmente com a prática e com um conjunto de pacotes úteis, como **lubridate**.

Na importação de dados brutos, o R frequentemente interpreta as datas como objetos de caracteres - isso significa que elas não podem ser usados para operações gerais de data, como criar séries temporais e calcular intervalos de tempo. Para tornar as coisas mais difíceis, existem muitas maneiras de formatar uma data e é preciso ajudar o R a saber qual parte da data representa o quê (mês, dia, hora, etc.).

As datas no R possuem sua própria classe de objeto - a classe `Date`. Deve-se destacar que também existe uma classe que armazena objetos com data e hora. Objetos de data e hora são formalmente chamados de classes `POSIXt`, `POSIXct`, e/ou `POSIXlt` (a diferença não é importante). Esses objetos são informalmente chamados de classes de data-e-hora (*datetime*).

-   É importante fazer com que o R reconheça quando uma coluna contém datas.\

-   As datas são uma classe de objeto própria e podem ser complicado de trabalhar com elas.

-   Aqui, são apresentadas várias maneiras de converter colunas com datas em classe de objeto Date.

<!-- ======================================================= -->

## Preparação

### Carregar os pacotes {.unnumbered}

Esse trecho de código mostra o carregamento dos pacotes necessários para esta página. Neste manual enfatizamos a função `p_load()` do **pacman**, que instala o pacote se necessário e o carrega para utilização. Tamém é possível carregar os pacotes instalados com `library()` a partir do R **base**. Para mais informações, veja a página em [Introdução ao R](#basics) sobre pacotes no R.

```{r dates_packages, warning=F, message=F}
# Confere se o pacote está instalado, instala o pacote se necessário, e carrega-o para a sessão atual

pacman::p_load(
  lubridate,  # pacote geral para manipulação e conversão de datas  
  parsedate,   # possui a função de "adivinhar" datas desorganizadas
  aweek,      # outra opção para conversão de datas em semanas, e de semanas em datas 
  zoo,        # funções adicionais de data/hora
  tidyverse,  # gerenciamento e visualização dos dados  
  rio)        # importação/exportação dos dados
```

### Importação dos dados {.unnumbered}

Importamos o conjunto de dados de casos de uma simulação de epidemia de Ebola. Se você deseja baixar os dados para acompanhar passo a passo, consulte as instruções na página [Baixar manual e dados](#data-used). Presumimos que o arquivo está no diretório de trabalho, portanto, nenhuma subpasta é especificada neste caminho de arquivo.

```{r,  echo=F}
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

```

```{r, eval=F}
linelist <- import("linelist_cleaned.xlsx")

```

<!-- ======================================================= -->

## Data atual

Você pode obter a data atual do "sistema" ou a data e hora do sistema do seu computador por meio da seguintes funções presentes no R **base**.

```{r}
# obter a data do sistema - esta é uma classe DATE
Sys.Date()

# obter a hora do sistema - esta é uma classe DATETIME
Sys.time()
```

Com o pacote **lubridate**, essas informações também pode ser retornadas com `today()` e `now()`, respectivamente. `date()` retorna a data e hora atual com os nomes dos dias da semana e dos meses.

<!-- ======================================================= -->

## Converter para Data

Depois de importar um conjunto de dados para o R, os valores da coluna com datas podem ser semelhantes a "1989/12/30", "05/06/2014", ou "13 Janeiro 2020". Nesses casos, é provável que o R ainda esteja lendo esses valores como caracteres. O R deve ser *informado* que esses valores são datas... e o que esse fomato de data representa (qual parte é referente ao dia, mês, ano, etc).

Uma vez informado, o R converte esses valores para a classe Date. Em segundo plano, o R armazenará as datas como números (o número de dias a partir de sua data de "origem" 1 de janeiro de 1970). Você não fará interface com o número da data com frequência, mas isso permite que R trate as datas como variáveis contínuas e permita operações especiais, como calcular a distância entre as datas.

Por padrão, os valores da classe Date em R são exibidos como AAAA-MM-DD. Posteriormente nesta seção, discutiremos como alterar a exibição dos valores de data.

A seguir, apresentamos duas abordagens para converter uma coluna de valores de caracteres para a classe Date.

[***DICA:*** Você pode checar a classe atual de uma coluna utilizando a função `class()`presente na **base** do R , como por exemplo `class(linelist$date_onset)`.]{style="color: darkgreen;"}

### R **base** {.unnumbered}

`as.Date()` é a função presente no R base para conversão um objeto ou coluna para a classe Data (observe a capitalização de "D").

Para o uso da função `as.Date()` é preciso que:

-   Você especifique o formato **existente** da data como um caractere bruto ou então que especifique a data de origem, caso forneça datas como números (consulte a seção sobre datas do Excel);
-   Se foi usado em uma coluna de caracteres, todos os valores de data devem ter o mesmo formato exato (se este não for o caso, tente `parse_date()` do pacote **parsedate**).

**Primeiro**, verifique a classe de sua coluna com `class()` do R **base**. Se você não tem certeza ou está confuso sobre a classe de seus dados (por exemplo, você vê "POSIXct", etc.) pode ser mais fácil primeiro converter a coluna para a classe *Character* com a função `as.character()`, e depois converter para a classe *Date*.

**Segundo**, dentro da função `as.Date()`, use o argumento `format =` para informar ao R o formato *atual* dos componentes da data como caractere - quais caracteres se referem ao mês, dia e ano, e como eles são separados. Se seus valores já estiverem em um dos formatos de data padrão do R ("AAAA-MM-DD" ou "AAAA/MM/DD"), o argumento `format =` não é necessário.

Para `format =`, forneça uma sequência de caracteres (entre aspas) que representa o formato de data atual usando as abreviações especiais "strptime" abaixo. Por exemplo, se as datas dos caracteres estão atualmente no formato "DD/MM/AAAA", como "24/04/1968", você usaria `format = "%d/%m/%Y"` para converter os valores em datas. **É necessário colocar o formato entre aspas. E não se esqueça de quaisquer barras ou travessões!**

```{r eval=F}
# Converter para classe data
linelist <- linelist %>% 
  mutate(date_onset = as.Date(date_of_onset, format = "%d/%m/%Y"))
```

A maioria das abreviações de *strptime* estão listadas abaixo. Você pode ver a lista completa executando `?strptime`.

%d = Número do dia do mês (5, 17, 28, etc.)\
%j = Número do dia do ano (dia Juliano 001-366)\
%a = Dia da semana abreviado (Seg, Ter, Quarta,etc. ou Mon, Tue, Wed, etc.)\
%A = Dia da semana completo (segunda, terça, etc.)

%w = Número do dia da semana (0-6, sendo que domingo é 0)\
%u = Número do dia da semana (1-7, sendo que segunda é 1)\
%W = Número da semana (00-53, segunda é início da semana)\
%U = Número da semana (01-53, domingo é o início da semana)\
%m = Número do mês (por exemplo, 01, 02, 03, 04)\
%b = Mês abreviado (Jan, Fev, etc.)\
%B = Mês completo (Janeiro, Fevereiro, etc.)  %y = Ano em 2 dígitos (por exemplo, 89)\
%Y = Ano em 4 dígitos (por exemplo, 1989)\
%h = horas (relógio de 24 horas)\
%M = minutos\
%s = segundos

%z = deslocamento do GMT\
%Z = fuso horário (caractere)

[***DICA:*** TO argumento `format =` da função `as.Date()` não está informando ao R o formato que deseja que as datas tenham, mas sim como identificar as partes da data da forma como elas estão, *antes* de rodar o comando.]{style="color: darkgreen;"}

[***DICA:*** Certifique-se de que no argumento `format =` você usa o separador de data (por exemplo, /, -, ou espaço) que está presente em suas datas.]{style="color: darkgreen;"}

Uma vez que os valores estão na classe Date, o R os exibirá no formato padrão, que é AAAA-MM-DD.

### **lubridate** {.unnumbered}

A conversão de objetos de caracteres em datas pode ser facilitada com o uso do pacote **lubridate**. Este é um pacote **tidyverse** projetado para tornar o trabalho com datas e horários mais simples e consistente do que nO R **base**. Por essas razões, **lubridate** é frequentemente considerado o pacote padrão ouro para datas e horários, e é recomendado sempre que trabalhar com eles.

O pacote **lubridate** fornece diferentes funções auxiliares projetadas para converter objetos de caracteres em datas de uma forma intuitiva e mais branda do que especificar o formato em `as.Date()`. Essas funções são específicas para o formato de data aproximada, mas permitem uma variedade de separadores e sinônimos para datas (como, 01 vs Jan vs Janeiro) - eles são nomeados após abreviações de formatos de data.

```{r, }
# instale/carregue lubridate 
pacman::p_load(lubridate)
```

A função `ymd()` converte de forma flexível os valores de data fornecidos como **ano, seguido de mês, e depois dia**.

```{r}
# Leia a data no formato ano-mês-dia
ymd("2020-10-11")
ymd("20201011")
```

A função `mdy()` converte de forma flexível os valores de data fornecidos como **mês, seguido de dia, e ano**.

```{r}
# Leia a data no formato mês-dia-ano
mdy("10/11/2020")
mdy("Oct 11 20")
```

A função `dmy()` converte de forma flexível os valores de data fornecidos como **dia, seguida de mês, e ano**.

```{r}
# Leia a data no formato dia-mês-ano
dmy("11 10 2020")
dmy("11 October 2020")
```

<!-- Os comandos `as.character()` e `as.Date()` podem ser combinados de forma opcional como:   -->

<!-- ```{r eval=F} -->

<!-- linelist_cleaned$date_of_onset <- as.Date(as.character(linelist_cleaned$date_of_onset), format = "%d/%m/%Y") -->

<!-- ``` -->

Se estiver usando o pipe `%>%`, a conversão de uma coluna de caracteres para datas com **lubridate** pode ser feita assim:

```{r, eval=F}
linelist <- linelist %>%
  mutate(date_onset = lubridate::dmy(date_onset))
```

Depois de concluído, você pode executar `class()` para verificar a classe da coluna

```{r, eval=F}
# Confira a classe da coluna 
class(linelist$date_onset)  
```

Uma vez que os valores estão na classe Date, o R os exibirá por padrão no formato AAAA-MM-DD.

Observe que as funções acima funcionam melhor com anos de 4 dígitos. Anos de 2 dígitos podem produzir resultados inesperados, à medida que lubridate tenta adivinhar o século.

Para converter um ano de 2 dígitos em um ano de 4 dígitos (todos no mesmo século) você pode converter as datas para caractere e então combinar os dígitos existentes com uma pré-correção usando `str_glue()` do pacote **stringr** (veja [Caracteres e strings](#characters-strings)). Em seguida, converta para data.

```{r}
ano_dois_digitos <- c("15", "15", "16", "17")
str_glue("20{ano_dois_digitos}")
```

### Combine colunas {.unnumbered}

Você pode usar as funções do **lubridate** `make_date()` e `make_datetime()` para combinar múltiplas colunas numéricas em uma coluna de data. Por exemplo, se você tiver colunas numéricas `onset_day`, `onset_month`, e `onset_year` na tabela de dados `linelist`:

```{r, eval=F}
linelist <- linelist %>% 
  mutate(onset_date = make_date(year = onset_year, month = onset_month, day = onset_day))
```

<!-- ======================================================= -->

## Datas do Excel

Em segundo plano, a maioria dos softwares armazena datas como números. O R armazena datas de uma origem de 1º Janeiro, 1970. Portanto, se você executar `as.numeric(as.Date("1970-01-01))` você obterá `0`.

O Microsoft Excel armazena datas com um origem em 30 de dezembro de 1899 (Windows) ou 1 de janeiro de 1904 (Mac), dependendo do seu sistema operacional. Consulte em [Microsoft guidance](https://docs.microsoft.com/en-us/office/troubleshoot/excel/1900-and-1904-date-system) para obter mais informações.

As datas do Excel geralmente são importadas para o R como esses valores numéricos, em vez de caracteres. Se o conjunto de dados que você importou do Excel mostra datas como números ou caracteres como "41369" ... use `as.Date()` (ou a função do **lubridate** `as_date()`) para converter, mas **no lugar de fornecer um "formato" como acima, forneça a data de origem do Excel** no argumento `origin =`.

Isso não irá funcionar se as datas do Excel contidas no R estiverem como caracteres, assim, confirme se os números estão classificados como Numérico!

[***NOTA:*** Você deve fornecer a data de origem no formato de data padrão do R ("AAAA-MM-DD").]{style="color: black;"}

```{r, eval = FALSE}
# Um exemplo de fornecimento da 'data de origem' do Excel ao converter datas numéricas do Excel
data_cleaned <- data %>% 
  mutate(date_onset = as.numeric(date_onset)) %>%   # garantir que a classe seja numérica
  mutate(date_onset = as.Date(date_onset, origin = "1899-12-30")) # converter para data usando a origem do Excel
```

<!-- ======================================================= -->

## Datas bagunçadas

A função `parse_date()` do pacote **parsedate** tenta ler uma coluna de data "bagunçada" contendo datas em muitos formatos diferentes e converte as datas para um formato padrão. Você pode [ler mais online sobre `parse_date()`](https://readr.tidyverse.org/reference/parse_datetime.html).

Por exemplo, o `parse_date()` vê um vetor dos seguintes caracteres de datas "03 Jan 2018", "07/03/1982", e "08/20/85" e os converteria para a classe Date como: `2018-01-03`, `1982-03-07`, e `1985-08-20`.

```{r, }
parsedate::parse_date(c("03 Jan 2018",
                        "07/03/1982",
                        "08/20/85"))
```

```{r eval = FALSE}
# Um exemplo usando parse_date() na coluna `date_onset` (data de início de sintomas)
linelist <- linelist %>%      
  mutate(date_onset = parse_date(date_onset))
```

<!-- ======================================================= -->

## Trabalhando com classe de data-hora

Conforme mencionado anteriormente, o R também oferece suporte para dados de classe `datetime` - uma coluna que contém informações de data **e** hora. Assim como a classe `Date`, eles geralmente precisam ser convertidos de objetos de `character` para objetos `datetime`.

### Converter datas com horas {.unnumbered}

Um objeto `datetime` padrão é formatado com a data primeiro, que é seguida por um componente de hora - por exemplo, *01 de janeiro de 2020*, *16:30*. Assim como acontece com as datas, isso pode ser formatado de muitas maneiras e vários níveis de precisão (horas, minutos, segundos) que podem ser fornecidos.

Felizmente, as funções auxiliares do **lubridate** também existem para ajudar a converter essas junções para objetos `datetime`. Essas funções são extensões das funções auxiliares de data, com `_h` (apenas horas fornecidas), `_hm` (horas e minutos fornecidos), ou `_hms` (horas, minutos e segundos fornecidos) anexado ao final (por exemplo, `dmy_hms()`). Eles podem ser usados conforme mostrado abaixo:

Converte "data e hora" contendo apenas horas para o objeto do tipo *datetime*

```{r warning=FALSE}
ymd_h("2020-01-01 16hrs")
```

Converte "data e hora" com horas e minutos para o objeto do tipo *datetime*

```{r}
dmy_hm("01 January 2020 16:20")
```

Converte "data e hora" com horas, minutos e segundos para o objeto do tipo *datetime*

```{r}
mdy_hms("01 January 2020, 16:20:40")
```

Você pode fornecer o fuso horário, mas ele será ignorado. Consulte a seção mais adiante nesta página sobre fusos horários.

```{r}
mdy_hms("01 January 2020, 16:20:40 PST")

```

Ao trabalhar com uma tabela de dados, as colunas de hora e data podem ser combinadas para criar uma coluna data-e-hora (*datetime*) usando `str_glue()` do pacote **stringr** e uma função apropriada do **lubridate**. Consulte a página em [Caracteres e strings](#characters-strings) para obter detalhes sobre o **stringr**.

Neste exemplo, a tabela de dados do `linelist` possui uma coluna no formato "horas:minutos". Para converter isso para data-e-hora, seguem-se algumas etapas:

1)  Crie uma coluna de tempo de admissão "limpa" na qual os valores ausentes são preenchidos pela mediana da coluna. Isso é realizado, pois **lubridate** não funciona com valores ausentes. Combine-o com a coluna `date_hospitalisation`, e então use a função `ymd_hm()` para converter.

```{r, eval = FALSE}
# pacotes
pacman::p_load(tidyverse, lubridate, stringr)

# time_admission é a coluna em horas:minutos
linelist <- linelist %>%
  
  # quando o horário de admissão não é fornecido, atribua o horário médio de admissão
  mutate(
    time_admission_clean = ifelse(
      is.na(time_admission),   # se horário estiver faltando
      median(time_admission),  # atribua a mediana
      time_admission           # se não estiver faltando, mantenha como está
  )) %>%
  
    # use str_glue() para combinar as colunas de data-e-horas em uma coluna de caracteres
    # em seguida, use ymd_hm() para converter em formato datetime
  mutate(
    date_time_of_admission = str_glue("{date_hospitalisation}{time_admission_clean}") %>% 
      ymd_hm()
  )

```

### Converta horários isolados {.unnumbered}

Se seus dados contém apenas caracteres referente a um horário (horas e minutos), você pode convertê-los e manipulá-los como tempos usando `strptime()` a partir do R **base**. Por exemplo, para obter a diferença entre dois desses tempos:

```{r}
# horário como caracteres brutos
time1 <- "13:45" 
time2 <- "15:20"

# horário convertidos para classe datetime 
time1_clean <- strptime(time1, format = "%H:%M")
time2_clean <- strptime(time2, format = "%H:%M")

# Por padrão, a diferença é da classe "difftime", aqui convertida em horas numéricas 
as.numeric(time2_clean - time1_clean)   # diferença em horas

```

Observe, entretanto, que sem um valor de data fornecido, ele assume que a data é hoje. , Veja como usar **stringr** na seção acima para combinar uma data string e um tempo string. Leia mais sobre `strptime()` [aqui](https://rdrr.io/r/base/strptime.html).

Para converter números de um dígito em dois dígitos (por exemplo, para "preencher" horas ou minutos com zeros à esquerda para atingir 2 dígitos), consulte a seção ["Pad length" da página Caracteres e junções](#str_pad).

### Extrair o tempo {.unnumbered}

Você pode extrair elementos de um tempo com `hour()`, `minute()`, ou `second()` do **lubridate**.

Aqui está um exemplo de extração da hora e em seguida, sua classificação por período do dia. Começamos com a coluna `time_admission`, a qual está na classe Caractere no formato "HH:MM". Primeiro, a `strptime()` é usado conforme descrito acima para converter os caracteres para a classe datetime. Em seguida, a hora é extraída com with `hour()`, retornando um número de 0-24. Finalmente, uma coluna `time_period` usando a lógica com a função `case_when()` para classificar as linhas em Manhã / Tarde / Início da noite / Noite com base na hora de admissão.

```{r}
linelist <- linelist %>%
  mutate(hour_admit = hour(strptime(time_admission, format = "%H:%M"))) %>%
  mutate(time_period = case_when(
    hour_admit > 06 & hour_admit < 12 ~ "Manhã",
    hour_admit >= 12 & hour_admit < 17 ~ "Tarde",
    hour_admit >= 17 & hour_admit < 21 ~ "Início da noite",
    hour_admit >=21 | hour_admit <= 6 ~ "Noite"))
```

Para saber mais sobre `case_when()` , consulte a página [Limpeza dos daos e principais funções](#cleaning).

<!-- ======================================================= -->

## Trabalhando com datas

`lubridate` também pode ser usado para uma variedade de outras funções, como **extrair aspectos de uma data / data e hora, realizar cálculos aritiméticos de data ou calcular intervalos de data**.

Aqui, definimos uma data que será usada para os exemplos:

```{r, }
# criar um objeto de classe Date
example_date <- ymd("2020-03-01")
```

### Extrair os componentes de datas {.unnumbered}

Você pode extrair aspectos comuns, como mês, dia, dia da semana:

```{r}
month(example_date)  # número do mês
day(example_date)    # dia do mês (número)
wday(example_date)   # número do dia da semana (1-7)
```

Você também pode extrair componentes de tempo de um objeto ou coluna `datetime`. Isso pode ser útil se você quiser ver a distribuição dos horários de admissão.

```{r, eval=F}
example_datetime <- ymd_hm("2020-03-01 14:45")

hour(example_datetime)     # extrair hora
minute(example_datetime)   # extrair minuto
second(example_datetime)   # extrair segundo
```

Existem várias opções para recuperar semanas. Veja a seção sobre semanas epidemiológicas abaixo.

Observe que se você deseja *exibir* uma data de uma determinada maneira (por exemplo, "janeiro de 2020" ou "Quinta-feira, 20 de março" ou "Semana 20 de 1977"), pode fazer isso de forma mais flexível, conforme descrito na seção Exibição de data.

### Cálculos com datas {.unnumbered}

Você pode adicionar determinados números de dias ou semanas usando suas respectivas funções do **lubridate**.

```{r}
# adicione 3 dias à essa data 
example_date + days(3)
  
# adicione 7 semanas e subtraia dois dias dessa data
example_date + weeks(7) - days(2)
```

### Intervalos entre datas {.unnumbered}

A diferença entre as datas pode ser calculada por:

1.  Certifique-se de que ambas as datas estejam como classe data\
2.  Use a subtração para retornar a diferença "difftime" entre as duas datas\
3.  Se necessário, converta o resultado em classe numérica para realizar cálculos matemáticos subsequentes

Abaixo, o intervalo entre duas datas é calculado e exibido. Você pode encontrar intervalos usando o símbolo de subtração "menos" em valores que estão como classe Data. Contudo, observe que a classe do valor retornado é "difftime" conforme exibido abaixo e deve ser convertida para numérico.

```{r}
# encontre o intervalo entre essa data e 20 de fevereiro de 2020
output <- example_date - ymd("2020-02-20")
output    # print
class(output)
```

Para fazer as operações subsequentes em um "difftime", converta-o para numérico com `as.numeric()`.

Tudo isso pode ser reunido para trabalhar com dados - por exemplo:

```{r, eval = F}
pacman::p_load(lubridate, tidyverse)   # carregue os pacotes

linelist <- linelist %>%
  
  # converter a data de início (date_onset) de caracteres em objetos de data, especificando o formato dmy
  mutate(date_onset = dmy(date_onset),
         date_hospitalisation = dmy(date_hospitalisation)) %>%
  
  # filtrar todos os casos sem início em março
  filter(month(date_onset) == 3) %>%
    
  # encontrar a diferença, em dias, entre a data de ínicio e o início da hospitalização
  mutate(days_onset_to_hosp = date_hospitalisation - date_of_onset)
```

No contexto de uma tabela de dados (*data frame*), se uma das datas acima estiver faltando, a operação falhará para essa linha. Isso resultará em um `NA` em vez de um valor numérico. Ao usar esta coluna para cálculos, certifique-se de definir o argumento `na.rm =` como `TRUE`. Por exemplo:

```{r, eval = FALSE}
# calcule o número médio de dias até a hospitalização para todos os casos em que os dados estão disponíveis
median(linelist_delay$days_onset_to_hosp, na.rm = T)
```

<!-- ======================================================= -->

## Exibição das datas

Uma vez que as datas essão na classe correta, você geralmente deseja que elas sejam exibidas de forma diferente, por exemplo, como "Segunda-feira, 5 de janeiro" em vez de "05/01/2018". Você também pode ajustar a exibição para agrupar as linhas pelos elementos de data exibidos - por exemplo, agrupar por mês-ano.

### `format()` {.unnumbered}

Ajuste a exibição de data com a função `format()`do R **base**. Esta função aceita uma cadeia de caracteres entre aspas (*string*) especificando o formato de saída *desejado* nas abreviações de strptime "%" (a mesma sintaxe usada em `as.Date()`). Abaixo estão relacionadas a maioria das abreviações comuns.

Observação: o uso de `format()` converterá os valores para a classe Caractere, então geralmente é usado no final de uma análise ou apenas para fins de exibição! Você pode ver a lista completa executando `?strptime`.

%d = Número do dia do mês (5, 17, 28, etc.)\
%j = Número do dia do ano (Julho dia 001-366)\
%a = Dia da semana abreviado (Mon, Tue, Wed, etc.)\
%A = Dia da semana completo (Monday, Tuesday, etc.)\
%w = Número do dia da semana (0-6, Domingo é 0)\
%u = Número do dia da semana (1-7, Segunda-feira é 1)\
%W = Número da semana (00-53, Segunda-feira é o início da semana)\
%U = Número da semana (01-53, Domingo é o início da semana)\
%m = Número do mês (exemplo, 01, 02, 03, 04)\
%b = Mês abreviado (Jan, Fev, etc.)\
%B = Mês completo (Janeiro, Fevereiro, etc.)\
%y = Ano em 2 dígitos (por exemplo, 89)\
%Y = Ano em 7 dígitos (por exemplo, 1989)\
%h = horas (relógio de 24 horas)\
%M = minutos\
%s = segundos\
%z = deslocamento do GMT\
%Z = Fuso horário (caractere)

Um exemplo de formatação da data de hoje:

```{r}
# data de hoje com formatação
format(Sys.Date(), format = "%d %B %Y")

# maneira fácil de obter data e hora completas (formatação padrão)
date()

# data, hora e fuso horário combinados e formatados usando a função str_glue()
str_glue("{format(Sys.Date(), format = '%A, %B %d %Y, %z  %Z, ')}{format(Sys.time(), format = '%H:%M:%S')}")

# Usando a função format para exibir as semanas
format(Sys.Date(), "%Y Week %W")
```

Observe que se estiver usando `str_glue()`, esteja ciente de que dentro das aspas duplas esperadas ", você deve usar apenas aspas simples (como acima).

### Mês-ano {.unnumbered}

Para converter uma coluna de Data para o formato mês-ano, sugerimos que você use a função `as.yearmon()` do pacote **zoo**. Isso converte a data para a classe "yearmon" e mantém a ordem adequada. Em contraste, o uso de `format(column, "%Y %B")` irá converter para a classe Caractere e irá ordenar os valores alfabeticamente (incorretamente).

Abaixo, uma nova coluna `yearmonth` é criada a partir da coluna `date_onset`, usando a função `as.yearmon()`. A ordem padrão (correta) dos valores resultantes é mostrada na tabela.

```{r}
# criando uma nova tabela 
test_zoo <- linelist %>% 
     mutate(yearmonth = zoo::as.yearmon(date_onset))

# mostrar tabela
table(test_zoo$yearmon)
```

Em contraste, você pode ver como usando apenas `format()` é possível atingir ao formato de exibição desejado, mas não na ordem correta.

```{r}
# criar uma nova coluna
test_format <- linelist %>% 
     mutate(yearmonth = format(date_onset, "%b %Y"))

# mostrar tabela
table(test_format$yearmon)
```

Observação: se você estiver trabalhando em um `ggplot()` e quiser ajustar apenas a forma como as datas são exibidas, pode ser suficiente fornecer um formato strptime para o argumento `date_labels =` na função `scale_x_date()` - você pode usar `"%b %Y"` ou `"%Y %b"`. Veja a página [Dicas para ggplot](#ggplot-tips).

**zoo** também oferece a função `as.yearqtr()`, e você pode usar `scale_x_yearmon()` ao usar `ggplot()`.

<!-- ======================================================= -->

## Semanas epidemiológicas {#dates_epi_wks}

### **lubridate** {.unnumbered}

Consulte a página em [Agrupando dados](#grouping) para exemplos mais abrangentes de dados de agrupamento por data. Abaixo, descrevemos resumidamente os dados de agrupamento por semanas.

Geralmente recomendamos usar a função `floor_date()` do **lubridate**, com o argumento `unit = "week"`. Isso arredonda a data para o "início" da semana, conforme definido pelo argumento `week_start =`. O início da semana padrão é 1 (para segundas-feiras), mas você pode especificar qualquer dia da semana como o início (por exemplo, 7 para domingos). `floor_date()` é versátil e pode ser usado para arredondar outras unidades de tempo definindo `unit =` para "segundo", "minuto", "hora", "dia", "mês" ou "ano".

O valor retornado é a data de início da semana, na classe Date. A classe de data é útil ao plotar os dados, pois serão facilmente reconhecidos e ordenados corretamente por `ggplot()`.

Se você estiver interessado apenas em ajustar as datas para *exibição* por semana em um gráfico, consulte a seção nesta página sobre Exibição de data. Por exemplo, ao plotar uma curva epidemiológica, você pode formatar a exibição da data fornecendo a nomenclatura "%" do strptime desejada. Por exemplo, use "%Y-%W" ou "%Y-%U" para retornar o ano e o número da semana (dado o início da semana na segunda-feira ou no domingo, respectivamente).

### Contagens semanais {.unnumbered}

Veja a página em [Agrupando dados](#grouping) para uma explicação completa de dados de agrupamento com `count()`, `group_by()`, e `summarise()`. Um breve exemplo está mostrado abaixo.

1)  Crie uma nova coluna 'semana' com `mutate()`, usando `floor_date()` com `unit = "week"`;
2)  Obtenha contagens de linhas (casos) por semana com `count()`; remova quaisquer casos com data ausente;
3)  Conclua com `complete()` do **tidyr** para garantir que todas as semanas apareçam nos dados - mesmo aquelas sem linhas/casos. Por padrão, os valores de contagem para quaisquer "novas" linhas são NA, mas você pode torná-los 0 com o argumento `fill =`, que espera uma lista nomeada (abaixo, `n` é o nome da coluna de contagens).

```{r}
# Faça um conjunto de dados agregado de contagens de casos semanais
weekly_counts <- linelist %>% 
  drop_na(date_onset) %>%             # remover casos sem data de início onset date
  mutate(weekly_cases = floor_date(   # fazer nova coluna, semana de início
    date_onset,
    unit = "week")) %>%            
  count(weekly_cases) %>%           # agrupar dados por semana e contar linhas por grupo (cria a coluna 'n')
  tidyr::complete(                  # garantir que todas as semanas estejam presentes, mesmo aquelas sem casos relatados
    weekly_cases = seq.Date(          # redefina a coluna "weekly_cases" como uma sequência completa,
      from = min(weekly_cases),       # a partir da data mínima
      to = max(weekly_cases),         # para a data máxima
      by = "week"),                   # por semanas
    fill = list(n = 0))             # preencha NAs na coluna de n contagens com 0
```

Aqui estão as primeiras linhas da tabela de dados resultante:

```{r message=FALSE, echo=F}
DT::datatable(head(weekly_counts, 20), rownames = FALSE, options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```

### Alternativas do Epiweek {.unnumbered}

Note que **lubridate** também tem as funções `week()`, `epiweek()`, e `isoweek()`, cada uma com datas de início ligeiramente diferentes e outras nuances. De modo geral, porém, `floor_date()` deve ser tudo o que você precisa. Leia os detalhes dessas funções inserindo `?week` no console ou lendo a documentação [aqui](https://www.rdocumentation.org/packages/lubridate/versions/1.7.4/topics/week).

Você pode considerar usar o pacote **aweek** para definir semanas epidemiológicas. Você pode ler mais sobre isso [no site do RECON](https://www.repidemicsconsortium.org/aweek/). Possui as funções `date2week()`e `week2date()` nas quais você pode definir o dia de início da semana com `week_start = "Monday"`. Este pacote é mais fácil se você quiser saídas no estilo "semana" (por exemplo, "2020-W12", sendo W = semana). Outra vantagem de **aweek** é que quando `date2week()` é aplicado a uma coluna de data, a coluna retornada (formato de semana) é automaticamente da classe Fator e e inclui níveis para todas as semanas no intervalo de tempo (isso evita a etapa extra de `complete()` descrito acima). Porém, **aweek** não tem a funcionalidade de arredondar datas para outras unidades de tempo, como meses, anos, etc..

Outra alternativa para séries temporais que também funciona bem para mostrar um formato de "semana" ("2020 W12") é `yearweek()` do pacote **tsibble**, como demonstrado na página [Séries temporais e detecção de surto](#time-series).

<!-- ======================================================= -->

## Conversão de datas / fusos horários

Quando os dados estão presentes em fusos horários diferentes, muitas vezes pode ser importante padronizar esses dados em um fuso horário unificado. Isso pode representar um desafio adicional, pois o componente de fuso horário dos dados deve ser codificado manualmente na maioria dos casos.

No R, cada objeto *datetime* possui um componente de fuso horário. Por padrão, todos os objetos datetime levarão o fuso horário local do computador que está sendo usado - isso geralmente é específico para um *local* em vez de um nome do fuso horário, pois os fusos horários geralmente mudam nos locais devido ao horário de verão. Não é possível compensar com precisão os fusos horários sem um componente de tempo de uma data, pois o evento que uma coluna de data representa não pode ser atribuído a um tempo específico e, portanto, as mudanças de tempo medidas em horas não podem ser razoavelmente contabilizadas.

Para lidar com fusos horários, há várias funções auxiliares no lubridate que podem ser usadas para alterar o fuso horário de um objeto datetime do seu fuso horário local para um fuso horário diferente. Os fusos horários são definidos atribuindo um fuso horário do banco de dados tz válido ao objeto datetime. Uma lista deles pode ser encontrada aqui - se o local do qual você está usando os dados não estiver nessa lista, grandes cidades próximas no fuso horário estão disponíveis e têm a mesma finalidade.

<https://en.wikipedia.org/wiki/List_of_tz_database_time_zones>

```{r}
# atribuir a hora atual a uma coluna
time_now <- Sys.time()
time_now

# use with_tz() para atribuir um novo fuso horário à coluna, enquanto ALTERA a hora do relógio
time_london_real <- with_tz(time_now, "Europe/London")

# use force_tz() para atribuir um novo fuso horário para a coluna, enquanto MANTÉM a hora do relógio
time_london_local <- force_tz(time_now, "Europe/London")


# observe que, desde que o computador usado para executar este código NÃO esteja definido para o horário de Londres,
# haverá uma diferença nos horários
# (o número de horas de diferença do fuso horário do computador para Londres)
time_london_real - time_london_local

```

Isso pode parecer muito abstrato e geralmente não é necessário se o usuário não estiver trabalhando em outros fusos horários.

<!-- ======================================================= -->

## Cálculos com valores anteriores ou posteriores

`lead()` and `lag()` são funções do pacote **dplyr** que ajudam a encontrar valores anteriores (lag) ou subsequentes (lead) em um vetor - normalmente um vetor numérico ou de data. Isso é útil ao fazer cálculos de mudança / diferença entre unidades de tempo.

```{r, echo=F}
counts <- import(here("data", "example", "district_weekly_count_data.xlsx")) %>% 
  filter(District == "Nibari") %>% 
  mutate(Date = as.Date(Date),
         week_start = lubridate::floor_date(Date, "week")) %>%
  group_by(week_start) %>% 
  summarize(cases_wk = sum(Cases, na.rm=T)) %>% 
  complete(week_start = seq.Date(min(week_start), max(week_start), by = "week"), fill = list(cases_wk = 0))
```

Digamos que você queira calcular a diferença de casos entre uma semana atual e a anterior. Os dados são fornecidos inicialmente em contagens semanais, conforme mostrado abaixo.

```{r message=FALSE, echo=F}
DT::datatable(counts, rownames = FALSE,  options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```

**Ao usar `lag()` ou `lead(),` a ordem das linhas no seus dados é muito importante! - preste atenção se suas datas / números estão de forma crescentes ou decrescentes**

Primeiro, crie uma nova coluna contendo o valor da semana anterior (defasada).

-   Controle o número de unidades para trás / para frente com `n =` (deve ser um número inteiro não negativo)\
-   Use `default =` para definir o valor colocado em linhas não existentes (por exemplo, a primeira linha para a qual não há valor defasado). Por padrão, isso é `NA`.\
-   Use `order_by = TRUE` se suas linhas não estiverem ordenadas por sua coluna de referência

```{r}
counts <- counts %>% 
  mutate(cases_prev_wk = lag(cases_wk, n = 1))
```

```{r message=FALSE, echo=F}
DT::datatable(counts, rownames = FALSE,  options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```

A seguir, crie uma nova coluna que é a diferença entre as duas colunas de casos:

```{r}
counts <- counts %>% 
  mutate(cases_prev_wk = lag(cases_wk, n = 1),
         case_diff = cases_wk - cases_prev_wk)
```

```{r message=FALSE, echo=F}
DT::datatable(counts, rownames = FALSE,  options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```

Você pode ler mais sobre `lead()` e `lag()` no documento [aqui](https://dplyr.tidyverse.org/reference/lead-lag.html) ou inserindo `?lag` no seu console.

<!-- ======================================================= -->

## Recursos

**lubridate** [página tidyverse](https://lubridate.tidyverse.org/)\
**lubridate** RStudio [cheatsheet](https://rawgit.com/rstudio/cheatsheets/master/lubridate.pdf)\
R para Ciência dos Dados na página [datas e horas](https://r4ds.had.co.nz/dates-and-times.html)\
[Tutorial Online](https://www.statmethods.net/input/dates.html) de [Formatos de datas](https://www.r-bloggers.com/2013/08/date-formats-in-r/)
```{r include=FALSE, cache=FALSE}

# clear workspace
rm(list = ls(all = TRUE))

# clear all packages except base
#lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))

# to ensure that tidyverse packages prevail
filter <- dplyr::filter
select <- dplyr::select
summarise <- dplyr::summarise
summary <- base::summary
incidence <- incidence2::incidence

#load core packages
pacman::p_load(
     rio,
     here,
     DT,
     stringr,
     lubridate,
     tidyverse
)

# import the cleaned ebola linelist
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

# import the count data - facility level
#count_data <- rio::import(here::here("data", "facility_count_data.rds"))

# Settings

options(scipen=1, digits=7)

# print only text (not code)
# library(knitr)
# opts_chunk$set(list(echo = FALSE, eval = FALSE))
```

<!--chapter:end:new_pages/dates.Rmd-->


# Caracteres e strings {#characters-strings}

```{r, out.width=c('100%'), echo=F, message=F}
knitr::include_graphics(here::here("images", "Characters_Strings_1500x500.png"))
```

Essa página mostra o uso do pacote **stringr** para avaliar e lidar com cadeias de caracteres ("strings").

1.  Combinar, ordenar, dividir, organizar - `str_c()`, `str_glue()`, `str_order()`, `str_split()`\

2.  Limpar e padronizar

    -   Ajuste o comprimento - `str_pad()`, `str_trunc()`, `str_wrap()`\
    -   Alterar maiúsculas e minúsculas - `str_to_upper()`, `str_to_title()`, `str_to_lower()`, `str_to_sentence()`\

3.  Avaliar e extrair por posição - `str_length()`, `str_sub()`, `word()`\

4.  Padrões

    -   Detectar e localizar - `str_detect()`, `str_subset()`, `str_match()`, `str_extract()`\
    -   Modificar e substituir - `str_sub()`, `str_replace_all()`\

5.  Expressões regulares ("regex")

Para facilitar a exibição, a maioria dos exemplos são mostrados agindo em um vetor curto do tipo caractere, no entanto, eles podem ser facilmente adaptados a uma coluna dentro de um quadro de dados (*data frame*).

Esse [manual das funções do stringr](https://cran.r-project.org/web/packages/stringr/vignettes/stringr.html) forneceu grande parte da inspiração para esta página.

<!-- ======================================================= -->

## Preparação

### Carregue os pacotes {.unnumbered}

Instale ou carregue o **stringr** e outros pacotes **tidyverse**.

```{r}
# instalar/carregar pacotes
pacman::p_load(
  stringr,    # muitas funções para lidar com strings
  tidyverse,  # para manipulação opicional de dados
  tools)      # alternativa para converter para maiúsculas

```

### Importar os dados {.unnumbered}

Nesta página, faremos referência ocasional à `linelist`, uma lista de casos de uma simulação de epidemia de Ebola. Se você quiser acompanhar, clique para realizar o download "[clean linelist](https://github.com/appliedepi/epirhandbook_eng/raw/master/data/case_linelists/linelist_cleaned.rds)" (como arquivo .rds). Importe dados com a função `import()` do pacote **rio** (ele lida com muitos tipos de arquivo como .xlsx, .csv, .rds - veja a página [Importar e exportar](#importing) para detalhes).

```{r, echo=F}
# importe a linelist para o R
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))
```

```{r, eval=F}
# Exemplo de importação 
linelist <- import("linelist_cleaned.rds")
```

As primeiras 50 linhas da lista estão exibidas abaixo.

```{r, message=FALSE, echo=F}
# mostrar a lista de dados como tabela
DT::datatable(head(linelist, 50), rownames = FALSE, filter="top", options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```

<!-- ======================================================= -->

## Unir, dividir e organizar

Essa seção aborda:

-   O uso das funções `str_c()`, `str_glue()`, e `unite()` para combinar strings (caracteres ou descrições)\
-   O uso da função `str_order()` para organizar strings\
-   O uso das funções `str_split()` e `separate()` para dividir strings

<!-- ======================================================= -->

### Combinar strings {.unnumbered}

Para combinar ou concatenar múltiplos strings em um único string, sugerimos usar `str_c` do **stringr**. Se você tiver distintos valores de caracteres para combinar, basta fornecê-los como argumentos exclusivos, separados por vírgulas.

```{r}
str_c("String1", "String2", "String3")
```

O argumento `sep =` insere um valor de caractere entre cada um dos argumentos fornecidos (por exemplo, inserir uma vírgula, espaço ou nova linha `"\n"`)

```{r}
str_c("String1", "String2", "String3", sep = ", ")
```

O argumento `collapse =` é relevante se você estiver inserindo múltiplos *vetores* como argumentos para a função `str_c()`. Ele é usado para separar os elementos do que seria um vetor de *saída*, de forma que o vetor de saída tenha apenas um longo elemento de caractere.

O exemplo abaixo mostra a combinação de dois vetores em um (nomes e sobrenomes). Outro exemplo semelhante pode ser sobre jurisdições e suas contagens de casos. Neste exemplo:

-   O valor `sep =` aparece entre cada nome e sobrenome\
-   O valor `collapse =` aparece entre cada pessoa

```{r}
first_names <- c("abdul", "fahruk", "janice") 
last_names  <- c("hussein", "akinleye", "okeke")

# sep é exibido entre as respectivas strings de entrada, enquanto collapse é exibido entre os elementos produzidos
str_c(first_names, last_names, sep = " ", collapse = ";  ")
```

Nota: Dependendo do contexto de exibição desejado, ao imprimir/exibir uma string combinada com novas linhas, você pode precisar inserir a frase inteira em `cat()` para que as novas linhas sejam impressas/exibidas corretamente:

```{r}
# Para que as novas linhas sejam impressas corretamente, a frase pode precisar estar inserida na função cat()
cat(str_c(first_names, last_names, sep = " ", collapse = ";\n"))
```

<!-- ======================================================= -->

### Strings dinâmicas {.unnumbered}

Use `str_glue()` para inserir um código R dinâmico em um string. Esta é uma função muito útil para criar legendas dinâmicas de gráficos, conforme demonstrado abaixo.

-   Todo o conteúdo fica entre aspas duplas `str_glue("")`\
-   Qualquer código dinâmico ou referências aos valores predefinidos são colocados entre chaves `{}` com aspas duplas. Pode haver muitas chaves no mesmo comando `str_glue()`.\
-   Para exibir aspas como caracter '', use aspas *simples* entre aspas duplas (por exemplo, ao fornecer o formato de data - veja o exemplo abaixo)\
-   Dica: você pode usar `\n` para forçar uma nova linha\
-   Dica: você usa `format()` para ajustar a exibição da data e usa `Sys.Date()` para exibir a data atual

Um simples exemplo da gráfico com legenda dinâmica:

```{r}
str_glue("Os dados incluem {nrow(linelist)} casos e são atuais para {format(Sys.Date(), '%d %b %Y')}.")
```

Um formato alternativo é usar espaços reservados dentro dos colchetes e definir o código em argumentos separados no final da função `str_glue()`, conforme abaixo. Isso pode melhorar a legibilidade do código se o texto for longo.

```{r}
str_glue("Lista  em {current_date}.\n dos último casos hospitalizados no {last_hospital}.\n{n_missing_onset} casos sem data de início e não mostrados",
         current_date = format(Sys.Date(), '%d %b %Y'),
         last_hospital = format(as.Date(max(linelist$date_hospitalisation, na.rm=T)), '%d %b %Y'),
         n_missing_onset = nrow(linelist %>% filter(is.na(date_onset)))
         )

```

**Extraindo de uma tabela de dados**

Às vezes, é útil extrair dados de um data frame e colá-los juntos na sequência. Abaixo está um exemplo de data frame. Vamos usá-lo para fazer uma declaração resumida sobre as jurisdições e as contagens de casos novos e totais.

```{r}
# fazer um data frame de casos
caso_tabela <- data.frame(
  zone        = c("Zone 1", "Zone 2", "Zone 3", "Zone 4", "Zone 5"),
  novos_casos   = c(3, 0, 7, 0, 15),
  total_casos = c(40, 4, 25, 10, 103)
  )
```

```{r, echo=F}
DT::datatable(caso_tabela, rownames = FALSE, options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```

Use `str_glue_data()`, que é feito especialmente para obter dados de linhas do data frame:

```{r}
caso_tabela %>% 
  str_glue_data("{zone}: {novos_casos} ({total_casos} total casos)")
```

**Combine strings em linhas**

Se você estiver tentando "acumular" valores em uma coluna de um data frame, por exemplo, combinar valores de várias linhas em apenas uma linha, colando-os juntos com um separador, consulte a seção da página [Eliminação de duplicidades](#deduplication) em ["acumulando" valores](#str_rollup).

**Data frame para uma linha**

Você pode fazer a frase aparecer em uma linha usando `str_c()` (especificando o data frame e os nomes das colunas) e fornecendo os argumentos `sep =` e `collapse =`.

```{r}
str_c(caso_tabela$zone, caso_tabela$novos_casos, sep = " = ", collapse = ";  ")
```

Você poderia adicionar o texto "Novos Casos:" ao início da instrução envolvendo a função com `str_c()` (se "Novos Casos:" estivesse dentro do `str_c()` original, ele apareceria várias vezes).

```{r}
str_c("Novos Casos: ", str_c(caso_tabela$zone, caso_tabela$novos_casos, sep = " = ", collapse = ";  "))
```

### Unir colunas {#str_unite .unnumbered}

Dentro de uma tabela de dados, reunir valores de caracteres de várias colunas pode ser obtido com `unite()` do pacote **tidyr**. Isso é o oposto de `separate()`.

Forneça o nome da nova coluna unida. Em seguida, forneça os nomes das colunas que deseja unir.

-   Por padrão, o separador usado na coluna unida é o underline `_`, mas isso pode ser alterado com o argumento `sep =`.\
-   `remove =` rremove as colunas de entrada da tabela de dados (TRUE por padrão)\
-   `na.rm =` remove os valores ausentes durante a união (FALSE por padrão)

Abaixo, definimos uma mini-tabela de dados para demonstrar:

```{r, message = F, warning=F}
df <- data.frame(
  case_ID = c(1:6),
  symptoms  = c("jaundice, fever, chills",     # paciente 1
                "chills, aches, pains",        # paciente 2 
                "fever",                       # paciente 3
                "vomiting, diarrhoea",         # paciente 4
                "bleeding from gums, fever",   # paciente 5
                "rapid pulse, headache"),      # paciente 6
  outcome = c("Recover", "Death", "Death", "Recover", "Recover", "Recover"))
```

```{r}
df_split <- separate(df, symptoms, into = c("sym_1", "sym_2", "sym_3"), extra = "merge")
```

Aqui está o exemplo da tabela de dados:

```{r, echo=F}
DT::datatable(df_split, rownames = FALSE, options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```

Abaixo, unimos as três colunas de sintomas:

```{r}
df_split %>% 
  unite(
    col = "all_symptoms",         # nome da nova coluna unida
    c("sym_1", "sym_2", "sym_3"), # colunas para unir
    sep = ", ",                   # separador para usar na coluna unida
    remove = TRUE,                # se TRUE (verdadeiro), remove colunas de entrada da tabela de dados
    na.rm = TRUE                  # se TRUE, os valores ausentes são removidos antes da união
  )
```

<!-- ======================================================= -->

### Dividir {.unnumbered}

Para dividir um objeto de texto (string) com base em um padrão, use `str_split()`. Ele avalia o(s) string(s) e retorna uma `list` de vetores de caracteres que consistem nos valores recém-divididos.

O exemplo simples abaixo avalia uma string e a divide em três. Por padrão, ele retorna um objeto da `list` de classes com um elemento (um vetor de caracteres) para cada string fornecida inicialmente. Se `simplify = TRUE`, ele retorna uma matriz de caracteres.

Neste exemplo, uma string é fornecida e a função retorna uma lista com um elemento - um vetor de caracteres com três valores.

```{r}
str_split(string = "jaundice, fever, chills",
          pattern = ",")
```

Se o resultado de saída for salvo, você poderá acessar o enésimo valor de divisão com a sintaxe de colchetes. Para acessar um valor específico, você pode usar uma sintaxe como esta: `the_returned_object[[1]][2]`, que acessaria o segundo valor da primeira string avaliada ("febre"). Consulte a página [Introdução ao R](#basics) para obter mais detalhes sobre como acessar os elementos.

```{r}
pt1_symptoms <- str_split("jaundice, fever, chills", ",")

pt1_symptoms[[1]][2]  # extrai o segundo valor do primeiro (e único) elemento da lista
```

Se múltiplos strings forem fornecidas por `str_split()`, haverá mais de um elemento na lista retornada.

```{r}
symptoms <- c("jaundice, fever, chills",     # paciente 1
              "chills, aches, pains",        # paciente 2 
              "fever",                       # paciente 3
              "vomiting, diarrhoea",         # paciente 4
              "bleeding from gums, fever",   # paciente 5
              "rapid pulse, headache")       # paciente 6

str_split(symptoms, ",")                     # dividir os sintomas de cada paciente
```

Para retornar uma "matriz de caracteres", que pode ser útil ao criar colunas de tabela de dados, defina o argumento `simplify = TRUE` como mostrado abaixo:

```{r}
str_split(symptoms, ",", simplify = TRUE)
```

Você também pode ajustar o número de divisões a serem criadas com o argumento `n =`. Por exemplo, isso restringe o número de divisões a 2. Quaisquer outras vírgulas permanecem dentro dos segundos valores.

```{r}
str_split(symptoms, ",", simplify = TRUE, n = 2)
```

*Oservação - as mesmas saídas podem ser obtidas com `str_split_fixed()`, em que você não fornece o argumento `simplify`, mas deve designar o número de colunas (`n`).*

```{r, eval=F}
str_split_fixed(symptoms, ",", n = 2)
```

### Dividir colunas {.unnumbered}

Se você está tentando dividir a coluna da tabela de dados, é melhor usar a função `separate()` do **dplyr**. É usado para dividir uma coluna de caracteres em outras colunas.

Digamos que temos uma simples tabela de dados `df` (definida e unida na [seção Unir](#str_unite)) contendo uma coluna `case_ID`, uma coluna de caractere com muitos sintomas e uma coluna de resultado. Nosso objetivo é separar a coluna de `symptoms` em várias colunas - cada uma contendo um sintoma.

```{r, echo=F}
DT::datatable(df, rownames = FALSE, options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```

Assumindo que os dados sejam divididos por meio do `separate()`, primeiro forneça a coluna a ser separada. Em seguida, forneça `into =` como um vetor `c( )` contendo os *novos* nomes das colunas, conforme mostrado abaixo.

-   `sep =` o separador, pode ser um caractere ou um número (interpretado como a posição do caractere para dividir)

-   `remove =` FALSE por padrão, remove a coluna de entrada

-   `convert =` FALSE por padrão, fará com que a string "NA" se torne `NA`

-   `extra =` isso controla o que acontece se houver mais valores criados pela separação do que novas colunas nomeadas.

-   `extra = "warn"` significa que você verá um aviso, mas os valores em excesso serão descartados (**o padrão**)

-   `extra = "drop"` significa que os valores em excesso serão descartados sem aviso

-   **`extra = "merge"` somente será dividido para o número de novas colunas listadas em `into` - *esta configuração preservará todos os seus dados**

Um exemplo com `extra = "merge"` está abaixo - nenhum dado é perdido. Duas novas colunas são definidas, mas quaisquer terceiros sintomas são combinados na segunda coluna nova:

```{r}
# terceiros sintomas combinados na segunda nova coluna
df %>% 
  separate(symptoms, into = c("sym_1", "sym_2"), sep=",", extra = "merge")
```

Quando o padrão `extra = "drop"` é usado abaixo, um aviso é dado, mas os terceiros sintomas são perdidos:

```{r}
# terceiros sintomas são perdidos
df %>% 
  separate(symptoms, into = c("sym_1", "sym_2"), sep=",")
```

[**CUIDADO:** Se você não fornecer valores suficientes `into` para as novas colunas, seus dados podem ser truncados.]{style="color: orange;"}

<!-- ======================================================= -->

### Organizar em ordem alfabética {.unnumbered}

Várias strings podem ser classificadas em ordem alfabética. `str_order()` retorna a ordem, enquanto `str_sort()` retorna as strings nessa ordem.

```{r}
# strings
health_zones <- c("Alba", "Takota", "Delta")

# retornar a ordem alfabética
str_order(health_zones)

# retornar as strings em ordem alfabética
str_sort(health_zones)
```

Para usar um alfabeto diferente, adicione o argumento `locale =`. Veja a lista completa de localidades digitando `stringi::stri_locale_list()` no R console.

<!-- ======================================================= -->

### Funções do R base {.unnumbered}

É comum ver as funções do R **base** `paste()` e `paste0()`, que concatenam vetores após converter todas as partes em caracteres. Eles agem de forma semelhante a `str_c()` , mas a sintaxe é indiscutivelmente mais complicada - entre parênteses cada parte é separada por uma vírgula. As partes são textos de caracteres (entre aspas) ou objetos de código predefinidos (sem aspas). Por exemplo:

```{r}
n_beds <- 10
n_masks <- 20

paste0("Hospital regional precisa ", n_beds, " camas e ", n_masks, " máscaras.")
```

Os argumentos `sep =` e `collapse =` podem ser especificados. `paste()` é simplesmente `paste0()` com um `sep = " "` padrão (um espaço).

## Limpe e padronize

<!-- ======================================================= -->

### Mudar maiúsculas e minúsculas {.unnumbered}

Frequentemente, é necessário alterar a capitalização / maiúsculas de um valor de string, por exemplo, nomes de jursidições. Use `str_to_upper()`, `str_to_lower()`, e `str_to_title()`, de **stringr**, como mostrado abaixo:

```{r}
str_to_upper("California")

str_to_lower("California")
```

Usando R **base**, o acima também pode ser obtido com `toupper()`, `tolower()`.

**Capitalização de título**

Transformar o string para que cada palavra inicie com maiúscula pode ser conseguido com `str_to_title()`:

```{r}
str_to_title("go to the US state of california ")
```

Use `toTitleCase()` do pacote **tools** para obter uma capitalização mais sutil (palavras como "para", "o" e "de" não são capitalizadas).

```{r}
tools::toTitleCase("Este é o estado da califórnia dos EUA")
```

Você também pode usar `str_to_sentence()`, que coloca em maiúscula apenas a primeira letra do string.

```{r}
str_to_sentence("o paciente precisa ser transportado")
```

### Comprimento do código {#str_pad .unnumbered}

Use `str_pad()` para adicionar caracteres a uma string, com um comprimento mínimo. Por padrão, espaços são adicionados, mas você também pode preencher com outros caracteres usando o argumento `pad =`.

```{r}
# Códigos ICD de comprimento diferente
ICD_codes <- c("R10.13",
               "R10.819",
               "R17")

# Códigos ICD preenchidos com 7 caracteres no lado direito
str_pad(ICD_codes, 7, "right")

# Pad com pontos em vez de espaços
str_pad(ICD_codes, 7, "right", pad = ".")
```

Por exemplo, para preencher números com zeros à esquerda (como para horas ou minutos), você pode preencher o número com o comprimento mínimo de 2 com `pad = "0"`.

```{r}
# Adicione zeros à esquerda de dois dígitos (por exemplo, para tempos minutos / horas)
str_pad("4", 2, pad = "0") 

# exemplo usando uma coluna numérica chamada "horas"
# hours <- str_pad(hours, 2, pad = "0")
```

### Truncar {.unnumbered}

`str_trunc()` define um comprimento máximo para cada string. Se uma string exceder esse comprimento, ela será truncada (encurtada) e uma reticência (...) será incluída para indicar que a string era anteriormente mais longa. Observe que as reticências *são* counted contadas no comprimento. Os caracteres de reticências podem ser alterados com o argumento `ellipsis =`. O argumento opcional `side =` especifica onde as reticências aparecerão dentro da string truncada ("esquerda", "direita" ou "centro").

```{r}
original <- "Symptom onset on 4/3/2020 with vomiting"
str_trunc(original, 10, "center")
```

### Padronizar comprimento {.unnumbered}

Use `str_trunc()` para definir um comprimento máximo, e então use `str_pad()` para expandir as strings muito curtas para aquele comprimento truncado. No exemplo abaixo, 6 é definido como o comprimento máximo (um valor é truncado) e, em seguida, um valor muito curto é preenchido para atingir o comprimento de 6.

```{r}
# Códigos ICD de comprimento diferente
ICD_codes   <- c("R10.13",
                 "R10.819",
                 "R17")

# truncar com comprimento máximo de 6
ICD_codes_2 <- str_trunc(ICD_codes, 6)
ICD_codes_2

# expandir para comprimento mínimo de 6
ICD_codes_3 <- str_pad(ICD_codes_2, 6, "right")
ICD_codes_3
```

### Remova os espaços em branco à esquerda / à direita {.unnumbered}

Use `str_trim()` para remover espaços, `\n` para novas linhas ou tabulações (`\t`) nos lados de uma entrada de string. Adicione `"right"` `"left"`, ou `"both"` ao comando para especificar qual lado cortar (por exemplo, `str_trim(x, "right")`.

```{r}
# Números ID com espaços em excesso à direita
IDs <- c("provA_1852  ", # dois espaços excedentes
         "provA_2345",   # zero espaço excedente
         "provA_9460 ")  # um espaço excedente

# IDs cortados para remover espaços em excesso apenas no lado direito
str_trim(IDs)
```

### Remova os espaços em branco repetidos dentro do texto {.unnumbered}

Use `str_squish()` para remover espaços repetidos que aparecem dentro de uma string. Por exemplo, para converter espaços duplos em espaços simples. Ele também remove espaços, novas linhas ou tabulações do lado de fora da string como `str_trim()`.

```{r}
# o original contém espaços em excesso dentro da string
str_squish("  Pt requires   IV saline\n") 
```

Digite `?str_trim`, `?str_pad` em seu console R para ver mais detalhes.

### Quebrar em parágrafos {.unnumbered}

Use `str_wrap()` para quebrar um texto longo e não estruturado em um parágrafo estruturado com comprimento de linha fixo. Fornece o comprimento de caractere ideal para cada linha e aplica um algoritmo para inserir novas linhas (`\n`) dentro do parágrafo, conforme mostrado no exemplo abaixo.

```{r}
pt_course <- "início dos sintomas 04/01/2020 vômito febre calafrios. Pt viu um curandeiro tradicional na aldeia natal em 04/02/2020. Em 04/05/2020 os sintomas de pt se agravaram e foi internado na clínica de Lumta. A amostra foi coletada e o pt foi transportado para o hospital regional em 04/06/2020. Pt morreu no hospital regional em 04/07/2020."

str_wrap(pt_course, 40)
```

A função **base** `cat()` pode ser envolvida no comando acima para mostrar o resultado, exibindo as novas linhas adicionadas.

```{r}
cat(str_wrap(pt_course, 40))
```

<!-- ======================================================= -->

## Manipular por posição

### Extrair pela posição dos caracteres {.unnumbered}

Use `str_sub()` para retornar apenas uma parte de uma string. A função tem três argumentos principais:

1)  o(s) vetor(es) de caracteres
2)  posição inicial
3)  posição final

Algumas notas sobre os números de posição:

-   Se um número de posição for positivo, a posição é contada a partir da extremidade esquerda da string.
-   Se um número de posição for negativo, ele é contado a partir da extremidade direita da string.
-   Os números das posições são inclusivos.
-   As posições que se estendem além da string serão truncadas (removidas).

Abaixo estão alguns exemplos aplicados à string "pneumonia":

```{r}
# começar e terminar em terceiro da esquerda (3ª letra da esquerda)
str_sub("pneumonia", 3, 3)

# 0 não está presente
str_sub("pneumonia", 0, 0)

# 6º da esquerda, para o 1º da direita
str_sub("pneumonia", 6, -1)

# 5º da direita, para o 2º da direita
str_sub("pneumonia", -5, -2)

# 4º da esquerda para uma posição fora da string
str_sub("pneumonia", 4, 15)
```

### Extrair por posição de palavra {.unnumbered}

Para extrair a enésima 'palavra', use `word()`, também do pacote **stringr**. Forneça as strings (descriçoes), a posição da primeira palavra a extrair e a posição da última palavra a extrair.

Por padrão, o separador entre 'palavras' é considerado um espaço, a menos que indicado de outra forma com `sep =` (por exemplo, `sep = "_"` quando as palavras são separadas por underlines).

```{r}
# strings para avaliar
chief_complaints <- c("Acabei de sair do hospital há 2 dias, mas ainda mal consigo respirar.",
                      "Meu estômago dói",
                      "Dor de ouvido severa")

# extraia a 1ª a 3ª palavras de cada string (descrição)
word(chief_complaints, start = 1, end = 3, sep = " ")
```

### Substituir pela posição do caractere {.unnumbered}

`str_sub()` emparelhado com o operador de atribuição (`<-`) pode ser usado para modificar uma parte de uma string:

```{r}
word <- "pneumonia"

# converter o terceiro e o quarto caracteres em X 
str_sub(word, 3, 4) <- "XX"

# exibe
word
```

Um exemplo aplicado a várias strings (por exemplo, uma coluna). Observe a expansão do comprimento de "HIV".

```{r}
words <- c("pneumonia", "tubercolose", "HIV")

# converter o terceiro e o quarto caracteres em X 
str_sub(words, 3, 4) <- "XX"

words
```

### Avalie o comprimento {.unnumbered}

```{r}
str_length("abc")
```

Alternativamente, use `nchar()` do R **base**

<!-- ======================================================= -->

## Padrões

Muitas funções **stringr** trabalham para detectar, localizar, extrair, combinar, substituir e dividir com base em um *padrão* especificado.

<!-- ======================================================= -->

### Detectar um padrão {.unnumbered}

Use `str_detect()` como abaixo para detectar a presença / ausência de um padrão dentro de uma string. Primeiro forneça a string ou vetor a ser pesquisado (`string =`) e, em seguida, o padrão a ser procurado (`pattern =`). Observe que, por padrão, a pesquisa *diferencia maiúsculas de minúsculas*!

```{r}
str_detect(string = "professor de escola primária", pattern = "prof")
```

O argumento `negate =` pode ser incluído e definido como `TRUE` se você quiser saber se o padrão NÃO está presente.

```{r}
str_detect(string = "professor de escola primária", pattern = "prof", negate = TRUE)
```

Para ignorar maiúsculas e minúsculas, envolva o padrão em `regex()`, e *em* `regex()` adicione o argumento `ignore_case = TRUE` (ou `T` como abreviação).

```{r}
str_detect(string = "Professor", pattern = regex("prof", ignore_case = T))
```

Quando `str_detect()` é aplicado a um vetor de caracteres ou uma coluna da tabela de dados, ele retornará TRUE ou FALSE para cada um dos valores.

```{r}
# um vetor / coluna de ocupações
occupations <- c("trabalhador do campo",
                 "professor universitário",
                 "educador de escola primária",
                 "tutor",
                 "enfermeira em hospital regional",
                 "eletricita da Fábrica em Amberdeen",
                 "médico",
                 "cardiologista",
                 "trabalhador de escritório",
                 "trabalhador de serviço de alimentação")

# Detecta a presença do padrão "prof" em cada string - a saída é um vetor TRUE / FALSE
str_detect(occupations, "prof")
```

Se você precisar contar os `TRUE`s, simplesmente some os resultados por meio da função `sum()`. Essa função conta o número de `TRUE`.

```{r}
sum(str_detect(occupations, "prof"))
```

Para pesquisar incluindo vários termos, inclua-os separados por barras OR (`|`) dentro do argumento `pattern =`, conforme mostrado abaixo:

```{r}
sum(str_detect(string = occupations, pattern = "prof|educador|tutor"))
```

Se precisar construir uma longa lista de termos de pesquisa, você pode combiná-los usando `str_c()` e `sep = |`, em seguida defina que este é um objeto de caractere e referencie o vetor posteriormente de forma mais sucinta. O exemplo abaixo inclui possíveis termos de pesquisa de ocupação para provedores médicos de linha de frente.

```{r}
# termos de busca
occupation_med_frontline <- str_c("medical", "medicine", "hcw", "healthcare", "home care", "home health",
                                "surgeon", "doctor", "doc", "physician", "surgery", "peds", "pediatrician",
                               "intensivist", "cardiologist", "coroner", "nurse", "nursing", "rn", "lpn",
                               "cna", "pa", "physician assistant", "mental health",
                               "emergency department technician", "resp therapist", "respiratory",
                                "phlebotomist", "pharmacy", "pharmacist", "hospital", "snf", "rehabilitation",
                               "rehab", "activity", "elderly", "subacute", "sub acute",
                                "clinic", "post acute", "therapist", "extended care",
                                "dental", "dential", "dentist", sep = "|")

occupation_med_frontline
```

Este comando retorna o número de ocupações que contêm qualquer um dos termos de pesquisa para provedores médicos de linha de frente (`occupation_med_frontline`):

```{r}
sum(str_detect(string = occupations, pattern = occupation_med_frontline))
```

**Funções de pesquisa de string do R base**

A função **base** `grepl()` funciona de forma similar à função `str_detect()`, no sentido de que procura por correspondências com um padrão e retorna um vetor lógico. A sintaxe básica é `grepl(pattern, strings_to_search, ignore.case = FALSE, ...)`. Uma vantagem é que o argumento `ignore.case` é mais fácil de escrever (não há necessidade de envolver a função `regex()`).

Da mesma forma, as funções de **base** `sub()` e `gsub()` agem de forma semelhante a `str_replace()`. Sua sintaxe básica é: `gsub(pattern, replacement, strings_to_search, ignore.case = FALSE)`. `sub()` substituirá a primeira instância do padrão, enquanto `gsub()` substituirá todas as instâncias do padrão.

#### Converta vírgulas em pontos {.unnumbered}

Aqui está um exemplo de uso de `gsub()` para converter vírgulas em pontos em um vetor de números. Isso pode ser útil se seus dados vierem de outras partes do mundo que não os Estados Unidos ou a Grã-Bretanha.

O `gsub()` interno que atua primeiro em `lengths` convertendo quaisquer pontos em nenhum espaço "". O caractere de ponto final "." deve ser "escapado" com duas barras para realmente significar um ponto, porque "." em regex significa "qualquer caractere". Em seguida, o resultado (apenas com vírgulas) é passado para o `gsub()` , no qual as vírgulas são substituídas por pontos.

```{r, eval=F}
lengths <- c("2.454,56", "1,2", "6.096,5")

as.numeric(gsub(pattern = ",",                # encontra vírgulas   
                replacement = ".",            # substitui por pontos
                x = gsub("\\.", "", lengths)  # vetor com outros pontos removidos (deve-se "escapar" os pontos)
                )
           )                                  # converter resultado em numérico
```

### Substituir tudo {.unnumbered}

Use `str_replace_all()` omo uma ferramenta de "localizar e substituir". Primeiro, forneça as strings a serem avaliadas para `string =`, depois o padrão a ser substituído por `pattern =` e, a seguir, o valor de substituição para `replacement =`. O exemplo abaixo substitui todas as ocorrências de "morto" por "falecido". Observe que isso É sensível a maiúsculas e minúsculas.

```{r}
outcome <- c("Karl: morto",
            "Samantha: morto",
            "Marco: não morto")

str_replace_all(string = outcome, pattern = "morto", replacement = "óbito")
```

Notas:

-   Para substituir um padrão por `NA`, use `str_replace_na()`.\
-   A função `str_replace()` substitui apenas a primeira instância do padrão em cada string avaliada.

<!-- ======================================================= -->

### Detectar dentro da lógica {.unnumbered}

**Dentro de `case_when()`**

`str_detect()` é frequentemente usado em `case_when()` (de **dplyr**). Digamos que `occupations` é uma coluna na lista. A função `mutate()` abaixo cria uma nova coluna chamada `is_educator` usando lógica condicional via `case_when()`. Veja a página sobre limpeza de dados para aprender mais sobre `case_when()`.

```{r, eval=F}
df <- df %>% 
  mutate(is_educator = case_when(
    # pesquisa de termo dentro da ocupação, sem distinção entre maiúsculas e minúsculas
    str_detect(occupations,
               regex("educador|prof|tutor|universidade",
                     ignore_case = TRUE))              ~ "Educador",
    # todos os outros
    TRUE                                               ~ "Não é educador"))
```

Como um lembrete, pode ser importante adicionar critérios de exclusão à lógica condicional (`negate = F`):

```{r, eval=F}
df <- df %>% 
  # valor na nova coluna is_educator é baseado na lógica condicional
  mutate(is_educator = case_when(
    
    # a coluna de ocupação deve atender a 2 critérios para ser atribuído "Educador":
    # deve ter um termo de pesquisa E NÃO qualquer termo de exclusão
    
    # Deve conter um termo de pesquisa
    str_detect(occupations,
               regex("educador|prof|tutor|universidade", ignore_case = T)) &              
    
    # E NÃO deve ter um termo de exclusão
    str_detect(occupations,
               regex("admin", ignore_case = T),
               negate = TRUE                        ~ "Educador"
    
    # Todas as linhas que não atendem aos critérios acima
    TRUE                                            ~ "Não é educador"))
```

<!-- ======================================================= -->

### Localize a posição do padrão {.unnumbered}

Para localizar a *primeira* posição de um padrão, use `str_locate()`. Ele produz uma posição inicial e final.

```{r}
str_locate("I wish", "sh")
```

Como outras funções `str`, há uma versão "\_all" (`str_locate_all()`) que retornará as posições de *todas* as instâncias do padrão dentro de cada string. Isso resulta em uma `list`.

```{r}
phrases <- c("I wish", "I hope", "he hopes", "He hopes")

str_locate(phrases, "h" )     # posição da *primeira* instância do padrão
str_locate_all(phrases, "h" ) # posição de *cada* instância do padrão
```

<!-- ======================================================= -->

### Extraia uma combinação {.unnumbered}

`str_extract_all()` retorna os próprios padrões de correspondência, o que é mais útil quando você oferece vários padrões por meio de condições "OU". Por exemplo, procurando no vetor string de ocupações (consulte a aba anterior) "educador", "prof" ou "tutor".

`str_extract_all()` retorna uma `list` que contém todas as correspondências para cada string avaliada. Veja abaixo como a ocupação 3 tem duas correspondências de padrão dentro dela.

```{r}
str_extract_all(occupations, "educador|prof|tutor")
```

`str_extract()` extrai apenas *a primeira combinação* (match) em cada string avaliada, produzindo um vetor de caracteres com um elemento para cada string avaliada. Retorna `NA` onde não há uma combinação. Os `NA`s pode ser removido envolvendo o vetor retornado com `na.exclude()`. Observe como o segundo dos acertos da ocupação 3 não é mostrado.

```{r}
str_extract(occupations, "educador|prof|tutor")
```

<!-- ======================================================= -->

### Subconjunto e contagem {.unnumbered}

As funções alinhadas incluem `str_subset()` e `str_count()`.

`str_subset()` retorna os valores reais que continham o padrão:

```{r}
str_subset(occupations, "educador|prof|tutor")
```

`str_count()` retorna um vetor de números: o **número de vezes** que um termo de pesquisa aparece em cada valor avaliado.

```{r}
str_count(occupations, regex("educador|prof|tutor", ignore_case = TRUE))
```

<!-- ======================================================= -->

### Grupos Regex {.unnumbered}

UNDER CONSTRUCTION

<!-- ======================================================= -->

## Caracteres especiais

**Barra invertida `\` como escape**

A barra invertida `\` é usada para "escapar" do significado do próximo caractere. Desta forma, uma barra invertida pode ser usada para exibir uma aspa dentro de outras aspas (`\"`) - a aspa do meio não "quebrará" as aspas circundantes.

Observação - portanto, se você deseja *exibir* uma barra invertida, deve-se escapar de seu significado com outra barra invertida. Portanto, você deve escrever duas barras invertidas `\\` para mostrar uma.

**Caracteres especiais**

+-----------------------------------------------------------------------------------+------------------------------------------------------+
| Caracteres especiais                                                              | Representa                                           |
+===================================================================================+======================================================+
| `"\\"`                                                                            | barra invertida                                      |
+-----------------------------------------------------------------------------------+------------------------------------------------------+
| `"\n"`                                                                            | uma nova linha                                       |
+-----------------------------------------------------------------------------------+------------------------------------------------------+
| `"\""`                                                                            | aspas duplas *entre* aspas duplas                    |
+-----------------------------------------------------------------------------------+------------------------------------------------------+
| `'\''`                                                                            | aspas simples *entre* aspas simples                  |
+-----------------------------------------------------------------------------------+------------------------------------------------------+
| `"\`"`| grave accent`"\r"`| carriage return`"\t"`| tab`"\v"`| vertical tab`"\b"\` | backspace (exclui caractere anterior ao selecionado) |
+-----------------------------------------------------------------------------------+------------------------------------------------------+

Execute `?"'"` no console R para exibir uma lista completa desses caracteres especiais (ela aparecerá no painel Ajuda do RStudio).

<!-- ======================================================= -->

## Regular expressões (regex)

<!-- ======================================================= -->

## Regex e caracteres especiais

Expressões regulares, ou "regex", é uma linguagem concisa para descrever padrões em strings. Se você não estiver familiarizado com ela, uma expressão regular pode parecer uma linguagem alienígena. Aqui tentamos desmistificar um pouco essa linguagem.

*Grande parte desta seção foi adaptada [desse tutorial](https://towardsdatascience.com/a-gentle-introduction-to-regular-expressions-with-r-df5e897ca432) e [desta página de referência](https://evoldyn.gitlab.io/evomics-2018/ref-sheets/R_strings.pdf)*. Nós adaptamos seletivamente aqui sabendo que este manual pode ser visto por pessoas sem acesso à Internet para ver os outros tutoriais.

Uma expressão regular é frequentemente aplicada para extrair padrões específicos de texto "não estruturado" - por exemplo, notas médicas, queixas principais, histórico do paciente ou outras colunas de texto livre em uma tabela de dados.

Existem quatro ferramentas básicas que podem ser usadas para criar uma expressão regular básica:

1)  Conjuntos de caracteres
2)  Meta caracteres
3)  Quantificadores
4)  Grupos

**Conjunto de caracteres**

Os conjuntos de caracteres são uma forma de expressar as opções de listagem para uma correspondência de caracteres, entre colchetes. Portanto, qualquer correspondência será acionada se qualquer um dos caracteres entre colchetes for encontrado na string. Por exemplo, para procurar vogais, pode-se usar este conjunto de caracteres: "\[aeiou\]". Alguns outros conjuntos de caracteres comuns são:

| Conjunto de caracteres | Correspondências para                   |
|------------------------|-----------------------------------------|
| `"[A-Z]"`              | qualquer letra maiúscula isolada        |
| `"[a-z]"`              | qualquer letra minúscula isolada        |
| `"[0-9]"`              | qualquer dígito                         |
| `[:alnum:]`            | qualquer caractere alfanumérico         |
| `[:digit:]`            | qualquer dígito numérico                |
| `[:alpha:]`            | qualquer letra (maiúscula ou minúscula) |
| `[:upper:]`            | qualquer letra maiúscula                |
| `[:lower:]`            | qualquer letra minúscula                |

Os conjuntos de caracteres podem ser combinados dentro de um colchete (sem espaços!), como `"[A-Za-z]"` (qualquer letra maiúscula ou minúscula), ou outro exemplo `"[t-z0-5]"` (t minúsculo até z OU número de 0 a 5).

**Metacaracteres**

Metacaracteres são abreviações para conjuntos de caracteres. Alguns dos mais importantes estão listados abaixo:

| Meta character | Representa                                              |
|----------------|---------------------------------------------------------|
| `"\\s"`        | um espaço simples                                       |
| `"\\w"`        | qualquer caractere alfanumérico único (A-Z, a-z ou 0-9) |
| `"\\d"`        | qualquer dígito numérico único (0-9)                    |

**Quantificadores**

Normalmente, você não deseja pesquisar uma correspondência em apenas um caractere. Os quantificadores permitem que você designe o comprimento das letras/números para permitir a correspondência.

Quantificadores são números escritos entre chaves `{ }` *após* o caractere que estão quantificando, por exemplo,

-   `"A{2}"` retornará instâncias de **duas** letras A maiúsculas.\
-   `"A{2,4}"` retornará instâncias **entre duas e quatro** letras A maiúsculas (*não coloque espaços!*).\
-   `"A{2,}"` retornará as correspondências de **duas ou mais** letras A maiúsculas.\
-   `"A+"` retornará instâncias de **uma ou mais** letras A maiúsculas (grupo estendido até que um caractere diferente seja encontrado).\
-   Preceda com um `*` asterisco para retornar **zero ou mais** correspondências (útil se você não tiver certeza de que o padrão está presente)

Usando o símbolo mais `+` como quantificador, a correspondência ocorrerá até que um caractere diferente seja encontrado. Por exemplo, esta expressão retornará *todas* as palavras (caracteres alfabéticos: `"[A-Za-z]+"`

```{r}
# teste string para quantificadores
test <- "A-AA-AAA-AAAA"
```

Quando um quantificador de {2} é usado, apenas pares de A's consecutivos são retornados. Dois pares são identificados dentro `AAAA`.

```{r}
str_extract_all(test, "A{2}")
```

Quando um quantificador de {2,4} é usado, grupos de A's consecutivos com comprimento de dois a quatro são retornados.

```{r}
str_extract_all(test, "A{2,4}")
```

Com o quantificador `+`, grupos de **um ou mais** são retornados:

```{r}
str_extract_all(test, "A+")
```

**Posição relativa**

Esses requisitos expressam o que precede ou segue um padrão. Por exemplo, para extrair frases, "dois números seguidos de um ponto" (`""`). (?\<=\\.)\\s(?=\[A-Z\])

```{r}
str_extract_all(test, "")
```

| Declaração de posição | Corresponde a                          |
|-----------------------|----------------------------------------|
| `"(?<=b)a"`           | "a" que **é precedido** por um "b"     |
| `"(?<!b)a"`           | "a" que **NÃO é precedido** por um "b" |
| `"a(?=b)"`            | "a" que **é seguido** por um "b"       |
| `"a(?!b)"`            | "a" que **NÃO é seguido** por um "b"   |

**Grupos**

Capturar grupos em sua expressão regular é uma maneira de ter um resultado mais organizado na extração.

**Exemplos de Regex**

Abaixo está um texto livre para os exemplos. Tentaremos extrair informações úteis dele usando um termo de pesquisa de expressão regular.

```{r}
pt_note <- "O paciente chegou ao pronto-socorro do Broward Hospital às 18h do dia 12/06/2005. O paciente apresentou dor abdominal irradiada no quadrante LR. A pele do paciente estava pálida, fria e úmida. A temperatura do paciente era de 99,8 graus Fahrenheit. A pulsação do paciente era de 100 bpm e intermitente. A frequência respiratória era de 29 por minuto."
```

Esta expressão corresponde a todas as palavras (qualquer caractere até atingir um objeto não caractere, como um espaço):

```{r}
str_extract_all(pt_note, "[A-Za-z]+")
```

A expressão `"[0-9]{1,2}"` corresponde a números consecutivos com 1 ou 2 dígitos de comprimento. Também pode ser escrito `"\\d{1,2}"`, ou `"[:digit:]{1,2}"`.

```{r}
str_extract_all(pt_note, "[0-9]{1,2}")
```

<!-- Esta expressão extrairá todas as frases (assumindo que a primeira letra está maiúscula e a frase termina com um ponto). O padrão é lido em inglês como: "A capital letter followed by some lowercase letters, a space, some letters, a space" -->

<!-- ```{r} -->

<!-- str_extract_all(pt_note, "[A-Z][a-z]+\\s\\w+\\s\\d{1,2}\\s\\w+\\s*\\w*") -->

<!-- ``` -->

Você pode ver uma lista útil de expressões regex e dicas na página 2 [deste cheatsheet](https://evoldyn.gitlab.io/evomics-2018/ref-sheets/R_strings.pdf)

Também veja o [tutorial](https://towardsdatascience.com/a-gentle-introduction-to-regular-expressions-with-r-df5e897ca432).

<!-- ======================================================= -->

## Recursos

Uma planilha de referencia para as funções de **stringr** pode ser encontrada [aqui](https://evoldyn.gitlab.io/evomics-2018/ref-sheets/R_strings.pdf)

Uma vinheta sobre **stringr** pode ser encontrada [aqui](https://cran.r-project.org/web/packages/stringr/vignettes/stringr.html)
```{r include=FALSE, cache=FALSE}

# clear workspace
rm(list = ls(all = TRUE))

# clear all packages except base
#lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))

# to ensure that tidyverse packages prevail
filter <- dplyr::filter
select <- dplyr::select
summarise <- dplyr::summarise
summary <- base::summary
incidence <- incidence2::incidence

#load core packages
pacman::p_load(
     rio,
     here,
     DT,
     stringr,
     lubridate,
     tidyverse
)

# import the cleaned ebola linelist
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

# import the count data - facility level
#count_data <- rio::import(here::here("data", "facility_count_data.rds"))

# Settings

options(scipen=1, digits=7)

# print only text (not code)
# library(knitr)
# opts_chunk$set(list(echo = FALSE, eval = FALSE))
```

<!--chapter:end:new_pages/characters_strings.Rmd-->

# Fatores {#factors}

```{r, out.width=c('100%'), echo=F, message=F}
knitr::include_graphics(here::here("images", "Factors_1500x500.png"))
```

No R, os *fatores* são uma classe de dados que permitem categorias ordenadas com um conjunto fixo de valores possíveis.

Normalmente, você converteria uma coluna de caractere ou classe numérica em um fator se quiser definir uma ordem intrínseca para os valores ("níveis") para que eles possam ser exibidos de forma não alfabética em gráficos e tabelas. Outro uso comum de fatores é padronizar as legendas dos gráficos para que não flutuem se certos valores estiverem temporariamente ausentes dos dados.

Esta página demonstra o uso de funções do pacote **forcats** (um nome curto para "**For** **cat**egorical variables" - "para variáveis categóricas") e algumas funções do R **base**. Também abordamos o uso de **lubridate** e **aweek** para casos de fatores especiais relacionados a semanas epidemiológicas (epiweeks).

Uma lista completa das funções do **forcats** pode ser encontrada online [aqui](https://forcats.tidyverse.org/reference/index.html). Abaixo, demonstramos alguns dos mais comuns.

<!-- ======================================================= -->

## Preparação

### Carregar pacotes {.unnumbered}

Este trecho de código mostra o carregamento de pacotes necessários para as análises. Neste manual, enfatizamos o `p_load()` do **pacman**, o qual instala o pacote se necessário *e* o carrega para uso. Você também pode carregar pacotes instalados com `library()` do R **base**. Veja a pagina em [Introdução ao R](#basics) para mais informações sobre pacotes R.

```{r}
pacman::p_load(
  rio,           # importar/exportar
  here,          # diretório
  lubridate,     # trabalhando com datas
  forcats,       # fatores
  aweek,         # criar epiweeks com níveis de fatores automático
  janitor,       # tabelas
  tidyverse      # dados mgmt e viz
  )
```

### Importe os dados {.unnumbered}

Importamos o conjunto de dados de casos de uma simulação de epidemia de Ebola. Se você quiser acompanhar, <a href='https://github.com/appliedepi/epirhandbook_eng/raw/master/data/case_linelists/linelist_cleaned.rds' class='download-button'>clique para baixar o "clean" linelist</a> (as .rds file). Importe seus dados com a função `import()` do pacote **rio** package (o pacote aceita muitos tipos de arquivo como .xlsx, .rds, .csv - veja a página [Importar e exportar](#importing) para detalhes).

```{r, echo=F}
# importar a linelist para o R
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))
```

```{r, eval=F}
# importar seu conjunto de dados
linelist <- import("linelist_cleaned.rds")
```

### Nova variável categórica {#fct_newcat .unnumbered}

Para demonstração nesta página, usaremos um cenário comum - a criação de uma nova variável categórica.

Observe que se você converter uma coluna numérica em fator, não será capaz de calcular estatísticas numéricas sobre ela.

#### Criar coluna {.unnumbered}

Usamos a coluna existente `days_onset_hosp` (dias desde o início dos sintomas até a admissão hospitalar) e criamos uma nova coluna `delay_cat` classificando cada linha em uma das várias categorias. Nós fazemos isso com a função do **dplyr** `case_when()`, que aplica critérios lógicos sequencialmente (lado direito) a cada linha e retorna o valor do lado esquerdo correspondente para a nova coluna `delay_cat`. Leia mais sobre `case_when()` em [Limpeza de dados e principais funções](#cleaning).

```{r}
linelist <- linelist %>% 
  mutate(delay_cat = case_when(
    # critério                                  # novo valor se TRUE
    days_onset_hosp < 2                        ~ "<2 dias",
    days_onset_hosp >= 2 & days_onset_hosp < 5 ~ "2-5 dias",
    days_onset_hosp >= 5                       ~ ">5 dias",
    is.na(days_onset_hosp)                     ~ NA_character_,
    TRUE                                       ~ "Verifique"))  
```

#### Padrão da ordem dos valores {.unnumbered}

Conforme criado com `case_when()`, a nova coluna `delay_cat` é uma coluna categórica da classe Caractere - *ainda não* é um fator. Assim, em uma tabela de frequência, vemos que os valores exclusivos aparecem por padrão em uma ordem alfanumérica - uma ordem que não faz muito sentido intuitivo:

```{r}
table(linelist$delay_cat, useNA = "always")
```

Da mesma forma, se fizermos um gráfico de barra, os valores também aparecem nesta ordem no eixo x (consulte a página [O básico o ggplot](#ggplot-basics) para mais informações sobre o **ggplot2** - o pacote de visualização mais comum no R).

```{r, warning=F, message=F}
ggplot(data = linelist)+
  geom_bar(mapping = aes(x = delay_cat))
```

## Converter para fator

Para converter um caractere ou coluna numérica para classe *fator*, você pode usar qualquer função do pacote **forcats** (muitos são detalhados [abaixo](#fct_adjust)). Eles serão convertidos para fator e, em seguida, também realizarão ou permitirão certa ordenação dos níveis - por exemplo, usar `fct_relevel()` permite que você especifique manualmente a ordem dos níveis. A função `as_factor()` simplesmente converte a classe sem quaisquer recursos adicionais.

A função do R **base** `factor()` converte uma coluna em fator e permite que você especifique manualmente a ordem dos níveis, como um vetor de caracteres para seu argumento `levels =`.

Abaixo usamos `mutate()` e `fct_relevel()` para converter a coluna `delay_cat` de classe caractere para classe fator. A coluna `delay_cat` é criada na seção [Preparação](#fct_newcat) acima.

```{r}
linelist <- linelist %>%
  mutate(delay_cat = fct_relevel(delay_cat))
```

*Os "valores" únicos nesta coluna são agora considerados "níveis" do fator.* Os níveis têm uma *ordem*, que pode ser exibida com a função do R **base** `levels()`, ou, alternativamente, visualizada em uma tabela de contagem via `table()` do R **base** ou `tabyl()` do **janitor**. Por padrão, a ordem dos níveis será alfanumérica, como antes. Observe que `NA` não é um nível de fator.

```{r}
levels(linelist$delay_cat)
```

A função `fct_relevel()` tem a utilidade adicional de permitir que você especifique manualmente a ordem dos níveis. Basta escrever os valores dos níveis em ordem, entre aspas, separados por vírgulas, conforme mostrado abaixo. Observe que a grafia deve corresponder exatamente aos valores. Se você quiser criar níveis que não existem nos dados, use [`fct_expand()` ao invés](#fct_add)).

```{r}
linelist <- linelist %>%
  mutate(delay_cat = fct_relevel(delay_cat, "<2 days", "2-5 days", ">5 days"))
```

Agora podemos ver que os níveis estão ordenados, conforme especificado no comando anterior, em uma ordem sensata.

```{r}
levels(linelist$delay_cat)
```

Agora, a ordem do gráfico também faz um sentido mais intuitivo.

```{r, warning=F, message=F}
ggplot(data = linelist)+
  geom_bar(mapping = aes(x = delay_cat))
```

## Adicionar ou remover níveis

### Adicionar {#fct_add .unnumbered}

Se você precisar adicionar níveis a um fator, você pode fazer isso com `fct_expand()`. Basta escrever o nome da coluna seguido pelos novos níveis (separados por vírgulas). Tabulando os valores, podemos ver os novos níveis e as contagens zero. Você pode usar `table()` do R **base**, ou `tabyl()` do **janitor**:

```{r}
linelist %>% 
  mutate(delay_cat = fct_expand(delay_cat, "Not admitted to hospital", "Transfer to other jurisdiction")) %>% 
  tabyl(delay_cat)   # print table
```

Nota: há uma função especial no **forcats** para adicionar facilmente valores ausentes (`NA`) como um nível. Consulte a seção abaixo sobre [Valores ausentes](#fct_missing).

### Remover {.unnumbered}

Se você usar `fct_drop()`, os níveis "não usados" com contagem zero serão retirados do conjunto de níveis. Os níveis que adicionamos acima ("Not admitted to a hospital" - Não admitido em um hospital) existem como um nível, mas nenhuma linha realmente possui esses valores. Portanto, eles serão eliminados aplicando `fct_drop()` na nossa coluna de fator:

```{r}
linelist %>% 
  mutate(delay_cat = fct_drop(delay_cat)) %>% 
  tabyl(delay_cat)
```

## Ajuste a ordem dos níveis {#fct_adjust}

O pacote **forcats** oferece funções úteis para ajustar facilmente a ordem dos níveis de um fator (após uma coluna ser definida como classe fator):

Essas funções podem ser aplicadas a uma coluna de fator em dois contextos:

1)  Para a coluna no data frame, como de costume, para que a transformação esteja disponível para qualquer uso subsequente dos dados\
2)  *Dentro de um gráfico,* de modo que a alteração seja aplicada apenas dentro do gráfico

### Manualmente {.unnumbered}

Esta função é usada para ordenar manualmente os níveis dos fatores. Se usada em uma coluna sem fator, a coluna será primeiro convertida para classe fator.

Entre parênteses, primeiro forneça o nome da coluna do fator e, em seguida, forneça:

-   Todos os níveis na ordem desejada (como um vetor de caracteres `c()`), ou\
-   Um nível e seu posicionamento corrigido usando o argumento `after =`

Aqui está um exemplo de redefinição da coluna `delay_cat` (que já é da classe Factor) e especificando toda a ordem de níveis desejada.

```{r}
# redefine a ordem dos níveis dos fatores
linelist <- linelist %>% 
  mutate(delay_cat = fct_relevel(delay_cat, c("<2 days", "2-5 days", ">5 days")))
```

Se você quiser mover apenas um nível, você pode especificá-lo sozinha para `fct_relevel()` e dar um número ao argumento `after =` para indicar onde na ordem ele deveria estar. Por exemplo, o comando abaixo muda "\<2 dias" para a segunda posição:

```{r, eval=F}
# redefinir a ordem dos níveis
linelist %>% 
  mutate(delay_cat = fct_relevel(delay_cat, "<2 days", after = 1)) %>% 
  tabyl(delay_cat)
```

### Dentro de um gráfico {.unnumbered}

Os comandos do **forcats** podem ser usados para definir a ordem dos níveis no data frame ou apenas dentro de um gráfico. Usando o comando para "envolver" o nome da coluna *dentro* do comando de plotagem `ggplot()` você pode reverter / reordenar / etc, assim, a transformação só se aplicará a esse gráfico.

Abaixo, dois gráficos são criados com `ggplot()` (consulte a página [O básico o ggplot](#ggplot-basics)). No primeiro, a coluna `delay_cat` é mapeada para o eixo x do gráfico, com sua ordem de nível padrão como nos dados da `linelist`. No segundo exemplo, ele é inserido em `fct_relevel()` e a ordem é alterada no gráfico.

```{r, echo =F}
linelist <- linelist %>% 
  mutate(delay_cat = fct_relevel(delay_cat, c("2-5 days", "<2 days", ">5 days")))

```

```{r, warning=F, message=F, out.width = c('50%', '50%'), fig.show='hold'}
# Ordem alfanumérica padrão - sem ajuste no ggplot
ggplot(data = linelist)+
    geom_bar(mapping = aes(x = delay_cat))

# Ordem dos níveis dos fatores ajustada dentro do ggplot
ggplot(data = linelist)+
  geom_bar(mapping = aes(x = fct_relevel(delay_cat, c("<2 days", "2-5 days", ">5 days"))))
```

Observe que o título padrão do eixo x agora é bastante complicado - você pode reescrever este título com o argumento `labs()` do **ggplot2**.

### Inverter {.unnumbered}

É bastante comum que você queira inverter a ordem dos níveis. Simplesmente envolva o fator com `fct_rev()`.

Observe que se você deseja reverter *apenas* uma legenda do gráfico, mas não os níveis reais dos fatores, pode fazer isso com `guides()` (consulte [Dicas para o ggplot](#ggplot-tips)).

### Por frequência {.unnumbered}

Para ordenar pela frequência com que o valor aparece nos dados, use `fct_infreq()`. Quaisquer valores ausentes (`NA`) serão incluídos automaticamente no final, a menos que sejam convertidos para um nível explícito (veja [essa seção](#fct_missing)). Você pode inverter a ordem envolvendo em seguida com `fct_rev()`.

Esta função pode ser usada em um `ggplot()`, conforme mostrado abaixo.

```{r, out.width = c('50%', '50%', '50%'), fig.show='hold', warning=F, message=F}
# ordenando por frequência
ggplot(data = linelist, aes(x = fct_infreq(delay_cat)))+
  geom_bar()+
  labs(x = "Delay onset to admission (days)",
       title = "Ordered by frequency")

# inverter frequência
ggplot(data = linelist, aes(x = fct_rev(fct_infreq(delay_cat))))+
  geom_bar()+
  labs(x = "Delay onset to admission (days)",
       title = "Reverse of order by frequency")
```

### Pela aparência {.unnumbered}

Use `fct_inorder()` para definir a ordem dos níveis para corresponder à ordem de aparecimento nos dados, começando da primeira linha. Isso pode ser útil se você primeiro organizar os dados cuidadosamente por meio do `arrange()` no data frame e, em seguida, usar isso para definir a ordem dos fatores.

### Pela estatística de resumo de outra coluna {.unnumbered}

Você pode usar `fct_reorder()` para ordenar os níveis de uma coluna *por uma estatística de resumo de outra coluna*. Visualmente, isso pode resultar em gráficos agradáveis, onde as barras / pontos sobem ou descem de forma constante no gráfico.

Nos exemplos abaixo, o eixo x é `delay_cat`, e o eixo y é a coluna numérica `ct_blood` (valor do limite do ciclo). Os gráficos de caixa mostram a distribuição do valor CT por grupo `delay_cat`. Queremos ordenar os gráficos de caixa em ordem crescente pelo valor de CT mediano do grupo.

No primeiro exemplo abaixo, a ordem padrão de nível alfanumérico é usada. Você pode ver que as alturas do box plot estão confusas e não em uma ordem específica. No segundo exemplo, a coluna `delay_cat` (mapeada para o eixo x) foi agrupada em `fct_reorder()`, a coluna `ct_blood` é fornecida como o segundo argumento e "median" (mediana) é fornecido como o terceiro argumento (você também pode usar "max", "mean", "min", etc). Portanto, a ordem dos níveis de `delay_cat` agora refletirá os valores médios de CT crescentes de cada valor de CT médio dos grupos presentes em `delay_cat`. Isso se reflete no segundo gráfico - os gráficos de caixa foram reorganizados para ascender. Observe como `NA` (ausente) aparecerá no final, a menos que seja convertido para um nível explícito.

```{r, fig.show='hold', message=FALSE, warning=FALSE, out.width=c('50%', '50%')}
# boxplots ordenados para os níveis originais dos fatores
ggplot(data = linelist)+
  geom_boxplot(
    aes(x = delay_cat,
        y = ct_blood, 
        fill = delay_cat))+
  labs(x = "Delay onset to admission (days)",
       title = "Ordered by original alpha-numeric levels")+
  theme_classic()+
  theme(legend.position = "none")


# boxplots ordenados pelo valor médio de CT
ggplot(data = linelist)+
  geom_boxplot(
    aes(x = fct_reorder(delay_cat, ct_blood, "median"),
        y = ct_blood,
        fill = delay_cat))+
  labs(x = "Delay onset to admission (days)",
       title = "Ordered by median CT value in group")+
  theme_classic()+
  theme(legend.position = "none")
```

Observe que neste exemplo acima não há etapas necessárias antes da função `ggplot()` - o agrupamento e os cálculos são todos feitos dentro do comando do ggplot.

### Por valor "final" {.unnumbered}

Use `fct_reorder2()` para gráficos de linha agrupados. Ele ordena os níveis (e, portanto, a *legenda*) para alinhar com a ordem vertical das linhas no "final" do gráfico. Tecnicamente falando, ele "ordena pelos valores y associados aos maiores valores x".

Por exemplo, se você tiver linhas mostrando contagens de casos por hospital ao longo do tempo, você pode aplicar `fct_reorder2()` ao argumento `color =` dentro do `aes()`, de modo que a ordem vertical dos hospitais que aparecem na legenda se alinhe com a ordem das linhas no extremidade final do gráfico. Leia mais na [documentação online](https://forcats.tidyverse.org/reference/fct_reorder.html).

```{r, warning=F, message=F}
epidemic_data <- linelist %>%         # comece com a linelist   
    filter(date_onset < as.Date("2014-09-21")) %>%    # limite a data para clareza visual
    count(                                            # obter a contagem dos casos por semana e por hospital
      epiweek = lubridate::floor_date(date_onset, "week"),  
      hospital                                            
    ) 
  
ggplot(data = epidemic_data)+                       # inicie o gráfico
  geom_line(                                        # faça as linhas 
    aes(
      x = epiweek,                                  # eixo-x epiweek
      y = n,                                        # altura é o número de casos por semana
      color = fct_reorder2(hospital, epiweek, n)))+ # dados agrupados e coloridos por hospital, com fator de ordem por altura no final do gráfico
  labs(title = "Factor levels (and legend display) by line height at end of plot",
       color = "Hospital")                          # change legend title
```

## Valores ausentes {#fct_missing}

Se você tiver valores `NA` em sua coluna de fatores, poderá convertê-los facilmente em um nível nomeado, como "Missing" (ausentes) com `fct_explicit_na()`. Por padrão, os valores `NA` são convertidos para "(Missing)" no final da ordenação dos nível. Você pode ajustar o nome do nível com o argumento `na_level =`.

A seguir, esta operação é realizada na `delay_cat` e uma tabela é exibida com `tabyl()` contendo `NA` convertido para "Missing delay".

```{r}
linelist %>% 
  mutate(delay_cat = fct_explicit_na(delay_cat, na_level = "Missing delay")) %>% 
  tabyl(delay_cat)
```

## Combine os níveis

### Manualmente {.unnumbered}

Você pode ajustar a exibibição dos níveis manualmente com `fct_recode()`. Essa função é similar a função `recode()` do **dplyr** (veja [Limpeza de dados e principais funções](#cleaning)), mas permite a criação de novos níveis de fator. Se você usar simplesmente o `recode()` em um fator, novos valores recodificados serão rejeitados, a menos que já tenham sido definidos como níveis permitidos.

Essa ferramenta também pode ser usada para "combinar" níveis, atribuindo vários níveis ao mesmo valor recodificado. Só tome cuidado para não perder informações! Considere fazer essas etapas de combinação em uma nova coluna (não sobrescrever a coluna existente).

`fct_recode()` tem uma sintaxe diferente de `recode()`. `recode()` usa `OLD = NEW`, enquanto `fct_recode()` usa `NEW = OLD`.

Os níveis atuais de `delay_cat` são:

```{r, echo=F}
linelist <- linelist %>% 
  mutate(delay_cat = fct_relevel(delay_cat, "<2 days", after = 0))
```

```{r}
levels(linelist$delay_cat)
```

Os novos níveis são criados usando a sintaxe `fct_recode(column, "new" = "old", "new" = "old", "new" = "old")` e exibidos:

```{r}
linelist %>% 
  mutate(delay_cat = fct_recode(
    delay_cat,
    "Less than 2 days" = "<2 days",
    "2 to 5 days"      = "2-5 days",
    "More than 5 days" = ">5 days")) %>% 
  tabyl(delay_cat)
```

Aqui, eles são combinados manualmente com `fct_recode()`. Observe que nenhum erro foi gerado na criação de um novo nível "Less than 5 days" (Menos de 5 dias) .

```{r, warning=F, message=F}
linelist %>% 
  mutate(delay_cat = fct_recode(
    delay_cat,
    "Less than 5 days" = "<2 days",
    "Less than 5 days" = "2-5 days",
    "More than 5 days" = ">5 days")) %>% 
  tabyl(delay_cat)
```

### Reduzir para "Outro" {.unnumbered}

Você pode usar `fct_other()` para atribuir manualmente níveis de fator a um nível chamado "Outros". Abaixo, todos os níveis da coluna `hospital`, aside from "Port Hospital" and "Central Hospital", are combined into "Other". exceto "Port Hospital" e "Central Hospital", são combinados em "Other". Você pode fornecer um vetor para `keep =`, ou `drop =`. Você pode alterar a exibição do nível "Outro" com `other_level =`.

```{r}
linelist %>%    
  mutate(hospital = fct_other(                      # ajustar níveis
    hospital,
    keep = c("Port Hospital", "Central Hospital"),  # manter esses separados
    other_level = "Other Hospital")) %>%            # Todos os outros como "Other Hospital"
  tabyl(hospital)                                   # exiba a tabela

```

### Reduzir por frequência {.unnumbered}

Você pode combinar os níveis do fator menos frequentes automaticamente usando `fct_lump()`.

Para "agrupar" muitos níveis de baixa frequência em um grupo "Outro", siga um destes procedimentos:

-   Defina `n =` como o número de grupos que deseja manter. Os n níveis mais frequentes serão mantidos e todos os outros serão combinados em "Outros".\
-   Defina `prop =` como a proporção de frequência limite para os níveis acima dos quais você deseja manter. Todos os outros valores serão combinados em "Outro".

Você pode alterar a exibição do nível "Outro" com `other_level =`. Abaixo, todos, exceto os dois hospitais mais frequentes, são combinados em "Other Hospital" (Outro hospital).

```{r, warning=F, message=F}
linelist %>%    
  mutate(hospital = fct_lump(                      # ajuste os níveis
    hospital,
    n = 2,                                          # mantenha os 2 níveis superiores
    other_level = "Other Hospital")) %>%            # todos os outros como "Other Hospital"
  tabyl(hospital)                                   # exiba a tabela

```

## Mostrar todos os níveis

Um benefício de usar fatores é padronizar a aparência das legendas e tabelas do gráfico, independentemente de quais valores estão realmente presentes em um conjunto de dados.

Se você estiver preparando muitas figuras (por exemplo, para várias jurisdições), você desejará que as legendas e tabelas apareçam de forma idêntica, mesmo com variação nos níveis de conclusão ou composição de dados.

### Em gráficos {.unnumbered}

Em uma figura `ggplot()`, simplesmente adicione o argumento `drop = FALSE` na função de escala relevante `scale_xxxx()`. Todos os níveis de fator serão exibidos, independentemente de estarem presentes nos dados. Se seus níveis de coluna de fator são exibidos usando `fill =`, então em scale_fill_discrete() você inclui `drop = FALSE`, conforme mostrado abaixo. Se seus níveis são exibidos com `x =` (para o eixo x), você deve fornecer `color =` ou `size =` para a função `scale_color_discrete()` ou para `scale_size_discrete()`, respectivamente.

Este exemplo é um gráfico de barras empilhadas das categorias por idade e por hospital. Adicionar `scale_fill_discrete(drop = FALSE)` garante que todas as faixas etárias apareçam na legenda, mesmo se não estiverem presentes nos dados.

```{r}
ggplot(data = linelist)+
  geom_bar(mapping = aes(x = hospital, fill = age_cat)) +
  scale_fill_discrete(drop = FALSE)+                        # mostra todos os grupos de idade na legenda, mesmo aqueles não presentes
  labs(
    title = "Todas as faixas etárias aparecerão na legenda, mesmo se não estiverem presentes nos dados")
```

### Em tabelas {.unnumbered}

Ambas as funções `table()` do R **base** e `tabyl()` do **janitor** mostrarão todos os níveis de fator (mesmo os níveis não utilizados).

Se você usar `count()` ou `summarise()` do **dplyr** para fazer uma tabela, adicione o argumento `.drop = FALSE` para incluir contagens para todos os níveis do fator, mesmo aqueles não usados.

Leia mais na página [Tabelas descritivas](#tables-descriptive), ou no [documento do scale_discrete](https://ggplot2.tidyverse.org/reference/scale_discrete.html), ou na [documentação do count()](https://dplyr.tidyverse.org/reference/count.html). Você pode ver outro exemplo na página [Rastreamento de contatos](#contact-tracing).

## Epiweeks (semanas epidemiológicas)

Consulte a ampla discussão sobre como criar semanas epidemiológicas na página [Agrupamento de dados](#grouping).

Consulte também a página [Trabalhando com datas](#dates) para obter dicas sobre como criar e formatar semanas epidemiológicas.

### Epiweeks em um gráfico {.unnumbered}

Se seu objetivo é criar epiweeks para exibir em um gráfico, você pode fazer isso simplesmente com o pacote **lubridate** e função `floor_date()`, conforme explicado na página [Agrupamento de dados](#grouping). Os valores retornados serão da classe Data com formato AAAA-MM-DD. Se você usar esta coluna em um gráfico, as datas irão naturalmente ordenar corretamente, e você não precisa se preocupar com os níveis ou com a conversão para a classe Fator. Veja o histograma `ggplot()` das datas de início abaixo.

Nesta abordagem, você pode ajustar a *exibição* das datas em um eixo com `scale_x_date()`. Consulte a página em [Curvas epidêmicas](#epicurves) para obter mais informações. Você pode especificar um formato de exibição "strptime" para o argumento `date_labels =` da função `scale_x_date()`. Esses formatos usam marcadores "%" e são abordados na página [Trabalhando com datas](#dates). Use "% Y" para representar um ano de 4 dígitos e "% W" ou "% U" para representar o número da semana (semanas de segunda ou domingo, respectivamente).

```{r, warning=F, message=F}
linelist %>% 
  mutate(epiweek_date = floor_date(date_onset, "week")) %>%  # criando uma coluna de semanas
  ggplot()+                                                  # iniciando o ggplot
  geom_histogram(mapping = aes(x = epiweek_date))+           # histograma da data de início
  scale_x_date(date_labels = "%Y-W%W")                       # ajustar a exibição das datas para YYYY-WWw
```

### Epiweeks nos dados {.unnumbered}

No entanto, se o seu objetivo na transformação para fator *não é* gerar um gráfico, você pode abordar isso de duas maneiras:

1)  *Para um controle preciso sobre a exibição*, converta no **lubridate** a coluna epiweek (YYYY-MM-DD) para o formato de exibição desejado (YYYY-WWw) *dentro do próprio data frame* e, em seguida, converta-o para a classe Fator.

Primeiro, use `format()` do R **base** para converter a exibição de data de YYYY-MM-DD para YYYY-Www (consulte a página [Trabalhando com datas](#dates)). Neste processo, a classe será convertida em caractere. Em seguida, converta de caractere para classe Fator com `factor()`.

```{r}
linelist <- linelist %>% 
  mutate(epiweek_date = floor_date(date_onset, "week"),       # cria semanas epidemiológicas - epiweeks (YYYY-MM-DD)
         epiweek_formatted = format(epiweek_date, "%Y-W%W"),  # Converter para mostrar (YYYY-WWW)
         epiweek_formatted = factor(epiweek_formatted))       # Converter para fator

# Mostrar níveis
levels(linelist$epiweek_formatted)
```

[***PERIGO:*** Se você colocar as semanas à frente dos anos ("Www-YYYY") ("% W-% Y"), a ordem de nível alfanumérico padrão estará incorreta (por exemplo, 01-2015 estará antes de 35-2014) . Pode ser necessário ajustar manualmente a ordem, o que seria um processo longo e doloroso.]{style="color: red;"}

2)  *Para uma exibição padrão rápida*, use o pacote **aweek** e sua função `date2week()`. Você pode definir o dia do início da semana por `week_start =` e, se definir `factor = TRUE` a coluna de saída é um fator ordenado. Como bônus, o fator inclui níveis para *todas* as semanas possíveis no intervalo - mesmo se não houver casos naquela semana.

```{r, eval=F}
df <- linelist %>% 
  mutate(epiweek = date2week(date_onset, week_start = "Monday", factor = TRUE))

levels(df$epiweek)
```

Veja a página [Trabalhando com datas](#dates) para mais informações sobre **aweek**. O pacote também oferece a função reversa `week2date()`.

<!-- ======================================================= -->

## Recursos

R para a página de Ciência de Dados em [factors](https://r4ds.had.co.nz/factors.html)\
[vinheta do pacote aweek](https://cran.r-project.org/web/packages/aweek/vignettes/introduction.html)
```{r include=FALSE, cache=FALSE}

# clear workspace
rm(list = ls(all = TRUE))

# clear all packages except base
#lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))

# to ensure that tidyverse packages prevail
filter <- dplyr::filter
select <- dplyr::select
summarise <- dplyr::summarise
summary <- base::summary
incidence <- incidence2::incidence

#load core packages
pacman::p_load(
     rio,
     here,
     DT,
     stringr,
     lubridate,
     tidyverse
)

# import the cleaned ebola linelist
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

# import the count data - facility level
#count_data <- rio::import(here::here("data", "facility_count_data.rds"))

# Settings

options(scipen=1, digits=7)

# print only text (not code)
# library(knitr)
# opts_chunk$set(list(echo = FALSE, eval = FALSE))
```

<!--chapter:end:new_pages/factors.Rmd-->


<!-- ======================================================= -->
<!-- ======================================================= -->
<!-- ======================================================= -->
# Pivoteando dados {#pivoting}


```{r, warning=F, message=F, out.height = c('50%'), fig.align="center", fig.show='hold', echo=F}
knitr::include_graphics(here::here("images", "pivoting", "Pivoting_500x500.png"))

#knitr::include_graphics(here::here("images", "pivoting", "pivot_longer_new.png"))
#knitr::include_graphics(here::here("images", "pivoting", "pivot_bar.png"))
#knitr::include_graphics(here::here("images", "pivoting", "pivot_wider_new.png"))
```



Ao lidar com dados, *pivotar* (pivoting) pode ser entendido como um dos dois processos abaixo:

1. A criação de *tabelas dinâmicas* (pivot tables), que são tabelas com estatísticas que resumem os dados de um tabela maior.
2. A conversão de uma tabela do formato **longo** (long) para o formato **largo** (wide), ou vice-versa.

**Nessa página, iremos nos focar na segunda definição**. A primeira é um passo crucial em análise de dados que está coberto em outras partes do livro, nos capítulos de [Agrupamento de Dados](#grouping) e [Tabelas Descritivas](#tables-descriptive).

Essa página discute os formatos dos dados. É importante estar atento à ideia de "dados tidy" (tidy data), na qual cada varíavel tem sua própria coluna, cada observação tem sua própria linha e cada valor tem sua própria célula. Você pode ler mais sobre esse tópico online [em seu capítulo do livro R para Ciência de Dados (em inglês)](https://r4ds.had.co.nz/tidy-data.html). 





## Preparação 

### Carregue os pacotes R {.unnumbered}  

O código abaixo realiza o carregamento dos pacotes necessários para a análise dos dados. Neste manual, enfatizamos o uso da função `p_load()`, do **pacman**, que instala os pacotes, caso não estejam instalados, *e* os carrega no R para utilização. Também é possível carregar pacotes instalados utilizando a função `library()`, do R **base**. Para mais informações sobre os pacotes do R, veja a página [Introdução ao R](#basics).  

```{r}
pacman::p_load(
  rio,          # File import
  here,         # File locator
  kableExtra,   # Build and manipulate complex tables
  tidyverse)    # data management + ggplot2 graphics
```



### Importe os dados {.unnumbered}


### Dados de Malária {-}  

Nesta página, iremos utilizar um banco fictício de casos diários de malária, divididos por local e grupos de idade. Se você quiser acompanhar a análise, <a href='https://github.com/appliedepi/epirhandbook_eng/raw/master/data/malaria_facility_count_data.rds' class='download-button'>clique aqui para baixar (como arquivo `.rds` )<span></a>. Importe os dados com a função `import()` do pacote **rio**  (a função suporta vários tipos de arquivo como .xlsx, .csv, .rds - cheque a página [Importar e exportar](#importing) para mais detalhes).  

```{r, echo=F}
count_data <- rio::import(here::here("data", "malaria_facility_count_data.rds")) %>%
  as_tibble()
```

```{r, eval=F}
# Import data
count_data <- import("malaria_facility_count_data.rds")
```

As primeras 50 linhas são mostradas abaixo.

```{r, message=FALSE, echo=F}
# display the linelist data as a table
DT::datatable(head(count_data, 50), rownames = FALSE, options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```


### Casos da Linelist {-}  

Nas seções finais dessa página também iremos utilizar dados de uma epidemia simulada de Ebola. Se você quiser acompanhar, <a href='https://github.com/appliedepi/epirhandbook_eng/raw/master/data/case_linelists/linelist_cleaned.rds' class='download-button'>clique para baixar a linelist "limpa"</a> (como um arquivo .rds). Importe os dados com a função `import()` do pacote **rio**  (a função suporta vários tipos de arquivo como .xlsx, .csv, .rds - cheque a página [Importar e exportar](#importing) para mais detalhes).  
```{r, echo=F}
# import the linelist into R
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))
```


```{r, eval=F}
# import your dataset
linelist <- import("linelist_cleaned.xlsx")
```







<!-- ======================================================= -->
## Largo-para-longo {}

```{r, warning=F, message=F, echo=F}
knitr::include_graphics(here::here("images", "pivoting", "pivot_longer_new.png"))
```


<!-- ======================================================= -->
### Formato "Largo" (wide) {.unnumbered}

Os dados são normalmente inseridos e armazenados no formato "largo" (*wide*) - em que as características ou respostas dos sujeitos são acondicionadas em apenas uma linha. Embora possa ser útil para apresentação, esse formato não é ideal para alguns tipos de análises.

Vamos pegar como exemplo o banco `count_data` importado na seção de Preparação acima. Você pode ver que cada linha representa um "dia-local" (*facility-day*). As contagens propriamente ditas dos casos (colunas mais à direita) estão armazenadas em um formato "largo", de forma que as informações para todos os grupos de idade em cada "dia-local" estão armazenadas em apenas uma coluna. 

```{r, echo=F}
DT::datatable(count_data, rownames = FALSE, options = list(pageLength = 5, scrollX=T) )
```

Cada observação nesse banco refere-se às contagens dos casos de malária em um dos 65 locais, em uma referida data, que vai desde ` count_data$data_date %>% min()` até ` count_data$data_date %>% max()`. Esse locais estão divididos em uma Província - `Province` (North) e quatro Distritos - `District` (Spring, Bolo, Dingo, e Barnard). O banco disponibiliza as contagens gerais de malária, bem como contagens específicas por idade em cada um dos quatro grupos = <4 anos, 5-14 anos, e 15 anos ou mais.

Dados em formato "largo" (*wide*) como esse não aderem aos padrões de dados "tidy", pois os cabeçalhos das colunas não representam, de fato, "variáveis" - eles representam *valores* de uma varíavel hipotética "grupo de idade" (*age group*). 


Esse formato pode ser útil para apresentar informações em uma tabela, ou para inserção de dados provenientes de formulários (no Excel, por exemplo). No entanto, na fase de análise, os dados devem ser transformados para um formato mais "longo", alinhado com os padrões de dados "tidy". O pacote de gráficos **ggplot2**, inclusive, funciona melhor quando os dados estão no formato "longo". 

No formato atual, não há dificuldade alguma em visualizar o *total* de casos versus tempo:

```{r, warning=F, message=F}
ggplot(count_data) +
  geom_col(aes(x = data_date, y = malaria_tot), width = 1)
```

No entanto, e se quiséssemos mostrar as contribuições relativas de cada grupo de idade a esse total? Neste caso, precisaríamos nos assegurar de que as varíaveis de interesse (grupos de idade - *age group*) aparecessem no banco em apenas uma coluna que possa ser passada ao `{ggplot2}` através do argumento `aes()`.




<!-- ======================================================= -->
### `pivot_longer()` {.unnumbered}

A função `pivot_longer()` do **tidyr** torna os dados mais "longos" ("longer"). O pacote **tidyr** faz parte dos pacotes da família **tidyverse**.  

Essa função recebe como argumento um intervalo de colunas que serão transformadas (especificado no argumento `cols = `). Assim, ela pode operar em apenas um parte do banco. Isso é útil para os dados de malária, pois queremos pivotar apenas as colunas com a contagem dos casos.

Executando esse processo, você vai obter duas "novas" colunas - uma com as categorias (que antes eram os nomes das colunas), e uma outra com os valores correspondentes (os números de casos). Você pode aceitar os nomes padrão para essas novas colunas ou você pode especificar seus próprios nomes através dos argumentos `names_to = ` e `values_to = ` respectivamente.  

vamos ver `pivot_longer()` em ação... 



### Pivot padrão {.unnumbered}  

Queremos usar a função `pivot_longer()` do **tidyr** para converter os dados do formato "largo" (wide) para o formato "longo" (long). Especificamente, converter as quatro colunas numéricas com as contagens dos casos de malária em duas novas colunas: uma com os grupos de idade (*age groups*) e uma com os *valores* correspondentes.  

```{r, eval=F}
df_long <- count_data %>% 
  pivot_longer(
    cols = c(`malaria_rdt_0-4`, `malaria_rdt_5-14`, `malaria_rdt_15`, `malaria_tot`)
  )

df_long
```

perceba que o data frame recém criado (`df_long`) possui mais linhas (12,152 vs 3,038); ele tornou-se mais longo - *longer*. De fato, ele está precisamente quatro vezes mais longo, pois cada linha do banco original agora representa quatro linhas em df_long, uma para cada contagem das observações (<4 anos, 5-14 anos, 15 anos+ e total).

Além de mais longo, o novo banco também tem menos colunas (8 vs 10), uma vez que os dados que estavam armazenados nas quatro colunas (aquelas que começavam com o prefixo `malaria_`) passaram a ser armazenados em apenas duas.

Uma vez que os nomes de todas essas quatro colunas começam com o prefixo `malaria_`, poderíamos ter utilizado uma função muito útil para fazer "tidyselect" - com `starts_with()` poderíamos chegar no mesmo resultado (veja a página [Limpeza de dados e principais funções](#cleaning) para conhecer mais dessas funções de auxílio).  

```{r}
# provide column with a tidyselect helper function
count_data %>% 
  pivot_longer(
    cols = starts_with("malaria_")
  )
```

ou por posição: 

```{r, eval=F}
# provide columns by position
count_data %>% 
  pivot_longer(
    cols = 6:9
  )
```

ou por intervalo nomeado:

```{r, eval=F}
# provide range of consecutive columns
count_data %>% 
  pivot_longer(
    cols = `malaria_rdt_0-4`:malaria_tot
  )
```



As novas colunas recebem os nomes padrão de `name` e `value`, mas podemos sobrescrever esses padrões para fornecer nomes mais semânticos, que vão ajudar a lembrar o que representam, utilizando os argumentos `names_to` e `values_to`. Vamos utilizar os nomes `age_group` e `counts`:

```{r}
df_long <- 
  count_data %>% 
  pivot_longer(
    cols = starts_with("malaria_"),
    names_to = "age_group",
    values_to = "counts"
  )

df_long
```

Agora podemos passar essa nova base para o `{ggplot2}`, e mapear a nova coluna `count` para o eixo y e a nova coluna `age_group` para o argumento `fill = ` (a cor de preenchimento da barra). Isso vai mostrar as contagens em um gráfico de barras empilhadas, por grupo de idade:

```{r, warning=F, message=F}
ggplot(data = df_long) +
  geom_col(
    mapping = aes(x = data_date, y = counts, fill = age_group),
    width = 1
  )
```

Veja esse novo gráfico, e compare com o gráfico criado anteriormento - *o que deu errado?*

Encontramos um problema comum ao manipular dados de vigilância - acabamos incluindo também o número total de casos da coluna `malaria_tot`, o que fez com que a altura de cada barra no gráfico fosse o dobro do que deveria.

Podemos lidar com isso de algumas formas. Podemos simplesmente filtrar esses totais da base antes de passá-la para o `ggplot()`:

```{r, warning=F, message=F}
df_long %>% 
  filter(age_group != "malaria_tot") %>% 
  ggplot() +
  geom_col(
    aes(x = data_date, y = counts, fill = age_group),
    width = 1
  )
```

Ou então, poderíamos ter excluído essa variável quando rodamos `pivot_longer()`, mantendo-na assim como uma variável separada na base de dados. Veja como os valores dela se "expandem" para preencher as novas linhas.

```{r, warning=F, message=F}
count_data %>% 
  pivot_longer(
    cols = `malaria_rdt_0-4`:malaria_rdt_15,   # does not include the totals column
    names_to = "age_group",
    values_to = "counts"
  )
```





### Pivoteando dados de múltiplas classes {.unnumbered}

O exemplo acima funciona bem em situações em que todas as colunas que você quer pivotar para o formato "longo" são da mesma classe (caracter, numérico, lógico, etc...) 

Porém, haverá muitos casos em que, como epidemiologista de campo, você estará trabalhando com dados que foram preparados por não-especialistas e que seguem suas próprias lógicas não padronizadas - como Hadley Wickham citou (em referência a Tolstoy) em seu [artigo seminal](https://vita.had.co.nz/papers/tidy-data.pdf) sobre os princípios de **Tidy Data**: *"Like families, tidy datasets are all alike but every messy dataset is messy in its own way."* (Como famílias, bases de dados tidy são todas parecidas mas todas as bases bagunçadas são bagunçadas à sua maneira.)

Um problema particularmente comum que você vai encontrar será a necessidade de pivotar colunas que possuem diferentes classes de dados. Essa pivotagem vai resultar no armazenamento desses diferentes tipos em uma única coluna, o que não é uma situação ideal. Existem várias abordagens possíveis para separar a bagunça que isso gera, mas existe um passo importante que você pode dar utilizando `pivot_longer()` para evitar cair nessa situação.

Vamos analisar a situação em que há uma série de observações em diferentes intervalos de tempo para cada um dos itens A, B e C. Exemplos desses itens podem ser indivíduos (ex: contatos de caso de Ebola sendo monitorados por 21 dias) ou postos de saúde de vilarejos remotos sendo monitorados uma vez por ano para assegurar que ainda funcionam. Vamos utilizar o exemplo do contato com o caso de Ebola. Imagine os dados armazenados da seguinte forma:


```{r, message=FALSE, echo=F}

df <- 
  tibble::tribble(
     ~id,   ~obs1_date, ~obs1_status,   ~obs2_date, ~obs2_status,   ~obs3_date, ~obs3_status,
     "A", "2021-04-23",    "Healthy", "2021-04-24",    "Healthy", "2021-04-25",     "Unwell",
     "B", "2021-04-23",    "Healthy", "2021-04-24",    "Healthy", "2021-04-25",    "Healthy",
     "C", "2021-04-23",    "Missing", "2021-04-24",    "Healthy", "2021-04-25",    "Healthy"
     ) 

DT::datatable(df, rownames = FALSE)

```

Como pode ser observado, os dados são um pouco complicados. Cada linha armazena informação sobre um item, mas com a série temporal avançando mais e mais para a direita à medida que o tempo passa. Além disso, a classe das colunas alternam entre valores de data e caracteres.

Um exemplo particularmente ruim encontrado por este autor envolvia dados de vigilância do cólera, no qual 8 novas colunas de observação eram adicionadas à base *por dia* ao longo de __4 anos__. Só para abrir o arquivo de Excel em que esses dados estavam levava mais de 10 minutos no meu laptop!

Para trabalhar com esses dados, precisamos transformar o data frame para o formato longo, mas mantendo a separação entre as colunas no formato `date` e `character` (status), para cada observação e cada item. Se não o fizermos, podemos acabar com uma mistura de tipos de variáveis na mesma coluna (um "sacrilégio" quando se trata de gerenciamento de dados e dados "tidy"):

```{r}
df %>% 
  pivot_longer(
    cols = -id,
    names_to = c("observation")
  )

```

Acima, nosso pivot mesclou *datas* e *caracteres* em apenas uma coluna `value`. R reagirá convertendo a coluna inteira para a classe de caracteres e assim, a utilidade das datas será perdida.

Para evitar essa situação, podemos aproveitar a sintaxe da estrutura original do nome das colunas. Existe uma estrutura comum nos nomes, com o número da observação, um underline e depois a palavra "status" ou "date". Podemos utilizar essa sintaxe para manter esses dois tipos de dados em colunas separadas após o pivot. 

Fazemos isso através de: 

* Fornecimento de um vetor de caracteres para o argumento `names_to = `, com o segundo item sendo (`".value"` ). Esse termo especial indica que as colunas pivotadas vão ser divididas baseadas em um caracter presente em seus nomes...  
* Você também precisa fornecer o caracter "separador" para o argumento `names_sep = `. Nesse caso, é o underline "_".  

Assim, o nome e a separação das novas colunas são baseados nos termos "em volta" do underline nos nomes das variáveis existentes. 

```{r}

df_long <- df %>% 
  pivot_longer(
    cols = -id,
    names_to = c("observation", ".value"),
    names_sep = "_"
  )

df_long

```

__Toques finais__:

Note que a coluna `date` está atualmente com a classe *caractere* - nós podemos convertê-la facilmente em sua classe apropriada utilizando as funções `mutate()` e `as_date()` descritas na página [Trabalhando com datas](#dates).  

Também podemos converter a coluna `observation` para o formato `numeric` removendo o prefixo "obs" e convertendo para numérico. Podemos fazer isso com a função `str_remove_all()` do pacote **stringr** (veja a página [Caracteres and strings](#characters-strings)).  

```{r}

df_long <- df_long %>% 
  mutate(
    date = date %>% lubridate::as_date(),
    observation = 
      observation %>% 
      str_remove_all("obs") %>% 
      as.numeric()
  )

df_long

```

E agora, podemos começar a trabalhar com os dados nesse formato. Ex: criando um de mapa de calor descritivo:

```{r}
ggplot(data = df_long, mapping = aes(x = date, y = id, fill = status)) +
  geom_tile(colour = "black") +
  scale_fill_manual(
    values = 
      c("Healthy" = "lightgreen", 
        "Unwell" = "red", 
        "Missing" = "orange")
  )

```





<!-- ======================================================= -->
## Longo-para-largo {}

```{r, warning=F, message=F, echo=F}
knitr::include_graphics(here::here("images", "pivoting", "pivot_wider_new.png"))
```


Em algumas instâncias, pode ser necessário converter uma base para o formato mais largo (wide) utilizando a função `pivot_wider()`.

Um caso de uso típico é quando queremos transformar o resultado de uma análise em um formato mais "palatável" ao leitor (tal como em [Tabelas para apresentação](#tables-presentation)). Normalmente, isso envolve transformar uma base em que a informação para um sujeito está espalhada em múltiplas linhas em um formato em que aquela informação esteja armazenada em apenas uma.

### Dados {.unnumbered}

Para essa seção da página, vamos utilizar o caso da linelist (veja a seção de [Preparação](#pivot_prep)), que contém uma linha por caso.  

Aqui estão as primeiras 50 linhas:

```{r, message=FALSE, echo=F}
# display the linelist data as a table
DT::datatable(head(linelist, 50), rownames = FALSE, options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```


Suponha que a gente queira saber a contagem dos indivíduos nos diferentes grupos de idade, por gênero:

```{r}
df_wide <- 
  linelist %>% 
  count(age_cat, gender)

df_wide
```

Isso vai produzir uma base longa que é ótima para fazer visualizações no **ggplot2**, mas não é ideal para apresentar em uma tabela:

```{r}
ggplot(df_wide) +
  geom_col(aes(x = age_cat, y = n, fill = gender))
```

### Pivot wider {.unnumbered}  

Desta forma, podemos utilizar `pivot_wider()` para transformar os dados em um formato melhor para inclusão nas tabelas de nossos relatórios.

O argumento `names_from` especifica a coluna *a partir da qual* serão gerados os nomes da nova coluna *names*, enquanto o argumento `values_from` especifica a coluna *a partir da qual* serão retirados os valores da coluna *values* que vão popular as células. O argumento `id_cols = ` é opcional, mas pode ser utilizado passando um vetor de nomes de colunas que não deverão ser pivotadas, e assim irá identificar cada linha.

```{r}
table_wide <- 
  df_wide %>% 
  pivot_wider(
    id_cols = age_cat,
    names_from = gender,
    values_from = n
  )

table_wide
```

Essa tabela é muito mais legível e assim, melhor para utilização em relatórios. Você pode convertê-la em tabelas elegantes e bonitas utilizando vários pacotes, incluindo **flextable** e **knitr**. Esse processo é elaborado na página [Tabelas para apresentação](#tables-presentation).  

```{r}
table_wide %>% 
  janitor::adorn_totals(c("row", "col")) %>% # adds row and column totals
  knitr::kable() %>% 
  kableExtra::row_spec(row = 10, bold = TRUE) %>% 
  kableExtra::column_spec(column = 5, bold = TRUE) 
```

---


<!-- ======================================================= -->
## Preenchimento

Em algumas situações após um `pivot`, e mais frequentemente após um `bind`, acabamos ficando com algumas células vazias que gostaríamos de preencher.  

<!-- ======================================================= -->
### Dados {.unnumbered}

Por exemplo, pegue duas bases, cada uma com observações para o número da medição, o nome do local e a contagem de casos naquele momento. No entanto, a segunda base também possui a variável `Year`. 


```{r}
df1 <- 
  tibble::tribble(
       ~Measurement, ~Facility, ~Cases,
                  1,  "Hosp 1",     66,
                  2,  "Hosp 1",     26,
                  3,  "Hosp 1",      8,
                  1,  "Hosp 2",     71,
                  2,  "Hosp 2",     62,
                  3,  "Hosp 2",     70,
                  1,  "Hosp 3",     47,
                  2,  "Hosp 3",     70,
                  3,  "Hosp 3",     38,
       )

df1 

df2 <- 
  tibble::tribble(
    ~Year, ~Measurement, ~Facility, ~Cases,
     2000,            1,  "Hosp 4",     82,
     2001,            2,  "Hosp 4",     87,
     2002,            3,  "Hosp 4",     46
  )

df2
```


Quando fazemos um `bind_rows()` para mesclar as bases, a variável `Year` será preenchida com `NA` para aquelas linhas em que não existia nenhuma informação prévia (ex: na primeira base):


```{r}
df_combined <- 
  bind_rows(df1, df2) %>% 
  arrange(Measurement, Facility)

df_combined

```

<!-- ======================================================= -->
### `fill()` {.unnumbered}

Nesse caso, `Year` é uma variável útil para ser incluída, particularmente se quisermos explorar as tendências ao longo do tempo. Por isso, utilizamos `fill()` para *preencher* as células vazias, especificando a coluna a ser preenchida e a direção (nesse caso, **acima**):

```{r}
df_combined %>% 
  fill(Year, .direction = "up")
```

Ou então, podemos rearranjar os dados para que possamos preencher na direção descendente:

```{r}
df_combined <- 
  df_combined %>% 
  arrange(Measurement, desc(Facility))

df_combined

df_combined <- 
  df_combined %>% 
  fill(Year, .direction = "down")

df_combined
```

Agora temos uma base útil para fazer um gráfico:

```{r}
ggplot(df_combined) +
  aes(Year, Cases, fill = Facility) +
  geom_col()
```

Mas menos útil para apresentar em uma tabela, então vamos praticar e converter esse dataframe longo e não "tidy" em um dataframe largo (wide) e "tidy":

```{r}
df_combined %>% 
  pivot_wider(
    id_cols = c(Measurement, Facility),
    names_from = "Year",
    values_from = "Cases"
  ) %>% 
  arrange(Facility) %>% 
  janitor::adorn_totals(c("row", "col")) %>% 
  knitr::kable() %>% 
  kableExtra::row_spec(row = 5, bold = TRUE) %>% 
  kableExtra::column_spec(column = 5, bold = TRUE) 
```

Obs: Nesse caso, foi necessário especificar para incluir apenas as três variáveis `Facility`, `Year`, e `Cases` pois a outra variável `Measurement` iria interferir com a criação da tabela:

```{r}
df_combined %>% 
  pivot_wider(
    names_from = "Year",
    values_from = "Cases"
  ) %>% 
  knitr::kable()
```

## Recursos  

Aqui tem um [tutorial](https://datacarpentry.org/r-socialsci/03-dplyr-tidyr/index.html) útil.  

```{r include=FALSE, cache=FALSE}

# clear workspace
rm(list = ls(all = TRUE))

# clear all packages except base
#lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))

# to ensure that tidyverse packages prevail
filter <- dplyr::filter
select <- dplyr::select
summarise <- dplyr::summarise
summary <- base::summary
incidence <- incidence2::incidence

#load core packages
pacman::p_load(
     rio,
     here,
     DT,
     stringr,
     lubridate,
     tidyverse
)

# import the cleaned ebola linelist
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

# import the count data - facility level
#count_data <- rio::import(here::here("data", "facility_count_data.rds"))

# Settings

options(scipen=1, digits=7)

# print only text (not code)
# library(knitr)
# opts_chunk$set(list(echo = FALSE, eval = FALSE))
```

<!--chapter:end:new_pages/pivoting.Rmd-->


# Agrupando dados {#grouping}  


```{r, out.width=c('100%'), echo=F, message=F}
knitr::include_graphics(here::here("images", "Grouping_1500x500.png"))
```


Esta página cobre como agrupar e agregar dados para análise descritiva. Ela faz uso da família de pacotes **tidyverse** que tem funções comuns e fáceis de usar. 


O agrupamento de dados é um componente central do gerenciamento e análise de dados. Os dados agrupados estatisticamente resumidos por grupo e que podem ser traçados por grupo em um gráfico. As funções do pacote **dplyr** (parte do **tidyverse**) tornam o agrupamento e as operações subseqüentes bastante fáceis.  


Esta página abordará os seguintes tópicos:  

* Agrupar dados com a função `group_by()`.  
* Dados desagrupados 
* `summarise()`dados agrupados com estatísticas  
* A diferença entre `count()` e `tally()`  
* 'arrange()`aplicado a dados agrupados  
* `filter()` aplicado aos dados agrupados  
* mutate()`aplicado a dados agrupados  
* select()` aplicado aos dados agrupados  
O comando do R **base** `aggregate()` como alternativa  

<!-- ======================================================= -->
## Preparação {  }
     
### Carregar pacotes {.unnumbered}  
     
Este trecho de código mostra o carregamento dos pacotes necessários para as análises. Neste manual, enfatizamos `p_load()` de **pacman**, que instala o pacote se necessário *e* o carrega para utilização. Você também pode carregar os pacotes instalados com `library()` do R **base**. Veja a página em [Introdução ao R](#basics) para mais informações sobre os pacotes R. 

```{r}
pacman::p_load(
  rio,       # para importar os dados
  here,      # localizar pacotes
  tidyverse, # limpar, manipular, e visualizar os dados (inlcui dplyr)
  janitor)   # adicionar totais às linhas e colunas 
```




### Importar datos {.unnumbered}

Nós importamos os dados de casos de uma epidemia simulada de Ebola. Se você quiser acompanhar, <a href='https://github.com/appliedepi/epirhandbook_eng/raw/master/data/case_linelists/linelist_cleaned.rds' class='download-button'> clique para baixar o linelist "limpo" </a> (as .rds file). O conjunto de dados é importado utilizando a função `import()` do pacote **rio**. Veja a página em [Importar e exportar](#importing) para várias formas de importação de dados.

```{r, echo=F}
linelist <- rio::import(here("data", "case_linelists", "linelist_cleaned.rds"))
```

```{r, eval=F}
linelist <- import("linelist_cleaned.rds")
```


As primeiras 50 linhas da `linelist`:  

```{r message=FALSE, echo=F}
DT::datatable(head(linelist,50), rownames = FALSE, filter="top", options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```



<!-- ======================================================= -->
## Agrupando os dados {  }
     
A função `group_by()` de **dplyr** agrupa as linhas pelos valores únicos na coluna especificada para ela. Se várias colunas forem especificadas, as linhas são agrupadas pelas combinações únicas de valores através das colunas. Cada valor único (ou combinação de valores) constitui um grupo. Alterações subseqüentes no conjunto de dados ou cálculos podem então ser realizadas dentro do contexto de cada grupo.  

Por exemplo, o comando abaixo toma a "linelist" e agrupa as linhas por valores únicos na coluna "outcome", salvando a saída como uma nova tabela de dados (*dataframe*) chamada "ll_by_outcome". A(s) coluna(s) de agrupamento são colocadas dentro dos parênteses da função `group_by()` 

```{r}
ll_by_outcome <- linelist %>% 
  group_by(outcome)
```

**Note que não há nenhuma mudança perceptível no conjunto de dados** após executar `group_by()`, *até* outra função do **dplyr** tal como `mutate()`, `summarise()`, ou `arrange()` ser aplicada no *dataframe* "grouped".  

Você pode, no entanto, "ver" os agrupamentos imprimindo o quadro de dados. Ao imprimir um quadro de dados agrupados, você verá que ele foi transformado em um objeto de classe [`tibble` (https://tibble.tidyverse.org/) que, quando impresso, mostra quais agrupamentos foram aplicados e quantos grupos existem - escritos logo acima da linha do cabeçalho.  

```{r}
# visualizar quais grupos estão ativvos
ll_by_outcome
```


### Grupos únicos {.unnumbered}  

**Os grupos criados refletem cada combinação única de valores através das colunas de agrupamento.** 

Para ver os grupos *e o número de linhas em cada grupo*, passe os dados agrupados para `tally()`. Para ver apenas os grupos únicos sem conta, você pode passar para `group_keys()`.  

Veja abaixo que existem **três** valores únicos na coluna de agrupamento `outcome` (desfecho, em português): "Death" (óbito), "Recover" (Recuperado), e `NA`. Veja que existem ` nrow(linelist %>% filter(outcome == "Death"))` óbitos, ` nrow(linelist %>% filter(outcome == "Recover"))` recuperações, e ` nrow(linelist %>% filter(is.na(outcome)))` sem nenhum resultado registrado.

```{r}
linelist %>% 
  group_by(outcome) %>% 
  tally()
```

Você pode agrupar por mais de uma coluna. Abaixo, o *dataframe* é agrupado por 'outcome' e 'gender', e depois contada. Observe como cada combinação única de "outcome" e "gender" é registrada como seu próprio grupo - incluindo valores ausentes para cada coluna.   

```{r}
linelist %>% 
  group_by(outcome, gender) %>% 
  tally()
```

### Novas colunas {.unnumbered} 

Você também pode criar uma nova coluna de agrupamento *dentro* da função `group_by()`. Isto equivale a chamar a função`mutate()` antes da instrução `group_by()`. Para uma tabulação rápida, este estilo pode ser útil, mas para maior clareza em seu código, considere criar esta coluna em seu próprio passo `mutate()` e depois encadear (usando o "pipe" %>%)  com o `group_by()`.

```{r}
# agrupar dados baseado em uma coluna biária criada dentro do próprio comando group_by  
linelist %>% 
  group_by(
    age_class = ifelse(age >= 18, "adult", "child")) %>% 
  tally(sort = T)
```

### Adicionar/Eliminar colunas de agrupamento {.unnumbered}  

Por padrão, se você executar `group_by()` em dados que já estão agrupados, os grupos antigos serão removidos e o(s) novo(s) grupo(s) será(ão) aplicado(s). Se você quiser adicionar novos grupos aos já existentes, inclua o argumento `.add = TRUE'.  

```{r, eval=F}
# Agrupado por 'outcome' (desfecho)
by_outcome <- linelist %>% 
  group_by(outcome)

# Adicionar um agrupamento por 'gender' (sexo) 
by_outcome_gender <- by_outcome %>% 
  group_by(gender, .add = TRUE)
```


**Manter todos os grupos**  

Se você agrupar em uma coluna do tipo fator, pode haver níveis do fator que não estão presentes atualmente nos dados. Se você agrupar nesta coluna, por padrão esses níveis não presentes são descartados e não incluídos como grupos. Para alterar isso para que todos os níveis apareçam como grupos (mesmo que não estejam presentes nos dados), defina `.drop = FALSE' em seu comando `group_by()`.    


## Desagrupar 

Os dados que foram agrupados permanecerão agrupados até que especificamente não sejam agrupados através do `ungroup()`. Se você se esquecer de desagradar, isso pode levar a cálculos incorretos! Abaixo está um exemplo de remoção de todos os agrupamentos:  

```{r, eval=F}
linelist %>% 
  group_by(outcome, gender) %>% 
  tally() %>% 
  ungroup()
```

Você também pode remover o agrupamento apenas para colunas específicas, colocando o nome da coluna dentro de `ungroup()`.  

```{r, eval=F}
linelist %>% 
  group_by(outcome, gender) %>% 
  tally() %>% 
  ungroup(gender) # remove o agrupamento por `gender` (sexo), mantendo o agrupamento por `outcome` (desfecho) 
```


<span style="color: black;">**_NOTA:_** O verbo `count()` desagrupa os dados automaticamente após a contagem.</span>


## Resumir os dados (Summarise) {#group_summarise} 

Consulte a seção **dplyr** da página [Tabelas descritivas](#tables-descriptive) para obter uma descrição detalhada de como produzir tabelas resumidas com `summarise()`. Aqui abordamos brevemente como seu comportamento muda quando aplicado a dados agrupados.  

A função **dplyr** `summarise()` (ou `summarize()`) pega um dataframe e o converte em um *novo* dataframe resumido, com colunas contendo as estatísticas resumidas que você definiu. Em dataframe não agrupados, as estatísticas resumidas serão calculadas a partir de todas as linhas. A aplicação de `summarise()` aos dados agrupados produz estas estatísticas resumidas *para cada grupo*.  

A sintaxe de `summarise()` é tal que você fornece o(s) nome(s) da(s) **nova(s)** coluna(s) resumo, um sinal de igual, e então uma função estatística a ser aplicada aos dados, como mostrado abaixo. Por exemplo, `min()`, `max()`, `median()`, ou `sd()`. Dentro da função estatística, liste a coluna a ser operada e qualquer argumento relevante (por exemplo, `na.rm = TRUE`). Você pode utilizar `sum()` para contar o número de linhas que satisfazem um critério lógico (com duplo igual a `==``).   

Abaixo está um exemplo de `summarise()` aplicado *em dados não-agrupados*. As estatísticas resultantes são produzidas a partir de todo o conjunto de dados. 

```{r}
# estatísticas resumo na linelist desagrupada 
linelist %>% 
  summarise(
    n_cases  = n(),
    mean_age = mean(age_years, na.rm=T),
    max_age  = max(age_years, na.rm=T),
    min_age  = min(age_years, na.rm=T),
    n_males  = sum(gender == "m", na.rm=T))
```

Em contraste, abaixo está a mesma declaração `summarise()` aplicada aos dados agrupados. As estatísticas são calculadas para cada grupo de "outcome" (desfecho). Observe como as colunas de agrupamento serão transportadas para o dataframe.   

```{r}
# statísticas resumo na linelist agrupada 
linelist %>% 
  group_by(outcome) %>% 
  summarise(
    n_cases  = n(),
    mean_age = mean(age_years, na.rm=T),
    max_age  = max(age_years, na.rm=T),
    min_age  = min(age_years, na.rm=T),
    n_males    = sum(gender == "m", na.rm=T))
```

<span style="color: darkgreen;">**_DICA:_** A função `summarise` funciona com a ortografia britânica e americana - `summarise()` e `summarize()` chamam a mesma função.</span>


## Contagens

As funções `count()` e `tally()` tem funcionalidade semelhante mas são diferentes. Leia mais sobre a distinção entre `tally()` e `count()` [here](https://dplyr.tidyverse.org/reference/tally.html)    

### `tally()` {.unnumbered}  

`tally()` é um atalho para `summarise(n = n())`, e *não* agrupa os dados. Assim, para ter `tallys` (contagens) agrupadas, esta função deve ser precedida de um comando `group_by()`. Você pode adicionar `sort = TRUE` para ver os grupos maiores primeiro.    

```{r}
linelist %>% 
  tally()
```


```{r}
linelist %>% 
  group_by(outcome) %>% 
  tally(sort = TRUE)
```


### `count()`  {.unnumbered}  

Por outro lado, `count()` faz o seguinte:  

1) aplica `group_by()` nas colunas especificadas  
2) aplica `summarise()` e retorna a coluna `n` com o número de linhas por grupo
3) aplica `ungroup()`  

```{r}
linelist %>% 
  count(outcome)
```

Assim como em  `group_by()` você pode adicionar uma nova coluna dentro do comando `count()`:  

```{r}
linelist %>% 
  count(age_class = ifelse(age >= 18, "adult", "child"), sort = T)
```


O comando`count()` pode ser chamado várias vezes, com a funcionalidade "rolling-up" (rolando para cima). Por exemplo, para resumir o número de hospitais presentes para cada sexo, execute o seguinte. Nota, o nome da coluna final é alterado do padrão "n" para maior clareza (com `name = `).   

```{r}
linelist %>% 
  # produz contagens para grupos únicos de  "outcome-gender" groups
  count(gender, hospital) %>% 
  # junta lingas por `gender` (3) e conta a quantidade de hospitais por gênero (6)
  count(gender, name = "hospitals per gender" ) 
```


### Adicionar contagens {.unnumbered}  

Em contraste com `count()` e `summarise()`, você pode utilizar `add_count()` para *adicionar* uma nova coluna `n` com a contagem de linhas por grupo *enquanto mantém todas as outras colunas do dataframe*.   

Isto significa que o número de contagem de um grupo, na nova coluna `n`, será impresso em cada linha do grupo. Para fins de demonstração, adicionamos esta coluna e depois reorganizamos as colunas para facilitar a visualização. Veja a seção abaixo em [filtro no tamanho do grupo](#group_filter_grp_size) para outro exemplo.  


```{r}
linelist %>% 
  as_tibble() %>%                   # converte para "tibble" para melhro vizualização
  add_count(hospital) %>%           # adiciona coluna n com as contages por hospital 
  select(hospital, n, everything()) # re-organiza para o propósito desta demostração
```



### Adicionar totais {.unnumbered} 

Para adicionar facilmente uma linhas ou colunas com os *total* ou colunas após utilizar `tally()` ou `count()`, veja a seção **janitor** da página [Tabelas descritivas](#tbl_janitor). Este pacote oferece funções como `adorn_totals()` e `adorn_percentagens()` para adicionar totais e converter para mostrar porcentagens. Abaixo está um breve exemplo:   

```{r}
linelist %>%                                  # caso linelist
  tabyl(age_cat, gender) %>%                  # tabela cruzada para duas colinas
  adorn_totals(where = "row") %>%             # adiciona uma linha de totais
  adorn_percentages(denominator = "col") %>%  # converte para proporções com a coluna `denominator`
  adorn_pct_formatting() %>%                  # converte proporções para porcentagens
  adorn_ns(position = "front") %>%            # mostrar como: "count (percent)"
  adorn_title(                                # ajustar título
    row_name = "Age Category",
    col_name = "Gender")
```

Para adicionar linhas de totais mais complexas que envolvam estatísticas resumidas diferentes de *somas*, ver [esta seção da página Tabelas Descritivas](#tbl_dplyr_totals). 

## Agrupoando por data

Ao agrupar os dados por data, você deve ter (ou criar) uma coluna para a unidade de data de interesse - por exemplo "dia", "epiweek", "mês", etc. Você pode fazer esta coluna utilizando `floor_date()` from **lubridate**, como explicado na seção [Semanas Epidemiológicas](#dates_epi_wks) da página [Trabalhando com datas](#dates). Uma vez que você tenha esta coluna, você pode utilizar `count()` from **dplyr*** para agrupar as linhas por esses valores de data únicos e obter contagens agregadas. 

Uma etapa adicional comum para situações de datas, é "preencher" quaisquer datas na seqüência que não estejam presentes nos dados. Utilize `complete()` do **tidyr*** para que a série de datas agregadas seja *completa* incluindo *todas as unidades de data possíveis* dentro do intervalo. Sem esta etapa, uma semana sem casos reportados pode não aparecer em seus dados!  

Dentro de `complete()` você *define* sua coluna de datas como uma *seqüência* de datas `seq.Date()` do mínimo para o máximo - assim, as datas são expandidas. Por padrão, os valores de contagem de casos em qualquer nova linha "expandida" serão `NA`. Você pode defini-los como 0 utilizando o `fill = ` argumento de `complete()`, que espera uma lista nomeada (se sua coluna de contagem for chamada `n`, forneça `fill = lista(n = 0)`. Veja `?complete' para detalhes e a página [Trabalhando com datas](#dates_epi_wks) para um exemplo.  


### Os casos da Linelist em dias  {.unnumbered}  

Aqui está um exemplo de agrupamento de casos em dias *sem* utilizar a função `complete()`. Observe que as primeiras linhas saltam as datas sem casos.  

```{r}
daily_counts <- linelist %>% 
  drop_na(date_onset) %>%        # remove casos que faltam date_onset
  count(date_onset)              # conta o número de linhas poro data única 
```

```{r message=FALSE, echo=F}
DT::datatable(daily_counts, rownames = FALSE, options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```

Abaixo nós adicionamos o comando `complete()` para assegurar que todos os dias estão representados.

```{r, eval=F}
daily_counts <- linelist %>% 
  drop_na(date_onset) %>%                 # remove casos em que faltam date_onset
  count(date_onset) %>%                   # conta o número de linhas poro data única
  complete(                               # assegura que todos os dias aparecem 
    date_onset = seq.Date(                # re-define a coluna data como uma sequencia diária
      from = min(date_onset, na.rm=T), 
      to = max(date_onset, na.rm=T),
      by = "day"),
    fill = list(n = 0))                   # configura as linhas adicionadas para apresentar 0 e na coluna n  (não NAcomo no padrão) 
```

```{r message=FALSE, echo=F}
DT::datatable(daily_counts, rownames = FALSE, options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```

### Casos Linelist em semanas {.unnumbered}  

O mesmo princípio pode ser aplicado durante semanas. Primeiro cria-se uma nova coluna que é a semana do caso utilizando `floor_date()` com `unit = "semana" `. Em seguida, utilize `count()` como acima para obter contagens semanais de casos. Termine com `complete()` para garantir que todas as semanas sejam representadas, mesmo que não contenham casos.

```{r}
# Mostrar dados por contagens semanais
weekly_counts <- linelist %>% 
  drop_na(date_onset) %>%                 # remove casos em que está faltando date_onset
  mutate(week = lubridate::floor_date(date_onset, unit = "week")) %>%  # nova coluna com a data 
  count(week) %>%                         #  agrupa dados por semana e conta 
  complete(                               # assegura que todos as semanas aparencem 
    week = seq.Date(                      # redefine a coluna data como uma sequência completa
      from = min(week, na.rm=T), 
      to = max(week, na.rm=T),
      by = "week"),
    fill = list(n = 0))                   # configura as linhas adicionadas para apresentar 0 e na coluna n  (não NAcomo no padrão) 
```

Aqui estão as 50 primeiras linhas do dataframe resultante:  

```{r message=FALSE, echo=F}
DT::datatable(weekly_counts, rownames = FALSE, options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```

### Casos da Linelist em meses {.unnumbered}

Para agregar os casos em meses, novamente utilize `floor_date()` do pacote **lubridate**, mas com o argumento `unit = "meses" `. Isto arredonda cada data até o dia 1 de seu mês. A saída será classe Data. Observe que no passo `complete()` também utilizamos `by = "meses"`.


```{r}
# Mostrar dados para contagens mensais
monthly_counts <- linelist %>% 
  drop_na(date_onset) %>% 
  mutate(month = lubridate::floor_date(date_onset, unit = "months")) %>%  # nova colua com o 1 mês do `onset` 
  count(month) %>%                          # conta casos por mês
  complete(
    month = seq.Date(
      min(month, na.rm=T),     # inclui todos os meses mesmo os sem casos reportados 
      max(month, na.rm=T),
      by="month"),
    fill = list(n = 0))
```

```{r message=FALSE, echo=F}
DT::datatable(monthly_counts, rownames = FALSE, options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```


### Contagens diárias em semanas {.unnumbered}

Para agregar as contagens diárias em contagens semanais, utilize `floor_date()` como acima. Entretanto, utilize `group_by()` e `summarize()` em vez de `count()` porque você precisa `sum()` contar casos diários em vez de apenas contar o número de filas por semana.


#### Contagens diárias em meses {.unnumbered}

Para agregar as contagens diárias em contagens de meses, utilize `floor_date()` com `unit = "month"` (mês) como acima. Entretanto, utilize `group_by()` e `summarize()` em vez de `count()` porque você precisa `sum()` contar casos diários em vez de apenas contar o número de filas por mês.    


## Organizando dados agrupados

Utilizando o verbo `arrange()`do **dplyr** para ordenar as linhas em um quadro de dados se comporta da mesma forma quando os dados são agrupados, *a menos que* você defina o argumento `.by_group =TRUE`. Neste caso, as linhas são ordenadas primeiro pelas colunas de agrupamento e depois por quaisquer outras colunas que você especificar para `arrange()`.   


## Filtrando dados agrupados

### `filter()` {.unnumbered}

Quando aplicadas em conjunto com funções que avaliam o dataframe (como `max()`, `min()`, `mean()`), estas funções serão agora aplicadas aos grupos. Por exemplo, se você quiser filtrar e manter linhas onde os pacientes estão acima da mediana de idade, isto agora será aplicado por grupo - filtrando para manter linhas acima da mediana de idade do *grupo*.   


### Linhas de corte por grupo {.unnumbered} 

A função `slice()` (literalmente: fatiar) do pacote **dplyr** , que [filtra linhas com base em sua posição](https://dplyr.tidyverse.org/reference/slice.html) nos dados, também pode ser aplicada por grupo. Lembre-se de levar em conta a ordenação dos dados dentro de cada grupo para obter a "fatia" desejada.  

Por exemplo, para recuperar apenas as últimas 5 admissões de cada hospital:  

1) Agrupar a lineliste por coluna "hospital".  
2) Organizar os registros da mais recente à mais antiga `date_hospitalisation` (data de hospitalização) *em cada grupo hospitalar*.  
3) Divide para recuperar as 5 primeiras fileiras de cada hospital  

```{r,}
linelist %>%
  group_by(hospital) %>%
  arrange(hospital, date_hospitalisation) %>%
  slice_head(n = 5) %>% 
  arrange(hospital) %>%                            # para visualizar
  select(case_id, hospital, date_hospitalisation)  # para visualizar
```

`slice_head()` - selecciona n linhas do topo  
`slice_tail()` - selecciona n linhas do final 
`slice_sample()` - seleciona aleatoriamente n linhas 
`slice_min()` - seleciona n linhas com os valores mais altos da coluna `order_by = `, use `with_ties = TRUE` para manter os vínculos
`slice_max()` - seleciona os menores valores da coluna `order_by = ` column, , use `with_ties = TRUE` para manter os vínculos

Veja a página [Eliminando duplicidades](#deduplication) para meis exemplos e detalhes de `slice()`.  


### Filtrar por tamanho do grupo {#group_filter_grp_size .unnumbered} 

A função `add_count()` adiciona uma coluna `n` aos dados originais dando o número de linhas no grupo daquela linha. 

Mostrado abaixo, `add_count()` é aplicado à coluna `hospital`, assim os valores na nova coluna `n` refletem o número de linhas no grupo hospitalar. Observe como os valores na coluna `n` são repetidos. No exemplo abaixo, o nome da coluna `n` poderia ser alterado utilizando `name = ` dentro de `add_count()`. Para fins de demonstração, reorganizamos as colunas com `select()`. 


```{r}
linelist %>% 
  as_tibble() %>% 
  add_count(hospital) %>%          # adiciona "número de linhas adimitidas no mesmo hospital que o dessa linha" 
  select(hospital, n, everything())
```

Torna-se então fácil filtrar para linhas de casos que foram hospitalizados em um hospital "pequeno", digamos, um hospital que admitiu menos de 500 pacientes:  

```{r, eval=F}
linelist %>% 
  add_count(hospital) %>% 
  filter(n < 500)
```


## Criando novas variáveis (mutate) em dados agrupados  

Para manter todas as colunas e linhas (não resumir) e *adicionar uma nova coluna contendo estatísticas de grupo*, utilizar `mutate()` após `group_by()` em vez de `summarise()`. 

Isto é útil se você quiser estatísticas de grupo no conjunto de dados original * com todas as outras colunas presentes* - por exemplo, para cálculos que comparam uma linha com seu grupo.  

Por exemplo, este código abaixo calcula a diferença entre o atraso de para a admissão de uma observação e o atraso mediano para seu hospital. As etapas são:  

1) Agrupar os dados por hospital  
2) Utilize a coluna `days_onset_hosp` (atraso à hospitalização) para criar uma nova coluna contendo o atraso médio no hospital para *aquela linha*.  
3) Calcular a diferença entre as duas colunas  

Nós usamos a função `select()` para selecionar apenas certas colunas a serem exibidas, para fins de demonstração.  

```{r}
linelist %>% 
  # agrupando dados por hospital (sem mudanças na linelist ainda)
  group_by(hospital) %>% 
  
  # novas colunas
  mutate(
    # quantidades de dias média para admissão por hospital (arredondado para 1 decimal)
    group_delay_admit = round(mean(days_onset_hosp, na.rm=T), 1),
    
    # diferença entre o atraso daquela observação e o atraso medio do hospital (arredondado para 1 decimal)
    diff_to_group     = round(days_onset_hosp - group_delay_admit, 1)) %>%
  
  # seleciona alguma linhas apenas - para fim de demostração/visualização  
  select(case_id, hospital, days_onset_hosp, group_delay_admit, diff_to_group)
```



## Selecionar em dados agrupados

O verbo `select()` funciona em dados agrupados, mas as colunas de agrupamento são sempre incluídas (mesmo se não mecionadas explicitamente em `select()`). Se você não quiser essas colunas, precisa usarprimeiro a função `ungroup()` para desagrupá-los.  


<!-- ======================================================= -->
## Recursos {  }

Aqui estão alguns recursos úteis para mais informações. 

Você pode aplicar funções de resumo em dados agrupados; ver a ["cheat sheet" (cola) de transformação de dados do RStudio. ](https://github.com/rstudio/cheatsheets/blob/master/data-transformation.pdf)  

A página do Data Carpentry [**dplyr**](https://datacarpentry.org/R-genomics/04-dplyr.html)  
As páginas de referência do **tidyverse** em [group_by()](https://dplyr.tidyverse.org/reference/group_by.html) and [grouping](https://dplyr.tidyverse.org/articles/grouping.html)  

Esta página em [Manipulação de dados](https://itsalocke.com/files/DataManipulationinR.pdf)  

[Resumindo com condicionamento no dplyr](https://stackoverflow.com/questions/23528862/summarize-with-conditions-in-dplyr)  






```{r include=FALSE, cache=FALSE}

# clear workspace
rm(list = ls(all = TRUE))

# clear all packages except base
#lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))

# to ensure that tidyverse packages prevail
filter <- dplyr::filter
select <- dplyr::select
summarise <- dplyr::summarise
summary <- base::summary
incidence <- incidence2::incidence

#load core packages
pacman::p_load(
     rio,
     here,
     DT,
     stringr,
     lubridate,
     tidyverse
)

# import the cleaned ebola linelist
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

# import the count data - facility level
#count_data <- rio::import(here::here("data", "facility_count_data.rds"))

# Settings

options(scipen=1, digits=7)

# print only text (not code)
# library(knitr)
# opts_chunk$set(list(echo = FALSE, eval = FALSE))
```

<!--chapter:end:new_pages/grouping.Rmd-->


# Juntando dados (Joins) {#joining-matching}  

```{r out.width = c('50%'), fig.show='hold', echo=F}
knitr::include_graphics(here::here("images", "left-join.gif"))
```

*Acima: um exemplo animado de uma operação de left join ([image source](https://github.com/gadenbuie/tidyexplain/tree/master/images))*  


Essa página descreve maneiras de combinar diferentes data frames com operações do tipo "join", "match", "link" e "bind".

Raramente nosso fluxo de análise epidemiológica não envolverá múltiplas fontes de dados e relações entre múltiplas bases. Talvez você precise conectar dados laboratoriais com desfechos clínicos dos pacientes, ou dados de mobilidade do Google às tendências de doenças infecciosas, ou ainda, uma base de dados em um estágio da análise com uma versão transormada dessa mesma base.

Nessa página vamos demonstrar como escrever código para:  

* Conduzir *joins* de dois dataframes de forma que as linhas sejam combinadas com base nos valores comuns das colunas de identificadores
* Juntar dois dataframes baseados na combinação *probabilística* (verossímil) entre valores  
* Expandir um dataframe através da ligação/anexação direta (*binding* ou *"appending"*) de linhas ou colunas de outro dataframe 


<!-- ======================================================= -->
## Preparação { }

### Carregue os pacotes R {.unnumbered}

O código abaixo realiza o carregamento dos pacotes necessários para a análise dos dados. Neste manual, enfatizamos o uso da função `p_load()`, do **pacman**, que instala os pacotes, caso não estejam instalados, *e* os carrega no R para utilização. Também é possível carregar pacotes instalados utilizando a função `library()`, do R **base**. Para mais informações sobre os pacotes do R, veja a página [Introdução ao R](#basics).   

```{r}
pacman::p_load(
  rio, # importar and exportar
  here, # localizar arquivos
  tidyverse, # gerenciamento e visualização de dados
  RecordLinkage, # combinações probabilisticas
  fastLink # combinações probabilisticas
)
```



### Importe dados {.unnumbered}

Para iniciar, importaremos a versão limpa da linelist de casos de uma epidemia simulada de Ebola. Se você quiser acompanhar, <a href='https://github.com/appliedepi/epirhandbook_eng/raw/master/data/case_linelists/linelist_cleaned.rds' class='download-button'>clique para baixar a linelist "limpa"</a> (com um arquivo .rds). Importe os dados com a função `import()` do pacote **rio** (ela manipula vários tipos de arquivo, tais como .xlsx, .csv, .rds - veja na página [Importando and exportando](#importing) para detalhes).  

```{r, echo=F}
# importa a linelist para o R
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))
```

```{r, eval=F}
# importa a linelist de casos
linelist <- import("linelist_cleaned.rds")
```

As primeiras 50 linhas da linelist são mostradas abaixo.

```{r, message=FALSE, echo=F}
# mostra os dados da linelist como uma tabela
DT::datatable(head(linelist, 50), rownames = FALSE, filter = "top", options = list(pageLength = 5, scrollX = T), class = "white-space: nowrap")
```




<!-- ======================================================= -->
### Base de dados de exemplo {.unnumbered}

Para demonstrar um join na seção abaixo, utilizaremos as seguintes bases de dados: 

1) Uma versão "miniatura" da `linelist` de casos, contendo apenas as colunas `case_id`, `date_onset`, e `hospital`, e apenas as primeiras 10 linhas 
2) Um dataframe separado chamado `hosp_info`, que contém mais detalhes sobre cada hospital 

Na seção de combinação probabilística, utilizaremos outras duas bases diferentes. O código para criar essas bases serão mostradas naquela seção.




#### Linelist de casos "miniatura" {#joins_llmini .unnumbered}  

Abaixo está a miniatura da linelist de casos, que contém apenas 10 linhas e só as colunas `case_id`, `date_onset`, e `hospital`.  

```{r}
linelist_mini <- linelist %>% # começa com a linelist original
  select(case_id, date_onset, hospital) %>% # seleciona colunas
  head(10) # seleciona apenas 10 primeira linhas
```

```{r message=FALSE, echo=F}
DT::datatable(linelist_mini, rownames = FALSE, options = list(pageLength = nrow(10)))
```




#### Dataframe com informações dos hospitais {#joins_hosp_info .unnumbered}  

Abaixo está o código para criar um dataframe separado com informações adicionais sobre sete hospitais (abrangência populacional e o nível de atenção disponível). Note que o nome "Military Hospital" pertence a dois hospitais diferentes - um no primeiro nível servindo 10000 residentes e outro no nível secundário servindo 50280 residentes.  

```{r}
# Cria o dataframe de informação dos hospitais
hosp_info <- data.frame(
  hosp_name     = c("central hospital", "military", "military", "port", "St. Mark's", "ignace", "sisters"),
  catchment_pop = c(1950280, 40500, 10000, 50280, 12000, 5000, 4200),
  level         = c("Tertiary", "Secondary", "Primary", "Secondary", "Secondary", "Primary", "Primary")
)
```

Aqui está esse dataframe: 

```{r message=FALSE, echo=F}
# mostra os dados dos hospitais como uma tabela
DT::datatable(hosp_info, rownames = FALSE, options = list(pageLength = nrow(hosp_info)))
```





<!-- ======================================================= -->
### Pré-limpeza {.unnumbered}

Joins tradicionais (não-probabilísticos) são sensíveis ao caso (maiúsculos/minúsculos) e necessitam que os caracteres combinem de forma exata (__exact match__) entre os valores nos dois dataframes. Para demonstrar alguns dos passos de limpeza que você possa precisar executar antes de iniciar um join, vamos limpar e alinhar as bases `linelist_mini` e `hosp_info` agora.  

**Identifique as diferenças**  

Precisamos que os valores da coluna `hosp_name` no dataframe `hosp_info` combinem com os valores da coluna `hospital` no dataframe `linelist_mini`.  

Aqui estão os valores do dataframe `linelist_mini`, impressos com a função `unique()` do R **base**:  

```{r}
unique(linelist_mini$hospital)
```

e aqui estão os valores do dataframe `hosp_info`:  

```{r}
unique(hosp_info$hosp_name)
```

Você pode ver que apesar de alguns dos hospitais existirem em ambos dataframes, existem muitas diferenças na forma como os nomes estão escritos.  



**Alinhando valores**  

Vamos começar limpando os valores do dataframe `hosp_info`. Como explicado na página [Limpando dados e funções principais](#cleaning), podemos recodificar valores com critérios lógicos utilizando a função `case_when()` do pacote **dplyr**. Para os quatro hospitais que existem em ambos os dataframes, vamos mudar os valores para alinhar com os valores da `linelist_mini`. Para os outros hospitais, deixaremos os valores como estão (`TRUE ~ hosp_name`).   

<span style="color: orange;">**_CUIDADO:_** Tipicamente, quando estamos limpando dataframes devemos criar uma nova coluna (ex: `hosp_name_clean`), mas para facilitar a demonstração vamos mostrar diretamente a modificação da antiga coluna</span>

```{r}
hosp_info <- hosp_info %>%
  mutate(
    hosp_name = case_when(
      # critério                         # novo valor
      hosp_name == "military" ~ "Military Hospital",
      hosp_name == "port" ~ "Port Hospital",
      hosp_name == "St. Mark's" ~ "St. Mark's Maternity Hospital (SMMH)",
      hosp_name == "central hospital" ~ "Central Hospital",
      TRUE ~ hosp_name
    )
  )
```

Os nomes dos hospitais que aparecem em ambos os dataframes estão alinhados. Existem dois hospitais em `hosp_info` que não estão presentes em `linelist_mini` - vamos lidar com estes depois, no join.  

```{r}
unique(hosp_info$hosp_name)
```

Antes de fazer um join, geralmente o mais fácil é converter uma coluna completamente para letras minúsculas (lowercase) ou letras maiúsculas (uppercase). Se você precisar converter todos os valores de uma coluna para MAIÚSCULO ou minúsculo, utilize a função `mutate()` e envolva a coluna com alguma dessas funções do pacote **stringr**, como mostrado na página [Caracteres e strings](#characters-strings).  

`str_to_upper()`  
`str_to_upper()`  
`str_to_title()`  




<!-- ======================================================= -->
## Joins com **dplyr** { }

O pacote **dplyr** oferece várias funções diferentes de join. **dplyr** está incluso no pacote **tidyverse**. Essas funções de join são descritas abaixo, com casos de uso simples.  

Agradecimentos a [https://github.com/gadenbuie](https://github.com/gadenbuie/tidyexplain/tree/master/images) pelos gifs informativos!  




<!-- ======================================================= -->
### Sintaxe geral {.unnumbered}

Os comandos de join podem ser executados individualmente para juntar dois dataframes em um novo objeto, ou podem ser usados em uma cadeia de comandos com pipe (`%>%`) para mesclar um dataframe em outro à medida que ele vai sendo limpo ou modificado de alguma outra forma.  

No exemplo abaixo, a função `left_join()` é utilizada como um comando individual para criar um novo dataframe chamado `joined_data`. As entradas (inputs) são os dataframes 1 e 2 (`df1` e `df2`). O primeiro dataframe listado é o dataframe de base e o segundo é o dataframe que será mesclado a (joined *to*) ele. 

O terceiro argumento `by = ` é onde você especifica as colunas em cada dataframe que serão utilizadas para alinhar as linhas dos dois dataframes. Se os nomes dessas colunas forem diferentes, insira o nome delas com um vetor `c()` como mostrado abaixo, onde as linhas são combinadas com base nos valores comuns entre a coluna `ID` em `df1` e a coluna `identifier` em `df2`.   


```{r, eval=F}
# Faz o join baseado nos valores comuns entre a coluna "ID" (primeiro dataframe) e coluna "identifier" (segundo dataframe)
joined_data <- left_join(df1, df2, by = c("ID" = "identifier"))
```

Se as colunas utilizadas no parâmetro `by` tiverem exatamente o mesmo nome em ambos os dataframes, você pode inserir apenas esse nome, entre aspas.  

```{r, eval=F}
# Join baseado nos valores comuns da coluna "ID" em ambos os dataframes
joined_data <- left_join(df1, df2, by = "ID")
```

Se você estiver juntando dataframes baseado em valores comuns ao longo de múltiplos campos, liste esses campos em um vetor `c()`. Esse exemplo junta linhas se os valores em três colunas em cada base de dado se alinham de forma exata.  

```{r, eval=F}
# join baseado nos mesmos primeiro nome, último nome e idade
joined_data <- left_join(df1, df2, by = c("name" = "firstname", "surname" = "lastname", "Age" = "age"))
```


Os comandos de join também podem ser rodados em uma cadeia de comandos com pipe. Isso irá modificar o dataframe que está sendo passado pelo pipe. 

No exemplo abaixo, `df1` está sendo pessado pelos pipes, `df2` será juntado a ele e `df1` então será modificado e redefinido.  

```{r eval=F}
df1 <- df1 %>%
  filter(date_onset < as.Date("2020-03-05")) %>% # miscellaneous cleaning
  left_join(df2, by = c("ID" = "identifier")) # join df2 to df1
```


<span style="color: orange;">**_CUIDADO:_** Joins são caso-específicos (maiúsculas e minúsculas)! Então, é útil converter todos os valores para minúsculo ou maiúsculo antes de fazer o join. Veja a página sobre caracteres/strings.</span>





<!-- ======================================================= -->
### Left joins e right joins {.unnumbered}  

**Um left join ou right join é normalmente utilizado para adicionar informação a um dataframe** - novas informações são adicionadas apenas a linhas que já existem no data frame base. Esses são tipos de joins comuns em trabalhos epidemiológicos pois eles são utilizados para adicionar informações de uma base de dado em outra. 

Para utilizar esses joins, a ordem em que os dataframes estão escritos nos comandos é importante*.  

* Em um *left join*, o *primeiro* dataframe escrito é o de base  
* Em um *right join*, o *segundo* dataframe escrito é o de base  

**Todas as linhas do dataframe base são mantidas.** As informações no outro dataframe (secundário) será juntada ao dataframe de base *apenas se houver a combinação via as colunas dos identificadores*. E ainda:  

* Linhas no dataframe secundário que não combinam são removidas. 
* Se houver muitas linhas no dataframe base que combinam com uma linha no secundário (muitos-para-um), a informação do secundário é adicionada a *cada linha do base que combina*.  
* Se uma linha do base combina com múltiplas linhas no secundário (um-para-muitos), todas as combinações são dadas, o que significa que *novas linhas podem ser adicionadas ao dataframe resultante!*

Exemplos animados de left e right joins ([fonte da imagem](https://github.com/gadenbuie/tidyexplain/tree/master/images))

```{r out.width = c('50%'), fig.show='hold', echo=F}
knitr::include_graphics(here::here("images", "left-join.gif"))
knitr::include_graphics(here::here("images", "right-join.gif"))
```

**Exemplo**  

Abaixo está a saída de um `left_join()` do `hosp_info` (dataframe secundário, [veja aqui](#joins_hosp_info))  *em* `linelist_mini` (dataframe base, [veja aqui](#joins_llmini)). O `linelist_mini` tem ` nrow(linelist_mini)` linhas. O `linelist_mini` modificado é mostrado. Note o seguinte:  

* Duas novas colunas, `catchment_pop` e `level` foram adicionadas ao lado esquerdo da `linelist_mini`  
* Todas as linhas originais do dataframe base `linelist_mini` são mantidas 
* Quaisquer linhas originais do `linelist_mini` para "Military Hospital" foram duplicadas porque combinaram com *duas* linhas no dataframe secundário, então ambas as combinações são retornadas
* A coluna de identificador do join na base secundária (`hosp_name`) desapareceu pois está em redundância com a coluna de identificador da base primária (`hospital`)  
* Quando a linha da base não combina com nenhuma linha da base secundária (ex: quando `hospital` é "Other" ou "Missing"), as colunas do dataframe secundário serão preenchidas com `NA` (em branco) 
* Linhas no dataframe secundário sem nenhuma combinação no dataframe base (hospitais "sisters" e "ignace") foram removidas 


```{r, eval=F}
linelist_mini %>%
  left_join(hosp_info, by = c("hospital" = "hosp_name"))
```

```{r message=FALSE, echo=F}
linelist_mini %>%
  left_join(hosp_info, by = c("hospital" = "hosp_name")) %>%
  DT::datatable(rownames = FALSE, options = list(pageLength = 11))
```





#### "Devo fazer um right join, ou um left join?" {.unnumbered}  

Para responder à pergunta acima, pergunte-se "qual dataframe deve manter todas as suas linhas?" - utilize esse como o base. Um *left join* manterá todas as linhas do primeiro dataframe escrito no comando, enquanto um *right join* manterá todas as linhas do segundo dataframe.  

Os dois comandos abaixo geram a mesma saída - um join de 10 linhas do `hosp_info` *em* `linelist_mini` (base), mas eles usam joins diferentes. O resultado é que a ordem das colunas vai diferir se `hosp_info` aparecer na direita (em um left join) ou na esquerda (em um right join). A ordem das linhas também pode mudar de posição da mesma forma. No entanto, ambas essas consequências podem ser resolvidas depois utilizando `select()` para reordenar as colunas, ou `arrange()` para ordenar (*sort*) as linhas.  

```{r, eval=F}
# Os dois comandos abaixo geram os memso dados, mas com linhas e colunas em ordem diferentes
left_join(linelist_mini, hosp_info, by = c("hospital" = "hosp_name"))
right_join(hosp_info, linelist_mini, by = c("hosp_name" = "hospital"))
```

Aqui está o resultado do join de `hosp_info` em `linelist_mini` por meio de um left join (novas colunas vindas da direita)

```{r message=FALSE, echo=F}
left_join(linelist_mini, hosp_info, by = c("hospital" = "hosp_name")) %>%
  DT::datatable(rownames = FALSE, options = list(pageLength = 11))
```

Aqui, o resultado do join de `hosp_info` em `linelist_mini` por meio de um right join (novas colunas vindas da esquerda)
```{r message=FALSE, echo=F}
right_join(hosp_info, linelist_mini, by = c("hosp_name" = "hospital")) %>%
  DT::datatable(rownames = FALSE, options = list(pageLength = 11))
```

Considere também se seu caso de uso está em meio a uma cadeia de comandos com pipe (`%>%`). Se os dados passando através dos pipes for o dataframe base, você irá preferivelmente utilizar um left join para adicionar mais dados a ele.


<!-- ======================================================= -->
### Full join {.unnumbered} 

**Um full join é o mais *inclusivo* dos joins** - ele retorna todas as linhas de ambos os dataframes.

Se houver alguma linha presente em um mas não em outro (onde não foi encontrada nenhuma combinação entre os dados), o dataframe vai incluir essa linha e tornar-se mais longo. Os valores `NA` para representar valores ausentes serão utilizados para preencher os espaços vazios criados. À medida que você for executando o join, monitore cuidadosamente o número de colunas e linhas para resolver problemas de sensitividade de caso (maiúsculo/minúsculo) ou combinação exata de caracteres. 

O dataframe base será aquele escrito primeiro no comando. Mudar essa posição não vai impactar em quais registros serão retornados pelo join, mas pode impactar na ordem das colunas e linhas resultantes e também em quais colunas de identificadores serão mantidos. 

```{r out.width = c('50%'), fig.show='hold', echo=F}
knitr::include_graphics(here::here("images", "full-join.gif"))
```

Exemplo animado de um full join ([fonte da imagem](https://github.com/gadenbuie/tidyexplain/tree/master/images))

**Exemplo**  

Abaixo está uma saída de um `full_join()` do `hosp_info` (originalmente ` nrow(hosp_info)`, [veja aqui](#joins_hosp_info))  *em* `linelist_mini` (originalmente ` nrow(linelist_mini)`, [veja aqui](#joins_llmini)). Note o seguinte:  

* Todas as linhas do dataframe base são mantidas (`linelist_mini`)  
* Linhas no dataframe secundário que não combinam com o dataframe base são mantidas ("ignace" e "sisters"), com valores nas colunas correspondentes do base (`case_id` e `onset`) preenchidas com os valores ausentes `NA`
* Da mesma forma, linhas no dataframe base que não combinam com o secundário ("Other" e "Missing") são mantidas, com as colunas `catchment_pop` e `level` do secundário preenchidas com `NA`
* Nos casos das combinações um-para-muitos ou muitos-para-um (ex: linhas para "Military Hospital"), todas as combinações possíveis são retornadas (aumentando o tamanho do dataframe final)  
* Apenas a coluna do identificador do dataframe base foi mantida (`hospital`)  


```{r, eval=F}
linelist_mini %>%
  full_join(hosp_info, by = c("hospital" = "hosp_name"))
```

```{r message=FALSE, echo=F}
linelist_mini %>%
  full_join(hosp_info, by = c("hospital" = "hosp_name")) %>%
  DT::datatable(rownames = FALSE, options = list(pageLength = 15))
```





<!-- ======================================================= -->
### Inner join {.unnumbered} 

**Um inner join é o mais *restritivo* dos joins** - ele retona apenas as linhas que combinam em ambos os dataframes.
Isso significa que o número linhas no dataframe base pode, de fato, *reduzir*. Ajustes em relação a qual dataframe será o base (escrito primeiro na função) não irá impactar quais linhas serão retornadas, mas vai impactar na ordem das colunas e linhas, e quais colunas de identificadores serão mantidas.   


```{r out.width = c('50%'), fig.show='hold', echo=F}
knitr::include_graphics(here::here("images", "inner-join.gif"))
```

Exemplo animado de um inner join ([fonte da imagem](https://github.com/gadenbuie/tidyexplain/tree/master/images))


**Exemplo**  

Abaixo está a saída de um `inner_join()` de `linelist_mini` (base) com `hosp_info` (secundário). Note o seguinte:  

* As linhas do dataframe base que não combinam com as do secundário são removidas (linhas onde `hospital` é "Missing" ou "Other")  
* De forma análoga, linhas do secundário que não combinam com o base são removidas (linhas onde `hosp_name` é "sisters" ou "ignace")  
* Apenas a coluna de identificador do base foi mantida (`hospital`)  


```{r, eval=F}
linelist_mini %>%
  inner_join(hosp_info, by = c("hospital" = "hosp_name"))
```


```{r message=FALSE, echo=F}
linelist_mini %>%
  inner_join(hosp_info, by = c("hospital" = "hosp_name")) %>%
  DT::datatable(rownames = FALSE, options = list(pageLength = 12))
```






<!-- ======================================================= -->
### Semi join {.unnumbered} 

Um semi join é "join filtro" que utiliza outra base de dados *não para adicionar linhas ou colunas, mas para fazer uma filtragem*.  

Um **semi-join mantém todas as observações do dataframe base que combinam com algum valor do dataframe secundário** (mas não adiciona novas colunas nem duplica nenhuma linha para o caso de múltiplas combinações). Leia mais sobre esses joins "filtros" [aqui](https://towardsdatascience.com/level-up-with-semi-joins-in-r-a068426096e0).  

```{r out.width = c('50%'), fig.show='hold', echo=F}
knitr::include_graphics(here::here("images", "semi-join.gif"))
```

Exemplo de um semi join animado ([fonte da imagem](https://github.com/gadenbuie/tidyexplain/tree/master/images))

Como um exemplo, o código abaixo retorna as linhas do dataframe `hosp_info` que tem combinações em `linelist_mini` baseados no nome do hospital.  

```{r}
hosp_info %>%
  semi_join(linelist_mini, by = c("hosp_name" = "hospital"))
```



### Anti join {.unnumbered} 
<!-- ======================================================= -->

**O anti join é um outro tipo de "join filtro" que retorna linhas no dataframe base que *não* possuem uma combinação no dataframe secundário.**  

Leia mais sobre esses joins "filtros" [aqui](https://towardsdatascience.com/level-up-with-semi-joins-in-r-a068426096e0).

Cenários comuns para anti-join incluem identificar registros que não estão presentes em outro data frame, checar erros de grafia em um join (revisão de registros que *deveriam* ter combinado) e examinar registros que foram excluídos depois de outro join.  

**Assim como com `right_join()` e `left_join()`, o dataframe *base* (listado primeiro) é importante**. As linhas retornadas serão apenas do dataframe base. Veja no gif abaixo qu e a linha no dataframe secundário (linha roxa 4) não é retornada mesmo que ela não tenha combinado com o base.  

```{r out.width = c('50%'), fig.show='hold', echo=F}
knitr::include_graphics(here::here("images", "anti-join.gif"))
```

Exemplo animado de um anti join ([fonte da imagem](https://github.com/gadenbuie/tidyexplain/tree/master/images))


#### Um exemplo simples de `anti_join()` {.unnumbered}  

Para um exemplo simples, vamos achar os hospitais de  `hosp_info` que não possuem nenhum caso presente em `linelist_mini`. Nós listamos `hosp_info` primeiro, como o dataframe base. Os hospitais que não estão presentes em `linelist_mini` são retornados.  

```{r, eval=F}
hosp_info %>%
  anti_join(linelist_mini, by = c("hosp_name" = "hospital"))
```

```{r message=FALSE, echo=F}
hosp_info %>%
  anti_join(linelist_mini, by = c("hosp_name" = "hospital")) %>%
  DT::datatable(rownames = FALSE, options = list(pageLength = 12))
```


#### Exemplo complexo de  `anti_join()` {.unnumbered}  

Para outro exemplo, vamos supor que rodamos um `inner_join()` entre `linelist_mini` e `hosp_info`. Será retornado apenas um subconjunto dos registros originais de `linelist_mini`, visto que alguns não estão presentes em `hosp_info`.  

```{r, eval=F}
linelist_mini %>%
  inner_join(hosp_info, by = c("hospital" = "hosp_name"))
```

```{r message=FALSE, echo=F}
linelist_mini %>%
  inner_join(hosp_info, by = c("hospital" = "hosp_name")) %>%
  DT::datatable(rownames = FALSE, options = list(pageLength = 8))
```

Para revisar os registros de `linelist_mini` que foram excluídos no inner join, podemos rodar um anti-join com as mesmas configurações (`linelist_mini` como o dataframe base).

```{r, eval = F}
linelist_mini %>%
  anti_join(hosp_info, by = c("hospital" = "hosp_name"))
```

```{r message=FALSE, echo=F}
linelist_mini %>%
  anti_join(hosp_info, by = c("hospital" = "hosp_name")) %>%
  DT::datatable(rownames = FALSE, options = list(pageLength = 8))
```


Para ver os registros de `hosp_info` que foram excluídos no inner join, também podemos rodar um anti-join com `hosp_info` como o dataframe base.  



<!-- ======================================================= -->
## Combinação probabilística { }

Se você não tiver um único identificador comum entre as bases de dados para fazer o join, considere utilizar um algoritmo de combinação probabilística. Ele acharia combinações entre os registros baseados em similaridade (ex: distância de strings de Jaro–Winkler, ou distância numérica).  Abaixo temos um exemplo simples utilizando o pacote **fastLink** .  

**Carregue o pacote**  

```{r}
pacman::p_load(
  tidyverse, # manipulação e visualização de dados
  fastLink # combinação dos registros
)
```


Aque estão duas pequenas bases de dados que nós iremos utilizar para demonstrar a combinação probabilística (`cases` e `test_results`):  

Aqui está o código utilizado para construir as bases de dados:


```{r}
# cria as bases de dados

cases <- tribble(
  ~gender, ~first, ~middle, ~last, ~yr, ~mon, ~day, ~district,
  "M", "Amir", NA, "Khan", 1989, 11, 22, "River",
  "M", "Anthony", "B.", "Smith", 1970, 09, 19, "River",
  "F", "Marialisa", "Contreras", "Rodrigues", 1972, 04, 15, "River",
  "F", "Elizabeth", "Casteel", "Chase", 1954, 03, 03, "City",
  "M", "Jose", "Sanchez", "Lopez", 1996, 01, 06, "City",
  "F", "Cassidy", "Jones", "Davis", 1980, 07, 20, "City",
  "M", "Michael", "Murphy", "O'Calaghan", 1969, 04, 12, "Rural",
  "M", "Oliver", "Laurent", "De Bordow", 1971, 02, 04, "River",
  "F", "Blessing", NA, "Adebayo", 1955, 02, 14, "Rural"
)

results <- tribble(
  ~gender, ~first, ~middle, ~last, ~yr, ~mon, ~day, ~district, ~result,
  "M", "Amir", NA, "Khan", 1989, 11, 22, "River", "positive",
  "M", "Tony", "B", "Smith", 1970, 09, 19, "River", "positive",
  "F", "Maria", "Contreras", "Rodriguez", 1972, 04, 15, "Cty", "negative",
  "F", "Betty", "Castel", "Chase", 1954, 03, 30, "City", "positive",
  "F", "Andrea", NA, "Kumaraswamy", 2001, 01, 05, "Rural", "positive",
  "F", "Caroline", NA, "Wang", 1988, 12, 11, "Rural", "negative",
  "F", "Trang", NA, "Nguyen", 1981, 06, 10, "Rural", "positive",
  "M", "Olivier", "Laurent", "De Bordeaux", NA, NA, NA, "River", "positive",
  "M", "Mike", "Murphy", "O'Callaghan", 1969, 04, 12, "Rural", "negative",
  "F", "Cassidy", "Jones", "Davis", 1980, 07, 02, "City", "positive",
  "M", "Mohammad", NA, "Ali", 1942, 01, 17, "City", "negative",
  NA, "Jose", "Sanchez", "Lopez", 1995, 01, 06, "City", "negative",
  "M", "Abubakar", NA, "Abullahi", 1960, 01, 01, "River", "positive",
  "F", "Maria", "Salinas", "Contreras", 1955, 03, 03, "River", "positive"
)
```


**A base de dados `cases` possui 9 registros** de pacientes que estão esperando para testar resultados.

```{r message=FALSE, echo=F}
# mostra os dados de hospitais como uma tabela
DT::datatable(cases, rownames = FALSE, options = list(pageLength = nrow(cases), scrollX = T), class = "white-space: nowrap")
```



**A base de dados `test_results`** possui 14 registros e contém a coluna `result`, que nós queremos adicionar aos registros `cases` baseados nas combinações probabilísticas dos registros.  

```{r message=FALSE, echo=F}
# mostra os dados de hospitais como uma tabela
DT::datatable(results, rownames = FALSE, options = list(pageLength = nrow(results), scrollX = T), class = "white-space: nowrap")
```

### Combinação Probabilística (probabilistic matching) {.unnumbered}  

A função `fastlink()` do pacote **fastlink** pode ser utilizada para aplicar um algoritmo que busca as combinações entre os valores. Aqui estão as informações básicas. Você pode ler mais detalhes digitando `?fastlink` no seu console.  

* Defina os dois dataframes que serão comparados nos argumentos `dfA = ` e `dfB = `  
* Em `varnames = ` defina todos os nomes de colunas que serão utilizadas para testar a combinação. Todas devem existir tanto em `dfA` quanto em `dfB`.  
* Em `stringdist.match = ` defina o nome das colunas que estão em `varnames` que serão avaliadas pela "distancia" entre strings.  
* Em `numeric.match = ` defina o nome das colunas que estão em `varnames` que serão avaliadas pela distância numérica.  
* Valores ausentes serão ignorados 
* Por padrão, cada linha em qualquer dos dataframes será combinada com no máximo uma linha do outro dataframe. Se você quiser ver todas as combinações que foram avaliadas defina o parâmetro `dedupe.matches = FALSE`. A deduplicação é feita utilizando a solução de Winkler para atribuição linear.  

*Dica: divida uma coluna única de data em 3 colunas numéricas separadas utilizadando `day()`, `month()`, e `year()` do pacote **lubridate***  

O limiar padrão para as combinações é 0.94 (`threshold.match = `) mas você pode ajustar para maior ou menor. Se você for ajustar manualmente o limiar, considere que com limiares mais altos você pode gerar mais falsos negativos (linhas que não combinam quando na verdade deveriam combinar) e, da mesma forma, um limiar mais baixo pode gerar falsos positivos.  

Abaixo, os dados estão sendo combinados pela distância de strings nas colunas de nome e distrito, e na distância numérica para ano, mês e dia do nascimento. Um limiar para combinação de 95% de probabilidade foi configurado.


```{r, message=F, warning=F}
fl_output <- fastLink::fastLink(
  dfA = cases,
  dfB = results,
  varnames = c("gender", "first", "middle", "last", "yr", "mon", "day", "district"),
  stringdist.match = c("first", "middle", "last", "district"),
  numeric.match = c("yr", "mon", "day"),
  threshold.match = 0.95
)
```

**Revisando as combinações**  

Nós definimos o objeto retornado da função `fastLink()` como `fl_output`. Ele é da classe `list`, e de fato contém vários dataframes internamente que detalham os resultados da combinação. Um desses dataframes é `matches`, que vai conter as combinações mais prováveis entre `cases` e `results`. Você pode acessar esse dataframe de combinações com `fl_output$matches`. Abaixo, ele está sendo salvo como `my_matches` para facilitar o acesso depois.    

Quando `my_matches` é impresso no console, você vê duas colunas de vetores: os pares de número de linhas/índices (também chamados "rownames") em `cases` ("inds.a") e em `results` ("inds.b") representando as melhores combinações. Se o número da linha de um dataframe estiver ausente, então nenhuma combinação foi achada no outro dataframe no limiar de combinação especificado.    


```{r}
# print matches
my_matches <- fl_output$matches
my_matches
```

Algumas coisas para se ter em mente: 

* As combinações ocorrem apesar de algumas diferenças sutis na grafia dos nomes ou nas datas de nascimento:  
  * "Tony B. Smith" combinou com "Anthony B Smith"  
  * "Maria Rodriguez" combinou com "Marialisa Rodrigues"  
  * "Betty Chase" combinou com "Elizabeth Chase"  
  * "Olivier Laurent De Bordeaux" combinou com "Oliver Laurent De Bordow" (data de nascimneto ausente foi ignorada)  
* Uma linha de `cases` (para "Blessing Adebayo", linha 9) não teve nenhuma boa combinação em `results`, por isso não está prente em `my_matches`.  




**Join baseado em combinações probabilísticas**  

Para utilizar essas combinações para fazer um join de `results` e `cases`, uma estratégia seria:  

1) Utilizar `left_join()` para fazer o join de `my_matches` em `cases` (combinando os nomes das colunas em `cases` com "inds.a" em  `my_matches`)  
2) Depois, utilizar outro `left_join()` para fazer o join de `results` em `cases` (combinando o recém adquirido "inds.b" em `cases` com os nomes das linhas em `results`)  

Antes dos joins, devemos limpar os três dataframes:  

* Ambos `dfA` e `dfB` devem ter seus números de linhas ("rowname") convertidos para uma coluna propriamente dita.  
* Ambas as colunas de `my_matches` devem ser convertidas para a classe *character*, para que o join possa ser feito com os nomes de coluna que são caracteres 

```{r}
# Limpeza dos dados antes do join
#############################

# converte os nomes das linhas de cases em coluna
cases_clean <- cases %>% rownames_to_column()

# converte os nomes das linhas de test_results em coluna
results_clean <- results %>% rownames_to_column()

# converte todas as colunas no dataframe de combinações (my_matches) para character, para que o join possa ser feito com os nomes das linhas
matches_clean <- my_matches %>%
  mutate(across(everything(), as.character))



# Faça o join das combinações com dfA, e depois adicione dfB
###################################
# a coluna "inds.b" é adicionada ao dfA
complete <- left_join(cases_clean, matches_clean, by = c("rowname" = "inds.a"))

# colunas do dfB são adicionadas
complete <- left_join(complete, results_clean, by = c("inds.b" = "rowname"))
```

Como feito no código acima, o dataframe `complete`, resultado dos joins, vai conter *todas* as colunas de `cases` e `results`. Muitas delas estarão com sufixos ".x" e ".y", por que, caso contrário, o nome das colunas seriam duplicados.  

```{r message=FALSE, echo=F}
DT::datatable(complete, rownames = FALSE, options = list(pageLength = nrow(complete), scrollX = T), class = "white-space: nowrap")
```

Como opção, para ter apenas os 9 registros "originais" em `cases` com as novaas colunas de `results`, utilize `select()` em `results` antes dos joins, de forma que ela contenha apenas os nomes de linhas e colunas que você queira adicionar a `cases` (ex: a coluna `result`).  

```{r}
cases_clean <- cases %>% rownames_to_column()

results_clean <- results %>%
  rownames_to_column() %>%
  select(rowname, result) # selecion apenas algumas colunas

matches_clean <- my_matches %>%
  mutate(across(everything(), as.character))

# joins
complete <- left_join(cases_clean, matches_clean, by = c("rowname" = "inds.a"))
complete <- left_join(complete, results_clean, by = c("inds.b" = "rowname"))
```


```{r message=FALSE, echo=F}
DT::datatable(complete, rownames = FALSE, options = list(pageLength = nrow(complete), scrollX = T), class = "white-space: nowrap")
```


Se você quiser um subconjunto de qualquer um dos dataframes contendo apenas as linhas que combinaram, você pode utilizar o código abaixo:

```{r}
cases_matched <- cases[my_matches$inds.a, ] # Linhas em cases que combinaram com uma linha em results
results_matched <- results[my_matches$inds.b, ] # Linhas em results que combinaram com uma linha em cases
```

Ou, para ver apenas as linhas que **não** combinaram:  

```{r}
cases_not_matched <- cases[!rownames(cases) %in% my_matches$inds.a, ] # Linhas em cases que NÃO combinaram com uma linha em results
results_not_matched <- results[!rownames(results) %in% my_matches$inds.b, ] # Linhas em results que NÃO combinaram com uma linha em cases
```


### Remoção de duplicidades probabilística {.unnumbered}  

A combinação probabilística também pode ser utilizada para remover duplicidades uma base de dados. Veja a página de remoção de duplicidades para outros métodos de deduplicação.  

Aqui, vamos começar com a base `cases`, mas a partir daqui chamaremos ela de `cases_dup`, pois ela tem 2 linhas adicionais que podem ser duplicidades de linhas anteriores:
Veja "Tony" com "Anthony", e "Marialisa Rodrigues" com "Maria Rodriguez".  

```{r, echo=F}
## Adiciona duplicidades
# cases_dup <- rbind(cases, cases[sample(1:nrow(cases), 3, replace = FALSE),])

cases_dup <- tribble(
  ~gender, ~first, ~middle, ~last, ~yr, ~mon, ~day, ~district,
  "M", "Amir", NA, "Khan", 1989, 11, 22, "River",
  "M", "Anthony", "B.", "Smith", 1970, 09, 19, "River",
  "F", "Marialisa", "Contreras", "Rodrigues", 1972, 04, 15, "River",
  "F", "Elizabeth", "Casteel", "Chase", 1954, 03, 03, "City",
  "M", "Jose", "Sanchez", "Lopez", 1996, 01, 06, "City",
  "F", "Cassidy", "Jones", "Davis", 1980, 07, 20, "City",
  "M", "Michael", "Murphy", "O'Calaghan", 1969, 04, 12, "Rural",
  "M", "Oliver", "Laurent", "De Bordow", 1971, 02, 04, "River",
  "F", "Blessing", NA, "Adebayo", 1955, 02, 14, "Rural",
  "M", "Tony", "B.", "Smith", 1970, 09, 19, "River",
  "F", "Maria", "Contreras", "Rodriguez", 1972, 04, 15, "River",
)
```

```{r message=FALSE, echo=F}
DT::datatable(cases_dup, rownames = FALSE, options = list(pageLength = nrow(cases_dup)))
```


Execute `fastLink()` como anteriormente, mas compare o dataframe `cases_dup` com ele mesmo. Quando os dois dataframes passados para a função são idênticos, ela assume que você quer fazer a remoção de duplicidades. Note que nós não especificamos `stringdist.match = ` ou `numeric.match = ` como havíamos feito anteriormente.  

```{r, message = F, warning = F}
## Execute fastLink na mesma base de dados
dedupe_output <- fastLink(
  dfA = cases_dup,
  dfB = cases_dup,
  varnames = c("gender", "first", "middle", "last", "yr", "mon", "day", "district")
)
```

Agora, você pode revisar as duplicidades em potencial com `getMatches()`. Passe o dataframe tanto como `dfA = ` como `dfB = `, e passa a saída da função `fastLink()` como `fl.out = `.  `fl.out` deve ser da classe `fastLink.dedupe`, ou em outras palavras, o resultado de `fastLink()`.  


```{r}
## Execute getMatches()
cases_dedupe <- getMatches(
  dfA = cases_dup,
  dfB = cases_dup,
  fl.out = dedupe_output
)
```

Veja a coluna da extrema direita, que indica os IDs das duplicatas - as duas últimas linhas estão identificadas como sendo potenciais duplicatadas das linhas 2 e 3.

```{r message=FALSE, echo=F}
DT::datatable(cases_dedupe, rownames = FALSE, options = list(pageLength = nrow(cases_dedupe)))
```

Para retornar o número de linhas que são potenciais duplicidades, você pode contar o número de linhas por valores únicos na coluna `dedupe.ids`, e aí filtrar para manter apenas aquelas com mais de uma linha. Nesse caso, isso deixaria as linhas 2 e 3.  

```{r}
cases_dedupe %>%
  count(dedupe.ids) %>%
  filter(n > 1)
```

Para investigar a totalidade das linhas que poderiam ser duplicidades, coloque o número da linha nesse comando:  

```{r}
# mostra a linha 2 e todas as possíveis duplicidades dela
cases_dedupe[cases_dedupe$dedupe.ids == 2, ]
```



## Anexando (binding) e alinhando

Um outro método de combinar dois dataframes é anexando ("binding") um ao outro. Você também pode pensar nisso como incluir ("appending") ou adicionar ("adding") linhas ou colunas.  

Essa seção também vai discutir como "alinhar" a ordem das linhas de um dataframe à ordem de outro dataframe. Esse tópico é discutido abaixo na seção de Anexar colunas.  



### Anexar linhas (bind rows) {.unnumbered}

Para anexar linhas de um dataframe no final de outro dataframe, utilize a função `bind_rows()` do pacote **dplyr**. Essa é uma função bastante inclusiva, então, todas as colunas presentes em cada dataframe será incluída na saída. Algumas notas:

* Diferente da versão `row.bind()` do R **base**, `bind_rows()` do **dplyr** não exige que a ordem das colunas seja a mesma em ambos os dataframes. Contanto que os nomes das colunas estejam grafados de forma idêntica, a função vai alinhá-las corretamente.   
* Você poder, opcionalmente, especificar o argumento `.id = `. Passe um nome de coluna para o argumento. Isso vai produzir uma nova coluna que serve para identificar de qual dataframe cada linha veio originalmente.
* Você pode usar `bind_rows()` em uma `lista` de dataframes que tenham estrutura semelhante para combiná-los em um só. Veja um exemplo na página [Iteração, loops e listas](#iteration) que envolve a importação de múltimplas linelists com **purrr**.  


Um exemplo comum de anexação de linhas é anexar uma linha de "total" no final de uma tabela descritiva feita utilizando a função `summarise()` do **dplyr**. Abaixo nós criamos uma tabela de contagem de casos e medianas dos valores de CT por hospital com uma linha total.

A função `summarise()` é utilizada em dados agrupados por hospital para retornar um dataframe sumárizado por hospital. Porém, a função `summarise()` não gera colunas de "totais" automaticamente, então, nós criamos uma sumarizando os dados *novamente*, mas com os dados não agrupados por hospital. Isso produz um segundo dataframe de apenas uma linha. Nós podemos anexar (bind) esses dataframes um ao outro para chegar na tabela final.

Veja outros exemplos práticos como esse nas páginas [Tabelas descritivas](#tables-descriptive) e [Tabelas para apresentação](#tables-presentation).  


```{r}
# Cria a tabela principal
###################
hosp_summary <- linelist %>%
  group_by(hospital) %>% # Agrupa os dados por hospital
  summarise( # Cria colunas sumário dos indicadores de interesse
    cases = n(), # Número de linhas por grupo hospital-desfecho
    ct_value_med = median(ct_blood, na.rm = T)
  ) # valores medianos de CT por grupo
```

Aqui está o dataframe `hosp_summary`:  

```{r message=FALSE, echo=F}
DT::datatable(hosp_summary, rownames = FALSE, options = list(pageLength = nrow(10)))
```

Cria um dataframe com as estatísticas de "total" (*sem o agrupamento por hospital*). Isso vai retornar apenas uma linha.  

```{r}
# cria totais
###############
totals <- linelist %>%
  summarise(
    cases = n(), # Número de linhas da base de dados inteira
    ct_value_med = median(ct_blood, na.rm = T)
  ) # CT Mediano para toda a base de dados
```

E abaixo está o dataframe `totals`. Note como tem apenas duas colunas. Essas colunas também está em `hosp_summary`, mas tem uma coluna em `hosp_summary` que não está em `totals` (`hospital`).  

```{r message=FALSE, echo=F}
DT::datatable(totals, rownames = FALSE, options = list(pageLength = nrow(10)))
```

Agora podemos anexar as linhas com `bind_rows()`.  

```{r}
# Bind data frames together
combined <- bind_rows(hosp_summary, totals)
```

Agora podemos visualizar o resultado. Veja como na última linha, um valor vazio, `NA`, preenche a coluna `hospital` que não estava em `hosp_summary`. Como explicado na página [Tabelas para apresentação](#tables-presentation), você pode preencher essa célula com "Total" utilizando `replace_na()`.  

```{r message=FALSE, echo=F}
DT::datatable(combined, rownames = FALSE, options = list(pageLength = nrow(10)))
```


### Anexar colunas {.unnumbered}

Existe uma função similar no **dplyr**, a `bind_cols()` que você pode utilizar para combinar dois dataframes "lateralmente". Note que as linhas são combinadas umas com as outras *por posição* (não como no *join* acima) - por exemplo, a 12ª linha de cada dataframe estarão alinhadas.  

Para demonstrar, vamos anexar várias tabelas de sumário juntas. Para fazer isso, também demonstraremos como rearranjar a ordem das linhas de um dataframe para combinar com a ordem do outro, com `match()`.    

Aqui nós definimos `case_info` como um dataframe de sumário dos casos da linelist, por hospital, com o número de casos e o número de mortes.


```{r}
# Informação dos casos
case_info <- linelist %>%
  group_by(hospital) %>%
  summarise(
    cases = n(),
    deaths = sum(outcome == "Death", na.rm = T)
  )
```

```{r message=FALSE, echo=F}
DT::datatable(case_info, rownames = FALSE, options = list(pageLength = nrow(10)))
```

Então, digamos que haja um dataframe diferente, `contact_fu` (*fu* -> *follow up*), contendo informação acerca da porcentagem de contatos expostos que foram investigados e "acompanhados" (*follow-up*), novamente por hospital. 

```{r}
contact_fu <- data.frame(
  hospital = c("St. Mark's Maternity Hospital (SMMH)", "Military Hospital", "Missing", "Central Hospital", "Port Hospital", "Other"),
  investigated = c("80%", "82%", NA, "78%", "64%", "55%"),
  per_fu = c("60%", "25%", NA, "20%", "75%", "80%") # fu -> follow up
)
```

```{r message=FALSE, echo=F}
DT::datatable(contact_fu, rownames = FALSE, options = list(pageLength = nrow(10)))
```

Note que os hospitais são os mesmos, mas estão em ordens diferentes em cada dataframe. A solução mais fácil seria utilizar `left_join()` na coluna `hospital`, mas você poderia também utilizar `bind_cols()` com um passo extra.  

#### Utilize `match()` para alinhar a ordem {.unnumbered}  

Pelo fato da ordem das linhas ser diferente, um simples `bind_cols()` resultaria em um desalinhamento dos dados. Para consertar isso, podemos utilizar `match()` do **base** R para alinhar as linhas de um dataframe na mesma ordem de outro. Vamos assumir, para essa abordagem, que não há valores duplicados em nenhum dos dataframes. 

Quando utilizamos `match()`, a sintaxe é `match(ORDEM DO VETOR ALVO, COLUNA PARA MUDAR)`, onde o primeiro argumento é a ordem desejada (seja um vetor individual, ou nesse caso, uma coluna do dataframe), e o segundo argumento é uma coluna do dataframe que será reordenado. A saída do `match()` é um vetor de números representando a posição correta do ordenamento. Você pode ler mais com `?match`.  

```{r}
match(case_info$hospital, contact_fu$hospital)
```

Você pode utilizar esse vetor numérico para reordenar o dataframe - coloque ele entre colchetes `[ ]` *antes da vírgula*. Leia mais sobre a sintaxe de subconjuntos com colchetes no **base** R na página [Introdução ao R](#basics). O comando abaixo cria um novo dataframe, definido como o anterior em que as linhas estão ordenadas de acordo com o vetor numérico acima.

```{r}
contact_fu_aligned <- contact_fu[match(case_info$hospital, contact_fu$hospital), ]
```


```{r message=FALSE, echo=F}
DT::datatable(contact_fu_aligned, rownames = FALSE, options = list(pageLength = nrow(10)))
```

Agora podemos anexar as colunas dos dataframes um no outro, com a ordem de linhas correta. Note que algumas colunas estão duplicadas e vão precisar de uma limpeza utilizando `rename()`. Leia mais sobre `bind_rows()` [aqui](https://dplyr.tidyverse.org/reference/bind.html).  

```{r}
bind_cols(case_info, contact_fu)
```

Uma alternativo do R **base** a `bind_cols` é a função `cbind()`, que faz a mesma operação.  




<!-- ======================================================= -->
## Recursos { }

A [página do tidyverse sobre joins](https://dplyr.tidyverse.org/reference/join.html)  

A [página do R for Data Science sobre dados relacionais](https://r4ds.had.co.nz/relational-data.html)  

A [página do tidyverse no dplyr](https://dplyr.tidyverse.org/reference/bind.html) sobre binding (ligação)  

Uma vignette sobre [fastLink](https://github.com/kosukeimai/fastLink) na página do Github do pacote  

Publicação descrevendo a metodologia do [fastLink](https://imai.fas.harvard.edu/research/files/linkage.pdf)  

Publicação descrevendo o [pacote RecordLinkage](https://journal.r-project.org/archive/2010/RJ-2010-017/RJ-2010-017.pdf)




```{r include=FALSE, cache=FALSE}

# clear workspace
rm(list = ls(all = TRUE))

# clear all packages except base
#lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))

# to ensure that tidyverse packages prevail
filter <- dplyr::filter
select <- dplyr::select
summarise <- dplyr::summarise
summary <- base::summary
incidence <- incidence2::incidence

#load core packages
pacman::p_load(
     rio,
     here,
     DT,
     stringr,
     lubridate,
     tidyverse
)

# import the cleaned ebola linelist
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

# import the count data - facility level
#count_data <- rio::import(here::here("data", "facility_count_data.rds"))

# Settings

options(scipen=1, digits=7)

# print only text (not code)
# library(knitr)
# opts_chunk$set(list(echo = FALSE, eval = FALSE))
```

<!--chapter:end:new_pages/joining_matching.Rmd-->


# Eliminação de duplicidades {#deduplication}  

```{r, out.width=c("50%"), echo=F}
knitr::include_graphics(here::here("images", "deduplication.png"))
```

Esta página abrange as seguintes técnicas de eliminação de duplicidades (ou deduplicação):  

1. Identificar e remover duplicidades  
2. "Fatiar/subdividir" linhas para manter apenas algumas linhas (por exemplo, mín. ou máx.) de cada grupo de linhas  
3. "Acumular" ou combinar de valores de várias linhas em uma linha  


<!-- ======================================================= -->
## Preparação


### Carregar pacotes {.unnumbered}

Este pedaço de código mostra o carregamento de pacotes necessários para as análises. Neste manual, enfatizamos `p_load()` de **pacman**, que instala o pacote se necessário *e* o carrega para uso. Você também pode carregar pacotes instalados com `library()` do R **base**. Veja a página em [Introdução ao R](#basics) para mais informações sobre pacotes R.  

```{r}
pacman :: p_load(
  tidyverse, # deduplicação, agrupamento e funções de fatiamento
  janitor, # função para revisar duplicidades
  stringr) # para pesquisas de strings, pode ser usado em valores "rolling-up"
```

### Importar dados {.unnumbered}

Para demonstração, usaremos um conjunto de dados de exemplo criado com o código R abaixo.  

Os dados são registros de encontros telefônicos COVID-19, incluindo encontros com contatos e casos. As colunas incluem `recordID` (gerado por computador), `personID`, `name`, `date` do encontro, `time` do encontro, o `propósito` do encontro (para entrevistar como um caso ou como um contato ), e `symptoms_ever` (se a pessoa nesse encontro relatou *sempre* ter sintomas).  

Aqui está o código para criar o conjunto de dados `obs`:  

```{r}
obs <- data.frame(
  recordID = c(1,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18),
  personID  = c(1,1,2,2,3,2,4,5,6,7,2,1,3,3,4,5,5,7,8),
  name = c("adam", "adam", "amrish", "amrish", "mariah", "amrish", "nikhil", "brian", "smita", "raquel", "amrish",
                "adam", "mariah", "mariah", "nikhil", "brian", "brian", "raquel", "natalie"),
  date = c("01/01/2020", "01/01/2020", "01/02/2020", "01/02/2020", "01/05/2020", "01/05/2020 ", "01/05/2020", "01/05/2020", "01/05/2020", "01/05/2020", "01/02/2020",
                "5/1/2020", "6/1/2020", "6/1/2020", "6/1/2020", "6/1/2020", "7/1/2020", "7/1/2020", "7/1/2020"),
  time = c("09:00", "09:00", "14:20", "14:20", "12:00", "16:10", "13:01", "15:20 ", "14:20", "12:30", "10:24",
                "09:40", "07:25", "08:32", "15:36", "15:31", "07:59", "11:13", "17:12"),
  encounter = c(1,1,1,1,1,3,1,1,1,1,2,
                2,2,3,2,2,3,2,1),
  purpose   = c("contact", "contact", "contact", "contact", "case", "case", "contact", "contact", "contact", "contact", "contact",
                "case", "contact", "contact", "contact", "contact", "case", "contact", "case"),
  symptoms_ever = c(NA, NA, "No", "No", "No", "Yes", "Yes", "No", "Yes", NA, "Yes",
                    "No", "No", "No", "Yes", "Yes", "No","No", "No")) %>%
  mutate(date = as.Date(date, format = "%d/%m/%Y"))
```


#### Aqui está o data frame {#dedup_data .unnumbered}  

Use as caixas de filtro na parte superior para revisar os encontros de cada pessoa.  

```{r, message=FALSE, echo=F}
DT::datatable(head (linelist, 10), rownames = FALSE, filter = "top", options = list(pageLength = 5, scrollX = T), class = 'white-space: nowrap')
```


Algumas coisas a serem observadas ao revisar os dados:  

* Os dois primeiros registros são duplicados 100% completos, incluindo `recordID` duplicado (deve ser uma falha do computador!)  
* As duas segundas linhas são duplicidades, em todas as colunas *exceto para `recordID`*  
* Várias pessoas tiveram vários encontros por telefone, em várias datas e horários, e como contatos e/ou casos  
* Em cada encontro, a pessoa foi perguntada se ela **alguma vez** teve sintomas, e algumas dessas informações estão faltando.  


E aqui está um resumo rápido das pessoas e os propósitos de seus encontros, usando `tabyl()` do **janitor**:  

```{r}
obs %>% 
  tabyl(name, purpose)
```
<!-- ======================================================= -->
## Remoção de duplicidades { }


Esta seção descreve como revisar e remover duplicidades em um data frame. Também mostra como lidar com elementos duplicados em um vetor.  


<!-- ======================================================= -->
### Examinar duplicidades {.unnumbered}  


Para revisar rapidamente as linhas que têm duplicidades, você pode usar `get_dupes()` do pacote **janitor**. *Por padrão*, todas as colunas são consideradas quando as duplicidades são avaliadas - as linhas retornadas pela função são 100% duplicadas considerando os valores em *todas* as colunas.  

No data frame `obs`, as duas primeiras linhas são *100% duplicadas* - elas têm o mesmo valor em todas as colunas (incluindo a coluna `recordID`, que *supõe* ser única - deve ser alguma falha do computador ). O data frame retornado inclui automaticamente uma nova coluna `dupe_count` no lado direito, mostrando o número de linhas com essa combinação de valores duplicados. 

```{r, eval=F}
# 100% duplicados em todas as colunas
obs %>% 
  janitor::get_dupes()
```

```{r, message=FALSE, echo=F}
obs %>% 
  janitor::get_dupes() %>% 
  DT::datatable(rownames = FALSE, options = list(pageLength = 10, scrollX = T), class = 'white-space: nowrap')
```

Veja os [dados originais](#dedup_data)  

No entanto, se optarmos por ignorar `recordID`, as linhas da 3ª e 4ª linhas também serão duplicadas umas das outras. Ou seja, eles têm os mesmos valores em todas as colunas *exceto* para `recordID`. Você pode especificar colunas específicas a serem ignoradas na função usando um símbolo de menos `-`.  

```{r, eval=F}
# Duplica quando a coluna recordID não é considerada
obs %>% 
  janitor::get_dupes(-recordID) # se várias colunas, envolva-as em c()
```

```{r, message=FALSE, echo=F}
obs %>% 
  janitor::get_dupes(-recordID) %>% 
  DT::datatable(rownames = FALSE, options = list(pageLength = 10, scrollX = T), class = 'white-space: nowrap')
```

Você também pode especificar positivamente as colunas a serem consideradas. Abaixo, apenas as linhas que possuem os mesmos valores nas colunas `name` e `purpose` são retornadas. Observe como "amrish" agora tem `dupe_count` igual a 3 para refletir seus três encontros de "contato".  

**Role para a esquerda para mais linhas**  

```{r, eval=F}
# duplicatas com base nas colunas de nome e propósito SOMENTE
obs %>% 
  janitor::get_dupes(name, purpose)
```

```{r, message=FALSE, echo=F}
obs %>% 
  janitor::get_dupes(name, purpose) %>% 
  DT::datatable(rownames = FALSE, options = list(pageLength = 7, scrollX = T), class = 'white-space: nowrap')
```

Veja os [dados originais](#dedup_data).  

Veja `?get_dupes` para mais detalhes, ou veja esta [referência online](https://cran.r-project.org/web/packages/janitor/vignettes/janitor.html#explore-records-with-duplicated-values -para-combinações-específicas-de-variáveis-com-get_dupes)  






<!-- ======================================================= -->
### Manter apenas linhas únicas {.unnumbered}


Para manter apenas linhas exclusivas de um data frame, use `distinct()` de **dplyr** (conforme demonstrado na página [Limpeza de dados e funções principais](#cleaning)). As duplicidades são removidas de forma que apenas a primeira dessas linhas seja mantida. Por padrão, "primeiro" significa o maior `número da linha` (ordem das linhas de cima para baixo). Apenas linhas exclusivas permanecem.  

No exemplo abaixo, executamos `distinct()` de forma que a coluna `recordID` seja excluída da consideração - portanto, **duas linhas duplicadas são removidas**. A primeira linha (para "adam") foi 100% duplicada e foi removida. Além disso, a linha 3 (para "amrish") era uma duplicata em todas as colunas *exceto* `recordID` (que não está sendo considerada) e, portanto, também foi removida. O conjunto de dados `obs` n agora é `nrow(obs)-2`, não `nrow(obs)` linhas).  

*Role para a esquerda para ver todo o data frame*  


```{r, eval=F}
# adicionado a uma cadeia de pipes (por exemplo, limpeza de dados)
obs %>% 
  distinct(across(-recordID), # reduz o data frame para apenas linhas únicas (mantém a primeira de todas as duplicidades)
           .keep_all = TRUE)

# se fora de pipes, inclua os dados como primeiro argumento 
# distinct(obs)
```

```{r, message=FALSE, echo=F}
obs %>% 
  distinct(across(-recordID), # reduz o data frame para apenas linhas únicas (mantém a primeira de todas as duplicidades)
           .keep_all = TRUE) %>%
  DT::datatable(rownames = FALSE, options = list(pageLength = 6, scrollX = T), class = 'white-space: nowrap')
```

<span style="color: orange;">**_CUIDADO:_** Se estiver usando `distinct()` em dados agrupados, a função será aplicada a cada grupo.</span>


**Remover duplicidades com base em colunas específicas**  

Você também pode especificar colunas para serem a base para eliminação de duplicação. Dessa forma, a eliminação de duplicidades se aplica apenas a linhas duplicadas nas colunas especificadas. A menos que você defina `.keep_all = TRUE`, todas as colunas não mencionadas serão descartadas.  

No exemplo abaixo, a eliminação de duplicidades se aplica apenas a linhas com valores idênticos para as colunas `name` e `purpose`. Assim, "brian" tem apenas 2 linhas em vez de 3 - seu *primeiro* encontro de "contato" e seu único encontro de "caso". Para ajustar para que o *último* encontro de brian de cada propósito seja mantido, veja a aba Fatiar dentro de grupos.  

*Role para a esquerda para ver todo o data frame*  

```{r, eval=F}
# adicionado a uma cadeia de pipes (por exemplo, limpeza de dados)
obs %>% 
  distinct(name, purpose, .keep_all = TRUE) %>% # mantém as linhas únicas por nome e propósito, mantém todas as colunas
  arrange(name)       # organize para facilitar a visualização
```

```{r, message=FALSE, echo=F}
obs %>% 
  distinct(name, purpose, .keep_all = TRUE) %>% # mantém as linhas únicas por nome e propósito, mantém todas as colunas
  arrange(name) %>% 
  DT::datatable(rownames = FALSE, options = list(pageLength = 6, scrollX = T), class = 'white-space: nowrap')
```

Veja os [dados originais](#dedup_data).  

<!-- ======================================================= -->
### Remover duplicidades em um vetor {.unnumbered}  


A função `duplicated()` do R **base** avaliará um vetor (coluna) e retornará um vetor lógico de mesmo comprimento (VERDADEIRO/FALSO). Na primeira vez que um valor aparecer, ele retornará FALSE (não uma duplicata) e, nas próximas vezes em que esse valor aparecer, ele retornará TRUE. Observe como `NA` é tratado da mesma forma que qualquer outro valor.    

```{r}
x <- c(1, 1, 2, NA, NA, 4, 5, 4, 4, 1, 2)
duplicated(x)
```

Para retornar apenas os elementos duplicados, você pode usar colchetes para subconjunto do vetor original: 

```{r}
x[duplicated(x)]
```

Para retornar apenas os elementos exclusivos, use a função `unique()` do R **base**. Para remover `NA`s da saída, aninhe `na.omit()` dentro de `unique()`.  

```{r}
unique(x) # alternativamente, use x[!duplicated(x)]
unique(na.omit(x)) # remove NAs 
```


<!-- ======================================================= -->
### Usando o R **base** {.unnumbered}

**Para retornar linhas duplicadas**  

No R **base**, você também pode ver quais linhas são 100% duplicadas em um data frame `df` com o comando `duplicated(df)` (retorna um vetor lógico das linhas).  

Assim, você também pode usar o subconjunto base `[ ]` no data frame para ver as linhas *duplicadas* com `df[duplicated(df),]` (não esqueça a vírgula, significando que você quer ver todas colunas!). 

**Para retornar linhas exclusivas**  

Veja as notas acima. Para ver as linhas *únicas*, você adiciona o negador lógico `!` na frente da função `duplicated()`:  
`df[!duplicado(df),]`  


**Para retornar linhas que são duplicidades em determinadas colunas**  

Subsete o `df` que está *dentro dos parênteses `duplicated()`*, então esta função irá operar apenas em certas colunas do `df`.  

Para especificar as colunas, forneça os números ou nomes das colunas após uma vírgula (lembre-se, tudo isso está *dentro* da função `duplicated()`).  

Certifique-se de manter a vírgula `,` *fora* após a função `duplicated()` também! 

Por exemplo, para avaliar apenas as colunas de 2 a 5 para duplicatas: `df[!duplicated(df[, 2:5]),]`  
Para avaliar apenas as colunas `name` e `purpose` para duplicatas: `df[!duplicated(df[, c("name", "purpose)]),]`  





<!-- ======================================================= -->
## Fatiar/Subdividir { }


Subdividir um data frame, ou "fatiá-lo" (literalmente do inglês *slice*), significa aplicar um filtro nas linhas por número/posição de linha. Isso se torna particularmente útil se você tiver várias linhas por grupo funcional (por exemplo, por "pessoa") e quiser manter apenas uma ou algumas delas. 

A função básica `slice()` aceita números e retorna linhas nessas posições. Se os números fornecidos forem positivos, somente eles serão retornados. Se negativo, essas linhas *não* são retornadas. Os números devem ser todos positivos ou todos negativos.     

```{r}
obs %>% slice(4) # retorna a 4ª linha
```

```{r}
obs %>% slice(c(2,4)) # retorna as linhas 2 e 4
#obs %>% slice(c(2:4)) # retorna as linhas 2 a 4
```


Veja os [dados originais](#dedup_data). 

Existem várias variações:  Estes devem ser fornecidos com uma coluna e um número de linhas para retornar (para `n = `).  

* `slice_min()` e `slice_max()` mantêm apenas a(s) linha(s) com o(s) valor(es) mínimo(s) ou máximo(s) da coluna especificada. Isso também funciona para retornar o "min" e o "max" dos fatores ordenados.    
* `slice_head()` e `slice_tail()` - mantém apenas a *primeira* ou *última* linha(s).  
* `slice_sample()` - mantém apenas uma amostra aleatória das linhas.  


```{r}
obs %>% slice_max(encounter, n = 1) # retorna linhas com o maior número de encontro
```

Use argumentos `n = ` ou `prop = ` para especificar o número ou a proporção de linhas a serem mantidas. Se não estiver usando a função em uma cadeia de pipes, forneça primeiro o argumento de dados (por exemplo, `slice(data, n = 2)`). Veja `?slice` para mais informações. 

Outros argumentos:  

`.order_by = ` usado em `slice_min()` e `slice_max()` esta é uma coluna para ordenar antes de fatiar.  
`with_ties = ` TRUE por padrão, significando que os empates são mantidos.  
`.preserve = ` FALSE por padrão. Se TRUE, a estrutura de agrupamento é recalculada após o fatiamento.  
`weight_by = ` Opcional, coluna numérica para ponderar (número maior com maior probabilidade de ser amostrado).  Também `replace = ` para se a amostragem é feita com/sem substituição.  

<span style="color: darkgreen;">**_DICA:_** Ao usar `slice_max()` e `slice_min()`, certifique-se de especificar/escrever o `n = ` (por exemplo, `n = 2` , não apenas `2`). Caso contrário, você pode receber um erro `Erro: `...` não está vazio.` </span>

<span style="color: black;">**_NOTE:_** Você pode encontrar a função [`top_n()`](https://dplyr.tidyverse.org/reference/top_n.html), que tem foi substituído pelas funções `slice`.</span>

 


<!-- ======================================================= -->
### Subdividão com grupos {.unnumbered}

As funções `slice_*()` podem ser muito úteis se aplicadas a um data frame agrupado porque a operação de fatia é executada em cada grupo separadamente. Use a **função** `group_by()` em conjunto com `slice()` para agrupar os dados para obter uma fatia de cada grupo.  

Isso é útil para a eliminação de duplicação se você tiver várias linhas por pessoa, mas quiser manter apenas uma delas. Você primeiro usa `group_by()` com colunas-chave que são as mesmas por pessoa e, em seguida, usa uma função de fatia em uma coluna que será diferente entre as linhas agrupadas.  

No exemplo abaixo, para manter apenas o *último* encontro *por pessoa*, agrupamos as linhas por `name` e então usamos `slice_max()` com `n = 1` na coluna `date`. Estar ciente! Para aplicar uma função como `slice_max()` em datas, a coluna de data deve ser da classe Date.   

Por padrão, "empates" (por exemplo, mesma data neste cenário) são mantidos e ainda obteríamos várias linhas para algumas pessoas (por exemplo, adam). Para evitar isso, configuramos `with_ties = FALSE`. Retornamos apenas uma fila por pessoa.  

<span style="color: orange;">**_CAUTION:_** Se estiver usando `arrange()`, especifique `.by_group = TRUE` para organizar os dados em cada grupo.</span>

<span style="color: red;">**_DANGER:_** Se `with_ties = FALSE`, a primeira linha de um empate é mantida. Isso pode ser enganoso. Veja como para Mariah, ela tem dois encontros em sua última data (6 de janeiro) e o primeiro (mais antigo) foi mantido. Provavelmente, queremos manter seu encontro posterior naquele dia. Veja como "quebrar" esses empates no próximo exemplo. </span>  




```{r, eval=F}
obs %>% 
  group_by(name) %>% # agrupa as linhas por 'name'
  slice_max(date, # mantém linha por grupo com valor máximo de data 
            n = 1, # mantém apenas a linha mais alta
            with_ties = F) # se houver empate (de data), pegue a primeira linha
```

```{r, message=FALSE, echo=F}
obs %>% 
  group_by(name) %>% # agrupa as linhas por 'name'
  slice_max(date, # mantém linha por grupo com valor máximo de data 
            n = 1, # mantém apenas a linha mais alta
            with_ties = F) %>% # se houver empate (de data), pegue a primeira linha
  DT::datatable(rownames = FALSE, options = list(pageLength = 8, scrollX = T), class = 'white-space: nowrap')
```

Acima, por exemplo, podemos ver que apenas a linha de Amrish em 5 de janeiro foi mantida, e apenas a linha de Brian em 7 de janeiro foi mantida. Veja os [dados originais](#dedup_data).  


**"Desempates"**  

Várias instruções de fatia podem ser executadas para "desempate". Neste caso, se uma pessoa tiver vários encontros em sua última *data*, o encontro com a última *hora* é mantido (`lubridate::hm()` é usado para converter os tempos dos caracteres em uma classe de tempo classificável).  
Observe como agora, a única linha mantida para "Mariah" em 6 de janeiro é o encontro 3 das 08:32, não o encontro 2 às 07:25.  

```{r, eval=F}
# Exemplo de várias instruções de fatia para "desempate"
obs %>%
  group_by(name) %>%
  
  # PRIMEIRO - fatia por data mais recente
  slice_max(date, n = 1, with_ties = TRUE) %>% 
  
  # SEGUNDO - se houver empate, selecione a linha com o horário mais recente; empates proibidos
  slice_max(lubridate::hm(time), n = 1, with_ties = FALSE)
```

```{r, message=FALSE, echo=F}
# Exemplo de várias instruções de fatia para "desempate"
obs %>%
  group_by(name) %>%
  
  # PRIMEIRO - fatia por data mais recente
  slice_max(date, n = 1, with_ties = TRUE) %>% 
  
  # SEGUNDO - se houver empate, selecione a linha com o horário mais recente; empates proibidos
  slice_max(lubridate::hm(time), n = 1, with_ties = FALSE) %>% 
  
  DT::datatable(rownames = FALSE, options = list(pageLength = 8, scrollX = T), class = 'white-space: nowrap')
```

*No exemplo acima, também seria possível dividir por número de `encounter`, mas mostramos a fatia em `data` e `hora` para fins de exemplo.*  

<span style="color: darkgreen;">**_DICA:_** Para usar `slice_max()` ou `slice_min()` em uma coluna "character", altere-a para uma classe de fator *ordenada*!</span> extensão>

Veja os [dados originais](#dedup_data).  


<!-- ======================================================= -->
### Mantenha tudo mas marque-os {.unnumbered}

Se você quiser manter todos os registros, mas marcar apenas alguns para análise, considere uma abordagem de duas etapas utilizando um recordID/número de encontro exclusivo:  

1) Reduza/faça o recorte do data frame original apenas nas linhas para análise. Salve/retenha este data frame reduzido.  
2) No data frame original, marque as linhas conforme apropriado com `case_when()`, com base no fato de seu identificador exclusivo de registro (recordID neste exemplo) estar presente no data frame reduzido.  


```{r}
# 1. Defina o data frame de linhas para manter para análise
obs_keep <- obs %>%
  group_by(name) %>%
  slice_max(encounter, n = 1, with_ties = FALSE) # mantém apenas o último encontro por pessoa


# 2. Marcar data frame original
obs_marked <- obs %>%

  # cria uma nova coluna dup_record
  mutate(dup_record = case_when(
    
    # se o registro estiver no data frame obs_keep
    recordID %in% obs_keep$recordID ~ "Para análise", 
    
    # tudo o mais marcado como "Ignorar" para fins de análise
    TRUE ~ "Ignorar"))

# imprimir
obs_marked
```


```{r, echo=F}
DT::datatable(obs_marked, rownames = FALSE, options = list(pageLength = 8, scrollX = T), class = 'white-space: nowrap')
```

Veja os [dados originais](#dedup_data).  

<!-- ======================================================= -->
### Calcular a completitude da linha {.unnumbered} 

Crie uma coluna que contenha uma métrica para a completitude da linha (não falta). Isso pode ser útil ao decidir quais linhas priorizar em relação a outras ao remover duplicidade/fatiar.  

Neste exemplo, as colunas "chave" sobre as quais você deseja medir a integridade são salvas em um vetor de nomes de coluna.  

Então a nova coluna `key_completeness` é criada com `mutate()`. O novo valor em cada linha é definido como uma fração calculada: o número de valores não omissos nessa linha entre as colunas-chave, dividido pelo número de colunas-chave.  

Isso envolve a função `rowSums()` do R **base**. Também é usado `.`, que dentro do  encadeamento do código (pipe - %>%) se refere ao data frame naquele ponto do pipe (neste caso, está sendo subconjunto com colchetes `[]`).  

*Role para a direita para ver mais linhas**  

```{r, eval=F}
# cria uma coluna "completude da variável chave"
# esta é uma *proporção* das colunas designadas como "key_cols" que não possuem valores omissos

key_cols = c("personID", "name", "symptoms_ever")

obs %>% 
  mutate(key_completeness = rowSums(!is.na(.[,key_cols]))/length(key_cols)) 
```

```{r, message=FALSE, echo=F}
key_cols = c("personID", "name", "symptoms_ever")

obs %>% 
  mutate(key_completeness = rowSums(!is.na(.[,key_cols]))/length(key_cols)) %>% 
  DT::datatable(rownames = FALSE, options = list(pageLength = 5, scrollX = T), class = 'white-space: nowrap')
```

Veja os [dados originais](#dedup_data).  




<!-- ======================================================= -->
## Valores acumulados {#str_rollup}


Esta seção descreve:  

1) Como "agregar" valores de várias linhas em apenas uma linha, com algumas variações  
2) Depois de ter os valores "acumulados", como substituir/priorizar os valores em cada célula  

Esta guia usa o conjunto de dados de exemplo da guia Preparação.  



<!-- ======================================================= -->
### Valores acumulados em uma linha {.unnumbered}  

O exemplo de código abaixo usa `group_by()` e `summarise()` para agrupar linhas por pessoa e depois colar todos os valores exclusivos nas linhas agrupadas. Assim, você obtém uma linha de resumo por pessoa. Algumas notas:  

* Um sufixo é anexado a todas as novas colunas ("_roll" neste exemplo)  
* Se você quiser mostrar apenas valores exclusivos por célula, envolva o `na.omit()` com `unique()`  
* `na.omit()` remove valores `NA`, mas se isso não for desejado, pode ser removido `paste0(.x)`...  



```{r, eval=F}
# Valores "roll-up" em uma linha por grupo (por "personID") 
cases_rolled <- obs %>% 
  
  #cria grupos por nome
  group_by(personID) %>% 
  
  # ordena as linhas dentro de cada grupo (por exemplo, por data)
  arrange(date, .by_group = TRUE) %>% 
  
  # Para cada coluna, cole todos os valores dentro das linhas agrupadas, separados por ";"
  summarise(
    across(everything(), # aplica-se a todas as colunas
           ~paste0(na.omit(.x), collapse = "; ")))) # função é definida que combina valores não-NA
```

O resultado é uma linha por grupo (`ID`), com entradas organizadas por data e coladas juntas. *Role para a esquerda para ver mais linhas*    

```{r, message=FALSE, echo=F}
# Valores "roll-up" em uma linha por grupo (por "personID") 
obs %>% 
  
  #cria grupos por nome
  group_by(personID) %>% 
  
  # ordena as linhas dentro de cada grupo (por exemplo, por data)
  arrange(date, .by_group = TRUE) %>% 
  
  # Para cada coluna, cole todos os valores dentro das linhas agrupadas, separados por ";"
  summarise(
    across(everything(), # aplica-se a todas as colunas
           ~paste0(na.omit(.x), collapse = "; "))) %>% # função é definida que combina valores não-NA

  DT::datatable(rownames = FALSE, options = list(pageLength = 5, scrollX = T), class = 'white-space: nowrap')
```

Veja os [dados originais](#dedup_data).  


**Esta variação mostra apenas valores únicos:**  

```{r}
# Variação - mostra apenas valores únicos 
cases_rolled <- obs %>% 
  group_by(personID) %>% 
  arrange(date, .by_group = TRUE) %>% 
  summarise(
    across(everything(), # aplica-se a todas as colunas
           ~paste0(unique(na.omit(.x)), collapse = "; "))) # função é definida que combina valores únicos não-NA
```

```{r, message=FALSE, echo=F}
# Variação - mostra apenas valores únicos 
obs %>% 
  group_by(personID) %>% 
  arrange(date, .by_group = TRUE) %>% 
  summarise(
    across(everything(), # aplica-se a todas as colunas
           ~paste0(unique(na.omit(.x)), collapse = "; "))) %>% # função é definida que combina valores únicos não-NA

  DT::datatable(rownames = FALSE, options = list(pageLength = 5, scrollX = T), class = 'white-space: nowrap')
```


**Esta variação anexa um sufixo a cada coluna.**  
Neste caso "_roll" para significar que foi agregado:  

```{r, eval=F}
# Variação - sufixo adicionado aos nomes das colunas 
cases_rolled <- obs %>% 
  group_by(personID) %>% 
  arrange(date, .by_group = TRUE) %>% 
  summarise(
    across(everything(),                
           list(roll = ~paste0(na.omit(.x), collapse = "; ")))) # _roll é anexado aos nomes das colunas
```

```{r, message=FALSE, echo=F}
# exibe os dados da linelist como uma tabela
# Variação - sufixo adicionado aos nomes das colunas 
obs %>% 
  group_by(personID) %>% 
  arrange(date, .by_group = TRUE) %>% 
  summarise(
    across(everything(),                
           list(roll = ~paste0(na.omit(.x), collapse = "; ")))) %>% # _roll é anexado aos nomes das colunas
  DT::datatable(rownames = FALSE, options = list(pageLength = 5, scrollX = T), class = 'white-space: nowrap')
```


<!-- ======================================================= -->
### Substituir valores/hierarquia {.unnumbered} 


Se você quiser avaliar todos os valores rolados e manter apenas um valor específico (por exemplo, valor "melhor" ou "máximo"), você pode usar `mutate()` nas colunas desejadas, para implementar `case_when()` , que usa `str_detect()` do pacote **stringr** para procurar sequencialmente padrões de string e sobrescrever o conteúdo da célula.  

```{r}
# CASOS LIMPOS
#############
cases_clean <- cases_rolled %>% 
# limpar vars Yes-No-Unknown: substitui o texto pelo valor "mais alto" presente na string
mutate(across(c(contains("symptoms_ever")), # opera em colunas especificadas (S/N/U)
       list(mod = ~case_when( # adiciona o sufixo "_mod" a new cols; implementa case_when()
               
       str_detect(.x, "Sim") ~ "Sim", # se "Sim" for detectado, o valor da célula será convertido em sim
       str_detect(.x, "No") ~ "No", # então, se "No" for detectado, o valor da célula será convertido em não
       str_detect(.x, "Desconhecido") ~ "Desconhecido", # então, se "Desconhecido" for detectado, o valor da célula será convertido em Desconhecido
               TRUE ~ as.character(.x)))), # então, se mais alguma coisa se mantiver como está
      .keep = "unused") # colunas antigas removidas, deixando apenas colunas _mod
```


Agora você pode ver na coluna `symptoms_ever` que se a pessoa ALGUMA VEZ disse "Sim" aos sintomas, então apenas "Sim" é exibido.  

```{r, message=FALSE, echo=F}
# exibe os dados da linelist como uma tabela
DT::datatable(cases_clean, rownames = FALSE, options = list(pageLength = 10, scrollX = T), class = 'white-space: nowrap')
```


Veja os [dados originais](#dedup_data).  


## Remoção de duplicidades probabilística  

Às vezes, você pode querer identificar duplicidades "prováveis" com base na semelhança (por exemplo, string "distance") em várias colunas, como nome, idade, sexo, data de nascimento etc. Você pode aplicar um algoritmo de correspondência probabilística para identificar duplicidades prováveis.  

Consulte a página em [Juntar dados](#joining-matching) para obter uma explicação sobre este método. A seção sobre Correspondência Probabilística contém um exemplo de aplicação desses algoritmos para comparar um data frame com o *próprio*, realizando assim a desduplicação probabilística.  



<!-- ======================================================= -->
## Recursos {}

Muitas das informações nesta página são adaptadas destes recursos e vinhetas online:  

[datanovia](https://www.datanovia.com/en/lessons/identify-and-remove-duplicate-data-in-r/)

[dplyr tidyverse reference](https://dplyr.tidyverse.org/reference/slice.html)  

[vinheta de janitor de cran](https://cran.r-project.org/web/packages/janitor/vignettes/janitor.html#explore-records-with-duplicated-values-for-specific-combinations-of-variables- com-get_dupes)  
```{r include=FALSE, cache=FALSE}

# clear workspace
rm(list = ls(all = TRUE))

# clear all packages except base
#lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))

# to ensure that tidyverse packages prevail
filter <- dplyr::filter
select <- dplyr::select
summarise <- dplyr::summarise
summary <- base::summary
incidence <- incidence2::incidence

#load core packages
pacman::p_load(
     rio,
     here,
     DT,
     stringr,
     lubridate,
     tidyverse
)

# import the cleaned ebola linelist
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

# import the count data - facility level
#count_data <- rio::import(here::here("data", "facility_count_data.rds"))

# Settings

options(scipen=1, digits=7)

# print only text (not code)
# library(knitr)
# opts_chunk$set(list(echo = FALSE, eval = FALSE))
```

<!--chapter:end:new_pages/deduplication.Rmd-->

# Iterações, loops e listas {#iteration}

Os epidemiologistas muitas vezes se deparam com análises repetidas em subgrupos, como países, distritos ou faixas etárias. Estas são apenas algumas das muitas situações envolvendo *iteração*. Codificar suas operações iterativamente usando as abordagens abaixo ajudará você a executar essas tarefas repetitivas mais rapidamente, reduzir a chance de erro e reduzir o comprimento do código.

Esta página apresentará duas abordagens para operações iterativas - usando os *loops for* e usando o pacote **purrr**.

1)  *loops for* iteram código a partir de uma série de entradas, mas são menos comuns em R do que em outras linguagens de programação. No entanto, nós os apresentamos aqui como uma ferramenta de aprendizagem e referência
2)  O pacote **purrr** é a abordagem **tidyverse** para operações iterativas - ele funciona "mapeando" uma função em muitas entradas (valores, colunas, conjuntos de dados etc.)

Ao longo do caminho, mostraremos exemplos como:

-   Importando e exportando vários arquivos
-   Criando curvas epidemiológicas para várias jurisdições
-   Executando testes T para várias colunas em um data frame

Na [seção](#iter_purrr) **purrr** também forneceremos vários exemplos de criação e manipulação de `listas`.

## Preparação

### Carregando pacotes {.unnumbered}

Este trecho de código mostra o carregamento de pacotes necessários para as análises. Neste livro nós enfatizamos o `p_load()` do **pacman**, que instala o pacote, se necessário, *e* o carrega para uso. Você também pode carregar pacotes instalados com o `library()` do R **base**. Veja a página sobre o [R - o básico] para mais informações sobre pacotes R.

```{r}
pacman::p_load(
     rio,         # importa/exporta
     here,        # localizador de arquivos
     purrr,       # iteração
     grates,      # scales in ggplot
     tidyverse    # gerenciamento e visualização de dados
)
```

### Importando dados {.unnumbered}

Importamos o conjunto de dados de casos de uma epidemia simulada de Ebola. Se você quiser acompanhar <a href='https://github.com/appliedepi/epirhandbook_eng/raw/master/data/case_linelists/linelist_cleaned.rds' class='download-button'>clique aqui para fazer download da linelist "limpa"</a> (como um arquivo .rds). Importamos os dados com a função `import()` do pacote **rio** (ela lida com muitos tipos de arquivos como .xlsx, .csv, .rds - veja a página [Importar e exportar](#importing) para detalhes).

```{r, echo=F}
# importando a linelist para o R
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))
```

```{r, eval=F}
# importando a linelist
linelist <- import("linelist_cleaned.rds")
```

As primeiras 50 linhas da linelist são exibidas abaixo.

```{r, message=FALSE, echo=F}
# exibindo os dados da linelist como uma tabela
DT::datatable(head(linelist, 50), rownames = FALSE, options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap')
```

<!-- ======================================================= -->

## *loops for*

### *loops for* no R {#iter_loops .unnumbered}

*loops for* não são enfatizados em R, mas são comuns em outras linguagens de programação. Para iniciantes, eles podem ser úteis para aprender e praticar porque são mais fáceis de "explorar", "depurar" e entender exatamente o que está acontecendo para cada iteração, especialmente quando você ainda não está confortável em escrever suas próprias funções .

Você pode passar rapidamente do *loop for* para iterar com funções mapeadas com o **purrr** (consulte a [seção abaixo](#iter_purrr))

### Principais componentes {.unnumbered}

Um *loop for* tem três partes principais:

1)  A **sequência** de itens para percorrer
2)  As **operações** a serem conduzidas por item na sequência
3)  O **contêiner** para armazenar os resultados (opcional)

A sintaxe básica é: `for (item em sequência) {fazer operações usando item}`. Observe os parênteses e os colchetes. Os resultados podem ser impressos no console ou armazenados em um objeto R (o container).

Um exemplo simples de *loop for* está abaixo.

```{r}
for (num in c(1,2,3,4,5)) {  # a SEQUÊNCIA é definida (números 1 a 5) e o loop é aberto com "{"
  print(num + 2)             # As OPERAÇÕES (adicione dois a cada número de sequência e imprima)
}                            # O loop é fechado com "}"                           
                             
```

### Sequência {.unnumbered}

Esta é a parte "for" de um *loop for* - as operações serão executadas "para" cada item na sequência. A sequência pode ser uma série de valores (por exemplo, nomes de jurisdições, doenças, nomes de colunas, elementos de lista, etc.), ou pode ser uma série de números consecutivos (por exemplo, 1,2,3,4,5). Cada abordagem tem suas próprias utilidades, descritas abaixo.

A estrutura básica de uma instrução de sequência é `item em vetor`.

-   Você pode escrever qualquer caractere ou palavra no lugar de "item" (por exemplo, "i", "num", "hosp", "distrito", etc.). O valor desse "item" muda a cada iteração do loop, passando por cada valor no vetor.
-   O *vetor* pode ser de valores do tipo caracteres, nomes de colunas ou talvez uma sequência de números - esses são os valores que mudarão a cada iteração. Você pode usá-los nas operações do *loop for* usando o termo "item".

**Exemplo: sequência de valores de caracteres**

Neste exemplo, um loop é executado para cada valor em um vetor de caracteres predefinido de nomes de hospitais.

```{r}
# criando um vetor com os nomes dos hospitais
hospital_names <- unique(linelist$hospital)
hospital_names # printe (mostre o nome do hospital)
```

Escolhemos o termo `hosp` para representar valores do vetor `hospital_names`. Para a primeira iteração do loop, o valor de `hosp` será `hospital_names[[1]]`. Para o segundo loop será `hospital_names[[2]]`. E assim por diante...

```{r, eval=F}
# um 'loop for' com sequência de caracteres

for (hosp in hospital_names){       # sequência
  
       # OPERAÇÕES AQUI
  }
```

**Exemplo: sequência de nomes de colunas**

Esta é uma variação da sequência de caracteres acima, na qual os nomes de um objeto R existente são extraídos e se tornam o vetor. Por exemplo, os nomes das colunas de um data frame. Convenientemente, no código de operações do *loop for*, os nomes das colunas podem ser usados para *indexar* (subconjunto) seu data frame original.

Abaixo, a sequência é o `names()` (nomes das colunas) do data frame `linelist`. Nosso nome de "item" é `col`, que representará o nome de cada coluna à medida que os loops prosseguem.

Para fins de exemplo, incluímos o código de operações dentro do *loop for*, que é executado para cada valor na sequência. Neste código, os valores de sequência (nomes das colunas) são usados para *indexar* (subconjunto) `linelist`, um de cada vez. Conforme ensinado na página [Introdução ao R](#basics), colchetes duplos `[[ ]]` são usados para subconjunto. A coluna resultante é passada para `is.na()`, então para `sum()` para produzir o número de valores na coluna que estão faltando. O resultado é impresso no console - um número para cada coluna.

```{r}
for (col in names(linelist)){        # o loop é executado para cada coluna na linelist; nome da coluna representado por "col" 
  
  # Exemplo de código de operações - printe o número de valores ausentes na coluna
  print(sum(is.na(linelist[[col]])))  # linelist é indexado pelo valor atual de "col"
     
}
```

**Sequência de números**

Nesta abordagem, a sequência é uma série de números consecutivos. Assim, o valor do "item" não é um valor de caractere (por exemplo, "Hospital Central" ou "data_onset"), mas é um número. Isso é útil para fazer loop pelos data frames, pois você pode usar o número do "item" dentro do *loop for* para indexar o data frame pelo *número da linha*.

Por exemplo, digamos que você queira percorrer cada linha em seu data frame e extrair determinadas informações. Seus "itens" seriam números de linha numéricos. Frequentemente, "itens" neste caso são escritos como `i`.

O processo *loop for* pode ser explicado em palavras como "para cada item em uma sequência de números de 1 ao número total de linhas no meu data frame, faça X". Para a primeira iteração do loop, o valor de "item" `i` seria 1. Para a segunda iteração, `i` seria 2, etc.

Aqui está a aparência da sequência no código: `for (i in 1:nrow(linelist)) {OPERATIONS CODE}` onde `i` representa o "item" e `1:nrow(linelist)` produz uma sequência de números de 1 até o número de linhas em `linelist`.

```{r, eval=F}
for (i in 1:nrow(linelist)) {  # use em um data frame
  # OPERAÇÕES AQUI
}  
```

Se você deseja que a sequência seja de números, mas está começando de um vetor (não de um data frame), use o atalho `seq_along()` para retornar uma sequência de números para cada elemento do vetor. Por exemplo, `for (i in seq_along(hospital_names) {OPERATIONS CODE}`.

O código abaixo na verdade retorna números, que se tornariam o valor de `i` em seu respectivo loop.

```{r}
seq_along(hospital_names)  # use em um vetor de nomes
```

Uma vantagem de usar números na sequência é que é fácil também usar o número `i` para indexar um *contêiner* que armazena as saídas do loop. Há um exemplo disso na seção Operações abaixo.

### Operações {.unnumbered}

Este é o código dentro das chaves `{ }` do *loop for*. Você deseja que esse código seja executado para cada "item" na *sequência*. Portanto, tome cuidado para que cada parte do seu código que muda pelo "item" seja codificada corretamente de forma que realmente mude! Por exemplo, lembre-se de usar `[[ ]]` para indexação.

No exemplo abaixo, iteramos em cada linha na `linelist`. Os valores `gender` e `age` de cada linha são colados e armazenados no vetor de caracteres do contêiner `cases_demographics`. Observe como também usamos a indexação `[[i]]` para salvar a saída do loop na posição correta no vetor "contêiner".

```{r}
# criando contêiner para armazenar resultados - um vetor de caractere
cases_demographics <- vector(mode = "character", length = nrow(linelist))

# o loop for
for (i in 1:nrow(linelist)){
  
  # OPERAÇÕES
  # extraindo valores da linelist para a linha i, usando colchetes para indexação
  row_gender  <- linelist$gender[[i]]
  row_age     <- linelist$age_years[[i]]    # não se esqueça de indexar!
     
  # combinando gender-age e armazenar no vetor de contêiner no local indexado
  cases_demographics[[i]] <- str_c(row_gender, row_age, sep = ",") 

}  # finalizando o loop for


# exibindo as primeiras 10 linhas do contêiner
head(cases_demographics, 10)
```

### Contêiner {.unnumbered}

Às vezes, os resultados do seu *loop for* serão impressos no console ou no painel RStudio Plots. Outras vezes, você desejará armazenar as saídas em um "contêiner" para uso posterior. Esse contêiner pode ser um vetor, um data frame ou até mesmo uma lista.

É mais eficiente criar o contêiner para os resultados *antes* mesmo de iniciar o *loop*. Na prática, isso significa criar um vetor, data frame ou lista vazio. Estes podem ser criados com as funções `vector()` para vetores ou listas, ou com `matrix()` e `data.frame()` para um data frame.

**Vetor vazio**

Use `vector()` e especifique o `mode =` com base na classe esperada dos objetos que você irá inserir - seja "double" (para armazenar números), "character" ou "logical". Você também deve definir o `length =` com antecedência. Este deve ser o comprimento da sua sequência *loop for*.

Digamos que você queira armazenar o atraso médio até a admissão de cada hospital. Você usaria "double" e definiria o comprimento como o número de saídas esperadas (o número de hospitais exclusivos no conjunto de dados).

```{r}
delays <- vector(
  mode = "double",                            # esperamos armazenar números
  length = length(unique(linelist$hospital))) # o número de hospitais únicos no conjunto de dados
```

**Data frame vazio**

Você pode criar um data frame vazio especificando o número de linhas e colunas assim:

```{r, eval=F}
delays <- data.frame(matrix(ncol = 2, nrow = 3))
```

**Lista vazia**

Você pode querer armazenar alguns gráficos criados por um *loop for* em uma lista. Uma lista é como um vetor, mas contém outros objetos R dentro dela que podem ser de diferentes classes. Os itens em uma lista podem ser um único número, um data frame, um vetor e até outra lista.

Você realmente inicializa uma lista vazia usando o mesmo comando `vector()` acima, mas com `mode = "list"`. Especifique o comprimento como desejar.

```{r, eval=F}
plots <- vector(mode = "list", length = 16)
```

### Imprimindo {.unnumbered}

Observe que para "printar" (mostrar) de dentro de um *loop for* você provavelmente precisará envolver explicitamente a função `print()`.

Neste exemplo abaixo, a sequência é um vetor de caracteres explícito, que é usado para acessar o subconjunto da linelist por hospital. Os resultados não são armazenados em um contêiner, mas são impressos no console com a função `print()`.

```{r}
for (hosp in hospital_names){ 
     hospital_cases <- linelist %>% filter(hospital == hosp)
     print(nrow(hospital_cases))
}
```

### Testando o seu loop {.unnumbered}

Para testar seu loop, você pode executar um comando para fazer uma atribuição temporária do "item", como `i <- 10` ou `hosp <- "Central Hospital"`. Faça isso *fora do loop* e execute apenas seu código de operações (o código entre colchetes) para ver se os resultados esperados são produzidos.

### Gráficos em loop {.unnumbered}

Para juntar todos os três componentes (contêiner, sequência e operações), vamos tentar traçar uma epicurva para cada hospital (consulte a página em [Curvas epidêmicas](#epicurves)).

Podemos fazer uma bela epicurva de *todos* os casos por gênero usando o pacote **incidence2** conforme abaixo:

```{r, warning=F, message=F}
# criando o objeto do tipo 'incidence'
outbreak <- incidence2::incidence(   
     x = linelist,                   # data frame - linelist completo
     date_index = "date_onset",        # coluna de data
     interval = "week",              # contagens agregadas semanalmente
     groups = "gender")                # valores de grupo por gênero
     #na_as_group = TRUE)             # o sexo ausente é um grupo próprio

# plotando a epicurva
ggplot(outbreak, # nom de l'objet d'incidence
        aes(x = date_index, #aesthetiques et axes
            y = count, 
            fill = gender), # Fill colour of bars by gender
       color = "black"      # Contour colour of bars
       ) +  
     geom_col() + 
     facet_wrap(~gender) +
     theme_bw() + 
     labs(title = "Outbreak of all cases", #titre
          x = "Counts", 
          y = "Date", 
          fill = "Gender", 
          color = "Gender")
```

Para produzir um gráfico separado para os casos de cada hospital, podemos colocar esse código da epicurva dentro de um *loop for*.

Primeiro, salvamos um vetor com os nomes exclusivos do hospital, `hospital_names`. O *loop for* será executado uma vez para cada um destes nomes: `for (hosp in hospital_names)`. A cada iteração do *loop for*, o nome do hospital atual do vetor será representado como `hosp` para uso dentro do loop.

Dentro das operações de loop, você pode escrever o código R normalmente, mas use o "item" (`hosp` neste caso) sabendo que seu valor será alterado. Dentro deste loop:

-   Um `filter()` é aplicado a `linelist`, de modo que a coluna `hospital` deve ser igual ao valor atual de `hosp`
-   O objeto do tipo *incidence* é criado na linelist filtrada
-   O gráfico para o hospital atual é criado, com um título de ajuste automático que usa `hosp`
-   O gráfico do hospital atual é salvo temporariamente e depois impresso
-   O loop então avança para repetir com o próximo hospital em `hospital_names`

```{r, out.width='50%', message = F}
# criando o vetor dos nomes dos hospitais
hospital_names <- unique(linelist$hospital)

# para cada nome ("hosp") em hospital_names, crie e imprima a epicurva
for (hosp in hospital_names) {
     
     # criando objeto de incidência específico para o hospital atual
     outbreak_hosp <- incidence2::incidence(
          x = linelist %>% filter(hospital == hosp),   # linelist é filtrada para o hospital atual
          date_index = "date_onset",
          interval = "week", 
          groups = "gender"#,
          #na_as_group = TRUE
     )
     
     # Criando e salvando o gráfico. O título se ajusta automaticamente ao hospital atual
      plot_hosp <- ggplot(outbreak_hosp, # incidence object name
                         aes(x = date_index, #axes
                             y = count, 
                             fill = gender), # fill colour by gender
                         color = "black"      # colour of bar contour
                         ) +  
          geom_col() + 
          facet_wrap(~gender) +
          theme_bw() + 
          labs(title = stringr::str_glue("Epidemic of cases admitted to {hosp}"), #title
               x = "Counts", 
               y = "Date", 
               fill = "Gender", 
               color = "Gender")
     
     # With older versions of R, remove the # before na_as_group and use this plot command instead.
    # plot_hosp <- plot(
#       outbreak_hosp,
#       fill = "gender",
#       color = "black",
#       title = stringr::str_glue("Epidemic of cases admitted to {hosp}")
#     )
     
     # exibindo o gráfico para o hospital atual
     print(plot_hosp)
     
} # encerrando o loop for quando ele tiver sido executado para todos os hospitais em hospital_names
```

### Acompanhando o progresso de um loop {.unnumbered}

Um loop com muitas iterações pode ser executado por muitos minutos ou até horas. Assim, pode ser útil imprimir o progresso no console R. A instrução `if` (que significa "se" em inglês) abaixo pode ser colocada *dentro* das operações de loop para exibir a cada 100 números. Basta ajustá-lo para que `i` seja o "item" em seu loop.

```{r, eval=F}
# loop com código para exibir o progresso a cada 100 iterações
for (i in seq_len(nrow(linelist))){

  # print progress
  if(i %% 100==0){    # O operador %% calcula o resto da operação
    print(i)

}
```

<!-- ======================================================= -->

## **purrr** e listas {#iter_purrr}

Outra abordagem para operações iterativas é o pacote **purrr** - essa é a abordagem **tidyverse** para iteração.

Se você tiver que executar a mesma tarefa várias vezes, provavelmente vale a pena criar uma solução generalizada que possa ser usada com várias entradas. Por exemplo, produzindo gráficos para várias jurisdições ou importando e combinando muitos arquivos.

Há também algumas outras vantagens para usar o **purrr** - você pode usá-lo com pipes `%>%`, ele lida com erros melhor do que o normal *loop for*, e a sintaxe é bastante limpa e simples! Se você estiver usando um *loop for*, provavelmente poderá fazê-lo de forma mais clara e sucinta com **purrr**!

Tenha em mente que o **purrr** é uma *ferramenta de programação funcional*. Ou seja, as operações que devem ser aplicadas iterativamente são agrupadas em *funções*. Consulte a página [Escrevendo funções](#writing-functions) para aprender a escrever suas próprias funções.

O **purrr** também é quase inteiramente baseado em *listas* e *vetores* - então pense nisso como aplicar uma função a cada elemento dessa lista/vetor!

### Carregando pacotes {.unnumbered}

O **purrr** faz parte do **tidyverse**, portanto, não há necessidade de instalar/carregar um pacote separado.

```{r}
pacman::p_load(
     rio,            # importa/exporta
     here,           # caminhos de arquivos relativos
     tidyverse,      # gerenciamento de dados e visualização
     writexl,        # escreve arquivos Excel com várias abas
     readxl          # importa arquivos Excel com várias abas
)
```

### `map()` {.unnumbered}

A função principal do **purrr** é a `map()`, que "mapeia" (aplica) uma função para cada elemento de entrada de uma lista/vetor que você fornece.

A sintaxe básica é `map(.x = SEQUENCE, .f = FUNCTION, OTHER ARGUMENTS)`. Com um pouco mais de detalhes:

-   `.x =` são as *entradas* nas quais a função `.f` será aplicada iterativamente - ex. um vetor de nomes de jurisdição, colunas em um data frame ou uma lista de data frames
-   `.f =` é a *função* a ser aplicada a cada elemento da entrada `.x` - pode ser uma função como `print()` que já existe, ou uma função personalizada que você define. A função geralmente é escrita após um til `~` (detalhes abaixo).

Mais algumas notas sobre a sintaxe:

-   Se a função não precisar de mais argumentos especificados, ela pode ser escrita sem parênteses e sem til (por exemplo, `.f = mean`). Para fornecer argumentos que terão o mesmo valor para cada iteração, forneça-os dentro da `map()` mas fora do argumento `.f =`, como `na.rm = T` em `map(.x = my_list, .f = média, na.rm=T)`.
-   Você pode usar `.x` (ou simplesmente `.`) *dentro* da função `.f =` como um espaço reservado para o valor `.x` dessa iteração
-   Use a sintaxe til (`~`) para ter maior controle sobre a função - escreva a função normalmente com parênteses, como: `map(.x = my_list, .f = ~mean(., na.rm = T) )`. Use esta sintaxe especialmente se o valor de um argumento mudar a cada iteração, ou se for o próprio valor `.x` (veja os exemplos abaixo)

**O resultado da função `map()` é uma *lista*** - uma lista é uma classe de objeto como um vetor, mas cujos elementos podem ser de classes diferentes. Assim, uma lista produzida pela `map()` pode conter muitos data frames, ou muitos vetores, muitos valores únicos, ou mesmo muitas listas! Existem versões alternativas da `map()` explicadas abaixo que produzem outros tipos de saídas (por exemplo, `map_dfr()` para produzir um data frame, `map_chr()` para produzir vetores de caracteres e `map_dbl()` para produzir vetores).

#### Exemplo - importar e combinar planilhas do Excel {#iter_combined .unnumbered}

**Vamos demonstrar com uma tarefa comum de um epidemiologista:** - *Você deseja importar um arquivo do Excel com dados do caso, mas os dados são divididos em diferentes abas com nomes. Como você importa e combina com eficiência as planilhas em um data frame?*

Digamos que recebemos arquivo Excel abaixo. Cada folha contém casos de um determinado hospital.

```{r, fig.align = "center", echo=F}
knitr::include_graphics(here::here("images", "hospital_linelists_excel_sheets.png"))
```

Aqui está uma abordagem que usa a função `map()`:

1)  `map()` a função `import()` para que seja executada para aba do Excel
2)  Combine em um os data frames importados usando `bind_rows()`
3)  Ao longo do caminho, preserve o nome da aba original para cada linha, armazenando essas informações em uma nova coluna no data frame final

Primeiro, precisamos extrair os nomes das abas e salvá-los. Fornecemos o caminho do arquivo Excel para a função `excel_sheets()` do pacote **readxl**, que extrai os nomes das abas Nós os armazenamos em um vetor de caracteres chamado `sheet_names`.

```{r, echo=F}
sheet_names <- readxl::excel_sheets(here::here("data", "example", "hospital_linelists.xlsx"))
```

```{r, eval=F}
sheet_names <- readxl::excel_sheets("hospital_linelists.xlsx")
```

Aqui estão os nomes:

```{r}
sheet_names
```

Agora que temos esse vetor de nomes, `map()` pode fornecê-los um a um para a função `import()`. Neste exemplo, os `sheet_names` são `.x` e `import()` é a função `.f`.

Lembre-se da página [Importar e exportar](#importing) que quando usado em arquivos do Excel, `import()` pode aceitar o argumento `which =` (qual) especificando a aba a ser importada. Dentro da função `.f` `import()`, fornecemos `which = .x`, cujo valor mudará a cada iteração através do vetor `sheet_names` - primeiro "Central Hospital" ("Hospital Central"), depois "Military Hospital" ("Hospital Militar") etc.

Nota - porque usamos `map()`, os dados em cada planilha do Excel serão salvos como um data frame separado dentro de uma lista. Queremos que cada um desses elementos de lista (data frame) tenha um *nome*, então antes de passarmos `sheet_names` para `map()`, passamos por `set_names()` de **purrr**, o que garante que cada elemento da lista recebe o nome apropriado.

Salvamos a lista de saída como o objeto `combined`.

```{r, echo=F}
combined <- sheet_names %>% 
  purrr::set_names() %>% 
  map(.f = ~import(here::here("data", "example", "hospital_linelists.xlsx"), which = .x))
```

```{r, eval=F}
combined <- sheet_names %>% 
  purrr::set_names() %>% 
  map(.f = ~import("hospital_linelists.xlsx", which = .x))
```

Quando inspecionamos o resultado, vemos que os dados de cada aba do Excel são salvos na lista com um nome. Isso é bom, mas ainda não terminamos.

```{r, fig.align = "center", echo=F}
knitr::include_graphics(here::here("images", "sheets_as_list.png"))
```

Por fim, usamos a função `bind_rows()` (do **dplyr**) que aceita a lista de data frames com estrutura semelhante e os combina em um único data frame. Para criar uma nova coluna a partir do elemento *names* da lista, usamos o argumento `.id =` e fornecemos o nome desejado para a nova coluna.

Abaixo está toda a sequência de comandos:

```{r, echo=F}
sheet_names <- readxl::excel_sheets(here::here("data", "example", "hospital_linelists.xlsx"))

combined <- sheet_names %>% 
  purrr::set_names() %>% 
  map(.f = ~import(here::here("data", "example", "hospital_linelists.xlsx"), which = .x)) %>% 
  bind_rows(.id = "origin_sheet")
```

```{r, eval=F}
sheet_names <- readxl::excel_sheets("hospital_linelists.xlsx")  # extraindo o nome das abas
 
combined <- sheet_names %>%                                     # começando com os nomes das abas
  purrr::set_names() %>%                                        # definindo seus nomes
  map(.f = ~import("hospital_linelists.xlsx", which = .x)) %>%  # iterando, importando, salvando na lista
  bind_rows(.id = "origin_sheet") # combinar lista de data frames, preservando a origem em uma nova coluna
```

E agora temos um data frame com uma coluna contendo a aba de origem!

```{r, fig.align = "center", echo=F}
knitr::include_graphics(here::here("images", "sheets_as_df.png"))
```

Existem variações da `map()` que você deve conhecer. Por exemplo, `map_dfr()` retorna um data frame, não uma lista. Assim, poderíamos tê-lo usado para a tarefa acima e não ter que vincular linhas. Mas aí não teríamos conseguido capturar de qual aba (hospital) veio cada caso.

Outras variações incluem `map_chr()`, `map_dbl()`. Estas são funções muito úteis por duas razões. Em primeiro lugar, elas convertem automaticamente a saída de uma função iterativa em um vetor (não uma lista). Em segundo lugar, elas podem controlar explicitamente a classe em que os dados voltam - você garante que seus dados voltem como um vetor de caracteres com `map_chr()`, ou vetor numérico com `map_dbl()`. Vamos voltar a eles mais tarde na seção!

As funções `map_at()` e `map_if()` também são muito úteis para iteração - elas permitem que você especifique em quais elementos de uma lista você deve iterar! Estes funcionam simplesmente aplicando um vetor de índices/nomes (no caso de `map_at()`) ou um teste lógico (no caso de `map_if()`).

Vamos usar um exemplo em que não queríamos ler a primeira aba de dados do hospital. Usamos `map_at()` em vez de `map()`, e especificamos o argumento `.at =` para `c(-1)` que significa *não* usar o primeiro elemento de `.x`. Alternativamente, você pode fornecer um vetor de números positivos, ou nomes, para `.at =` para especificar quais elementos usar.

```{r, echo=F}
sheet_names <- readxl::excel_sheets(here::here("data", "example", "hospital_linelists.xlsx"))

combined <- sheet_names %>% 
     purrr::set_names() %>% 
     # excluindo a primeira aba
     map_at(.f = ~import(here::here("data", "example", "hospital_linelists.xlsx"), which = .x),
            .at = c(-1))
```

```{r, eval=F}
sheet_names <- readxl::excel_sheets("hospital_linelists.xlsx")

combined <- sheet_names %>% 
     purrr::set_names() %>% 
     # excluindo a primeira aba
     map_at(.f = ~import( "hospital_linelists.xlsx", which = .x),
            .at = c(-1))
```

Observe que o nome da primeira aba ainda aparecerá como um elemento da lista de saída - mas é apenas um nome de caractere único (não um data frame). Você precisaria remover esse elemento antes de vincular as linhas. Abordaremos como remover e modificar elementos de uma lista em uma seção posterior.

### Divida o conjunto de dados e exporte {.unnumbered}

Abaixo, damos um exemplo de como dividir um conjunto de dados em partes e, em seguida, usar a iteração `map()` para exportar cada parte como uma aba separada do Excel ou como um arquivo CSV separado.

#### Conjunto de dados dividido {.unnumbered}

Digamos que temos o caso completo `linelist` como um data frame e agora queremos criar uma linelist separada para cada hospital e exportar cada um como um arquivo CSV separado. Abaixo, fazemos os seguintes passos:

Use `group_split()` (do **dplyr**) para dividir o data frame `linelist` por valores únicos na coluna `hospital`. A saída é uma lista contendo um data frame por subconjunto de hospital.

```{r}
linelist_split <- linelist %>% 
     group_split(hospital)
```

Podemos executar `View(linelist_split)` e ver que esta lista contém 6 data frames ("tibbles"), cada um representando os casos de um hospital.

```{r, fig.align = "center", echo=F}
knitr::include_graphics(here::here("images", "purrr_linelist_split.png"))
```

No entanto, observe que os data frames na lista não possuem nomes por padrão! Queremos que cada um tenha um nome e, em seguida, use esse nome ao salvar o arquivo CSV.

Uma abordagem para extrair os nomes é usar `pull()` (do **dplyr**) para extrair a coluna `hospital` de cada data frame na lista. Então, por segurança, convertemos os valores em caracteres e usamos `unique()` para obter o nome desse data frame específico. Todas essas etapas são aplicadas a cada data frame via `map()`.

```{r}
names(linelist_split) <- linelist_split %>%   # Atribuindo os nomes de data frames listados
     # Extraia os nomes fazendo o seguinte para cada data frame:
     map(.f = ~pull(.x, hospital)) %>%        # Puxe a coluna do hospital
     map(.f = ~as.character(.x)) %>%          # Converta em caractere, apenas por garantia
     map(.f = ~unique(.x))                    # Pegue o nome exclusivo do hospital
```

Agora podemos ver que cada um dos elementos da lista tem um nome. Esses nomes podem ser acessados via `names(linelist_split)`.

```{r, fig.align = "center", echo=F}
knitr::include_graphics(here::here("images", "purrr_linelist_split_named.png"))
```

```{r}
names(linelist_split)
```

##### Mais de uma coluna `group_split()` {.unnumbered}

Se você quiser dividir a linelist por *mais de uma coluna de agrupamento*, como para produzir uma lista de linelist pela interseção de hospital E sexo, precisará de uma abordagem diferente para nomear os elementos da lista. Isso envolve coletar as "chaves de grupo" exclusivas usando `group_keys()` do **dplyr** - elas são retornadas como um data frame. Então você pode combinar as chaves de grupo em valores com `unite()` como mostrado abaixo, e atribuir esses nomes de conglomerados a `linelist_split`.

```{r}
# dividindo a linelist por combinações exclusivas de hospital-gênero
linelist_split <- linelist %>% 
     group_split(hospital, gender)

# extraindo group_keys() como um data frame
groupings <- linelist %>% 
     group_by(hospital, gender) %>%       
     group_keys()

groupings      # mostrando agrupamentos únicos
```

Agora combinamos os agrupamentos, separados por traços, e os atribuímos como os nomes dos elementos da lista em `linelist_split`. Isso leva algumas linhas extras, pois substituimos `NA` por "Ausente", usamos `unite()` do **dplyr** para combinar os valores das colunas (separados por traços) e, em seguida, convertemos em um vetor sem nome para que ele pode ser usado como nomes de `linelist_split`.

```{r, eval=F}
# Combinando em um valor de um nome
names(linelist_split) <- groupings %>% 
     mutate(across(everything(), replace_na, "Ausente")) %>%  # substituindo NA por "Ausente" em todas as colunas
     unite("combined", sep = "-") %>%                         # unindo todos os valores da coluna em um
     setNames(NULL) %>% 
     as_vector() %>% 
     as.list()
```

#### Exportando como abas do Excel {.unnumbered}

Para exportar as linelists do hospital como *um arquivo do Excel com uma linelist por aba*, podemos apenas fornecer a lista nomeada `linelist_split` para a função `write_xlsx()` do pacote **writexl**. Isso tem a capacidade de salvar um arquivo Excel com várias abas. Os nomes dos elementos da lista são aplicados automaticamente como os nomes das abas

```{r, eval=F}
linelist_split %>% 
     writexl::write_xlsx(path = here("data", "hospital_linelists.xlsx"))
```

Agora você pode abrir o arquivo Excel e ver que cada hospital tem sua própria aba

```{r, fig.align = "center", echo=F}
knitr::include_graphics(here::here("images", "purrr_export_sheets.png"))
```

#### Exportando como arquivos CSV {.unnumbered}

É um comando um pouco mais complexo, mas você também pode exportar cada linelist específica do hospital como um arquivo CSV separado, com um nome de arquivo específico para o hospital.

Novamente usamos `map()`: pegamos o vetor de nomes de elementos da lista (mostrado acima) e usamos `map()` para iterar por eles, aplicando `export()` (do pacote **rio**, veja página [Importar e exportar](#importing)) no data frame na lista `linelist_split` que tem esse nome. Também usamos o nome para criar um nome de arquivo exclusivo. Aqui está como funciona:

-   Começamos com o vetor de nomes de caracteres, passado para `map()` como `.x`

-   A função `.f` é `export()` , que requer um data frame e um caminho de arquivo para gravar

-   A entrada `.x` (o nome do hospital) é usada *dentro* de `.f` para extrair/indexar aquele elemento específico da lista `linelist_split`. Isso resulta em apenas um data frame por vez sendo fornecido para `export()`.

-   Por exemplo, quando `map()` itera para "Military Hospital" ("Hospital Militar"), então `linelist_split[[.x]]` é na verdade `linelist_split[["Military Hospital"]]`, retornando assim o segundo elemento de `linelist_split` - que são todos os casos do Hospital Militar.

-   O caminho do arquivo fornecido para `export()` é dinâmico através do uso de `str_glue()` (consulte a página [Caracteres e strings](#characters-strings)):

    -   `here()` é usado para obter a base do caminho do arquivo e especificar a pasta "data" (observe as aspas simples para não interromper as aspas duplas `str_glue()`)

-   Em seguida, uma barra `/`, e novamente o `.x` que imprime o nome do hospital atual para tornar o arquivo identificável

-   Finalmente a extensão ".csv" que `export()` usa para criar um arquivo CSV

```{r, eval=F, message = F, warning=F}
names(linelist_split) %>%
     map(.f = ~export(linelist_split[[.x]], file = str_glue("{here('data')}/{.x}.csv")))
```

Agora você pode ver que cada arquivo é salvo na pasta "data" do R Project "Epi_R\_handbook"!

```{r, fig.align = "center", echo=F}
knitr::include_graphics(here::here("images", "purrr_export_csv.png"))
```

### Customizar funções {.unnumbered}

Você pode querer criar sua própria função para fornecer ao `map()`.

Digamos que queremos criar curvas epidêmicas para os casos de cada hospital. Para fazer isso usando **purrr**, nossa função `.f` pode ser `ggplot()` e extensões com `+` como de costume. Como a saída de `map()` é sempre uma lista, os gráficos são armazenados em uma lista. Por serem gráficos, eles podem ser extraídos e plotados com a função `ggarrange()` do pacote **ggpubr** ([documentação](https://rpkgs.datanovia.com/ggpubr/reference/ggarrange.html) ).

```{r, message = F, warning=F}

# carregando pacote para plotar elementos da lista
pacman::p_load(ggpubr)

# mapeando o vetor de 6 "nomes" de hospitais (criados anteriormente)
# usando a função ggplot especificada
# a saída é uma lista com 6 ggplots

hospital_names <- unique(linelist$hospital)

my_plots <- map(
  .x = hospital_names,
  .f = ~ggplot(data = linelist %>% filter(hospital == .x)) +
                geom_histogram(aes(x = date_onset)) +
                labs(title = .x)
)

# exibindo os ggplots (eles são armazenados em uma lista)
ggarrange(plotlist = my_plots, ncol = 2, nrow = 3)
```

Se este código `map()` parecer muito confuso, você pode obter o mesmo resultado salvando seu comando `ggplot()` específico como uma função personalizada definida pelo usuário, por exemplo, podemos chamá-lo de `make_epicurve())`. Esta função é então usada dentro do `map()`. `.x` será substituído iterativamente pelo nome do hospital e usado como `hosp_name` na função `make_epicurve()`. Consulte a página sobre [Escrevendo funções](#writing-functions).

```{r, eval=F}
# Criando a função
make_epicurve <- function(hosp_name){
  
  ggplot(data = linelist %>% filter(hospital == hosp_name)) +
    geom_histogram(aes(x = date_onset)) +
    theme_classic()+
    labs(title = hosp_name)
  
}
```

```{r, eval=F}
# mapeando
my_plots <- map(hospital_names, ~make_epicurve(hosp_name = .x))

# exibindo os ggplots (eles são armazenados em uma lista)
ggarrange(plotlist = my_plots, ncol = 2, nrow = 3)
```

### Mapeando uma função ao longo de colunas {.unnumbered}

Outro caso de uso comum é mapear uma função ao longo de muitas colunas. Abaixo, mapeamos (`map()`) a função `t.test()` em colunas numéricas no data frame `linelist`, comparando os valores numéricos por gênero.

Lembre-se da página em [Testes estatísticos simples](#stat-tests) que `t.test()` pode receber entradas em um formato de fórmula, como `t.test(coluna numérica ~ coluna binária)`. Neste exemplo, fazemos o seguinte:

-   As colunas numéricas de interesse são selecionadas de `linelist` - elas se tornam as entradas `.x` para `map()`

-   A função `t.test()` é fornecida como a função `.f`, que é aplicada a cada coluna numérica

-   Dentro dos parênteses de `t.test()`:

    -   o primeiro `~` precede o `.f` que `map()` irá iterar sobre `.x`
    -   o `.x` representa a coluna atual sendo fornecida para a função `t.test()`
    -   o segundo `~` faz parte da equação do teste t descrita acima
    -   a função `t.test()` espera uma coluna binária no lado direito da equação. Nós fornecemos o vetor `linelist$gender` independentemente e estaticamente (observe que ele não está incluído em `select()`).

`map()` retorna uma lista, então a saída é uma lista de resultados do teste t - um elemento de lista para cada coluna numérica analisada.

```{r}
# Resultados são salvos como uma lista
t.test_results <- linelist %>% 
  select(age, wt_kg, ht_cm, ct_blood, temp) %>%  # mantendo apenas algumas colunas numéricas para mapear
  map(.f = ~t.test(.x ~ linelist$gender))        # função t.test com equação NUMERIC ~ CATEGORICAL
```

Aqui está a aparência da lista `t.test_results` quando aberta (Visualizada) no RStudio. Destacamos partes que são importantes para os exemplos nesta página.

-   Você pode ver no topo que a lista inteira é chamada de `t.test_results` e tem cinco elementos. Esses cinco elementos são nomeados `age`, `wt_km`, `ht_cm`, `ct_blood`, `temp` após cada variável que foi usada em um teste t com `gender` da `linelist`.
-   Cada um desses cinco elementos são listas, com elementos dentro deles, como `p.value` e `conf.int`. Alguns desses elementos como `p.value` são números únicos, enquanto alguns como `estimate` consistem em dois ou mais elementos (`média no grupo f` e `média no grupo m`).

```{r, out.height="150%", echo=F}
knitr::include_graphics(here::here("images", "purrr_ttest.png"))
```

Nota: Lembre-se que se você deseja aplicar uma função a apenas certas colunas em um data frame, você também pode simplesmente usar `mutate()` e `across()`, conforme explicado na página [Limpeza de dados e principais funções](#cleaning). Abaixo está um exemplo de aplicação de `as.character()` apenas para as colunas "age". Observe o posicionamento dos parênteses e vírgulas.

```{r, eval=F}
# convertendo colunas com nome da coluna contendo "idade" para classe Character
linelist <- linelist %>% 
  mutate(across(.cols = contains("age"), .fns = as.character))  
```

### Extraindo de listas {.unnumbered}

Como `map()` produz uma saída da classe List (lista), vamos gastar algum tempo discutindo como extrair dados de listas usando funções acompanhantes do **purrr**. Para demonstrar isso, usaremos a lista `t.test_results` da seção anterior. Esta é uma lista de 5 listas - cada uma das 5 listas contém os resultados de um teste t entre uma coluna do data frame `linelist` e sua coluna binária `gender`. Veja a imagem na seção acima para uma visualização da estrutura da lista.

#### Nomes dos elementos {.unnumbered}

Para extrair os nomes dos próprios elementos, simplesmente use `names()` do R **base**. Neste caso, usamos `names()` em `t.test_results` para retornar os nomes de cada sub-lista , que são os nomes das 5 variáveis que tiveram testes t realizados.

```{r}
names(t.test_results)
```

#### Elementos por nome ou posição {.unnumbered}

Para extrair elementos da lista por nome ou por posição, você pode usar colchetes `[[ ]]` conforme descrito na página [Introdução ao R](#basics). Abaixo usamos colchetes duplos para indexar a lista `t.tests_results` e exibir o primeiro elemento que é o resultado do teste t em `age` (idade).

```{r}
t.test_results[[1]] # primeiro elemento por posição
t.test_results[[1]]["p.value"] # retorna o elemento nomeado "p.value" do primeiro elemento
```

No entanto, abaixo vamos demonstrar o uso das funções simples e flexíveis do **purrr** `map()` e `pluck()` para alcançar os mesmos resultados.

#### `pluck()` {.unnumbered}

`pluck()` extrai elementos por nome ou por posição. Por exemplo - para extrair os resultados do teste t para idade, você pode usar `pluck()` assim:

```{r}
t.test_results %>% 
  pluck("age")        # alternativamente, use pluck(1)
```

Indexe níveis mais profundos especificando os níveis adicionais com vírgulas. O código abaixo extrai o elemento chamado "p.value" (o p-valor)da lista `age` de dentro da lista `t.test_results`. Você também pode usar números em vez de nomes de caracteres.

```{r}
t.test_results %>% 
  pluck("age", "p.value")
```

Você pode extrair esses elementos internos de *todos* os elementos de primeiro nível usando `map()` para executar a função `pluck()` em cada elemento de primeiro nível. Por exemplo, o código abaixo extrai os elementos "p.value" de todas as listas dentro de `t.test_results`. A lista de resultados do teste t é o `.x` iterado, `pluck()` é a função `.f` sendo iterada e o valor "p-value" é fornecido para a função.

```{r}
t.test_results %>%
  map(pluck, "p.value")   # retorna cada p-valor
```

Como outra alternativa, `map()` oferece uma abreviação onde você pode escrever o nome do elemento entre aspas, e ele irá "arrancá-lo". Se você usar `map()` a saída será uma lista, enquanto que se você usar `map_chr()` será um vetor de caractere nomeado e se você usar `map_dbl()` será um vetor numérico nomeado.

```{r}
t.test_results %>% 
  map_dbl("p.value")   # retorna o p-valor como um vetor numérico com nome
```

Você pode ler mais sobre `pluck()` em sua [documentação](https://purrr.tidyverse.org/reference/pluck.html) **purrr**. Ele tem uma função irmã `chuck()` que retornará um erro em vez de NULL se um elemento não existir.

### Convertendo uma lista em um data frame {.unnumbered}

Este é um tópico complexo - consulte a seção Recursos para tutoriais mais completos. No entanto, demonstraremos a conversão da lista de resultados do teste t em um data frame. Criaremos um data frame com colunas para a variável, seu p-valor e as médias dos dois grupos (masculino e feminino).

Aqui estão algumas das novas abordagens e funções que serão usadas:

-   A função `tibble()` será usada para criar um tibble (como um data frame)

    -   Envolvemos a função `tibble()` com chaves `{ }` para evitar que todo o `t.test_results` seja armazenado como a primeira coluna do tibble

-   Dentro de `tibble()`, cada coluna é criada explicitamente, semelhante à sintaxe de `mutate()`:

    -   O `.` representa `t.test_results`
    -   Para criar uma coluna com os nomes das variáveis do teste t (os nomes de cada elemento da lista) usamos `names()` conforme descrito acima
    -   Para criar uma coluna com os p-valores, usamos `map_dbl()` conforme descrito acima para extrair os elementos `p.value` e convertê-los em um vetor numérico

```{r}
t.test_results %>% {
  tibble(
    variables = names(.),
    p         = map_dbl(., "p.value"))
  }
```

Mas agora vamos adicionar colunas contendo as médias para cada grupo (masculino e feminino).

Precisaríamos extrair o elemento `estimate`, mas na verdade ele contém *dois* elementos dentro dele (`média no grupo f` e `média no grupo m`). Portanto, não pode ser simplificado em um vetor com `map_chr()` ou `map_dbl()`. Em vez disso, usamos `map()`, que usado dentro de `tibble()` criará *uma coluna da lista de classes dentro do tibble*! Sim, isso é possível!

```{r}
t.test_results %>% 
  {tibble(
    variables = names(.),
    p = map_dbl(., "p.value"),
    means = map(., "estimate"))}
```

Depois de ter essa coluna de lista, há várias funções **tidyr** (parte do **tidyverse**) que ajudam a "retangular" ou "desaninhar" essas colunas de "lista aninhada". Leia mais sobre eles [aqui](), ou executando `vignette("rectangle")`. Em resumo:

-   `unnest_wider()` - dá a cada elemento de uma coluna de lista sua própria coluna
-   `unnest_longer()` - dá a cada elemento de uma coluna de lista sua própria linha
-   `hoist()` - funciona como `unnest_wider()` mas você especifica quais elementos serão desaninhados

Abaixo, passamos o tibble para `unnest_wider()` especificando a coluna `means` do tibble (que é uma lista aninhada). O resultado é que `means` é substituído por duas novas colunas, cada uma refletindo os dois elementos que estavam anteriormente em cada célula `means`.

```{r}
t.test_results %>% 
  {tibble(
    variables = names(.),
    p = map_dbl(., "p.value"),
    means = map(., "estimate")
    )} %>% 
  unnest_wider(means)
```

### Descartar, manter e compactar listas {.unnumbered}

Como trabalhar com **purrr** geralmente envolve listas, exploraremos brevemente algumas funções do **purrr** para modificar listas. Consulte a seção Recursos para tutoriais mais completos sobre as funções **purrr**.

-   `list_modify()` tem muitos usos, um dos quais pode ser remover um elemento da lista
-   `keep()` retém os elementos especificados para `.p =`, ou onde uma função fornecida para `.p =` é avaliada como TRUE
-   `discard()` remove os elementos especificados para `.p`, ou onde uma função fornecida para `.p =` é avaliada como TRUE
-   `compact()` remove todos os elementos vazios

Aqui estão alguns exemplos usando a lista `combined` criada na seção acima em [usando map() para importar e combinar vários arquivos](#iter_combined) (contém 6 data frames de linelist):

Elementos podem ser removidos por nome com `list_modify()` e definindo o nome igual a `NULL`.

```{r, eval=F}
combined %>% 
  list_modify("Central Hospital" = NULL)   # remove elemento da lista por nome
```

Você também pode remover elementos por critérios, fornecendo uma equação de "predicado" para `.p =` (uma equação que avalia como TRUE ou FALSE). Coloque um til `~` antes da função e use `.x` para representar o elemento da lista. Usando `keep()` os elementos da lista que forem avaliados como TRUE serão mantidos. Inversamente, se estiver usando `discard()`, os elementos da lista que forem avaliados como TRUE serão removidos.

```{r, eval=F}
# mantenha apenas elementos de lista com mais de 500 linhas
combined %>% 
  keep(.p = ~nrow(.x) > 500)  
```

No exemplo abaixo, os elementos da lista são descartados se suas classes não forem data frames.

```{r, eval=F}
# descartando elementos que não são data frame
combined %>% 
  discard(.p = ~class(.x) != "data.frame")
```

Sua função de predição também pode referenciar elementos/colunas dentro de cada item da lista. Por exemplo, abaixo, os elementos da lista onde a média da coluna `ct_blood` é superior a 25 são descartados.

```{r, eval=F}
# mantenha apenas elementos onde a média da coluna ct_blood é maior que 25
combined %>% 
  discard(.p = ~mean(.x$ct_blood) > 25)  
```

Este comando remove todos os elementos vazios da lista:

```{r, eval=F}
# remove todos os elementos vazios da lista
combined %>% 
  compact()
```

### `pmap()` {.unnumbered}

ESTA SEÇÃO ESTÁ EM CONSTRUÇÃO

## funções Apply

A família de funções "apply" é uma alternativa do R **base** ao **purrr** para operações iterativas. Você pode ler mais sobre eles [aqui](https://www.datacamp.com/community/tutorials/r-tutorial-apply-family).

<!-- ======================================================= -->

## Recursos

[para loops com Data Carpentry](https://datacarpentry.org/semester-biology/materials/for-loops-R/)

A [página R for Data Science sobre iteração](https://r4ds.had.co.nz/iteration.html#iteration)

[Vinheta sobre gravação/leitura de arquivos Excel](https://martinctc.github.io/blog/vignette-write-and-read-multiple-excel-files-with-purrr/)

Um [tutorial](https://jennybc.github.io/purrr-tutorial/index.html) purrr por jennybc

Outro purrr [tutorial](http://www.rebeccabarter.com/blog/2019-08-19_purrr/) por Rebecca Barter

Um [tutorial](http://zevross.com/blog/2019/06/11/the-power-of-three-purrr-poseful-iteration-in-r-with-map-pmap-and-imap/) purrr para map, pmap e imap

[purrr cheatsheet](https://raw.githubusercontent.com/rstudio/cheatsheets/master/pngs/thumbnails/purrr-cheatsheet-thumbs.png)

[dicas e truques do purrr](https://www.hvitfeldt.me/blog/purrr-tips-and-tricks/)

[manter e descartar](https://hookedondata.org/going-off-the-map/#keep-and-discard)
```{r include=FALSE, cache=FALSE}

# clear workspace
rm(list = ls(all = TRUE))

# clear all packages except base
#lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))

# to ensure that tidyverse packages prevail
filter <- dplyr::filter
select <- dplyr::select
summarise <- dplyr::summarise
summary <- base::summary
incidence <- incidence2::incidence

#load core packages
pacman::p_load(
     rio,
     here,
     DT,
     stringr,
     lubridate,
     tidyverse
)

# import the cleaned ebola linelist
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

# import the count data - facility level
#count_data <- rio::import(here::here("data", "facility_count_data.rds"))

# Settings

options(scipen=1, digits=7)

# print only text (not code)
# library(knitr)
# opts_chunk$set(list(echo = FALSE, eval = FALSE))
```

<!--chapter:end:new_pages/iteration.Rmd-->

# (PART) Análise dos dados {.unnumbered}
```{r include=FALSE, cache=FALSE}

# clear workspace
rm(list = ls(all = TRUE))

# clear all packages except base
#lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))

# to ensure that tidyverse packages prevail
filter <- dplyr::filter
select <- dplyr::select
summarise <- dplyr::summarise
summary <- base::summary
incidence <- incidence2::incidence

#load core packages
pacman::p_load(
     rio,
     here,
     DT,
     stringr,
     lubridate,
     tidyverse
)

# import the cleaned ebola linelist
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

# import the count data - facility level
#count_data <- rio::import(here::here("data", "facility_count_data.rds"))

# Settings

options(scipen=1, digits=7)

# print only text (not code)
# library(knitr)
# opts_chunk$set(list(echo = FALSE, eval = FALSE))
```

<!--chapter:end:new_pages/cat_analysis.Rmd-->

# Tabelas descritivas {#tables-descriptive}

```{r out.width = c('75%'), fig.align='center', fig.show='hold', echo=F}
knitr::include_graphics(here::here("images", "descriptive_tables.png"))
```

Esta página demonstra o uso dos pacotes **janitor**, **dplyr**, **gtsummary**, **rstatix**, e R **base** para gerar um resumo dos dados e criar tabelas com estatísticas descritivas.

*Esta página explica como* criar\* as tabelas básicas e detalhadas, enquanto que a página [Tabelas para apresentações](#tables-presentation) descreve como formatar e imprimir essas tabelas de forma visualmente agradável.\*

Cada um destes pacotes tem vantagens e desvantagens em relação à simplicidade do código, acessibilidade dos resultados gerados, e qualidade da impressão destes resultados. Utilize esta página para decidir qual abordagem funciona melhor para a sua realidade.

Você tem várias opções para produzir tabelas simples e tabelas cruzadas (também conhecidas como tabelas de contingência). Entretanto, é necessário levar em consideração alguns fatores, como a simplicidade do código R utilizado; a capacidade de personalização deste código; a forma de geração dos resultados (para visualização no terminal do R, ou como uma tabela de dados (*data frame*), e/ou como uma imagem 'bonita' nos formatos .png/.jpeg/.html); e a facilidade de pós-processamento dos resultados gerados. Leve em consideração os pontos abaixo ao escolher uma ferramenta para atender as suas necessidades.

-   Use a função `tabyl()` do **janitor** para produzir e personalizar tabulações simples e tabulações cruzadas\
-   Use a função `get_summary_stats()` do **rstatix** para gerar tabelas com resumos estatísticos de diferentes colunas e/ou grupos de dados de forma fácil\
-   Use as funções `summarise()` e `count()` do **dplyr** para realizar análises estatísticas mais complexas, gerar tabelas de dados organizadas, ou preparar os dados para utilizar na função `ggplot()`\
-   Use a função `tbl_summary()` do **gtsummary** para produzir tabelas detalhadas prontas para publicação\
-   Use a função `table()` do R **base** se você não tiver acesso aos pacotes citados acima

<!-- ======================================================= -->

## Preparação

### Carregue os pacotes R {.unnumbered}

O código abaixo realiza o carregamento dos pacotes necessários para a análise dos dados. Neste manual, enfatizamos o uso da função `p_load()`, do **pacman**, que instala os pacotes, caso não estejam instalados, *e* os carrega no R para utilização. Também é possível carregar pacotes instalados utilizando a função `library()`, do r **base**. Para mais informações sobre os pacotes do R, veja a página [Introdução ao R](#basics).

```{r, warning=F, message=F}
pacman::p_load(
  rio,          # importa arquivos
  here,         # localiza arquivos
  skimr,        # gera visualização dos dados
  tidyverse,    # gestão dos dados + gráficos no ggplot2 
  gtsummary,    # resumo estatísticos e testes
  rstatix,      # resumo e testes estatísticos
  janitor,      # adiciona números absolutos e porcentagens às tabelas
  scales,       # facilmente converte proporções para porcentagens
  flextable     # converte tabelas para o formato de imagens
  )
```

### Importe os dados no R {.unnumbered}

Nós iremos importar o banco de dados de casos de uma simulação de epidemia de Ebola. Se você quiser acompanhar os passos abaixo, <a href='https://github.com/epirhandbook/Epi_R_handbook/raw/master/data/case_linelists/linelist_cleaned.rds' class='download-button'>clique aqui para fazer o download do banco de dados 'limpo'</a> (como arquivo .rds). Importe seus dados utilizando a função `import()` do pacote **rio** (esta função importa muitos tipos de arquivos, como .xlsx, .rds, .csv - veja a página [Importar e exportar](#importing) para detalhes).

```{r, echo=F}
# importe o banco de dados
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))
```

```{r, eval=F}
# importe o banco de dados limpo
linelist <- import("linelist_cleaned.rds")
```

As primeiras 50 linhas do banco de dados são mostradas abaixo.

```{r, message=FALSE, echo=F}
# mostre as linhas como tabela
DT::datatable(head(linelist, 50), rownames = FALSE, filter="top", options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```

<!-- ======================================================= -->

## Explore seus dados

### Pacote **skimr** {.unnumbered}

Ao utilizar o pacote **skimr**, você pode obter um resumo detalhado e esteticamente agradável de cada variável do seu banco de dados. Leia mais sobre o **skimr** na sua [página no github](https://github.com/ropensci/skimr).

Abaixo, a função `skim()` é aplicada a todos os dados do objeto `linelist,` criado no código acima. Após execução do código, uma visão geral dos dados e um resumo de cada coluna (por classe) são gerados.

```{r}
## obtenha informações sobre cada variável no banco de dados
skim(linelist)
```

```{r  eval=F, echo=F}
# exclui a apresentação de dados com histogramas irregulares
skim_without_charts(linelist)
```

Você também pode usar a função `summary()`, do R **base**, para obter informações sobre o banco de dados inteiro, mas os resultados obtidos podem ser mais difíceis de visualizar do que utilizando o **skimr**. O resultado da análise com `summary()` não é mostrado abaixo, visando poupar espaço na página.

```{r, eval=F}
## obtenha informações sobre cada coluna no banco de dados
summary(linelist)
```

### Resumos estatísticos {.unnumbered}

Você pode utilizar as funções do R **base** para obter resumos estatísticos de uma coluna com dados numéricos. Boa parte das análises estatísticas mais úteis com este tipo de coluna pode ser obtido utilizando a função `summary()`, como mostrado abaixo. Observe que o nome da tabela de dados e da coluna (linelist) precisam ser especificados como mostrado abaixo.

```{r}
summary(linelist$age_years)
```

Você pode obter e salvar uma parte específica da análise utilizando o indexador com colchetes [ ]:

```{r}
summary(linelist$age_years)[[2]] # obtém apenas o resultado da análise no índice [2]
# alternativa equivalente ao indexador [2], utilizando o nome do campo:
# summary(linelist$age_years)[["1st Qu."]]  
```

Você pode obter estatísticas individuais com outras funções do R **base**, como `max()`, `min()`, `median()`, `mean()`, `quantile()`, `sd()`, e `range()`. Veja a página [Introdução ao R](#basics) para uma lista completa.

[***CUIDADO:*** Caso seus dados contenham campos em branco, o R quer que você saiba disso e irá gerar `NA` na análise. Isso só não irá ocorrer caso você 'peça' para o R ignorar esses campos em branco nas funções matemáticas acima. Isso pode ser realizado com o argumento]{style="color: orange;"}`na.rm = TRUE`[.]{style="color: orange;"}

Você pode usar a função `get_summary_stats()`, do **rstatix**, para obter o resumo estatístico *em formato de quadro de dados (data frame)*. Isso pode ser útil na execução de comandos posteriores ou para criação de gráficos com os valores. Veja a página [Testes estatísticos simples](#stat-tests) para mais detalhes do pacote **rstatix** e suas funções.

```{r}
linelist %>% 
  get_summary_stats(
    age, wt_kg, ht_cm, ct_blood, temp,  # variáveis para realizar o cálculo
    type = "common")                    # tipo do resumo estatístico a ser gerado

```

## **Pacote janitor** {#tbl_janitor}

O pacote **janitor** contém a função `tabyl()`, que gera tabulações simples e tabulações cruzadas que podem ser modificadas com funções auxiliares para mostrarem porcentagens, proporções, contagens, etc.

Abaixo, nós utilizamos as funções do **janitor** no banco de dados `linelist`, criado anteriormente, e visualizamos o resultado da análise. Se necessário, é possível salvar as tabelas geradas utilizando o operador `<-`, e atribuindo elas a um novo objeto no R.

### Básico do tabyl {.unnumbered}

O uso do `tabyl()`, no modo padrão, em uma coluna específica produz uma tabela com os valores únicos desta coluna, suas contagens, e "porcentagens" (proporções, na realidade). Como as proporções podem ter muitos dígitos, é possível ajustar o número de casas decimais com a função `adorn_rounding()`, descrita abaixo.

```{r}
linelist %>% tabyl(age_cat)
```

Como observado acima, se existirem campos em branco na coluna analisada, eles são mostrados em uma linha chamada `<NA>`. Você pode omitir estes campos com o atributo `show_na = FALSE`. Se não existirem campos em branco, essa linha não irá aparecer. Se estes campos existirem, todas as proporções são geradas como 'brutas' (coluna 'percent' gerada, em que a quantidade de campos `NA` está inclusa no denominador) e 'válidas' (coluna 'valid_percent', onde a quantidade de campos `NA` não é considerada no cálculo).

Se a coluna for um fator (da classe Factor) e apenas alguns níveis dessa classe estiverem presentes em seus dados, todos os níveis desta classe serão mostrados na tabela de análise. Você pode omitir essa característica ao usar o atributo `show_missing_levels = FALSE`. Leia mais na página [Fatores](#factors).

### Tabulação cruzada (tabela de contingência) {.unnumbered}

As quantidades absolutas das tabulações cruzadas são obtidas ao adicionarmos uma ou mais variáveis dentro da função `tabyl()`. Observe que agora apenas os números absolutos são obtidos - proporções e porcentagens podem ser adicionadas à análise com etapas adicionais mostradas abaixo.

```{r}
linelist %>% tabyl(age_cat, gender)
```

### Personalizando o tabyl {#tbl_adorn .unnumbered}

Use as funções "adorn", do **janitor**, para adicionar ao resultado da análise as colunas de números absolutos assim como converter para proporções, percentuais, ou ajustar o formato de gerado. Você utilizar essas funções nas tabelas geradas pelo tabyl frequentemente.

+--------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Função                   | Resultado                                                                                                                                                                                                              |
+==========================+========================================================================================================================================================================================================================+
| `adorn_totals()`         | Adiciona uma linha/coluna com os totais (`where =` "row", "col", or "both"). "row": linhas; "col": colunas; "both": ambas. Atribua ao campo `name =` o nome "Total".                                                   |
+--------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `adorn_percentages()`    | Converte contagens absolutas para proporções, escolhendo o `denominator =` "row", "col", or "all".                                                                                                                     |
+--------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `adorn_pct_formatting()` | Converte proporções para percentuais. Especifique o número de casas decimais com o atributo `digits =`. Remova o símbolo "%" com o atributo `affix_sign = FALSE`.                                                      |
+--------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `adorn_rounding()`       | Arredonde as proporções utilizando `digits =` nº de casas decimais. Para arredondar percentuais, utilize a função `adorn_pct_formatting()` com `digits =`.                                                             |
+--------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `adorn_ns()`             | Adicione a tabela as quantidades absolutas com as proporções ou porcentagens. Utilize o atributo `position =` "rear" para mostrar as quantidades em parênteses, ou "front" para colocar as porcentagens em parênteses. |
+--------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `adorn_title()`          | Adiciona títulos à tabela gerada através dos argumentos `row_name =` e/ou `col_name =`                                                                                                                                 |
+--------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

Preste atenção na ordem em que você utiliza estas funções. Abaixo estão alguns exemplos:

Uma tabela simples com porcentagens no lugar das proporções, que são padrão.

```{r}
linelist %>%               # fonte dos dados
  tabyl(age_cat) %>%       # tabula números absolutos e proporções por idade
  adorn_pct_formatting()   # converte as proporções para porcentagens
```

Uma tabela cruzada com os números absolutos e porcentagens de cada linha.

```{r}
linelist %>%                                  
  tabyl(age_cat, gender) %>%                  # contagens absolutas e proporções cruzando idade e gênero
  adorn_totals(where = "row") %>%             # adiciona uma linha chamada 'Total', com os totais
  adorn_percentages(denominator = "row") %>%  # converte os números absolutos para proporções
  adorn_pct_formatting(digits = 1)            # converte as proporções para porcentagens
```

O código abaixo modifica uma tabela cruzada de dados de forma que as quantidades absolutas e os percentuais sejam mostrados.

```{r}
linelist %>%                                  # fonte dos dados
  tabyl(age_cat, gender) %>%                  # geração da tabela cruzada
  adorn_totals(where = "row") %>%             # adiciona uma linha "Total", com os totais
  adorn_percentages(denominator = "col") %>%  # converte as quantidades absolutas para proporções
  adorn_pct_formatting() %>%                  # converte as proporções para porcentagens
  adorn_ns(position = "front") %>%            # mostra os dados como: "n° absoluto (porcentagem)"
  adorn_title(                                # nomeia os títulos das colunas e linhas
    row_name = "Age Category",
    col_name = "Gender")
```

### Convertendo a tabela do tabyl para uma imagem {.unnumbered}

Por padrão, o tabyl vai gerar uma tabela 'crua' no seu console do R.

Adicionalmente, você pode obter a tabela no tabyl e utiliza-la nas funções do pacote **flextable**, ou outros pacotes similares, para gerar uma tabela no formato de imagem no RStudio Viewer, que pode ser exportada nos formatos .png, .jpeg, .html, etc. Isto é discutido na página [Tabelas para apresentação](#tables-presentation). Observe que, caso você gere a tabela desta forma e utilize a função `adorn_titles()`, você precisa aplicar o atributo `placement = "combined"`.

```{r}
linelist %>%                                  # fonte dos dados
  tabyl(age_cat, gender) %>%                  # geração da tabela cruzada
  adorn_totals(where = "row") %>%             # adiciona uma linha "Total", com os totais
  adorn_percentages(denominator = "col") %>%  # converte as quantidades absolutas para proporções
  adorn_pct_formatting() %>%                  # converte as proporções para porcentagens
  adorn_ns(position = "front") %>% 
  adorn_title(
    row_name = "Age Category",
    col_name = "Gender",
    placement = "combined") %>% # isto é necessário para gerar a tabela como imagem
  flextable::flextable() %>%    # converte a tabela em imagem
  flextable::autofit()          # formata a tabela em linha por coluna

```

### Personalizando outras tabelas com funções 'adorn' {.unnumbered}

Você pode utilizar as funções `adorn_*()`, do pacote **janitor**, em outras tabelas, como as criadas pelas funções `summarise()` e `count()` do pacote **dplyr**, ou `table()` do R **base**. Simplesmente aplique a tabela gerada à função desejada do pacote **janitor**. Por exemplo:

```{r}
linelist %>% 
  count(hospital) %>%   # função do pacote dplyr
  adorn_totals()        # função do pacote janitor
```

### Salvando a tabela do tabyl {.unnumbered}

Se você converteu a tabela para uma imagem 'bonita' utilizando um pacote como **flextable**, você pode salvar ela com as funções desse pacote - utilizando as funções `save_as_html()`, `save_as_word()`, `save_as_ppt()`, e `save_as_image()` do **flextable** (discutido em detalhes na página [Tabelas para apresentação](#tables-presentation)). No código abaixo, a tabela é salva em um documento Word, onde poderá ser editada manualmente.

```{r, eval=F}
linelist %>%
  tabyl(age_cat, gender) %>% 
  adorn_totals(where = "col") %>% 
  adorn_percentages(denominator = "col") %>% 
  adorn_pct_formatting() %>% 
  adorn_ns(position = "front") %>% 
  adorn_title(
    row_name = "Faixa-Etária",
    col_name = "Gênero",
    placement = "combined") %>% 
  flextable::flextable() %>%                     # converte para imagem
  flextable::autofit() %>%                       # garante apenas uma linha por coluna
  flextable::save_as_docx(path = "tabyl.docx")   # salva a imagem como um documento Word no endereço do documento (filepath)
```

```{r out.width = "50%", fig.align = "center", echo=F}
knitr::include_graphics(here::here("images", "tabyl_word.png"))
```

### Análises estatísticas {#janitor_age_out_stats .unnumbered}

Como mostrado abaixo, você pode aplicar testes estatísticos nas tabelas dos tabyls, como `chisq.test()` ou `fisher.test()` do pacote **stats**. Observe que campos em branco não são permitidos, devendo serem excluídos do tabyl com o atributo `show_na = FALSE`.

```{r, warning=F, message=F}
age_by_outcome <- linelist %>% 
  tabyl(age_cat, outcome, show_na = FALSE) 

chisq.test(age_by_outcome)
```

Veja a página [Testes estatísticos simples](#stat-tests) para mais códigos e dicas sobre estatística.

### Outras dicas {.unnumbered}

-   Utilize o argumento `na.rm = TRUE` para excluir campos em brancos de qualquer um dos cálculos acima.\
-   Se utilizar qualquer função `adorn_*()` em tabelas criadas com outra função além do `tabyl()`, você pode especificar a(s) coluna(s) para aplicar o "adorn", como em `adorn_percentage(,,,c(cases,deaths))` (onde a porcentagem será adicionada somente no quarto argumento da análise). Como a sintaxe não é simples, considere utilizar a função `summarise()` em seu lugar.\
-   Você pode obter mais detalhes na [página do janitor](https://cran.r-project.org/web/packages/janitor/vignettes/janitor.html) e nesse [resumo do tabyl](https://cran.r-project.org/web/packages/janitor/vignettes/tabyls.html).

## **Pacote dplyr**

**dplyr** faz parte dos pacotes **tidyverse**, sendo uma ferramenta de gestão de dados muito comum. Criar tabelas com as funções `summarise()` e `count()` do **dplyr** é uma abordagem útil para obter resumos estatísticos, resumos *por grupos*, ou para utilizá-las no `ggplot()`.

A função `summarise()` cria uma *nova tabela resumo dos dados.* Se os dados *não são agrupados*, esta função gera uma tabela de dados de uma linha com os resumos estatísticos desejados do banco de dados inteiro. Se os dados são *agrupados*, a nova tabela terá um linha por *grupo* (veja a página [Agrupando dados](#grouping)).

Dentro dos parênteses da função `summarise()`, você pode incluir os nomes de cada nova coluna, seguido pelo sinal de igual e uma função estatística a ser utilizada.

[***DICA:*** A função `summarise` pode ser escrita na forma do inglês britânico e americano (`summarise()` e `summarize()`).]{style="color: darkgreen;"}

### Obtendo as quantidades absolutas {.unnumbered}

A função mais simples para utilizar dentro de `summarise()` é a função `n()`. Não insira nada dentro dos parênteses para a função contar o total de linhas.

```{r}
linelist %>%                 # inicia com o banco de dados 'linelist'
  summarise(n_rows = n())    # gera uma nova tabela com uma coluna contendo o número de linhas
```

Esta análise é mais interessante se agruparmos os dados antes.

```{r}
linelist %>% 
  group_by(age_cat) %>%     # agrupe os dados por valores únicos da coluna 'age_cat'
  summarise(n_rows = n())   # gera o número de linhas *por grupo*
```

O código acima pode ser encurtado ao utilizar a função `count()` em vez de `summarise()` e `n()`. A função `count()` faz o seguinte:

1)  Agrupa os dados de acordo com as colunas escolhidas\
2)  Gera um resumo destes grupos utilizando a função `n()` (criando a coluna `n`)\
3)  Desagrupa os dados

```{r}
linelist %>% 
  count(age_cat)
```

Você pode mudar o nome da coluna resultante `n` para um diferente, ao especificar o novo nome com o atributo `name =`.

Os resultados das contagens de duas ou mais colunas usadas para agrupar os dados são gerados no formato "longo", com as contagens na coluna `n`. Veja a página sobre [Pivotando dados](#pivoting) para aprender sobre as tabelas nos formatos "longos" e "amplos".

```{r}
linelist %>% 
  count(age_cat, outcome)
```

### Mostre todos os níveis da classe *factor* {.unnumbered}

Se você estiver tabelando uma coluna da classe *factor*, é possível fazer com que *todos* os níveis dessa classe sejam mostrados (não apenas os níveis presentes nos dados) ao adicionar o atributo `.drop = FALSE` dentro das funções `summarise()` ou `count()`.

Está técnica é útil para padronizar suas tabelas/gráficos. Por exemplo, se você estiver criando figuras para diferentes sub-grupos, ou precisar criar um mesmo tipo de figura para relatórios de rotina. Em cada uma dessas circuntâncias, os valores nos dados podem variar, mas é possível definir níveis que continuem constantes.

Veja a página sobre [Fatores](#factors) para mais informações.

### Proporções {#tbl_dplyr_prop .unnumbered}

Colunas com proporções podem ser criadas ao canalizar (*pipe*) a tabela gerada para a função `mutate()`. A partir disso, as proporções podem ser calculadas através da divisão das quantidades absolutas geradas na coluna de contagem (`n` por padrão), divididos pela soma (`sum()`) de todas as contagens nessa coluna.

Observe que, neste caso, utilizar a função `sum()` dentro do `mutate()` irá gerar a soma da coluna `n` inteira, e utilizá-la como denominador no cálculo das proporções. Como explicado [na página de agrupamento de dados](#group_summarise), *se* `sum()` for utilizada em dados *agrupados* (por exemplo, se o `mutate()` for imediatamente seguido pela função `group_by()`), as somas serão realizadas *por grupos*. Como dito acima, a função `count()` termina as suas ações realizando o *desagrupamento* dos dados. Assim, neste cenário, nós obtemos as proporções da coluna inteira, e não apenas dos grupos.

Para facilmente mostrar os percentuais, é possível incorporar a proporção gerada dentro da função `percent()`, do pacote **scales** (tenha em mente que isso converte a porcentagem para a classe character).

```{r}
age_summary <- linelist %>% 
  count(age_cat) %>%                     # agrupe e conte por gênero (produz a coluna 'n'), finaliza desagrupando os dados
  mutate(                                # cria a porcentagem da coluna - observe o denominador
    percent = scales::percent(n / sum(n))) 

# print
age_summary
```

Abaixo, um método para calcular proporções *dentro* dos grupos é mostrado. Esta metodologia utiliza os diferentes níveis de agrupamento e desagrupamento de dados. Primeiro, os dados são agrupados de acordo com o `outcome`, utilizando a função `group_by()`. Então, a função `count()` é aplicada. Essa função realiza mais agrupamentos dos dados utilizando a variável `age_cat`, e gera contagens para cada combinação `outcome`-`age-cat`. Lembre-se que, ao finalizar o processo, a função `count()` também *desagrupa* os grupos `age_cat`. Assim, o único grupo de dados restante é o agrupamento inicial pelo `outcome`. Assim, a etapa final em que as proporções são calculadas (denominador `sum(n)`) é realizada com o grupo `outcome`.

```{r}
age_by_outcome <- linelist %>%                  # inicie com os dados do linelist
  group_by(outcome) %>%                         # agrupe por outcome 
  count(age_cat) %>%                            # agrupe e conte por age_cat, e então remova os grupos age_cat
  mutate(percent = scales::percent(n / sum(n))) # calcule as porcentagem - repare que o denominador é o grupo outcome
```

```{r, echo=F}
DT::datatable(age_by_outcome, rownames = FALSE, options = list(pageLength = 12, scrollX=T), class = 'white-space: nowrap' )
```

### Visualização dos dados {.unnumbered}

Utilizar a função `ggplot()` com os dados de uma tabela no formato "longo", como a mostrada acima, é relativamente simples. Esses dados, no formato "longo", são facilmente aceitos pelo `ggplot()`. Veja mais exemplos nas páginas [básico do ggplot](#ggplot-basics) e [dicas do ggplot](#ggplot-tips).

```{r, warning=F, message=F}
linelist %>%                      # inicie com a linelist
  count(age_cat, outcome) %>%     # agrupe e tabule as contagens utilizando duas variáveis
  ggplot()+                       # utilize a tabulação gerada no ggplot
    geom_col(                     # crie um gráfico de barras
      mapping = aes(   
        x = outcome,              # mapeie o grupo outcome para o eixo x
        fill = age_cat,           # mapeie o grupo age_cat para o fill
        y = n))                   # mapeie as contagens (coluna 'n') para o eixo y
```

### Resumo estatístico {.unnumbered}

Uma das principais vantagens do pacote **dplyr** e da função `summarise()` é a habilidade deles gerarem resumos estatísticos mais avançados, como `median()`, `mean()`, `max()`, `min()`, `sd()` (desvio padrão), e percentis. Você também pode utilizar a função `sum()` para contar o número de linhas que cumprem certos critérios lógicos. Como mostrado acima, essas informações podem ser obtidas com todo o banco de dados, ou por grupos.

A sintaxe é a mesma - dentro dos parênteses da função `summarise()`, você adiciona os nomes de cada nova coluna resumo, seguido pelos sinais de igual e a função estatística a ser realizada. Dentro da função estatística, escolha a(s) coluna(s) para serem utilizadas no cálculo, e qualquer outro argumento relevante (exemplo: `na.rm = TRUE` para boa parte das funções matemáticas).

Como dito acima, a função `sum()` também pode ser utilizada para obter o número de linhas que cumprem certos critérios lógicos. São contadas apenas as linhas que forem verdade (`TRUE`) para os critérios em parênteses. Por exemplo:

-   `sum(age_years < 18, na.rm=T)`\
-   `sum(gender == "male", na.rm=T)`\
-   `sum(response %in% c("Likely", "Very Likely"))`

Abaixo, os dados do `linelist` são analisados para avaliar os dias entre o início dos sintomas e a admissão no hospital (coluna `days_onset_hosp`), de acordo com o hospital.

```{r}
summary_table <- linelist %>%                                        # inicie com o linelist, salvando os novos dados como um novo objeto
  group_by(hospital) %>%                                             # agrupe todos os cálculos por hospital
  summarise(                                                         # apenas as colunas abaixo serão geradas
    cases       = n(),                                                # n° de casos por grupo
    delay_max   = max(days_onset_hosp, na.rm = T),                    # tempo máximo entre o ínicio dos sintomas e a admissão
    delay_mean  = round(mean(days_onset_hosp, na.rm=T), digits = 1),  # tempo médio, arredondado
    delay_sd    = round(sd(days_onset_hosp, na.rm = T), digits = 1),  # desvio padrão do intervalo de tempo, arredondado
    delay_3     = sum(days_onset_hosp >= 3, na.rm = T),               # n° de acsos com intervalo igual ou maior à 3 dias
    pct_delay_3 = scales::percent(delay_3 / cases)                    # gera nova coluna convertendo o delay_3 em porcentagem
  )

summary_table  # exporte a tabela
```

Algumas dicas:

-   Use a função `sum()` com uma expressão lógica para quantificar linhas que cumprem certos critérios (`==`)\

-   Repare no uso do argumento `na.rm = TRUE` dentro de funções matemáticas como `sum()`. Seu uso impede que `NA` seja gerado caso existam campos em branco\

-   Use a função `percent()`, do pacote **scales**, para facilmente obter as porcentagens

    -   Escolha `accuracy =` para 0.1 ou 0.01 para garantir 1 ou 2 vírgulas decimais, respectivamente\

-   Use a função `round()`, do pacote R **base**, para arredondar e especificar quantidade de casas decimais\

-   Para obter dados estatísticos do banco de dados completo, utilize a função `summarise()` sem a função `group_by()`\

-   Você pode criar colunas para realizar cálculos futuros (ex.: como denominadores), que podem ser, posteriormente, retiradas da sua tabela de dados com a função `select()`.

### Estatísticas condicionais {.unnumbered}

Você pode querer realizar *análises estatísticas condicionais* - por exemplo, a quantidade de linhas que cumprem certos critérios. Isto pode ser feito ao utilizar os colchetes `[ ]` para especificar os grupos desejados dentro de uma coluna. No código abaixo, a temperatura máxima dos pacientes com e sem febre é obtida. Entranto, neste caso, é melhor criar uma nova coluna utilizando as funções `group_by()` e `pivot_wider()` (como demonstrado [abaixo](#tbls_pivot_wider)).

```{r}
linelist %>% 
  group_by(hospital) %>% 
  summarise(
    max_temp_fvr = max(temp[fever == "yes"], na.rm = T),
    max_temp_no = max(temp[fever == "no"], na.rm = T)
  )
```

### Unindo colunas {.unnumbered}

A função `str_glue()`, do pacote **stringr**, é útil para combinar valores de diferentes colunas em uma nova coluna. Geralmente, essa função é aplicada *após* utilizar a função `summarise()`.

Na página sobre [Caracteres e strings](#characters-strings), várias opções para combinar colunas são discutidas, incluindo as funções `unite()` e `paste0()`. Entretanto, nós recomendamos a função `str_glue()` por ser mais flexível do que `unite()` e possuir uma sintaxe mais simples do que `paste0()`.

Abaixo, a tabela `summary_table` (criada acima) é modificada de forma que as colunas `delay_mean` e `delay_sd` sejam combinadas. A nova coluna é gerada com os dados formatados utilizando parênteses, e as colunas utilizadas são removidas.

Então, para tornar a coluna mais apresentável, uma linha com os totais é adicionada com a função `adorn_totals()`, do pacote **janitor** (que ignora colunas não-numéricas). Finalmente, nós utilizamos a função `select()`, do pacote **dplyr**, para reordenar as colunas e renomeá-las como desejado.

Também é possível utilizar as funções do **flextable** para exportar a tabela para Word, .png, .jpeg, .html, Powerpoint, RMarkdown, etc.! (veja a página [Tabelas para apresentações](#tables-presentation)).

```{r}
summary_table %>% 
  mutate(delay = str_glue("{delay_mean} ({delay_sd})")) %>%  # crie uma nova coluna ao combinar e formatar valores de outras colunas
  select(-c(delay_mean, delay_sd)) %>%                       # remova as duas colunas utilizadas   
  adorn_totals(where = "row") %>%                            # adiciona uma linha com os totais
  select(                                                    # reorganize e renomeie as colunas
    "Nome do Hospital"   = hospital,
    "Casos"           = cases,
    "Atraso máximo"       = delay_max,
    "Média (dp)"       = delay,
    "Atraso 3+ dias"   = delay_3,
    "% atrasos 3+ dias" = pct_delay_3
    )
```

#### Percentis {.unnumbered}

O cálculo dos *percentis* e quantis no **dplyr** merece uma menção especial. Para obter os quantis, utilize a função `quantile()` com os intervalos padrões, ou especifique os valores alterando o atributo `probs =`.

```{r}
# obtenha os percentis padrões da variável age (0%, 25%, 50%, 75%, 100%)
linelist %>% 
  summarise(age_percentiles = quantile(age_years, na.rm = TRUE))

# obtenha os percentis em diferentes níveis da mesma variável (5%, 50%, 75%, 98%)
linelist %>% 
  summarise(
    age_percentiles = quantile(
      age_years,
      probs = c(.05, 0.5, 0.75, 0.98), 
      na.rm=TRUE)
    )
```

Se você quiser obter os quantis *por grupos*, é mais viável utilizar a função `group_by()` e criar novas colunas, uma vez que isso irá gerar dados mais claros em relação ao método acima, onde seriam obtidos resultados longos e menos úteis. Desta forma, experimente essa abordagem: crie um coluna para cada nível de quantil desejado.

```{r}
# obtenha os valores de percentis nos níveis desejados de acordo com a variável age (5%, 50%, 75%, 98%), agrupando os dados por hospital
linelist %>% 
  group_by(hospital) %>% 
  summarise(
    p05 = quantile(age_years, probs = 0.05, na.rm=T),
    p50 = quantile(age_years, probs = 0.5, na.rm=T),
    p75 = quantile(age_years, probs = 0.75, na.rm=T),
    p98 = quantile(age_years, probs = 0.98, na.rm=T)
    )
```

Enquanto a função `summarise()` do **dplyr** certamente possibilita mais controle das alterações, todos os resumos estatísticos de que precisa podem ser produzidos com a função `get_summary_stat()`, do pacote **rstatix**. Ao ser utilizado em dados agrupados, esta função vai retornar percentis de 0%, 25%, 50%, 75%, e 100%. Se utilizado em dados não agrupados, você pode especificar os percentis com o atributo `probs = c(.05, .5, .75, .98)`.

```{r}
linelist %>% 
  group_by(hospital) %>% 
  rstatix::get_summary_stats(age, type = "quantile")
```

```{r}
linelist %>% 
  rstatix::get_summary_stats(age, type = "quantile")
```

### Obtenha um resumo dos dados agregados {.unnumbered}

*Se* você iniciar sua análise com *dados* agregados, ao utilizar a função `n()` você irá obter o número de *linhas*, não a soma das contagens agregadas. Para obter as somas, use a função `sum()` na coluna de contagens.

Por exemplo, suponha que você está iniciando com a tabela de contagens abaixo, chamada `linelist_agg` - ela mostra no formato "longo" as contagens do número de casos por `outcome` e `gender`.

Para fins de exemplificação, abaixo, nós criamos uma tabela de dados com a quantidade de casos por `outcome` e `gender` dos dados do `linelist` (campos em branco foram removidos para facilitar o entendimento).

```{r}
linelist_agg <- linelist %>% 
  drop_na(gender, outcome) %>% 
  count(outcome, gender)

linelist_agg
```

Para somar as contagens (da coluna `n`) por grupo, você pode usar a função `summarise()` e ajustar a nova coluna para ser igual à `sum(n, na.rm=T)`. Para adicionar um elemento condicional à essa operação, você pode selecionar, na coluna de contagem (`n`), uma parte dos dados utilizando os colchetes [ ].

```{r}
linelist_agg %>% 
  group_by(outcome) %>% 
  summarise(
    total_cases  = sum(n, na.rm=T),
    male_cases   = sum(n[gender == "m"], na.rm=T),
    female_cases = sum(n[gender == "f"], na.rm=T))
```

### `across()` em mais de uma coluna {.unnumbered}

Você pode utilizar a função `summarise()` em mais de uma coluna utilizado a função `across()`. Isto torna o trabalho mais fácil quando você quer obter a mesma estatística de muitas colunas. Coloque `across()` dentro de `summarise()` e especifique o seguinte:

-   `.cols =` vetor com o nome das colunas `c()` ou funções auxiliares do "tidyselect" (explicado abaixo)\
-   `.fns =` a função a ser aplicada (sem parênteses) - você pode fornecer múltiplas funções dentro de uma `list()`

Abaixo, a função `mean()` é aplicada para diferentes colunas numéricas. Um vetor com as colunas é dado explicitamente para o atributo `.cols =` e uma função simples (`mean`) é especificada (sem parênteses) em `.fns =`. Quaisquer argumentos adicionais para a função (por ex.: `na.rm=TRUE`) são colocados após `.fns =`, separados por uma vírgula.

Pode ser difícil acertar a ordem dos parênteses e vírgulas ao utilizar `across()`. Lembre que, dentro do `across()`, você deve incluir as colunas, as funções, e qualquer argumento extra que seja necessário para as funções.

```{r}
linelist %>% 
  group_by(outcome) %>% 
  summarise(across(.cols = c(age_years, temp, wt_kg, ht_cm),  # colunas utilizadas
                   .fns = mean,                               # função aplicada
                   na.rm=T))                                  # argumentos extras
```

Funções múltiplas podem ser executadas de uma vez. Abaixo, o atributo `.fns =` recebe as funções `mean` e `sd` dentro de uma `list()`. Você tem a oportunidade de escolher nomes das características (ex.: "mean" e "sd") que serão colocadas inseridas ao nome das novas colunas.

```{r}
linelist %>% 
  group_by(outcome) %>% 
  summarise(across(.cols = c(age_years, temp, wt_kg, ht_cm), # colunas
                   .fns = list("mean" = mean, "sd" = sd),    # múltiplas funções
                   na.rm=T))                                 # argumentos extras
```

Aqui são as funções auxiliares "tidyselect", que você pode utilizar em `.cols =` para selecionar colunas:

-   `everything()` - todas as outras colunas não mencionadas\
-   `last_col()` - a última coluna\
-   `where()` - aplica uma função à todas as colunas, e seleciona apenas aquelas que são verdadeiras (TRUE)\
-   `starts_with()` - seleciona colunas cujos nomes iniciam com determinado prefixo. Exemplo: `starts_with("date")`
-   `ends_with()` - seleciona colunas cujos normes terminam com determinado sufixo. Exemplo: `ends_with("_end")`\
-   `contains()` - colunas que contêm determinada sequência de caracteres. Exemplo: `contains("time")`
-   `matches()` - aplica a sintaxe de uma expressão regular (regex). Exemplo: `contains("[pt]al")`\
-   `num_range()` -
-   `any_of()` - seleciona colunas com certos nomes. Útil caso o nome buscado não exista. Exemplo: `any_of(date_onset, date_death, cardiac_arrest)`

Por exemplo, para obter a média de cada coluna numérica, use a função `where()` e aplique a função `as.numeric()` (sem os parêntesese) para escolher as colunas numéricas, e então obtenha a média com `mean`. Tudo isso dentro da função `across()`.

```{r}
linelist %>% 
  group_by(outcome) %>% 
  summarise(across(
    .cols = where(is.numeric),  # all numeric columns in the data frame
    .fns = mean,
    na.rm=T))
```

### Utilizando o pivot_wider() {#tbls_pivot_wider .unnumbered}

Se você preferir sua tabela no formato "largo", você pode transformar ela utilizando a função `pivot_wider()`, do pacote **tidyr**. Você provavelmente precisará renomear as colunas com a função `rename()`. Para mais informações, veja a página sobre [Pivoteando os dados](#pivoting).

O exemplo abaixo utiliza a tabela `age_by_outcome` com formato "longo", da [seção de proporções](#tbl_dplyr_prop). Para faciliar o entendimento, nós criamos essa tabela novamente, e mostramos como é seu formato "longo":

```{r}
age_by_outcome <- linelist %>%                  # inicie com o linelist
  group_by(outcome) %>%                         # agrupe por outcome 
  count(age_cat) %>%                            # agrupe e conte por age_cat, e então remova o agrupamento age_cat
  mutate(percent = scales::percent(n / sum(n))) # calcule a porcentagem - observe que o denominador é o grupo outcome
```

```{r, echo=F}
DT::datatable(age_by_outcome, rownames = FALSE, options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```

Para realizar o pivoteamento para a tabela criada fique no formato "largo", nós criamos as novas colunas a partir dos *valores* na coluna existente `age_cat` (ao configurar `names_from = age_cat`). Nós também especificamos que os valores da nova tabela virão da coluna existente `n`, utilizando o atributo `values_from = n`. As colunas não mencionadas no nosso comando de pivoteamento (`outcome`) continuarão sem alterações na extremidade esquerda da tabela final.

```{r}
age_by_outcome %>% 
  select(-percent) %>%   # para não complicar, mantenha apenas as contagens
  pivot_wider(names_from = age_cat, values_from = n)  
```

### Adicionando as linhas com os totais {#tbl_dplyr_totals .unnumbered}

Quando a função `summarise()` é utilizada em dados agrupados, a linha com os "totais" não é produzida automaticamente. Abaixo, duas abordagens para adicionar esta linha são mostrados:

#### **Função** `adorn_totals()` do pacote janitor {.unnumbered}

Se sua tabela contém apenas contagens ou proporções/porcentagens, que podem ser somados para obter os totais, então é possível realizar essa soma utilizando a função `adorn_totals()`, do pacote **janitor**, como descrito na seção acima. Observe que esta função consegue somar apenas as colunas numéricas - se você quiser calcular outros resumos estatísticos, veja a próxima abordagem com o pacote **dplyr**.

Abaixo, os dados do `linelist` são agrupados por gênero e resumidos em uma tabela que descreve o número de casos com evolução conhecida (outcome), mortes (deaths) ou recuperados (recovered). Ao canalizar a tabela para a função `adorn_totals()`, uma linha com os totais é adicionada no final para refletir a soma de cada coluna. As próximas funções `adorn_*()` ajustam o design, como comentado no código.

```{r}
linelist %>% 
  group_by(gender) %>%
  summarise(
    known_outcome = sum(!is.na(outcome)),           # N° de linhas em que o outcome não é desconhecido
    n_death  = sum(outcome == "Death", na.rm=T),    # N° de linhas em que o outcome é Death
    n_recover = sum(outcome == "Recover", na.rm=T), # N° de linhas em que o outcome é Recovered
  ) %>% 
  adorn_totals() %>%                                # Adiciona a linha 'total' (soma de cada coluna numérica)
  adorn_percentages("col") %>%                      # Obtenha as proporções
  adorn_pct_formatting() %>%                        # Converta as proporções para porcentagens
  adorn_ns(position = "front")                      # mostra % e n° absolutos juntos (com n° absoluto na frente)
```

#### Uso da função `summarise()` nos dados "totais" seguido por `bind_rows()` {.unnumbered}

Se sua tabela consistir for feita de resumos estatísticos como `median()`, `mean()`, etc, a função`adorn_totals()` utilizada acima *não* será suficiente. Assim, para obter o resumo estatístico de todo o banco de dados, você precisa calcular eles com uma função `summarise()` separada e, então, conectar os resultados à tabela resumo inicial. Para fazer essa conexão, você pode usar a função `bind_rows()`, do pacote **dplyr**, descrito na página [Agrupando dados](#grouping). Abaixo está um exemplo:

Você pode criar uma tabela resumo com os resultados da intersecção *por hospital*, com as funções `group_by()` e `summarise()` da seguinte forma:

```{r, warning=F, message=F}
by_hospital <- linelist %>% 
  filter(!is.na(outcome) & hospital != "Missing") %>%  # Remova os casos sem resultado (outcome) ou nome do hospital
  group_by(hospital, outcome) %>%                      # Agrupe os dados
  summarise(                                           # Crie um novo resumo com as colunas com os indicadores de interesse
    N = n(),                                           # N° de linhas por grupo hospital-outcome     
    ct_value = median(ct_blood, na.rm=T))              # Obtenha a média dos valores CT por grupo
  
by_hospital # exporte a tabela
```

Para obter os totais, execute a mesma função `summarise()`, mas com os dados agrupados apenas por outcome (não por hospital), da seguinte forma:

```{r}
totals <- linelist %>% 
      filter(!is.na(outcome) & hospital != "Missing") %>%
      group_by(outcome) %>%                            # Agrupado apenas por outcome, não por hospital    
      summarise(
        N = n(),                                       # Essas estatísticas são apenas por outcome
        ct_value = median(ct_blood, na.rm=T))

totals # exporte a tabela gerada
```

Agora, nós podemos unir as duas tabelas geradas. Observe que a tabela `by_hospital` tem 4 colunas, enquanto a tabela `totals` tem 3 colunas. Ao utilizar a função `bind_rows()`, as colunas são combinadas por nome, onde cada espaço extra (linhas a mais) são preenchidos com `NA` (ex.: na coluna `hospital` os campos das duas novas linhas de `totals`). Após unir as linhas, nós iremos converter esses espaços em branco para "Total" utilizando a função `replace_na()` (veja a página [Limpando os dados e funções essenciais](#cleaning)).

```{r}
table_long <- bind_rows(by_hospital, totals) %>% 
  mutate(hospital = replace_na(hospital, "Total"))
```

Aqui está a nova tabela com as linhas "Total" no final.

```{r, message=FALSE, echo=F}
DT::datatable(table_long, rownames = FALSE, options = list(pageLength = 12, scrollX=T), class = 'white-space: nowrap' )
```

Esta tabela está no formato "longo/comprido", que pode ser o desejado. *Opcionalmente*, você pode *mudar* essa tabela para o formato *largo*, de forma a torná-la mais fácil de interpretar. Veja a seção acima sobre como transformar a tabela para o formato "largo", ou na página [Pivoteando dados](#pivoting). Você também pode adicionar mais colunas, e ajustá-las de forma que considere mais agradável. Segue o código:

```{r}
table_long %>% 
  
  # Muda para o formato amplo e formata a tabela
  ########################
  mutate(hospital = replace_na(hospital, "Total")) %>% 
  pivot_wider(                                         # Mude de "longo" para "largo"
    values_from = c(ct_value, N),                       # novos valores provenientes das colunas ct e de contagen (n)
    names_from = outcome) %>%                           # novos nomes das colunas proveniente dos outcomes
  mutate(                                              # adiciona novas colunas
    N_Known = N_Death + N_Recover,                               # casos com evolução (outcome) conhecido
    Pct_Death = scales::percent(N_Death / N_Known, 0.1),         # percentual de casos que evoluíram para óbito (até 1ª casa decimal)
    Pct_Recover = scales::percent(N_Recover / N_Known, 0.1)) %>% # percentual de casos que recuperaram (até a 1ª casa decimal)
  select(                                              # Reordena as colunas
    hospital, N_Known,                                   # Coluna introdutórias
    N_Recover, Pct_Recover, ct_value_Recover,            # Colunas dos recuperados
    N_Death, Pct_Death, ct_value_Death)  %>%             # Colunas de óbitos
  arrange(N_Known)                                  # Organize as linhas do menor para o maior (linha com totais por último)

```

Após isso, você pode exportar essa tabela como uma imagem - abaixo, o resultado é exportado com o pacote **flextable**. Para mais detalhes sobre esse exemplo, e sobre como produzir uma imagem dessa forma, leia a página [Tabelas para apresentações](#tables-descriptive).

```{r echo=FALSE, fig.show='hold', message=FALSE, warning=FALSE, out.width=c('50%', '50%')}

linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds")) 

border_style = officer::fp_border(color="black", width=1)

pacman::p_load(
  rio,            # importar/exportar
  here,           # endereço dos arquivos
  flextable,      # gera imagens a partir de tabelas 
  officer,        # funções auxiliares para tabelas
  tidyverse)      # gestão dos dados, resumos, e visualização

table <- linelist %>% 
  # filtros
  ########
  #filter(!is.na(outcome) & hospital != "Missing") %>%  # Exclui os casos com campos em branco nas colunas outcome ou hospital
  
  # Obtenha um resumo de valores por grupos hospital-outcome
  ###############################################
  group_by(hospital, outcome) %>%                      # Agrupe os dados
  summarise(                                           # Crie novas colunas com resumos de indicadores de interesse
    N = n(),                                            # N° de linhas por grupo hospital-outcome     
    ct_value = median(ct_blood, na.rm=T)) %>%           # Obtenha os valores médios de CT por grupo
  
  # adiciona a linha com os totais
  ############
  bind_rows(                                           # Junte a tabela anterior com essa mini-tabela com totais
    linelist %>% 
      filter(!is.na(outcome) & hospital != "Missing") %>%
      group_by(outcome) %>%                            # Agrupado apenas por outcome, não por hospital    
      summarise(
        N = n(),                                       # N° de linhas do banco de dados inteiro     
        ct_value = median(ct_blood, na.rm=T))) %>%     # Valores médios do CT do banco de dados inteiro
  
  # Transforme a tabela para o formato amplo e faça formatações
  ########################
  mutate(hospital = replace_na(hospital, "Total")) %>% 
  pivot_wider(                                         # Transforme de "longo" para "largo"
    values_from = c(ct_value, N),                       # novos valores das colunas ct e de contagens (n)
    names_from = outcome) %>%                           # novos nomes das colunas dos outcomes
  mutate(                                              # Adicione novas colunas
    N_Known = N_Death + N_Recover,                               # casos com evolução conhecida
    Pct_Death = scales::percent(N_Death / N_Known, 0.1),         # percentual de casos que evoluíram para óbito (até 1ª casa decimal)
    Pct_Recover = scales::percent(N_Recover / N_Known, 0.1)) %>% # percentual de casos que se recupararam (até a 1ª casa decimal)
  select(                                              # reordene as colunas
    hospital, N_Known,                                   # Colunas iniciais
    N_Recover, Pct_Recover, ct_value_Recover,            # Colunas com recuperados
    N_Death, Pct_Death, ct_value_Death)  %>%             # Colunas com os óbitos
  arrange(N_Known) %>%                                 # Ordene as linhas do menor para o maior (com a linha "Total" por último)

  # formatando a tabela
  ############
  flextable() %>% 
  add_header_row(
    top = TRUE,                # Novo cabeçalho vai acima do cabeçalho existente
    values = c("Hospital",     # Os valores do cabeçalho estão abaixo
               "Total cases with known outcome", 
               "Recovered",    # Este será o título para esta e as próximas duas colunas
               "",
               "",
               "Died",         # Este será o título para esta e as próximas duas colunas
               "",             # Deixe em branco, uma vez que será unida com os "Death"
               "")) %>% 
    set_header_labels(         # Renomeie as colunas na linha original com os títulos
      hospital = "", 
      N_Known = "",                  
      N_Recover = "Total",
      Pct_Recover = "% of cases",
      ct_value_Recover = "Median CT values",
      N_Death = "Total",
      Pct_Death = "% of cases",
      ct_value_Death = "Median CT values")  %>% 
  merge_at(i = 1, j = 3:5, part = "header") %>% # Una as colunas 3 a 5 de forma horizontal na nova linha de cabeçalho
  merge_at(i = 1, j = 6:8, part = "header") %>%  
  border_remove() %>%  
  theme_booktabs() %>% 
  vline(part = "all", j = 2, border = border_style) %>%   # na coluna 2 
  vline(part = "all", j = 5, border = border_style) %>%   # na coluna 5
  merge_at(i = 1:2, j = 1, part = "header") %>% 
  merge_at(i = 1:2, j = 2, part = "header") %>% 
  width(j=1, width = 2.7) %>% 
  width(j=2, width = 1.5) %>% 
  width(j=c(4,5,7,8), width = 1) %>% 
  flextable::align(., align = "center", j = c(2:8), part = "all") %>% 
  bg(., part = "body", bg = "gray95")  %>% 
  colformat_num(., j = c(4,7), digits = 1) %>% 
  bold(i = 1, bold = TRUE, part = "header") %>% 
  bold(i = 6, bold = TRUE, part = "body")


table
```

## **Pacote gtsummary** {#tbl_gt}

Se você quer exportar seu resumo estatístico em um gráfico 'bonito', pronto para publicação, você pode usar o pacote **gtsummary** e sua função `tbl_summary()`. Em um primeiro momento, o código pode parecer complexo, mas as tabelas geradas são lindas e exportadas para o seu painel do RStudio Viewer como uma imagem HTML. Veja um tutorial mais detalhado [aqui](http://www.danieldsjoberg.com/gtsummary/articles/tbl_summary.html).

Você também pode adicionar os resultados dos testes estatísticos nas tabelas geradas pelo **gtsummary**. Este processo está decrito na seção do **gtsummary**, da página [testes estatísticos simples](#stat-tests).

Para introduzir a função `tbl_summary()`, nós vamos primeiro demostrar seu funcionamento básico, que produz uma tabela bonita e extensa. Então, examinaremos em detalhes como fazer ajustes finos e tabelas mais customizadas.

### Tabela resumo {.unnumbered}

O comportamento padrão do `tbl_summary()` é incrível - ele utiliza as colunas fornecidas e cria uma tabela resumo em apenas um comando. Esta função realiza as estatísticas apropriadas de acordo com a classe da coluna: média e intervalo interquartil (IQR) para colunas numéricas, e contagens (%) para colunas categóricas. Valores em branco são convertidos para "Unknown". Notas de rodapé são adicionadas para explicar as estatísticas utilizadas, enquanto a quantidade total N é mostrada no topo.

```{r, warning=F, message=F}

# Use a função abaixo para que a tabela saia em portugês

theme_gtsummary_language("pt")

linelist %>% 
  select(age_years, gender, outcome, fever, temp, hospital) %>%  # mantenha apenas as colunas de interesse
  tbl_summary()                                                  # função no modo padrão
```

### Ajustes {.unnumbered}

Agora iremos explicar como esta função funciona e como fazer ajustes. Os argumentos chave estão detalhados abaixo:

**`by =`**\
Você pode estratificar a sua tabela utilizando uma coluna (ex.: `outcome`), ao criar uma tabela de duas vias.

**`statistic =`**\
Use as equações para especificar quais estatísticas mostrar e como mostrá-las. Existem dois lados para essa equação, separados por um til `~`. Do lado direito, entre aspas, é colocado o teste estatístico desejado, e no lado esquerdo são colocadas as colunas em que esse teste será aplicado.

-   O lado direito da equação utiliza a sintaxe da função `str_glue()`, do pacote **stringr** (veja mais em [Caractéres e Strings](#characters-strings)), com o texto a ser mostrado entre aspas e o teste estatístico dentro de colchetes encaracolados `{ }`. Você pode incluir estatísticas como "n" (para contagens), "N" (para denominador), "mean" (média), "median" (mediana), "sd" (desvio padrão), "max" (valor máximo), "min" (valor mínimo), percentis "p\#\#" como "p25", ou percentual do total como "p". Utilize o comando `?tbl_summary` para mais detalhes.\
-   No lado esquerdo da equação, você pode especificar colunas por nome (ex.: `age` ou `c(age, gender)`) ou utilizando funções auxiliares como `all_continuous()`, `all_categorical()`, `contains()`, `starts_with()`, etc.

Uma exemplo simples da equação `statistic =` é mostrado abaixo, onde apenas a média da coluna `age_years` é obtida:

```{r}
linelist %>% 
  select(age_years) %>%         # mantenha apenas as colunas de interesse
  tbl_summary(                  # crie uma tabela resumo
    statistic = age_years ~ "{mean}") # calcule a média de idades (age)
```

Uma equação um pouco mais complexa é obtida `"({min}, {max})"`, incorporando os valores mínimos e máximos dentro de parênteses e separados por vírgula:

```{r}
linelist %>% 
  select(age_years) %>%                       # mantenha apenas as colunas de interesse
  tbl_summary(                                # crie uma tabela resumo
    statistic = age_years ~ "({min}, {max})") # calcule o min e max da idade (age)
```

Você também pode utilizar uma sintaxe diferente para colunas distintas ou diferentes tipos de colunas. Em um exemplo mais complexo, mostrado abaixo, o argumento dado à `statistic =` é uma **list** (list) indicando que para todas as colunas com valores contínuos, a tabela deve gerar a média com o desvio padrão em parênteses, enquanto que, para colunas categóricas, ela deve gerar o n, o denominador, e o percentual.

**`digits =`**\
Ajuste a quantidade de dígitos e de arredondamento. Opcionalmente, isto pode ser limitado à colunas contínuas apenas (como mostrado abaixo).

**`label =`**\
Ajuste como o rótulo da coluna deve ser mostrado. Forneça o nome da coluna e o rótulo desejado, separado por um til `~`. O padrão do rótulo é o nome da coluna.

**`missing_text =`**\
Ajuste como os campos em branco são mostrados. A opção padrão é "Unknown".

**`type =`**\
Isto é utilizado para ajustar quantos níveis das estatísticas são mostradas. A sintaxe é similar ao atributo `statistic =`, pois você fornece uma equação com colunas no lado esquerdo, e um valor no lado direito. Dois cenários comuns incluem:

-   `type = all_categorical() ~ "categorical"` Força colunas dicotômicas (ex.: `fever` sim/não) a mostrar todos os níveis em vez de apenas a linha "sim"\
-   `type = all_continuous() ~ "continuous2"` Permite a realização de estatísticas em múltiplas linha ("multi-line") por variável, como mostrado em seção posterior

No exemplo abaixo, cada um desses argumentos é utilizado para modificar a tabela resumo original:

```{r}
linelist %>% 
  select(age_years, gender, outcome, fever, temp, hospital) %>% # utilize apenas as colunas de interesse
  tbl_summary(     
    by = outcome,                                               # estratifique a tabela inteira pelo outcome
    statistic = list(all_continuous() ~ "{mean} ({sd})",        # estatísticas e formatação para colunas contínuas
                     all_categorical() ~ "{n} / {N} ({p}%)"),   # estatísticas e formatação para colunas categóricas
    digits = all_continuous() ~ 1,                              # arredondamento para colunas contínuas
    type   = all_categorical() ~ "categorical",                 # force todos os níveis de colunas categóricas a serem mostrados
    label  = list(                                              # mostre etiquetas de acordo com o nome das colunas
      outcome   ~ "Outcome",                           
      age_years ~ "Age (years)",
      gender    ~ "Gender",
      temp      ~ "Temperature",
      hospital  ~ "Hospital"),
    missing_text = "Missing"                                    # como valores em branco devem ser mostrados
  )
```

### Estatísticas de múltiplas linhas ("multi-line") para variáveis contínuas {.unnumbered}

Se você quiser obter múltiplas linhas de estatísticas para variáveis contínuas, é possível indicar isto ao ajustar o atributo `type =` para "continuous2". É possível combinar todos os elementos mostrados anteriormente em uma tabela, ao escolher quais estatísticas quer mostrar. Para fazer isso, é necessário 'dizer' para a função que você quer a tabela de volta ao inserir seu tipo como "continous2". A quantidade de campos em braco é mostrado como "Unknown".

```{r}
linelist %>% 
  select(age_years, temp) %>%                      # mantenha apenas colunas de interesse
  tbl_summary(                                     # crie tabelas resumo
    type = all_continuous() ~ "continuous2",       # indique que você quer obter mais de uma estatística
    statistic = all_continuous() ~ c(
      "{mean} ({sd})",                             # linha 1: média e desvio padrão
      "{median} ({p25}, {p75})",                   # linha 2: média e IQR
      "{min}, {max}")                              # linha 3: min e max
    )
```

Existem diversas formas de modificar essas tabelas, como adicionar valores do p, ajustar cores e títulos, etc. Muitas destas modificações estão descritas na documentação (digite `?tbl_summary` no Console), e algumas destas são mostradas na seção sobre [testes estatísticos](#stat-tests).


## Pacote R **base**

Você pode usar a função `table()` para tabular e realizar tabulações cruzadas das colunas. Diferente das opções acima, você precisa especificar o quadro de dados cada vez que o nome de uma coluna é apontado, como mostrado abaixo.

[***CUIDADO:*** `NA` valores em branco **não** serão tabulados a não ser que você coloque o argumento `useNA = "always"` (que também pode ser ajustado para "no" ou "ifany").]{style="color: orange;"}

[***DICA:*** É possível usar o `%$%` do pacote **magrittr** para remover a necessidade de repetir a quantidade de vezes que o quadro de dados é chamado dentro das funções do pacote R **base**. Por exemplo, o código abaixo poderia ser reescrito como `linelist %$% table(outcome, useNA = "always")`]{style="color: darkgreen;"}

```{r}
table(linelist$outcome, useNA = "always")
```

Múltiplas colunas podem ser utilizadas para tabulação cruzada ao listá-las uma após a outra, separadas por vírgulas. Opcionalmente, você pode dar um "nome" a cada coluna, como em `Outcome = linelist$outcome`.

```{r}
age_by_outcome <- table(linelist$age_cat, linelist$outcome, useNA = "always") # salve a tabela como objeto
age_by_outcome   # exporte a tabela
```

### Proporções {.unnumbered}

Para obter proporções, utilize a tabela acima na função `prop.table()`. Use o argumento `margins =` para especificar caso você queira que as proporções sejam calculadas das linhas (1), colunas (2), ou da tabela inteira (3). No código abaixo, encadeamos ("piped") a tabela com a função `round()`, do R **base**, especificando 2 dígitos.

```{r}
# obtenhas as proporções da tabela definida acima, por linhas, arredondado
prop.table(age_by_outcome, 1) %>% round(2)
```

### Totais {.unnumbered}

Para adicionar colunas e linhas com totais, passe a tabela gerada para a função `addmargins()`. Isto funciona para contagens e proporções.

```{r}
addmargins(age_by_outcome)
```

### Converta para um quadro de dados {.unnumbered}

Converter um objeto `table()` diretamente para um quadro de dado (*data frame*)s não é simples. Uma possível abordagem é mostrada abaixo:

1)  Crie a tabela, *sem utilizar* `useNA = "always"`. Em vez disso, converta os valores `NA` para "(Missing)" com a função `fct_explicit_na()`, do pacote **forcats**.\
2)  Adicione os totais (opcional) ao aplicar a tabela na função `addmargins()`\
3)  Utilize a tabela na função do R **base** `as.data.frame.matrix()`\
4)  Transforme a tabela utilizando a função do pacote **tibble,** `rownames_to_column()`, especificando o nome da primeira coluna\
5)  Exporte, Visualize, ou exporte como desejado. Neste exemplo, nós utilizamos a função `flextable()`, do pacote **flextable**, como descrito na página [Tabelas para apresentação](#tables-presentation). Isto irá exportar a tabela para o RStudio viewer como uma linda imagem HTML.

```{r, warning=F, message=F}
table(fct_explicit_na(linelist$age_cat), fct_explicit_na(linelist$outcome)) %>% 
  addmargins() %>% 
  as.data.frame.matrix() %>% 
  tibble::rownames_to_column(var = "Age Category") %>% 
  flextable::flextable()
```

<!-- ======================================================= -->

## Recursos extras

Muitas das informações desta página foram adaptadas destes recursos e tutoriais online:

[gtsummary](http://www.danieldsjoberg.com/gtsummary/articles/tbl_summary.html)

[dplyr](https://dplyr.tidyverse.org/articles/grouping.html)
```{r include=FALSE, cache=FALSE}

# clear workspace
rm(list = ls(all = TRUE))

# clear all packages except base
#lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))

# to ensure that tidyverse packages prevail
filter <- dplyr::filter
select <- dplyr::select
summarise <- dplyr::summarise
summary <- base::summary
incidence <- incidence2::incidence

#load core packages
pacman::p_load(
     rio,
     here,
     DT,
     stringr,
     lubridate,
     tidyverse
)

# import the cleaned ebola linelist
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

# import the count data - facility level
#count_data <- rio::import(here::here("data", "facility_count_data.rds"))

# Settings

options(scipen=1, digits=7)

# print only text (not code)
# library(knitr)
# opts_chunk$set(list(echo = FALSE, eval = FALSE))
```

<!--chapter:end:new_pages/tables_descriptive.Rmd-->

# Testes estatísticos simples {#stat-tests}


Esta página demonstra como realizar testes estatísticos simples com os pacotes R **base**, **rstatix**, e **gtsummary**.  

* Teste t  
* Teste de Shapiro-Wilk  
* Teste de Wilcoxon  
* Teste de Kruskal-Wallis  
* Teste qui-quadrado de Pearson  
* Correlações entre variáveis numéricas  

...muitos outros testes podem ser realizados, mas mostramos apenas os mais comuns e fornecemos links para outras fontes.  

Cada um dos pacotes acima possui certas vantagens e desvantagens:

* Utilize as funções do pacote R **base** para exportar resultados estatísticos para o console do R
* Utilize as funções do pacote **rstatix** para gerar os resultados em um quadro de dados, ou caso queira que os testes sejam realizados por grupos
* Utilize o pacote **gtsummary** para exportar facilmente tabelas prontas para publicação.



<!-- ======================================================= -->
## Preparação {  }


### Carregue os pacotes {.unnumbered}

Este pequeno código carrega os pacotes necessários para as análises. Neste manual, nós estimulamos o uso da função `p_load()`, do **pacman**, que instala os pacotes, caso necessários, *e* os carrega para utilização. Também é possível carregar pacotes já instalados com a função `library()` do pacote R **base**. Veja a página sobre [Introdução ao R](#basics) para mais informações sobre pacotes do R.


```{r}
pacman::p_load(
  rio,          # Importa arquivos
  here,         # Localiza arquivos
  skimr,        # visualize os dados
  tidyverse,    # gerenciamento dos dados + gráficos no ggplot2, 
  gtsummary,    # resumo estatístico e testes
  rstatix,      # estatísticas
  corrr,        # análise de correlação entre variáveis numéricas
  janitor,      # adicione totais e porcentagens às tabelas
  flextable     # converte tabelas para o formato HTML
  )
```

### Importando os dados {.unnumbered}

Nós iremos importar o banco de dados dos casos de uma simulação de epidemia de Ebola. Se você quiser acompanhar, <a href='https://github.com/appliedepi/epirhandbook_eng/raw/master/data/case_linelists/linelist_cleaned.rds' class='download-button'>clique para baixar o banco "limpo"</a> (como arquivo .rds). Importe os dados com a função `import()`, do pacote **rio** (ela aceita muitos formatos de arquivos, como .xlsx, .rds, .csv - veja a página [Importar e exportar](#importing) para detalhes).  


```{r, echo=F}
# importa o banco de dados para o ambiente R
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))
```

```{r, eval=F}
# importa o 'linelist'
linelist <- import("linelist_cleaned.rds")
```

As primeiras 50 linhas dos dados são mostradas abaixo.

```{r, message=FALSE, echo=F}
# display the linelist data as a table
DT::datatable(head(linelist, 50), rownames = FALSE, filter="top", options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```





## Pacote R **base** {}

Você pode utilizar as funções do pacote R **base** para realizar testes estatísticos. Os comandos são relativamente simples, e os resultados são exportados para o terminal do R para visualização. Entretanto, normalmente os resultados são gerados no formato de listas, o que dificulta a manipulação, caso queira utilizá-los posteriormente.

### Testes T {.unnumbered} 

O [teste t](https://en.wikipedia.org/wiki/Student%27s_t-test), também chamando de "Teste t de Student", é tipicamente utilizado para determinar se existem diferenças significativas entre as médias de variáveis numéricas de dois grupos distintos. Aqui, nós iremos mostrar duas sintaxes para realizar esse teste, de acordo com a presença ou não das colunas no mesmo quadro de dados.

**Sintaxe 1:** Esta é a sintaxe utilizada quando as colunas numéricas e categóricas estão no mesmo quadro de dados (*data frame*). Especifique a coluna numérica no lado esquerdo da equação, e a coluna categórica no lado direito. Coloque o nome do banco de dados no argumento `data = `. Opcionalmente, ajuste os argumentos `paired = TRUE`, `conf.level = ` para (0.95 default), e `alternative = ` para ("two.sided", "less", ou "greater"). Digite `?t.test` para mais detalhes.  

```{r}
## compare a média das idades de acordo com o sexo com um teste t
t.test(age_years ~ gender, data = linelist)
```

**Sintaxe 2:** Você pode comparar dois vetores numéricos separados com essa sintaxe. Por exemplo, se as duas colunas estão em bancos de dados distintos.

```{r, eval=F}
t.test(df1$age_years, df2$age_years)
```

Também é possível utilizar o teste t para determinar se a média de uma amostra é significativamente diferente de algum valor específico. Aqui, nós aplicamos o teste t entre uma amostra e uma média conhecida/suposta de uma população (`mu = `):

```{r, eval=F}
t.test(linelist$age_years, mu = 45)
```

### Teste de Shapiro-Wilk {.unnumbered}  

O [teste de Shapiro-Wilk](https://en.wikipedia.org/wiki/Shapiro%E2%80%93Wilk_test) pode ser utilizado para determinar se uma amostra foi obtida de uma população com distribuição normal (um pré-requisito de muitos outros testes e análises, como o teste t). Entretanto, isto só pode ser utilizado em uma amostra de 3 a 5000 observações. Para amostras maiores, um [gráfico de Quantil-Quantil](https://ggplot2.tidyverse.org/reference/geom_qq.html) é recomendado.


```{r, eval=F}
shapiro.test(linelist$age_years)
```

### Teste de Wilcoxon {.unnumbered}

O teste de Wilcoxon, também chamado de [teste U de Mann–Whitney](https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test), é frequentemente utilizado para determinar se duas amostras numéricas possuem a mesma distribuição, mesmo quando suas populações não possuem distribuição normal ou possuem variância independente (desiguais).

```{r wilcox_base}

## compare a distribuição da idade de acordo com o grupo 'outcome' utilizando o teste wilcox
wilcox.test(age_years ~ outcome, data = linelist)

```


### Teste de Kruskal-Wallis {.unnumbered}


O [tesde de Kruskal-Wallis](https://en.wikipedia.org/wiki/Kruskal%E2%80%93Wallis_one-way_analysis_of_variance) é uma extensão do teste de Wilcoxon que pode ser utilizado para verificar diferenças na distribuição de mais de duas amostras. Quando apenas duas amostras são utilizadas, os resultados são idênticos ao teste de Wilcoxon.

```{r }

## compare a distribuição da idade de acordo com o grupo 'outcome' utilizando o teste de kruskal-wallis
kruskal.test(age_years ~ outcome, linelist)

```

### Teste de qui-quadrado {.unnumbered} 

[O teste do qui-quadrado de Pearson](https://en.wikipedia.org/wiki/Chi-squared_test) é utilizado para verificar se existem diferenças significativas entre grupos categóricos.

```{r}

## compare as proporções em cada grupo utilizando o teste do qui-quadrado
chisq.test(linelist$gender, linelist$outcome)

```



## Pacote **rstatix** {}

O pacote **rstatix** realiza testes estatísticos e gera os resultados de forma que possam ser manipulados ("pipe-friendly"). Os resultados são gerados automaticamente em um quadro de dados (*data frame*), sendo possível realizar operações posteriores com eles. Também é fácil agrupar os dados utilizados nas funções, podendo as estatísticas serem executadas por cada grupo.


### Estatísticas resumo {.unnumbered}  

A função `get_summary_stats()` é uma maneira rápida de gerar resultados estatísticos. Simplesmente aplique seu banco de dados nessa função, e escolha as colunas para analisar. Se nenhuma coluna for especificada, as estatísticas são calculadas com todas as colunas.

Por padrão, um resumo estatístico completo é gerado: n, max, min, mediana, 25%ile, 75%ile, IQR, desvio absoluto mediano (mad), média, desvio padrão, erro padrão, e o intervalo de confiança da média.


```{r}
linelist %>%
  rstatix::get_summary_stats(age, temp)
```

Você pode especificar um sub-grupo do resumo estatístico a ser gerado, ao fornecer um dos seguintes valores ao argumento `type = `: "full", "common", "robust", "five_number", "mean_sd", "mean_se", "mean_ci", "median_iqr", "median_mad", "quantile", "mean", "median", "min", "max".  

Esta função também pode ser utilizada com dados agrupados, de forma que uma linha é gerada por cada variável agrupável:

```{r}
linelist %>%
  group_by(hospital) %>%
  rstatix::get_summary_stats(age, temp, type = "common")
```

O pacote **rstatix** também pode ser utilizado para realizar testes estatísticos:

### Teste t {.unnumbered}  

Utilize a sintaxe para especificar as colunas numérica e categórica:

```{r}
linelist %>% 
  t_test(age_years ~ gender)
```

Ou utilize `~ 1` e especifique `mu = ` para realizar o teste t de uma amostra. Isto também pode ser realizado por grupos.

```{r}
linelist %>% 
  t_test(age_years ~ 1, mu = 30)
```

Se necessário, os testes estatísticos podem ser realizados por grupos, como mostrado abaixo:

```{r}
linelist %>% 
  group_by(gender) %>% 
  t_test(age_years ~ 1, mu = 18)
```

### Tesde de Shapiro-Wilk {.unnumbered}  

Como dito acima, o tamanho da amostra precisa estar entre 3 e 5000.

```{r}
linelist %>% 
  head(500) %>%            # primeiras 500 linhas dos dados em linelist, para exemplificação apenas
  shapiro_test(age_years)
```

### Tesde de Wilcoxon {.unnumbered}  

```{r}
linelist %>% 
  wilcox_test(age_years ~ gender)
```


### Teste de Kruskal-Wallis {.unnumbered}  

Também conhecido como teste U de Mann-Whitney.

```{r}
linelist %>% 
  kruskal_test(age_years ~ outcome)
```


### Teste do Qui-quadrado {.unnumbered}  

A função do teste do Qui-quadrado pode utilizar uma tabela, então primeiro criamos uma tabulação cruzada. Existem diversas formas de realizar isto (veja página de [Tabelas descritivas](#tables-descriptive)), mas aqui utilizamos a função `tabyl()`, do pacote **janitor**, e então removemos a coluna mais a esquerda (com os nomes) antes de utilizá-la na função `chisq_test()`.

```{r}
linelist %>% 
  tabyl(gender, outcome) %>% 
  select(-1) %>% 
  chisq_test()

```

Muitas outras funções e testes estatísticos podem ser realizados com as funções do **rstatix**. Veja a documentação do **rstatix** [online aqui](https://github.com/kassambara/rstatix) ou digite `?rstatix`.  





## Pacote `gtsummary` {#stats_gt}

Use o **gtsummary** se você quiser adicionar os resultados de um teste estatístico em uma tabela criada com esse pacote (como descrito na seção do **gtsummary** na página de [Tabelas descritivas](#tbl_gt)).  

Para realizar testes estatísticos de comparação com a função `tbl_summary`, basta adicionar a função `add_p` na tabela e especificar qual teste utilizar. É possível obter os p-valores corrigidos para testes múltiplos ao utilizar a função `add_q`. Utilize o comando `?tbl_summary` para mais detalhes.  

### Teste Qui-quadrado {.unnumbered}

Compare as proporções de uma variável categórica em dois grupos. O teste estatístico padrão para a função `add_p()` para uma variável categórica é o teste Qui-quadrado de independência com correção de continuidade. Entretanto, caso alguma contagem seja abaixo de 5, o teste exato de Fisher é utilizado em seu lugar.

```{r chi_gt}

theme_gtsummary_language("pt") # acrescentando tradução para o portugues

linelist %>% 
  select(gender, outcome) %>% # selecione as variáveis de interesse
  mutate(outcome=ifelse(outcome=="Death", "Óbito",
                        ifelse(outcome=="Recover", "Recuperado",outcome))) %>%  #só traduzindo 
  tbl_summary(by = outcome, # produza uma tabela resumo e especifique a variável de agrupamento
              label = list( gender ~"gênero")) %>% # traduzindo o rótulo
  add_p()                        # especifique qual teste estatístico realizar %>% 



```


### Testes t {.unnumbered} 

Compare a diferença média de uma variável contínua em dois grupos.
Por exemplo, compare a média das idades de acordo com a evolução clínica do paciente.

```{r ttest_gt}

linelist %>% 
  select(age_years, outcome) %>%             # selecione as variáveis de interesse
  mutate(outcome=ifelse(outcome=="Death", "Óbito",
                        ifelse(outcome=="Recover", "Recuperado",outcome))) %>%  #só traduzindo 
  tbl_summary(                               # produza uma tabela resumo
    statistic = age_years ~ "{mean} ({sd})", # especifique quais estatísticas mostrar
    by = outcome, # especifique a variável de agrupamento
    label = list(age_years ~ "idade")) %>%   # traduzindo                     
  add_p(age_years ~ "t.test")                # especifique quais testes realizar


```

### Teste de Wilcoxon {.unnumbered}

Compare a distribuição de uma variável contínua em dois grupos. O padrão é utilizar o teste de Wilcoxon e a mediana (IQR) quando comparar dois grupos. Entretanto, para dados sem distribuição normal ou ao comparar grupos múltiplos, o teste de Kruskal-Wallis é o mais apropriado.

```{r wilcox_gt}

linelist %>% 
  select(age_years, outcome) %>%                       # selecione as variáveis de interesse
  mutate(outcome=ifelse(outcome=="Death", "Óbito",
                        ifelse(outcome=="Recover", "Recuperado",outcome))) %>% # traduzindo
  tbl_summary(                                         # produz uma tabela resumo
    statistic = age_years ~ "{median} ({p25}, {p75})", # especifique quais estatísticas mostrar (estes valores são padrão e podem ser removidos)
    by = outcome, # especifique a variável de agrupamento
    label = list( age_years ~ "idade")) %>%    # traduxindo                              
  add_p(age_years ~ "wilcox.test")                     # especifique qual teste realizar (existem testes padrão, então é possível deixar os parênteses em branco)


```

### Teste de Kruskal-wallis {.unnumbered}

Compare a distribuição de uma variável contínua em dois ou mais grupos, independentemente dos dados terem distribuição normal ou não.

```{r kruskal_gt}

linelist %>% 
  select(age_years, outcome) %>%                       # selecione as variáveis de interesse
  mutate(outcome=ifelse(outcome=="Death", "Óbito",
                        ifelse(outcome=="Recover", "Recuperado",outcome))) %>% # traduzindo
  tbl_summary(                                         # produza tabelas resumo
    statistic = age_years ~ "{median} ({p25}, {p75})", # especifique quais estatísticas mostrar (existem valores padrão, então pode-se deixar os parênteses em branco)
    by = outcome, # especifique a variável de agrupamento
    label = list(age_years ~ "idade")) %>%     # traduzindo                             
  add_p(age_years ~ "kruskal.test")                    # especifique qual teste realizar


```




<!-- ## `dplyr` package {} -->

<!-- Performing statistical tests in `dplyr` alone is very dense, again because it  -->
<!-- does not fit within the tidy-data framework. It requires using `purrr` to create -->
<!-- a list of dataframes for each of the subgroups you want to compare. See the page on [Iteration, loops, and lists] to learn about **purrr**.   -->

<!-- An easier alternative may be the `rstatix` package.  -->

<!-- ### T-tests {.unnumbered}  -->

<!-- ```{r ttest_dplyr} -->

<!-- linelist %>%  -->
<!--   ## only keep variables of interest -->
<!--   select(age, outcome) %>%  -->
<!--   ## drop those missing outcome  -->
<!--   filter(!is.na(outcome)) %>%  -->
<!--   ## specify the grouping variable -->
<!--   group_by(outcome) %>%  -->
<!--   ## create a subset of data for each group (as a list) -->
<!--   nest() %>%  -->
<!--   ## spread in to wide format -->
<!--   pivot_wider(names_from = outcome, values_from = data) %>%  -->
<!--   mutate( -->
<!--     ## calculate the mean age for the death group -->
<!--     Death_mean = map(Death, ~mean(.x$age, na.rm = TRUE)), -->
<!--     ## calculate the sd among dead  -->
<!--     Death_sd = map(Death, ~sd(.x$age, na.rm = TRUE)), -->
<!--     ## calculate the mean age for the recover group -->
<!--     Recover_mean = map(Recover, ~mean(.x$age, na.rm = TRUE)),  -->
<!--     ## calculate the sd among recovered  -->
<!--     Recover_sd = map(Recover, ~sd(.x$age, na.rm = TRUE)), -->
<!--     ## using both grouped data sets compare mean age with a t-test -->
<!--     ## keep only the p.value -->
<!--     t_test = map2(Death, Recover, ~t.test(.x$age, .y$age)$p.value) -->
<!--   ) %>%  -->
<!--   ## drop datasets  -->
<!--   select(-Death, -Recover) %>%  -->
<!--   ## return a dataset with the medians and p.value (drop missing) -->
<!--   unnest(cols = everything()) -->

<!-- ``` -->


<!-- ### Wilcoxon rank sum test {.unnumbered} -->

<!-- ```{r wilcox_dplyr} -->

<!-- linelist %>%  -->
<!--   ## only keep variables of interest -->
<!--   select(age, outcome) %>%  -->
<!--   ## drop those missing outcome  -->
<!--   filter(!is.na(outcome)) %>%  -->
<!--   ## specify the grouping variable -->
<!--   group_by(outcome) %>%  -->
<!--   ## create a subset of data for each group (as a list) -->
<!--   nest() %>%  -->
<!--   ## spread in to wide format -->
<!--   pivot_wider(names_from = outcome, values_from = data) %>%  -->
<!--   mutate( -->
<!--     ## calculate the median age for the death group -->
<!--     Death_median = map(Death, ~median(.x$age, na.rm = TRUE)), -->
<!--     ## calculate the sd among dead  -->
<!--     Death_iqr = map(Death, ~str_c( -->
<!--       quantile(.x$age, probs = c(0.25, 0.75), na.rm = TRUE),  -->
<!--       collapse = ", " -->
<!--       )), -->
<!--     ## calculate the median age for the recover group -->
<!--     Recover_median = map(Recover, ~median(.x$age, na.rm = TRUE)),  -->
<!--     ## calculate the sd among recovered  -->
<!--     Recover_iqr = map(Recover, ~str_c( -->
<!--       quantile(.x$age, probs = c(0.25, 0.75), na.rm = TRUE),  -->
<!--       collapse = ", " -->
<!--       )), -->
<!--     ## using both grouped data sets compare age distribution with a wilcox test -->
<!--     ## keep only the p.value -->
<!--     wilcox = map2(Death, Recover, ~wilcox.test(.x$age, .y$age)$p.value) -->
<!--   ) %>%  -->
<!--   ## drop datasets  -->
<!--   select(-Death, -Recover) %>%  -->
<!--   ## return a dataset with the medians and p.value (drop missing) -->
<!--   unnest(cols = everything()) -->

<!-- ``` -->

<!-- ### Kruskal-wallis test {.unnumbered} -->


<!-- ```{r kruskal_dplyr} -->

<!-- linelist %>%  -->
<!--   ## only keep variables of interest -->
<!--   select(age, outcome) %>%  -->
<!--   ## drop those missing outcome  -->
<!--   filter(!is.na(outcome)) %>%  -->
<!--   ## specify the grouping variable -->
<!--   group_by(outcome) %>%  -->
<!--   ## create a subset of data for each group (as a list) -->
<!--   nest() %>%  -->
<!--   ## spread in to wide format -->
<!--   pivot_wider(names_from = outcome, values_from = data) %>%  -->
<!--   mutate( -->
<!--     ## calculate the median age for the death group -->
<!--     Death_median = map(Death, ~median(.x$age, na.rm = TRUE)), -->
<!--     ## calculate the sd among dead  -->
<!--     Death_iqr = map(Death, ~str_c( -->
<!--       quantile(.x$age, probs = c(0.25, 0.75), na.rm = TRUE),  -->
<!--       collapse = ", " -->
<!--       )), -->
<!--     ## calculate the median age for the recover group -->
<!--     Recover_median = map(Recover, ~median(.x$age, na.rm = TRUE)),  -->
<!--     ## calculate the sd among recovered  -->
<!--     Recover_iqr = map(Recover, ~str_c( -->
<!--       quantile(.x$age, probs = c(0.25, 0.75), na.rm = TRUE),  -->
<!--       collapse = ", " -->
<!--       )), -->
<!--     ## using the original data set compare age distribution with a kruskal test -->
<!--     ## keep only the p.value -->
<!--     kruskal = kruskal.test(linelist$age, linelist$outcome)$p.value -->
<!--   ) %>%  -->
<!--   ## drop datasets  -->
<!--   select(-Death, -Recover) %>%  -->
<!--   ## return a dataset with the medians and p.value (drop missing) -->
<!--   unnest(cols = everything()) -->

<!-- ``` -->

<!-- ### Chi-squared test {.unnumbered}  -->


<!-- ```{r} -->
<!-- linelist %>%  -->
<!--   ## do everything by gender  -->
<!--   group_by(outcome) %>%  -->
<!--   ## count the variable of interest -->
<!--   count(gender) %>%  -->
<!--   ## calculate proportion  -->
<!--   ## note that the denominator here is the sum of each gender -->
<!--   mutate(percentage = n / sum(n) * 100) %>%  -->
<!--   pivot_wider(names_from = outcome, values_from = c(n, percentage)) %>%  -->
<!--   filter(!is.na(gender)) %>%  -->
<!--   mutate(pval = chisq.test(linelist$gender, linelist$outcome)$p.value) -->
<!-- ``` -->


<!-- ======================================================= -->

## Correlações

Correlações entre variáveis numéricas podem ser investigadas utilizando os pacotes **tidyverse** **corrr**. Assim, é possível realizar os testes de correlação de Pearson, tau ($\tau$) de Kendall ou rho ($\rho$) de Spearman. O pacote cria uma tabela e tem uma função para gerar um gráfico os valores automaticamente.

```{r, warning=F, message=F}

correlation_tab <- linelist %>% 
  select(generation, age, ct_blood, days_onset_hosp, wt_kg, ht_cm) %>%   # selecione as variáveis numéricas de interesse
  correlate()      # cria uma tabela de correlação (utilizando o teste padrão pearson)

correlation_tab    # exporte a tabela para o terminal 

## remove entradas duplicadas (a tabela acima é espelhada) 
correlation_tab <- correlation_tab %>% 
  shave()

## visualize a a tabela de correlação
correlation_tab

## plote as correlações
rplot(correlation_tab)
```


<!-- ======================================================= -->

## Recursos {  }

Muitas informações dessa página foram adaptadas dos recursos e tutoriais online abaixo:

[gtsummary](http://www.danieldsjoberg.com/gtsummary/articles/tbl_summary.html)
[dplyr](https://dplyr.tidyverse.org/articles/grouping.html)
[corrr](https://corrr.tidymodels.org/articles/using-corrr.html)
[sthda correlation](http://www.sthda.com/english/wiki/correlation-test-between-two-variables-in-r)
```{r include=FALSE, cache=FALSE}

# clear workspace
rm(list = ls(all = TRUE))

# clear all packages except base
#lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))

# to ensure that tidyverse packages prevail
filter <- dplyr::filter
select <- dplyr::select
summarise <- dplyr::summarise
summary <- base::summary
incidence <- incidence2::incidence

#load core packages
pacman::p_load(
     rio,
     here,
     DT,
     stringr,
     lubridate,
     tidyverse
)

# import the cleaned ebola linelist
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

# import the count data - facility level
#count_data <- rio::import(here::here("data", "facility_count_data.rds"))

# Settings

options(scipen=1, digits=7)

# print only text (not code)
# library(knitr)
# opts_chunk$set(list(echo = FALSE, eval = FALSE))
```

<!--chapter:end:new_pages/stat_tests.Rmd-->

# Regressão simples e múltipla {#regression}

<!-- ======================================================= -->

Esta página demonstra o uso das funções de regressão do pacote R **base** , como `glm()`, e o pacote **gtsummary** para 
verificar as associações entre as variáveis (ex.: riscos relativos, relações de risco e *hazard ratio*).
Também serão mostradads funções como `tidy()`, do pacote **broom**, para limpar os resultados da regressão.

1.  Univariado: tabelas 2 x 2
2.  Estratificado: método de Mantel-Haenszel
3.  Multivariada: seleção variada, seleção de modelo, tabela final
4.  Gráfico em floresta

Para realizar a regressão proporcional de riscos (regressão Cox), veja a página [Análise de sobrevivência](#survival-analysis).  

<span style="color: black;">**_NOTE:_** O termo *multivariável* é utilizado aqui ao se referir à uma regressão com múltiplas variáveis explicativas. Assim, um modelo *multivariado* seria uma regressão com diferentes resultados - veja esse [editorial](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3518362/) para detalhes </span> 

<!-- ======================================================= -->

## Preparação {  }


### Carregue os pacotes {.unnumbered}

Este código realiza o carregamento dos pacotes necessários para as análises. Neste manual, nós enfatizamos o uso da função `p_load()`, do pacote **pacman**, que instala os pacotes, caso necessário, *e* os carrega para utilização. Você também pode utilizar a função `library()`, do pacote R **base** , para carregar pacotes instalados. Veja a página sobre o Introdução ao R](#basics) para mais informações sobre os pacotes R.

```{r}
pacman::p_load(
  rio,          # Importa arquivos
  here,         # Localiza arquivos
  tidyverse,    # gestão dos dados + gráficos no ggplot2
  stringr,      # manipulação de textos em formato string
  purrr,        # explore os objetos de forma organizada
  gtsummary,    # resumos estatísticos e testes
  broom,        # organize os resultados das regressões
  lmtest,       # testes de relação de verosimilhança
  parameters,   # alternativa para organizar os resultados das regressões
  see           # alternativa para visualizar os gráficos em floresta
  )
```

### Importe os dados {.unnumbered}

Nós iremos importar o banco de dados dos casos de uma simulação de epidemia de Ebola. Se você quiser acompanhar os passos abaixo, <a href='https://github.com/epirhandbook/Epi_R_handbook/raw/master/data/case_linelists/linelist_cleaned.rds' class='download-button'>clique aqui para fazer o download do banco de dados 'limpo'</a> (como arquivo .rds). Importe seus dados utilizando a função `import()`, do pacote **rio** (esta função importa muitos tipos de arquivos, como .xlsx, .rds, .csv - veja a página [Importar e exportar](#importing) para detalhes).


```{r, echo=F}
# importe os dados no R no objeto linelist
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))
```

```{r, eval=F}
# importe os dados no R no objeto linelist
linelist <- import("linelist_cleaned.rds")
```

As primeiras 50 linhas do `linelist` são mostradas abaixo.

```{r, message=FALSE, echo=F}
# display the linelist data as a table
DT::datatable(head(linelist, 50), rownames = FALSE, options = list(pageLength = 5, scrollX=T) )
```

### Limpando os dados {.unnumbered}

#### Armazene as variáveis explicativas {.unnumbered}  

No código abaixo, os nomes das colunas explicativas são salvos como um vetor de caracteres. Eles serão utilizados posteriormente.

```{r}
## escolha as variáveis de interesse
explanatory_vars <- c("gender", "fever", "chills", "cough", "aches", "vomit")
```


#### Converta para 1s e 0s {.unnumbered}   

Abaixo, as colunas de variáveis explicativas com as opções binárias "yes"/"no", "m"/"f", e "dead"/"alive" são convertidas para **1 / 0**, visando serem utilizadas nos modelos de regressão. Para fazer isso de forma eficiente, utilize a função `across()`, do **dplyr**, para transformar múltiplas colunas de uma vez. A função `case_when()` (também do **dplyr**) utiliza argumentos lógicos para converter valores específicos para 1s ou 0s. Veja as seções das funções `across()` e `case_when()` na [página de limpando dados e funções essenciais](#clean_across)).  

Nota: o "." abaixo representa a coluna que está sendo processada pela função `across()` no momento.

```{r}
## converte variáveis dicotômicas para 0/1 
linelist <- linelist %>%  
  mutate(across(                                      
    .cols = all_of(c(explanatory_vars, "outcome")),  ## para cada coluna listada e "outcome"
    .fns = ~case_when(                              
      . %in% c("m", "yes", "Death")   ~ 1,           ## transforma male/yes/death em 1
      . %in% c("f", "no",  "Recover") ~ 0,           ## transforma female/no/recover em 0
      TRUE                            ~ NA_real_)    ## do contrário, transforma em 'missing'
    )
  )

       
      
```

#### Exclua linhas com valores em branco {.unnumbered}  

Para excluir linhas com valores em branco, é possível utilizar a função `drop_na()`, do pacote **tidyr**. Entretanto, nós queremos que isso aconteça apenas nas linhas com campos em branco nas colunas de interesse.

A primeira coisa a fazer é garantir que o nosso vetor `explanatory_vars` contenha a coluna `age` (`age` deve ter gerado um erro na operação anterior utilizando `case_when()`, que era apenas para variáveis dicotômicas). Então, nós utilizamos o objeto `linelist` na função `drop_na()` para remover qualquer linha com campos em branco na coluna `outcome` ou em qualquer uma das colunas salvas em `explanatory_vars`.  

Antes de executar o código, o número de linhas no objeto `linelist` é obtido por ` nrow(linelist)`.  

```{r}
## adiciona a coluna age_category no vetor explanatory_vars 
explanatory_vars <- c(explanatory_vars, "age_cat")

## exclua linhas com campos em branco nas variáveis de interesse
linelist <- linelist %>% 
  drop_na(any_of(c("outcome", explanatory_vars)))

```

O número de linhas restante no `linelist` é ` nrow(linelist)`.  


<!-- ======================================================= -->

## Univariado {  }

Assim como na página sobre [Tabelas descritivas](#tables-descriptive), os seus objetivos irão determinar quais pacotes R utilizar. Aqui, nós apresentamos duas opções para realizar análises univariadas:

* Utilize as funções disponíveis no pacote R **base** para rapidamente obter os resultados no terminal. Utilize o pacote **broom** para organizar os resultados.
* Utilize o pacote **gtsummary** para modelar e obter resultados prontos para publicação



<!-- ======================================================= -->

### Pacote R **base** {.unnumbered}

#### Regressão linear {.unnumbered}  

A função `lm()`, do R **base**, executa regressões lineares, avaliando a relação entre respostas numéricas e variáveis explanatórias (independentes), que se presume terem uma relação linear.

Forneça a equação como uma fórmula, com os nomes das colunas contendo as respostas numéricas e as variáveis explanatórias separadas por um til `~`. Adicionalmente, especifique qual o banco de dados em `data = `. Para utiliza-los posteriormente, atribua os resultados da modelagem a um objeto R.

```{r lin_reg}
lm_results <- lm(ht_cm ~ age, data = linelist)
```

Você pode executar a função `summary()` nos resultados obtidos para visualizar os coeficientes (*Estimates*), p-valor, resíduos, e outras medições.

```{r lin_reg_res}
summary(lm_results)
```

Alternativamente, é possível utilizar a função `tidy()`, do pacote **broom**, para organizar os resultados em uma tabela. O que os resultados nos mostram é que, a cada ano, a altura aumenta em 3.5 cm, e isto é estatisticamente significativo.

```{r lin_reg_res_tidy}
tidy(lm_results)
```

Você também pode adicionar essa regressão na função **ggplot**. Para tanto, 
primeiro plotamos os dados observados e a linha de tendência da regressão linear em um quadro de dados
utilizando a função `augment()`, do pacote **broom**. 

```{r lin_reg_res_plot}

## coloque os pontos da regressão e os dados observados em um banco de dados
points <- augment(lm_results)

## trace um gráfico dos dados utilizando a variável 'age' no eixo x
ggplot(points, aes(x = age)) + 
  ## inclua os pontos para a altura
  geom_point(aes(y = ht_cm)) + 
  ## inclua a linha de tendência da regressão linear
  geom_line(aes(y = .fitted), colour = "red")

```

Também é possível adicionar uma linha simples de regressão linear diretamente no **ggplot**, 
utilizando a função `geom_smooth()`. 

```{r geom_smooth}

## coloque seus dados em um gráfico
 ggplot(linelist, aes(x = age, y = ht_cm)) + 
  ## mostre os pontos
  geom_point() + 
  ## inclua uma regressão linear
  geom_smooth(method = "lm", se = FALSE)
```

Veja a seção sobre Recursos extras no final deste capítulo para mais tutoriais detalhados.


#### Regressão logística {.unnumbered}  

A função `glm()`, do pacote **stats** (parte do pacote R **base**), é utilizada para ajustar Modelos Lineares Generalizados (GLM).  

`glm()` pode ser utilizada para regressões logísticas univariadas e multivariadas (ex.: para obter probabilidades). Aqui estão as partes principais:

```{r, eval=F}
# argumentos utilizados na função glm()
glm(formula, family, data, weights, subset, ...)
```

* `formula = ` o modelo é fornecido ao `glm()` como uma equação, com o resultado no lado esquerdo e as variáveis explicativas no lado direito de um til `~`.
* `family = ` Isto determina o tipo de modelo a ser executado. Para regressão logística, utilize `family = "binomial"`, para o modelo log-linear de poisson utilize `family = "poisson"`. Outros exemplos estão na tabela abaixo.
* `data = ` Especifique sua fonte de dados


Se necessário, você pode especificar o link da função utilizando a sintaxe `family = familytype(link = "linkfunction"))`. Você pode obter mais informações sobre outras famílias e argumentos opcionais, como `weights = ` e `subset = ` (`?glm`), na documentação.  



Família                 | Link padrão da função 
-----------------------|-------------------------------------------  
`"binomial"` | `(link = "logit")`  
`"gaussian"` | `(link = "identity")`  
`"Gamma"` | `(link = "inverse")`  
`"inverse.gaussian"` | `(link = "1/mu^2")`  
`"poisson"` | `(link = "log")`  
`"quasi"` | `(link = "identity", variance = "constant")`  
`"quasibinomial"` | `(link = "logit")`  
`"quasipoisson"` | `(link = "log")`  


Ao executar a funçaõ `glm()`, é comum salvar os resultados em um objeto R. Assim, você pode visualizar os resultados em seu terminal utilizando a função `summary()`, como mostrado abaixo, ou realizar outras operações com os resultados (ex.: potenciação).

Se você precisa executar uma regressão binominal negativa, é possível utilizar o pacote **MASS**; a função `glm.nb()` utiliza a mesma sintaxe que `glm()`.
Para um passo a passo sobre os diferentes modelos de regressão, acesse a [página sobre estatística da UCLA](https://stats.idre.ucla.edu/other/dae/). 

#### Função `glm()` univariada {.unnumbered}

Neste exemplo, nós iremos avaliar a associação entre diferentes categorias de idades e a evolução para óbito (codificado como 1 na seção de Preparação). Abaixo está um modelo univariado de `outcome` por `age_cat`. Os resultados do modelo são savos como `model`, e mostrados no terminal com a função `summary()`. Observe que as estimativas fornecidas são as *probabilidades em log*, onde o nível base é o primeiro Factor (classe Factor) da variável `age_cat`("0-4").

```{r}
model <- glm(outcome ~ age_cat, family = "binomial", data = linelist)
summary(model)
```

Para alterar o nível base de comparação de dada variável, garanta que a coluna é da classe Factor e altere a primeira posição ao nível desejado utilizando a função `fct_relevel()` (veja a página sobre [Fatores](#factors)). Por exemplo, abaixo nós adaptamos a coluna `age_cat` e escolhemos "20-29" como nível base antes de aplicar estes dados na função `glm()`.

```{r}
linelist %>% 
  mutate(age_cat = fct_relevel(age_cat, "20-29", after = 0)) %>% 
  glm(formula = outcome ~ age_cat, family = "binomial") %>% 
  summary()
```

#### Vizualizando os resultados {.unnumbered}

Na maioria das vezes, diferentes modificações precisam ser feitas nos resultados acima. A função `tidy()`, do pacote **broom**, é conveniente para transformar os resultados em um formato apresentável.

Aqui, nós demonstramos como combinar o resultado da modelagem com uma tabela de contagens.

1) Obtenha as probabilidades em log na forma *exponencial* e os intervalos de confiança ao aplicar o modelo na função `tidy()`, e ajustar os atributos `exponentiate = TRUE` e `conf.int = TRUE`.  

```{r odds_base_single}

model <- glm(outcome ~ age_cat, family = "binomial", data = linelist) %>% 
  tidy(exponentiate = TRUE, conf.int = TRUE) %>%        # realize a potenciação e produza intervalos de confiança
  mutate(across(where(is.numeric), round, digits = 2))  # arredonde todas as colunas numéricas
```

Abaixo é o objeto `model` mostrado de forma organizada:  

```{r, message=FALSE, echo=F}
# mostre os dados do objeto linelist como uma tabela
DT::datatable(model, rownames = FALSE, options = list(pageLength = nrow(model), scrollX=T), class = 'white-space: nowrap' )
```

2) Combine os resultados dessa modelagem com uma tabela de contagens. Abaixo, nós criamos uma tabela cruzada de contagens com a função `tabyl()` do pacote **janitor**, como descrito na página sobre [Tabelas descritivas](#tables-descriptive):

```{r}
counts_table <- linelist %>% 
  janitor::tabyl(age_cat, outcome)
```


<!-- * Group rows by outcome, and get counts by age category   -->
<!-- * Pivot wider so the column are `age_cat`, `0`, and `1`   -->
<!-- * Remove row for `NA` `age_cat`, if applicable, to align with the model results   -->

<!-- ```{r} -->
<!-- counts_table <- linelist %>%  -->
<!--   filter(!is.na(outcome) & !is.na(age_cat)) %>%    # ensure outcome and age_cat are present  -->
<!--   group_by(outcome) %>%                            # get counts of variable of interest grouped by outcome -->
<!--   count(age_cat) %>%   ## gets number or rows by unique outcome-age category combinations   -->
<!--   pivot_wider(names_from = outcome, values_from = n)    ## spread data to wide format (as in cross-tabulation) -->

<!-- ``` -->


Aqui está como os dados em `counts_table` ficam quando tabelados:

```{r, message=FALSE, echo=F}
# exibe os dados do objeto linelist como uma tabela
DT::datatable(counts_table, rownames = FALSE, options = list(pageLength = nrow(counts_table), scrollX=T), class = 'white-space: nowrap' )
```

Agora nós podemos ligar os resultados dos objetos `counts_table` e `model` horizontalmente com a função `bind_cols()` (**dplyr**). Lembre que, com a função `bind_cols()`, as linhas dos dois objetos precisam estar alinhadas perfeitamente. Neste código, porque estamos ligando uma cadeia de comandos, nós utilizamos o `.` para representar o objeto de `counts_table` enquanto o ligamos ao `model`. Para finalizar o processo, a função `select()` é utilizada para selecionar colunas de interesse e sua ordem, e finalmente aplicar a função `round()`, do R **base**, em todas as colunas numéricas para até duas casas decimais.

```{r, message=F, warning=F}
combined <- counts_table %>%           # inicie com uma tabela de contagens
  bind_cols(., model) %>%              # combine ela com os resultados da regressão
  select(term, 2:3, estimate,          # selecione e organize as colunas
         conf.low, conf.high, p.value) %>% 
  mutate(across(where(is.numeric), round, digits = 2)) # arredonde para 2 casas decimais
```

Aqui está o resultado da combinação de duas tabelas, exportado como um bela imagem utilizando uma função do **flextable**. A página [Tabelas para apresentação](#tables-presentation) explica como customizar tais tabelas com o **flextable**, mas você pode utilizar outros inúmeros pacotes do R, como **knitr** ou **GT**.

```{r}
combined <- combined %>% 
  flextable::qflextable()
```


#### Rodando múltiplos modelos univariados {.unnumbered}  

Abaixo, nós mostramos um método usando `glm()`e `tidy()`. Para uma abordagem mais simples, veja a seção sobre o **gtsummary**.

Para rodar os modelos com diferentes variáveis e produzir probabilidades univariadas (ex.: sem dependência entre elas), você pode utilizar a abordagem abaixo. Ela utiliza a função `str_c()`, do pacote **stringr**, para criar fórmulas univaridas (veja a página [caracteres e strings](#characters-strings)), e rodar a regressão `glm()`com cada fórmula, aplicando cada resultado `glm()` no `tidy()`, e, finalmente, unindo todos os resultados dos modelos com a função `bind_rows()`, do pacote **tidyr**. Esta abordagem utiliza a função `map()`, do pacote **purrr**, para repetir as funções - veja a página sobre [Iteração, loops, e listas](#iteration) para mais informações sobre essa ferramenta.

1) Crie um vetor com o nome das colunas com as variáveis explicativas. Nós já criamos este vetor como `explanatory_vars` na seção Preparação desta página.

2) Utilize a função `str_c()` para criar múltiplas fórmulas em texto, com o `outcome` no lado esquerdo, e o nome de uma coluna do `explanatory_vars`no lado direito. O ponto final '.' é substituído pelo nome da coluna em `explanatory_vars`.  

```{r}
explanatory_vars %>% str_c("outcome ~ ", .)
```

3) Utilize essas fórmulas na função `map()` e ajuste `~glm()` como a função a ser utilizada com cada entrada. Dentro da função `glm()`, ajuste a fórmula de regressão para `as.formula(.x)`, onde `.x` será substituído pela fórmula definida na etapa acima. A função `map()`irá rodar com cada uma das fórmulas, executando regressões para cada uma.

4) Os resultados deste primeiro `map()` são utilizados em um segundo comando `map()`, que aplica `tidy()` nos resultados das regressões.

5) Finalmente, o resultado do segundo `map()` (uma lista de quadros de dados organizados) é condensado com a função `bind_rows()`, resultando em um quadro de dados com todos os resultados univariados.


```{r odds_base_multiple}

models <- explanatory_vars %>%       # inicie com as variáveis de interesse
  str_c("outcome ~ ", .) %>%         # combine cada variável na fórmula ("outcome ~ variável de interesse")
  
  # repita as etapas para cada fórmula univariável
  map(                               
    .f = ~glm(                       # utilize as fórmulas uma por uma no glm()
      formula = as.formula(.x),      # dentro do glm(), a formula é representada por .x
      family = "binomial",           # especifique o tipo do glm (logístico)
      data = linelist)) %>%          # indique o banco de dados
  
  # organize cada um dos resultados das regressões acima
  map(
    .f = ~tidy(
      .x, 
      exponentiate = TRUE,           # realize a exponenciação
      conf.int = TRUE)) %>%          # obtenha os intervalos de confiança
  
  # condensa a lista dos resultados das regressões em um único quadro de dados
  bind_rows() %>% 
  
  # arredonde todas as colunas numéricas
  mutate(across(where(is.numeric), round, digits = 2))
```

Desta vez, o objeto final `models` é maior porque agora representa os resultados combinados de diferentes regressões univariadas. Clique na tabela para visualizar todas as linhas do `model`.

```{r, message=FALSE, echo=F}
# mostra os dados do linelist como uma tabela
DT::datatable(models, rownames = FALSE, options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```

Como antes, nós podemos criar uma tabela de contagem do objeto `linelist` para cada variável explicativa, ligar ela no objeto `models`, e fazer uma bela tabela. Nós podemos começar com as variáveis, e repetir os processos com a função `map()`. Nós repetimos a execução de uma função definida pelo usuário, que envolve a criação de uma tabela de contagem utilizando as funções do **dplyr**. Então, os resultados são combinados e ligados com os resultados de `models`.


```{r, warning=F, message=F}

## para cada variável explanatória
univ_tab_base <- explanatory_vars %>% 
  map(.f = 
    ~{linelist %>%                ## inicie com o linelist
        group_by(outcome) %>%     ## agrupe os dados por outcome
        count(.data[[.x]]) %>%    ## produza contagens das variáveis de interesse
        pivot_wider(              ## transforme para o formato amplo (wide), como em uma tabulação cruzada
          names_from = outcome,
          values_from = n) %>% 
        drop_na(.data[[.x]]) %>%         ## exclua as linhas com campos em branco
        rename("variable" = .x) %>%      ## altere a coluna com a variável de interesse para "variable"
        mutate(variable = as.character(variable))} ## converta para caractéres, do contrário as variáveis não dicotômicas (categóricas) geram a classe factor e não podem ser unidas
      ) %>% 
  
  ## condensa a lista com o resultado das contagens em um único quadro de dados
  bind_rows() %>% 
  
  ## une com os resultados da regressão
  bind_cols(., models) %>% 
  
  ## mantenha apenas as colunas de interesse
  select(term, 2:3, estimate, conf.low, conf.high, p.value) %>% 
  
  ## arredonde as casas decimais
  mutate(across(where(is.numeric), round, digits = 2))

```

Abaixo é como o quadro de dados fica após a execução do código. Veja a página sobre [Tabelas para apresentação](#tables-presentation) para ideias de como converter essa tabela para um formato bonito em HTML (ex.: com **flextable**).

```{r, message=FALSE, echo=F}
# mostre os dados da linelist como uma tabela
DT::datatable(univ_tab_base, rownames = FALSE, options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```





<!-- ======================================================= -->

### Pacote **gtsummary** {#reg_gt_uni .unnumbered}

Abaixo, nós apresentamos o uso da função `tbl_uvregression()` do pacote **gtsummary**. Assim como na página sobre [Tabelas descritivas](#tables-descriptive), as funções do **gtsummary** fazem um bom trabalho executando estatísticas *e* produzindo resultados com aparência profissional. A função `tbl_uvregression()` produz uma tabela com os resultados de uma regressão univariada.

Primeiro, nós selecionamos apenas as colunas de interesse do objeto `linelist` (variáveis explanatórias e a variável de evolução clínica \[outcome\]), e as aplicamos na função `tbl_uvregression()`. Então, iremos executar uma regressão univariada em cada uma das colunas definidas no vetor `explanatory_vars`, previamente criado na seção sobre Preparação dos dados (colunas gender, fever, chills, cough, aches, vomit, e age_cat).  

Dentro da função, os atributos serão modificados, como em `method = ` ao `glm` (sem aspas), o `y = ` com a coluna de evolução dos casos (`outcome`), especificar para o `method.args = ` que queremos rodar uma regressão logística através do atributo `family = binomial`, e então finalizamos com um comando para realizar a exponenciação dos resultados.

O resultado é gerado no formado HTML, e contém as contagens

```{r odds_gt, message=F, warning=F}

univ_tab <- linelist %>% 
  dplyr::select(explanatory_vars, outcome) %>% ## selecione as variáveis de interesse

  tbl_uvregression(                         ## produz uma tabela univariável
    method = glm,                           ## define qual regressão será rodada (glm)
    y = outcome,                            ## define a variável da evolução clínica (outcome)
    method.args = list(family = binomial),  ## define qual tipo de glm será rodador (logístico)
    exponentiate = TRUE                     ## realiza a exponenciação para produzir as probabilidades (em vez de probabilidaes em log)
  )

## visualize a tabela com os resultados da análise univariada
univ_tab
```

Exitem muitas modificações que podem ser feitas com a tabela gerada, como ajustar os rótulos em texto, destacar linhas pelo seu valor de p, etc. Veja tutoriais [aqui](http://www.danieldsjoberg.com/gtsummary/articles/tbl_regression.html) e em outras fontes online.



<!-- ======================================================= -->

## Análise estratificada {  }

A seção sobre análise estratificada ainda está sendo trabalhada no **gtsummary**. 
Esta página será atualizada quando possível.




## Multivariada

Para a análise multivariada, novamente apresentamos duas abordagens:

* `glm()` e `tidy()`  
* pacote **gtsummary**  

O fluxo de trabalho é similar para cada uma das abordagens, sendo apenas a última diferente quando a tabela final é obtida.


### Conduza a análise multivariada {.unnumbered}  


Aqui nós utilizamos a função `glm()`, mas adicionaremos mais variáveis no lado direito da equação, separadas pelos símbolos de mais (`+`).


Para rodar o modelo com todas as nossas variáveis exploratórias, nós executamos o seguinte código:

```{r}
mv_reg <- glm(outcome ~ gender + fever + chills + cough + aches + vomit + age_cat, family = "binomial", data = linelist)

summary(mv_reg)
```

Se você quiser incluir duas variáveis e uma interação entre elas, é possível separá-las com um asterisco `*` em vez do `+`. Separe eles com dois pontos `:` se você está especificando apenas a interação. Por exemplo:

```{r, eval=F}
glm(outcome ~ gender + age_cat * fever, family = "binomial", data = linelist)
```


*Opcionalmente*, você pode utilizar este código para nivelar o vetor pré-definido com os nomes das colunas, e re-criar o comando acima utilizando a função `str_c()`. Isto pode ser útil caso os nomes das suas variáveis explicativas estiverem mudando, ou se você não quiser digitar todas elas novamente.

```{r mv_regression}

## rode uma regressão com todas as variáveis de interesse
mv_reg <- explanatory_vars %>%  ## inicie com um vetor contendo o nome das colunas explicativas
  str_c(collapse = "+") %>%     ## combine todos os nomes das variáveis de interesse separados por um 'mais'
  str_c("outcome ~ ", .) %>%    ## combine os nomes das variáveis de interesse com o 'outcome' no estilo de fórmula
  glm(family = "binomial",      ## defina o tipo de glm como logístico,
      data = linelist)          ## defina seu banco de dados
```


#### Construíndo o modelo {.unnumbered}  

É possível construir seu modelo passo a passo, salvando diferentes modelos que incluem certas variáveis explicativas. Esses modelos podem ser comparados com os testes de probabilidade utilizando a função `lrtest()`, do pacote **lmtest**, como mostrado abaixo:  

<span style="color: black;">**_NOTA:_** Utilizar o teste `anova(model1, model2, test = "Chisq)` do R **base** produz os mesmos resultados </span> 

```{r}
model1 <- glm(outcome ~ age_cat, family = "binomial", data = linelist)
model2 <- glm(outcome ~ age_cat + gender, family = "binomial", data = linelist)

lmtest::lrtest(model1, model2)
```

Outra opção é utilizar o objeto modelado diretamente na função `step()`, do pacote **stats**. Especifique qual a direção da seleção das variáveis que quer utilizar quando for construir o modelo.

```{r}
## escolha um modelo utilizando a seleção 'foward' baseada no AIC
## você também pode escolher "backward" ou "both" ao ajustar a direção
final_mv_reg <- mv_reg %>%
  step(direction = "forward", trace = FALSE)
```


Para facilitar a visualização, é possível desativar a notação científica na sua sessão do R:

```{r}
options(scipen=999)
```

Como descrito na seção sobre análise univariada, aplique o resultado da modelagem na função `tidy()` para potencializar as probabilidades em log e os intervalos de confiança. Finalmente,  todas as colunas numéricas são arredondadads para duas casas decimais. Role o cursor para visualizar todas as linhas.

```{r mv_regression_base}

mv_tab_base <- final_mv_reg %>% 
  broom::tidy(exponentiate = TRUE, conf.int = TRUE) %>%  ## obtenha um quadro de dados organizado das estimativas
  mutate(across(where(is.numeric), round, digits = 2))          ## arredonde 
```

Aqui está o quadro de dados final:

```{r, message=FALSE, echo=F}
DT::datatable(mv_tab_base, rownames = FALSE, options = list(pageLength = 10, scrollX=T), class = 'white-space: nowrap' )
```





<!-- ======================================================= -->

### Combine as análises univariadas e multivariadas {.unnumbered}

#### Combine com o **gtsummary**  {.unnumbered}  

O pacote **gtsummary** possui a função `tbl_regression()`, que utiliza 
os resultados de uma regressão (`glm()` neste caso) e produz uma linda 
tabela resumo. 

```{r mv_regression_gt}
## mostra a tabela de resultados de uma regressão
mv_tab <- tbl_regression(final_mv_reg, exponentiate = TRUE)
```

Vamos visualizar a tabela:

```{r}
mv_tab
```

Também é possível combinar diferentes tabelas de resultados produzidas pelo **gtsummary** com 
a função `tbl_merge()`. Assim, podemos combinar os resultados multivariados com os resultados *univariados* do **gtsummary** que criamos [acima](#reg_gt_uni):  

```{r}
## combine com os resultados univariados
tbl_merge(
  tbls = list(univ_tab, mv_tab),                          # combine as tabelas
  tab_spanner = c("**Univariate**", "**Multivariable**")) # escolha o nome dos cabeçalhos
```



#### Combine com o pacote **dplyr** {.unnumbered}  

Uma alternativa para combinar os resultados univariados e multivariados do `glm()`/`tidy()` é com as funções de união do **dplyr**.

* Una os resultados univariados anteriores (`univ_tab_base`, com contagens) com os resultados multivariados organizados `mv_tab_base`  
* Use a função `select()` para manter apenas as colunas de interesse, especificar a sua ordem, e renomear elas
* Use a função `round()` com duas casas decimais em todas as colunas da classe Double

```{r, warning=F, message=F}
## combine tabelas univariadas e multivariadas 
left_join(univ_tab_base, mv_tab_base, by = "term") %>% 
  ## escolha as colunas e as renomeie
  select( # new name =  old name
    "characteristic" = term, 
    "recovered"      = "0", 
    "dead"           = "1", 
    "univ_or"        = estimate.x, 
    "univ_ci_low"    = conf.low.x, 
    "univ_ci_high"   = conf.high.x,
    "univ_pval"      = p.value.x, 
    "mv_or"          = estimate.y, 
    "mvv_ci_low"     = conf.low.y, 
    "mv_ci_high"     = conf.high.y,
    "mv_pval"        = p.value.y 
  ) %>% 
  mutate(across(where(is.double), round, 2))   

```




<!-- ======================================================= -->

## Gráfico em floresta (Forest Plot) {  }

Esta seção mostra como produzir um gráfico com os resultados da sua regressão.
Existem duas opções. Você pode construir uma plotagem utilizando o **ggplot2** ou utilizando 
um pacote-meta (um pacote que incluí muitos pacotes) chamado **easystats**.  

Veja a página sobre [básico do ggplot](#ggplot-basics) se você não é familiar com o pacote de plotagem **ggplot2**.  


<!-- ======================================================= -->

### Pacote **ggplot2** {.unnumbered}

É possível construir um gráfico em floresta com a função `ggplot()` ao plotar os resultados de uma regressão multivariada. Adicione as camadas das plotagens com estas funções "geoms":  

* realize estimativas com `geom_point()`  
* obtenha intervalos de confiança com `geom_errorbar()`  
* uma linha vertical em OU = 1 com `geom_vline()`  

Antes de traçar o gráfico, é interessante utilizar a função `fct_relevel()`, do pacote **forcats**, para escolher a ordem das variáveis/níveis no eixo y. `ggplot()` pode mostrar elas em uma ordem alfa-numérica que pode não funcionar bem com os valores da variável 'age category' ("30" apareceria antes de "5"). Veja a página sobre [fatores](#factors) para mais detalhes.

```{r ggplot_forest}

## remove o termo da intercepção dos seus resultados multivariados
mv_tab_base %>% 
  
  # escolhe a ordem dos níveis que aparecem no eixo y
  mutate(term = fct_relevel(
    term,
    "vomit", "gender", "fever", "cough", "chills", "aches",
    "age_cat5-9", "age_cat10-14", "age_cat15-19", "age_cat20-29",
    "age_cat30-49", "age_cat50-69", "age_cat70+")) %>%
  
  # remove a linha "intercept" do gráfico
  filter(term != "(Intercept)") %>% 
  
  ## trace um gráfico no eixo y e/ou as estimativas no eixo x
  ggplot(aes(x = estimate, y = term)) +
  
  ## mostre a estimativa como um ponto
  geom_point() + 
  
  ## adicione uma barra de erro para os intervalos de confiança
  geom_errorbar(aes(xmin = conf.low, xmax = conf.high)) + 
  
  ## mostre a linha. OR = 1 é referência para uma linha tracejada
  geom_vline(xintercept = 1, linetype = "dashed")
  
```


<!-- ======================================================= -->

### Pacotes **easystats** {.unnumbered}

Uma alternativa, caso você não queira realizar os ajustes finos no **ggplot2**, é utilizar uma combinação dos pacotes do **easystats**.  

A função `model_parameters()`, do pacote **parameters**, faz o equivalente
da função `tidy()` do pacote **broom**. O pacote **see** aceita estes resultados
e cria uma plotagem em floresta padrão, como se fosse um objeto `ggplot()`. 

```{r easystats_forest}
pacman::p_load(easystats)

## remove a intercepção dos seus resultados multivariados
final_mv_reg %>% 
  model_parameters(exponentiate = TRUE) %>% 
  plot()
  
```


<!-- ======================================================= -->

## Recursos {  }

O conteúdo desta página foi adaptado destes recursos e tutoriais onlines:

[Regressão linear no R](https://www.datacamp.com/community/tutorials/linear-regression-R)  

[gtsummary](http://www.danieldsjoberg.com/gtsummary/articles/tbl_regression.html)  

[Página sobre estatística da UCLA](https://stats.idre.ucla.edu/other/dae/)  

[Regressão gradual sthda](http://www.sthda.com/english/articles/36-classification-methods-essentials/150-stepwise-logistic-regression-essentials-in-r/)   

```{r include=FALSE, cache=FALSE}

# clear workspace
rm(list = ls(all = TRUE))

# clear all packages except base
#lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))

# to ensure that tidyverse packages prevail
filter <- dplyr::filter
select <- dplyr::select
summarise <- dplyr::summarise
summary <- base::summary
incidence <- incidence2::incidence

#load core packages
pacman::p_load(
     rio,
     here,
     DT,
     stringr,
     lubridate,
     tidyverse
)

# import the cleaned ebola linelist
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

# import the count data - facility level
#count_data <- rio::import(here::here("data", "facility_count_data.rds"))

# Settings

options(scipen=1, digits=7)

# print only text (not code)
# library(knitr)
# opts_chunk$set(list(echo = FALSE, eval = FALSE))
```

<!--chapter:end:new_pages/regression.Rmd-->


# Campos em branco/faltantes {#missing-data}

```{r, out.width=c("50%"), echo=F}
knitr::include_graphics(here::here("images", "missingness.png"))
knitr::include_graphics(here::here("images", "missingness_overview.png"))
```

Está página irá abordar como:

1) Avaliar a quantidade de campos em branco
2) Filtrar linhas com variáveis em branco
3) Traçar um gráfico da quantidade de campos em branco ao longo do tempo
4) Modificar como os valores `NA` são mostrados nos gráficos
5) Realizar a atribuição de valores aos campos em branco: MCAR, MAR, MNAR



<!-- ======================================================= -->
## Preparando o ambiente R { }

### Carregue os pacotes {.unnumbered}  

O código abaixo realiza o carregamento dos pacotes necessários para a análise dos dados. Neste manual, enfatizamos o uso da função `p_load()`, do **pacman**, que instala os pacotes, caso não estejam instalados, *e* os carrega no R para utilização. Também é possível carregar pacotes instalados utilizando a função `library()`, do R **base**. Para mais informações sobre os pacotes do R, veja a página [Introdução ao R](#basics).  

```{r}
pacman::p_load(
  rio,           # importar/exportar
  tidyverse,     # gerenciamento e visualização dos dados
  naniar,        # avaliar e visualizar campos em branco
  mice           # atribuir valores aos campos em branco
)
```


### Importe os dados {.unnumbered}

Nós iremos importar o banco de dados de casos de uma simulação de epidemia de Ebola. Se você quiser acompanhar os passos abaixo, <a href='https://github.com/epirhandbook/Epi_R_handbook/raw/master/data/case_linelists/linelist_cleaned.rds' class='download-button'>clique aqui para fazer o download do banco de dados 'limpo'</a> (como arquivo .rds). Importe seus dados utilizando a função `import()` do pacote **rio** (esta função importa muitos tipos de arquivos, como .xlsx, .rds, .csv - veja a página [Importar e exportar](#importing) para detalhes).

```{r, echo=F}
# importe os dados no R
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))
```

```{r, eval=F}
# importe os dados no R
linelist <- import("linelist_cleaned.rds")
```

As primeiras 50 linhas do banco são mostradas abaixo

```{r, message=FALSE, echo=F}
# mostre os dados do objeto linelist no formato de tabela
DT::datatable(head(linelist, 50), rownames = FALSE, filter="top", options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```


### Padronize os dados dos campos em branco durante a importação {.unnumbered}  

Ao importar os seus dados, esteja ciente de valores que deveriam ser classificados como campos em branco. Por exemplo, 99, 999, "Missing", células em branco (""), ou céluas com um espaço em branco (" "). Você pode converter esses tipos de campos em branco (e outros) para `NA` (formato de campos em branco no R) ainda no código usado para importar os dados.
Veja a seção sobre como importar os dados na página [Campos em branco](#import_missing) para mais detalhes, uma vez que a sintaxe muda de acordo com o tipo de arquivo.


<!-- ======================================================= -->
## Campos em branco no R { }

Abaixo, nós exploramos as formas como os campos em branco são mostrados e analisados no R, assim como valores e funções adjacentes.

### `NA` {.unnumbered}  

No R, campos em branco são representados por um valor especial e reservado - `NA`. Notar que é escrito *sem* as aspas. Já "NA", com aspas, é diferente, sendo apenas um caractere normal no R (além de ser parte da letra de Hey Jude dos Beatles).

Os campos em branco nos seus dados podem estar representados com outras formas, como "99", ou "Missing", ou "Unknown" - ou até como um caractere vazio "", parecido com um campo em branco, ou um espaço simples " ". Esteja ciente disto, e verifique a possibilidade de [converte-los para `NA` durante a importação](#import_missing) ou durante a limpeza dos dados, com a função  `na_if()`.  

Durante a limpeza dos dados, você também pode realizar o oposto - alterando todos os `NA` para "Missing", ou algo similar, utilizando a função `replace_na()` ou `fct_explicit_na()`, para valores da classe Factor.




### Versões de `NA` {.unnumbered}  

Para boa parte dos casos, `NA` representa os campos em branco e tudo funciona bem. Entretanto, em algumas circunstâncias você pode precisar de *variações* do `NA`, específicas para uma classe de objeto (caractere, numérico, etc). Isto será raro, mas esteja ciente dessa possibilidade.
O cenário típico para isso ocorre ao criar uma nova coluna com a função `case_when()`, do pacote **dplyr**. Como descrito na página sobre [Limpeza dos dados e principais funções](#clean_case_when), esta função verifica cada linha do banco de dados, avalia se cumprem regras lógicas (lado direito do código), e atribuem um novo valor correto (lado esquerdo do código). *Importante: todos os valores no lado direito da fórmula precisam ser da mesma classe*.

```{r, eval=F}
linelist <- linelist %>% 
  
  # Cria uma nova coluna chamada "age_years", utilizando a coluna "age"
  mutate(age_years = case_when(
    age_unit == "years"  ~ age,       # se a idade (age) é dada em anos, este valor é mantido
    age_unit == "months" ~ age/12,    # se a idade é dada em meses, o valor é dividido por 12
    is.na(age_unit)      ~ age,       # se a unidade da idade não é informada, assume-se que sejam em anos
    TRUE                 ~ NA_real_)) # para qualquer outra circunstância, o valor de campo em branco é atribuído
```

Se você quiser `NA` no lado direito, é necessário especificar uma das opções especiais da `NA`, listadas abaixo. Para valores em caracteres, utilize "Missing" em vez de `NA`, ou `NA_character_`. Se todos os valores são numéricos, utilize a opção `NA_real_`. Se todos os valores são formato de datas ou lógicos, utilize `NA`.

* `NA` - utilize para datas ou valores lógicos TRUE/FALSE 
* `NA_character_` - utilize para caracteres
* `NA_real_`  - utilize para valores numéricos

Novamente, é improvável que você encontre essas variações, **a não ser que** você esteja utilizando a função `case_when()`para criar uma nova coluna. Veja [a documentação do R sobre NA](https://stat.ethz.ch/R-manual/R-devel/library/base/html/NA.html) para mais informações.





### `NULL` {.unnumbered}  

`NULL` é outro valor reservado (especial) no R. É a representação lógica de uma declaração que não é nem verdadeira (true), tampouco falsa (false). Ele é gerado por expressões ou funções em que os valores são indefinidos. Geralemnte, não atribua NULL como um valor, exceto ao escrever funções ou, talvez, uma [aplicação em **shiny**][Dashboards com Shiny] para gerar `NULL` em cenários específicos.

Para avaliar se é um valor NULL, é só utilizar a função `is.null()`, e conversões podem ser feitas com a função `as.null()`.  

Veja essa [postagem](https://www.r-bloggers.com/2010/04/r-na-vs-null/) detalhando as diferenças entre `NULL` e `NA`.  




### `NaN` {.unnumbered}  

Valores impossíveis são representados pelo valor especial `NaN`. Um exemplo disso é quando você força o R a dividir 0 por 0. Você pode verificar se algo é impossível com a função `is.nan()`. Você também pode encontrar funções complementares, incluindo `is.infinite()` e `is.finite()`.  


### `Inf` {.unnumbered}  

`Inf` representa um valor infinito, como o obtido ao dividir um número por 0.

Um exemplo de como isto pode impactar seu trabalho: digamos que você possua um vetor/coluna `z` que contém estes valores: `z <- c(1, 22, NA, Inf, NaN, 5)`

Se você utilizar a função `max()` nesta coluna para encontrar o maior valor, é possível utilizar o atributo `na.rm = TRUE` para remover o `NA` da análise, mas os valores `Inf` e `NaN` continuarão e `Inf` será o resultado desta análise. Para resolver isto, você pode utilizar colchetes quadrados `[ ]` e a função `is.finite()` para analisar apenas o subconjunto de dados com apenas valores finitos: `max(z[is.finite(z)])`.  

```{r, eval=F}
z <- c(1, 22, NA, Inf, NaN, 5)
max(z)                           # retorna NA
max(z, na.rm=T)                  # retorna Inf
max(z[is.finite(z)])             # retorna 22
```


### Exemplos {.unnumbered}  


Comando R | Resultado
----------|--------------
`5 / 0` | `Inf`  
`0 / 0` | `NaN`  
`5 / NA` | `NA`  
`5 / Inf | `0`  
`NA - 5` | `NA`  
`Inf / 5` | `Inf`  
`class(NA)` | "logical"  
`class(NaN)` | "numeric"  
`class(Inf)` | "numeric"  
`class(NULL)` | "NULL"  

"NAs introduzidos forçadamente" ("NAs introduced by coercion") é uma mensagem de aviso comum. Isto pode acontecer se você tentar realizar uma conversão ilegal, como inserir um valor do tipo caractere em um vetor numérico. 

```{r}
as.numeric(c("10", "20", "thirty", "40"))
```

`NULL` é ignorado em um vetor.

```{r}
my_vector <- c(25, NA, 10, NULL)  # defina
my_vector                         # print
```


Variação de um número resulta em `NA`.  

```{r}
var(22)
```


<!-- ======================================================= -->
## Funções úteis { }

Abaixo são elencadas funções úteis do R **base** para avaliar e trabalhar com campos em branco:


### `is.na()` e `!is.na()` {.unnumbered}  

Utilize a função `is.na()` para identificar campos em branco, ou utilize o oposto desta função (com `!` na frente) para identificar campos preenchidos. Ambas funções retornam um valor lógico (`TRUE` ou `FALSE`). Lembre que você pode somar (`sum()`) o vetor resultante para contar a quantidade de `TRUE`, ex.: `sum(is.na(linelist$date_outcome))`.    

```{r}
my_vector <- c(1, 4, 56, NA, 5, NA, 22)
is.na(my_vector)
!is.na(my_vector)
sum(is.na(my_vector))
```


### `na.omit()` {.unnumbered}  

Esta função, se aplicada em um conjunto de dados, irá remover linhas com *qualquer* campo em branco. Esta função também é do pacote R **base**.  
Se aplicada em um vetor, os valores `NA` neste vetor serão removidos. Por exemplo:

```{r}
na.omit(my_vector)
```

### `drop_na()` {.unnumbered}  

Esta é uma função do pacote **tidyr**, que é útil em um [pipeline de limpeza de dados](#cleaning). Se executada com os parênteses vazios, ela remove linhas com *qualquer* um dos campos esteja em brancos. Se o nome das colunas são especificados em parênteses, linhas com campos em branco apenas nestas colunas serão excluídas. Você pode também utilizar a sintaxe do "tidyselect" para especificar as colunas.

```{r, eval=F}
linelist %>% 
  drop_na(case_id, date_onset, age) # exclui linhas com campos em branco em alguma dessas colunas
```


### `na.rm = TRUE` {.unnumbered}  

Quando você executa uma função matemática, como `max()`, `min()`, `sum()` ou `mean()`, se existir quaisquer valores `NA` presentes, o resultado da análise será `NA`. Este comportamento padrão é intencional, de forma que você seja alertado no caso de seus dados estarem em branco.

Você pode evitar isto ao remover os campos em branco dos cálculos. Para fazer isto, inclua o argumento `na.rm = TRUE` ("na.rm" significa  "remova os `NA`").


```{r}
my_vector <- c(1, 4, 56, NA, 5, NA, 22)

mean(my_vector)     

mean(my_vector, na.rm = TRUE)
```



<!-- ======================================================= -->
## Avalie os campos em branco no conjunto de dados { }

Você pode utilizar o pacote **naniar** para avaliar e visualizar os campos em brancos no seu conjunto de dados presente no objeto  `linelist`.  

```{r}
# instale e/ou carregue o pacote
pacman::p_load(naniar)
```

### Quantificando os campos em branco {.unnumbered}

Para encontrar o percentual da quantidade de campos em branco, utilize a função `pct_miss()`. Utilize `n_miss()` para obter o número absoluto de campos em branco.

```{r}
# percentual de TODOS os campos em branco no banco de dados
pct_miss(linelist)
```

As duas funções abaixo retornam o percentual de linhas com qualquer campo em branco, ou que estão com todos os campos preenchidos, respectivamente. Lembre que `NA` significa perdido/em branco, e que `""` ou `" "` não serão considerados campos em branco.

```{r}
# Percentual de linhas com algum campo em branco
pct_miss_case(linelist)   # utilize n_complete() para obter quantidades absolutas
```

```{r}
# Percentual de linhas com todos os campos preenchidos (sem campos em branco)
pct_complete_case(linelist) # utilize n_complete() para obter quantidades absolutas
```



### Visualizando as quantidades de campos em branco {.unnumbered}  

A função `gg_miss_var()` irá gerar o número absoluto (ou %) de campos em branco em cada coluna. Seguem alguns detalhes:

* Você pode adicionar um nome de coluna (sem as aspas) ao atributo `facet = ` para visualizar o gráfico por grupos
* Por padrão, contagens absolutas são mostradas no lugar dos percentuais. Altere isso com o atributo `show_pct = TRUE`  
* Você pode adicionar etiquetas aos eixos e títulos utilizando `+ labs(...)`, como no `ggplot()`


```{r}
gg_miss_var(linelist, show_pct = TRUE)
```

Aqui, os dados são encadeados `%>%` (do inglês *pipe*) na função. O atributo `facet = ` também é utilizado para dividir os dados.

```{r}
linelist %>% 
  gg_miss_var(show_pct = TRUE, facet = outcome)
```


Você pode utilizar a função `vis_miss()` para visualizar os dados como um mapa de calor, mostrando se algum campo está em branco ou não. Também é possível utilizar o `select()` para escolher colunas específicas do banco de dados, e trabalhar apenas com elas.

```{r}
# Mapa de calor dos campos em branco no banco de dados inteiro
vis_miss(linelist)
```


### Explore e visualize as relações entre os campos em branco {.unnumbered} 

Como você visualiza algo que não existe??? Por padrão, o `ggplot()` remove pontos sem valores dos gráficos.

O pacote **naniar** oferece uma solução com a função `geom_miss_point()`. Ao criar um gráfico de dispersão de duas colunas, uma delas é construída sem os valores em branco, e a outra com estes pontos, onde valores 10% menores do que o menor valor da coluna são atribuídos a estes campos em branco, que são então coloridos de forma distinta dos demais pontos.

No gráfico de dispersão abaixo, os pontos vermelhos são os que foram adicionados, estando presentes em uma coluna, mas não na outra. Isto permite visualizar a distribuição de campos em branco em relação aos campos preenchidos.



```{r}
ggplot(
  data = linelist,
  mapping = aes(x = age_years, y = temp)) +     
  geom_miss_point()
```

Para analisar os campos em branco nos dados, *estratificados por outra coluna*, utilize a função `gg_miss_fct()`, que gera um mapa de calor com o percentual de campos em brancos no banco de dados *utilizando uma coluna da classe factor/categórica (ou por datas)*:

```{r}
gg_miss_fct(linelist, age_cat5)
```


Esta função também pode ser utilizada com uma coluna com datas, para visualizar como a quantidade de campos em branco alterou de acordo com o tempo:

```{r}
gg_miss_fct(linelist, date_onset)
```




### Colunas Sombra "Shadow" {.unnumbered}

Outra forma de visualizar os campos em branco em uma coluna, de acordo com os valores de uma segunda coluna, é utilizando o "shadow" que o pacote **naniar** consegue criar. A função `bind_shadow()` cria uma nova coluna com os valores binários `NA`/not `NA` para cada coluna existente, e então conecta todas essas colunas novas ao banco de dados original utilizando o sufixo "_NA" em seus nomes. Isto duplica o número de colunas:


```{r}
shadowed_linelist <- linelist %>% 
  bind_shadow()

names(shadowed_linelist)
```

Estas colunas "shadow" podem ser utilizadas para traçar um gráfico da proporção de campos em branco, em relação à qualquer outra coluna.

Por exemplo, o gráfico abaixo mostra a proporção de campos em branco na coluna `days_onset_hosp` (número de dias entre o início dos sintomas e a hospitalização), de acordo com o campo em `date_hospitalisation`. Essencialmente, você está criando um gráfico da densidade da coluna no eixo x, mas estratificando os resultados (`color = `) pela coluna "shadow" de interesse. Esta análise funciona melhor se o eixo x é uma coluna numérica ou com dados cronológicos.


```{r, message = F}
ggplot(data = shadowed_linelist,          # banco de dados com as colunas "shadow"
  mapping = aes(x = date_hospitalisation, # colunas numéricas ou cronológicas
                colour = age_years_NA)) + # coluna "shadow" de interesse
  geom_density()                          # adição das curvas de densidade
```

Você pode também utilizar as colunas "shadow" para estratificar um resumo estatístico, como mostrado abaixo:

```{r}
linelist %>%
  bind_shadow() %>%                # cria as colunas "shadow"
  group_by(date_outcome_NA) %>%    # coluna "shadow" escolhida para estratificar
  summarise(across(
    .cols = age_years,             # variável de interesse para realizar os cálculos
    .fns = list("mean" = mean,     # estatísticas calculadas
                "sd" = sd,
                "var" = var,
                "min" = min,
                "max" = max),  
    na.rm = TRUE))                 # outros argumentos para o cálculo das estatísticas
```


Uma forma alternativa para traçar um gráfico da proporção de campos em branco em uma coluna de acordo com o tempo é mostrada abaixo. Esta forma *não* involve o pacote **naniar**. Este exemplo mostra a porcentagem de observações semanais que estão em branco.

1) Agregue os dados em uma unidade de tempo útil (dias, semanas, etc.), resumindo a proporção de observações com `NA`(e/ou qualquer outro valor de interesse)
2) Faça um gáfico da proporção de campos em brancos como uma linha, utilizando o `ggplot()`  

Abaixo, nós trabalhamos com a linelist, adicionamos uma nova coluna contendo a semana, então agrupamos os dados por semana, e calculamos o percentual de registros em branco de acordo com a semana. (nota: se você quisesse obter a % por 7 dias, o cálculo seria sutilmente diferente).

```{r}
outcome_missing <- linelist %>%
  mutate(week = lubridate::floor_date(date_onset, "week")) %>%   # crie uma coluna com as semanas
  group_by(week) %>%                                             # agrupe as linhas por semana
  summarise(                                                     # faça o resumo por cada semana
    n_obs = n(),                                                  # número absoluto de registros
    
    outcome_missing = sum(is.na(outcome) | outcome == ""),        # número de registros com campos em branco
    outcome_p_miss  = outcome_missing / n_obs,                    # proporção de registros em branco
  
    outcome_dead    = sum(outcome == "Death", na.rm=T),           # número de registros com evolução para óbito
    outcome_p_dead  = outcome_dead / n_obs) %>%                   # proporção de registros com evolução para óbito
  
  tidyr::pivot_longer(-week, names_to = "statistic") %>%         # para utilizar o ggplot, altere todas as colunas, exceto a coluna com as semanas, para o formato longo
  filter(stringr::str_detect(statistic, "_p_"))                  # mantenha apenas os valores proporcionais
```

Então nóstraçamos um gráfico das proporções dos campos em branco como uma linha, de acordo com a semana. A página sobre [básico do ggplot](#ggplot-basics) pode ser utilizada se você não tiver familiaridade com o pacote **ggplot2** de visuzalização de dados.

```{r, message=F, warning=F}
ggplot(data = outcome_missing)+
    geom_line(
      mapping = aes(x = week, y = value, group = statistic, color = statistic),
      size = 2,
      stat = "identity")+
    labs(title = "Weekly outcomes",
         x = "Week",
         y = "Proportion of weekly records") + 
     scale_color_discrete(
       name = "",
       labels = c("Died", "Missing outcome"))+
    scale_y_continuous(breaks = c(seq(0,1,0.1)))+
  theme_minimal()+
  theme(legend.position = "bottom")
```





<!-- ======================================================= -->
## Utilizando dados com campos em branco


### Exclua linhas com campos em branco {.unnumbered}

Para rapidamente excluir linhas com valores em branco, utilize a função `drop_na()`, do pacote **dplyr**.

O objeto `linelist` original possui ` nrow(linelist)` linhas. O número ajustado de linhas, após exclusão das que possuíam campos em branco, é mostrado abaixo:

```{r}
linelist %>% 
  drop_na() %>%     # excluí linhas com QUALQUER campo em branco
  nrow()
```

Você pode especificar para excluir linhas com campos em branco apenas em colunas específicas:

```{r}
linelist %>% 
  drop_na(date_onset) %>% # exclua as linhas com campos em branco na coluna date_onset 
  nrow()
```

Você pode listar as colunas uma após a outra, ou utilizar as [funções auxiliares do "tidyselect"](#clean_tidyselect):  

```{r}
linelist %>% 
  drop_na(contains("date")) %>% # exclua linhas com campos em branco em qualquer coluna que contenha "date" no nome
  nrow()
```



<!-- ======================================================= -->
### Trabalhando com `NA` no `ggplot()` {.unnumbered}

Frequentemente, é sábio mostrar a quantidade de valores excluídos na confeção de um gráfico em sua legenda. Abaixo é um exemplo:

No `ggplot()`, você pode adicionar etiquetas com `labs()`, e dentro da função utilizar o atributo `caption = `. Neste atributo, você pode utilizar a função `str_glue()`, do pacote **stringr**, para unir os valores em uma senteça, de forma que eles são ajustados automaticamente. Um exemplo é mostrado abaixo:

* Observe o uso do `\n` para adicionar uma nova linha
* Observe que, caso colunas múltiplas contribuam para a exclusão dos valores do gráfico (ex.: age ou sex se estes interferirem no gráfico), então você precisa filtrar por estas colunas assim como calcular o número de registros não mostrados de forma correta.

```{r, eval=F}
labs(
  title = "",
  y = "",
  x = "",
  caption  = stringr::str_glue(
  "n = {nrow(central_data)} do Hospital Central;
  {nrow(central_data %>% filter(is.na(date_onset)))} registros sem as datas de início dos sintomas não são mostrados."))  
```

As vezes, pode ser mais fácil salvar o texto em um objeto em comandos anteriores a função `ggplot()`, e, simplesmente, referenciar o objeto criado dentro da função `str_glue()`.  


<!-- ======================================================= -->
### `NA` na classe factors {.unnumbered}

Se a sua coluna de interesse for um fator (da classe factors), utilize a função `fct_explicit_na()`, do pacote **forcats**, para converter os valores do tipo `NA` para valores do tipo caractere. Veja mais detalhes na página [Fatores](#factors). Por padrão, o novo valor atribuído é "(Missing)", mas pode ser ajustado através do argumento `na_level =`.

```{r}
pacman::p_load(forcats)   # carregue o pacote

linelist <- linelist %>% 
  mutate(gender = fct_explicit_na(gender, na_level = "Missing"))

levels(linelist$gender)
```



<!-- ======================================================= -->
## Imputação de dados nos campos em branco { }


As vezes, ao analisar os dados, será importante "preencher as lacunas" e atribuir valores nos campos vazios. Mesmo que você possa analisar os dados após remover todos os campos em branco, isto pode causar diversos problemas. Aqui estão dois exemplos:

1) Ao remover todas as observações com campos em branco, ou variáveis com uma quantidade elevada de dados em branco, você pode reduzir seu poder de amostra ou capacidade para realizar algumas análises. Por exemplo, como descobrimos anteriormente, apenas uma pequena fração das observações no nosso banco de dados no linelist não possui campos em branco em todas as variáveis. Se nós removessemos a maioria dessas linhas, estaríamos perdendo muita informação! Também vimos que boa parte das nossas variáveis possui alguma quantidade de dados em branco -- assim, para boa parte da análise, provavelmente não é razoável excluir todas as variáveis que possuem muitos campos vazios.

2) Dependendo do motivo de seus dados estarem em branco, realizar a análise apenas de dados completos pode levar a resultados enviesados ou incorretos. Por exemplo, anteriormente, nós descobrimos que estamos sem dados de alguns pacientes no que tange à presença de sintomas importantes, como febre e tosse. Mas, como uma possibilidade, talvez essa informação não foi registrada para pessoas que, obviamente, não estavam muito doentes. Neste caso, se nós apenas removermos essas observações, estaremos excluindo algumas das pessoas mais saudáveis do nosso banco de dados, o que iria enviesar nossos resultados.

É importante pensar sobre o porque seus dados podem estar em branco, além de avaliar a quantidade de campos em branco. Fazer isto pode ajudá-lo a decidir o quão importante será atribuir valores nos campos em branco, e qual o melhor método de imputação para a sua situação.

### Tipos de dados em branco {.unnumbered}

Aqui estão três tipos gerais de dados em branco:

1) **Dados faltantes completamente de forma aleatória** (MCAR, do inglês *Missing Comnpletely at Random*). Isto significa que não existe relação entre os dados em branco e qualquer outra variável dos seus dados. A probabilidade dos dados estarem em branco são as mesmas para todos os casos. Isto é uma situação rara. Mas, se você tiver uma forte razão para acreditar que seus dados são do tipo MCAR, analisar apenas os dados completos sem atribuir valores não irá enviesar seus resultados (apesar de que você pode perder algum poder de amostra). [A fazer: considere discutir testes estatísticos para MCAR]

2) **Dados faltantes aleatoriamente** (MAR, do inglês *Missing at Random*). Este nome é, na verdade, um pouco  incorreto, uma vez que dados do tipo MAR não estão perdidos de forma alearória, e sim de forma sistemática e previsível, baseado em outras informações que você tem. Por exemplo, talvez cada observação em branco do seu banco de dados para febre não foi registrada porque assumiram que todos os pacientes com calafrios e dores estavam com febre, e, então, suas temperaturas não foram medidas. Se verdade, nós poderíamos facilmente predizer que cada observação em branco em que o paciente tivesse calafrios e dores, ele também teve febre, e utilizar essa informação para atribuir dados. Na prática, existe um espectro de possibilidades. Talvez, se um paciente sem a temperatura medida tivesse tanto calafrios quanto dores, ele provavelmente também teria febre, mas nem sempre. Isto ainda é previsível, embora não seja perfeitamente previsível. Este é um tipo comum de perda de dados.

3) **Dados faltantes de forma não aleatória** (MNAR, do inglês *Missing not at Random*). As vezes, também chamado de **Não perdidos aleatoriamente** (NMAR). Esta situação considera que a probabilidade de um campo estar em branco NÃO é sistemática ou previsível utilizando as outras informações que temos, mas também não foram perdidos de forma aleatória. Assim, os dados foram perdidos por razões desconhecidas ou por motivos que você não tem informações sobre. Por exemplo, em nosso banco de dados, talvez as informações sobre as idades estejam em branco porque alguns pacientes muito idosos ou não sabiam a idade, ou recusaram informar a idade. Nesta situação, os dados perdidos de idade estão relacionados à idade diretamente (e, assim, não são perdas aleatórias), e não são dados previsíveis através de outras informações que temos. MNAR é complexo e, frequentemente, a melhor forma de trabalhar com isso é tentar coletar mais dados ou informações sobre o porque os dados estão faltando, em vez de atribuir valores.

Concluindo, geralmente, atribuir valores em dados MCAR é simples, enquanto em dados MNAR é desafiador, senão impossível. Muitos dos métodos de imputação de valores assumem dados MAR.

### Pacotes úteis {.unnumbered}

Alguns pacotes úteis para imputar dados perdidos são Mmisc, missForest (que utiliza o modelo de florestas aleatórias para imputar dados perdidos), e mice (Imputação Multivariada por Equações em Cadeia). Para essa seção, nós iremos utilizar apenas o pacote mice, que implementa uma variedade de técnicas. O mantenedor do pacote mice publicou um livro online com mais detalhes sobre como imputar dados perdidos (https://stefvanbuuren.name/fimd/).

Segue o código para carregar o pacote mice:

```{r}
pacman::p_load(mice)
```

### Imputação por média {.unnumbered}

As vezes, se você está realizando uma análise simples, ou possui uma forte razão para pensar que pode assumir os dados perdidos como MCAR, é possível simplesmente atribuir a média daquela variável nos campos em branco. Talvez possamos assumir que a perda de medições de temperatura em nosso banco de dados foi MCAR ou apenas valores normais. Aqui está o código para criar uma nova variável que substitui os valores faltantes pela temperatura média do nosso banco de dados. Entretanto, em muitas situações, substituir dados com o valor médio pode gerar resultados enviesados, então seja cuidadoso.

```{r}
linelist <- linelist %>%
  mutate(temp_replace_na_with_mean = replace_na(temp, mean(temp, na.rm = T)))
```

Você pode também realizar um processo similar para substituir dados categóricos por um valor específico. Para o nosso banco de dados, imagine que você soubesse que todas observações com um campo em branco na variável outcome (evolução clínica, que pode ser "Death" ou "Recover") foram de pessoas que evoluíram para óbito (nota: isto não é verdade para o nosso banco de dados):

```{r}
linelist <- linelist %>%
  mutate(outcome_replace_na_with_death = replace_na(outcome, "Death"))
```

### Imputação por regressão {.unnumbered}

Outro método de certa forma mais avançado para imputar valores é utilizar algum tipo de modelo estatístico para prever o que um valor perdido é. Aqui está um exemplo onde os valores preditos são criados para todos os campos sem a temperatura, mas com os campos de age (idade) e fever (febre) preenchidos, utilizando estas variáveis como preditoras em uma regressão linear simples. Na prática, você iria querer utilizar um modelo melhor do que este, que é mais simples.

```{r, warning=F, message=F}
simple_temperature_model_fit <- lm(temp ~ fever + age_years, data = linelist)

#utilizando o nosso simples modelo de temperatura para predizer valores de temperatura apenas para os campos em branco
predictions_for_missing_temps <- predict(simple_temperature_model_fit,
                                        newdata = linelist %>% filter(is.na(temp))) 
```

Ou, utilizando a mesma abordagem de modelagem com o pacote mice para imputar valores de temperatura nos campos em branco:

```{r}
model_dataset <- linelist %>%
  select(temp, fever, age_years)  

temp_imputed <- mice(model_dataset,
                            method = "norm.predict",
                            seed = 1,
                            m = 1,
                            print = F)

temp_imputed_values <- temp_imputed$imp$temp

```


Este é o mesmo tipo de abordagem feita por alguns métodos mais avançados, como utilizando o pacote missForest para substituir os campos em branco pelos valores preditos. Neste caso, o modelo de predição utilizado é o de florestas aleatórias (random forest) em vez de uma regressão linear. Você pode utilizar outros tipos de modelos para fazer isso. Entretanto, enquanto esta abordagem funciona bem com dados MCAR, você deve ser cuidadoso se acredita que seus dados perdidos sejam do tipo MAR ou MNAR. A qualidade da imputação irá depender no quão bom o seu modelo de predição é, e, mesmo com um modelo muito bom, a variedade dos dados imputados pode ser subestimada.

### LOCF e BOCF {.unnumbered}

Última observação levada adiante (LOCF, do inglês "Last observation carried forward") e observação de base levada adiante (BOCF, do inglês "baseline observation carried forward") são métodos de imputação para séries temporais/dados longitudinais. A ideia é utilizar o último valor observado para atribuir nos campos em branco. Quando valores múltiplos são perdidos sucessivamente, o método busca pelo último valor observado.

A função `fill()`, do pacote **tidyr**, pode ser utilizada para realizar imputação por LOCF e BOCF (entretanto, outros pacotes como **HMISC**, **zoo**, e **data.table** também incluem métodos para fazer isto). Para mostrar a sintaxe do `fill()`, nós iremos criar um simples banco de dados com série temporal contendo o número de casos de uma doença para cada quadrimestre dos anos 2000 e 2001. Entretanto, os valores para os quadrimestres após Q1 estão faltando, então nós iremos imputá-los. A sintaxe do `fill()` também é demonstrada na página sobre [Pivoteamento dos dados](#pivoting).  

```{r}
#criando um banco de dados simples
disease <- tibble::tribble(
  ~quarter, ~year, ~cases,
  "Q1",    2000,    66013,
  "Q2",      NA,    69182,
  "Q3",      NA,    53175,
  "Q4",      NA,    21001,
  "Q1",    2001,    46036,
  "Q2",      NA,    58842,
  "Q3",      NA,    44568,
  "Q4",      NA,    50197)

#imputando os valores perdidos dos anos
disease %>% fill(year)

```

Nota: tenha certeza de que seus dados estão ordenados corretamente antes de utilizar a função `fill()`. Por padrão, `fill()` irá preencher de cima para baixo, mas você também pode imputar valores em direções diferentes ao mudar o parâmetro `.direction`. Nós podemos criar um banco de dados similar onde os valores dos anos estão registrados apenas no ano final, e ausentes para quadrimestres anteriores:

```{r}
#criando um banco de dados sutilmente diferente
disease <- tibble::tribble(
  ~quarter, ~year, ~cases,
  "Q1",      NA,    66013,
  "Q2",      NA,    69182,
  "Q3",      NA,    53175,
  "Q4",    2000,    21001,
  "Q1",      NA,    46036,
  "Q2",      NA,    58842,
  "Q3",      NA,    44568,
  "Q4",    2001,    50197)

#impute os anos nos campos em branco na direção para 'cima' ("up"):
disease %>% fill(year, .direction = "up")

```
Neste exemplo, LOCF e BOCF são claramente os métodos corretos para se fazer, mas, em situações mais complicadas, pode ser mais difícil decidir se estes métodos são apropriados. Por exemplo, você pode ter valores em branco dos dados laboratoriais de um paciente do hospital após o primeiro dia. As vezes, isto quer dizer que os resultados laboratoriais não mudaram após o primeiro dia...mas também pode significar que o paciente se recuperou e seus valores seriam muito diferentes em relação ao primeiro dia! Utilize estes métodos com cautela.


### Imputação múltipla {.unnumbered}

O livro online que mencionamos anteriormente, do autor do pacote mice (https://stefvanbuuren.name/fimd/), contém uma explicação detalhada da imputação múltipla e porque você gostaria de utilizá-la. Mas aqui está uma explicação básica do método:

Quando você faz uma imputação múltipla, múltiplos bancos de dados com valores plausíveis imputados nos campos em branco são criados (dependendo dos seus dados de pesquisa, você pode querer criar mais ou menos desses bancos de dados, mas o pacote mice produz 5 bancos de dados por padrão). A diferença é que, ao invés de um valor único e específico, cada valor imputado é retirado de uma distribuição estimada (então inclui alguma aleatoridade). Como resultado, cada um desses bancos de dados terá valores imputados ligeiramente diferentes (entretanto, os dados que não estavam em branco continuarão os mesmos nos diferentes bancos de dados). Você irá utilizar algum tipo de modelo preditivo para realizar a imputação em cada um dos novos bancos de dados (o pacote mice possui muitas opções para cada método de predição, incluíndo *Correspondência Média Preditiva*, *regressão logística*, e *florestas aleatórias*), mas o pacote mice cuida de muitos dos detalhes da modelagem.

Então, assim que você tiver criado estes novos bancos de dados com os valores imputados, é possível aplicar quaisquer modelos estatísticos ou análises que estava planejando realizar em cada um dos bancos, e então unir os resultados destes modelos. Isto funciona muito bem para reduzir o enviesamento dos resultados nas situações de MCAR e MAR, e, frequentemente, os resultados são mais acurados.

Aqui está um exemplo da aplicação da Imputação Múltipla para predizer as temperaturas em nosso banco de dados do linelist, utilizando as variáveis idade (age) e status da febre (fever) (nosso simples model_dataset anterior):

```{r}
# imputando valores perdidos para todas as variáveis em nosso model_dataset, criando 10 novos bancos de dados com valores imputados
multiple_imputation = mice(
  model_dataset,
  seed = 1,
  m = 10,
  print = FALSE) 

model_fit <- with(multiple_imputation, lm(temp ~ age_years + fever))

base::summary(mice::pool(model_fit))
```

Aqui nós utilizamos o método padrão do mice para imputação, que é a Correspondência Média Preditiva. Nós, então, utilizamos os bancos de dados gerados para, separadamente, estimar resultados com regressões lineares simples, e então uni-los. Existem muitos detalhes que não discutimos e muitas configurações que podem ser ajustadas durante o processo de Imputação Múltipla utilizando o pacote mice. Por exemplo, você nem sempre terá dados numéricos e pode precisar usar outros métodos de imputação (você ainda pode utilizar o pacote mice para muitos outros tipos de dados e métodos). Mas, para uma análise mais robusta quando os campos em branco são uma preocupação significativa, o método de Imputação Múltipla é uma boa solução que, quase sempre, não é muito mais trabalhosa do que realizar uma análise completa dos casos.





<!-- ======================================================= -->
## Recursos { }

Manual sobre o [pacote naniar ](https://cran.r-project.org/web/packages/naniar/vignettes/getting-started-w-naniar.html)

Galeria com [a visualização dos valores perdidos](https://cran.r-project.org/web/packages/naniar/vignettes/naniar-visualisation.html)

[Livro online](https://stefvanbuuren.name/fimd/) sobre imputação múltipla no R, escrito pelo mantenedor do pacote **mice** 
```{r include=FALSE, cache=FALSE}

# clear workspace
rm(list = ls(all = TRUE))

# clear all packages except base
#lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))

# to ensure that tidyverse packages prevail
filter <- dplyr::filter
select <- dplyr::select
summarise <- dplyr::summarise
summary <- base::summary
incidence <- incidence2::incidence

#load core packages
pacman::p_load(
     rio,
     here,
     DT,
     stringr,
     lubridate,
     tidyverse
)

# import the cleaned ebola linelist
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

# import the count data - facility level
#count_data <- rio::import(here::here("data", "facility_count_data.rds"))

# Settings

options(scipen=1, digits=7)

# print only text (not code)
# library(knitr)
# opts_chunk$set(list(echo = FALSE, eval = FALSE))
```

<!--chapter:end:new_pages/missing_data.Rmd-->


# Normalização de taxas {#standardization}  

Esta página irá descrever duas maneiras de normalizar os dados, como hospitalizações ou mortalidade, com características como idade e sexo.

* Utilizando o pacote **dsr** 
* Utilizando o pacote **PHEindicatormethods**

Nós iniciaremos enfatizando os processos de preparação/limpeza/união dos dados, por serem atividades comuns ao combinar dados populacionais de diferentes países, dados populacionais padrões, óbitos, etc.

## Visão geral  

Existem duas principais formas de normalizar: normalização direta e indireta.
Digamos que gostaríamos de normalizar as taxas de mortalidade por idade e sexo, nos países A e B, e, então, comparar as taxas entre esses países.

* Para realizar a normalização direta, você precisa saber o número da população sob-risco, e o número de mortes para cada faixa etária por sexo, tanto para o país A, quanto para o B. Uma faixa etária em nosso exemplo poderia ser mulheres entre 15-44 anos.
* Para realizar a normalizaçaõ de forma indireta, você apenas precisa saber o número total de mortes, e a composição da população por sexo e idade em cada país. Logo, está opção é viável quando as taxas de mortalidade específicas por idade e sexo, ou números da população, não estão disponíveis. A normalização indireta também é preferida nos casos de pequenas quantidades por estrato, uma vez que estimativas com a normalização direta seriam influenciadas pela variação amostral.

<!-- ======================================================= -->
## Preparação {  }

Para mostrar como a normalização é feita, nós iremos utilizar dados ficcionais com a quantidade populacional e quantidade de mortes dos países A e B, por idade (em categorias de 5 anos) e sexo (mulheres, homens). Para criar conjuntos de dados prontos para uso, nós iremos executar as seguintes etapas de preparação:

1. Carregar os pacotes
2. Carregar os conjuntos dos dados
3. Unir os dados populacionais e de óbitos dos dois países
4. Transformar para o formato longo, de forma que haja apenas uma linha por estrato idade-sexo
5. Limpar a população de referência (população mundial padrão) e uni-la aos dados dos países

No seu cenário, os dados podem estar em um formato diferente. Talvez seus dados sejam por províncias, cidades, ou outros tipos de área. Talvez você tenha uma linha para cada óbito, e informações (ou uma proporção significante) sobre idade e sexo para cada um desses óbitos. Neste caso, veja as páginas sobre [Agrupando dados](#grouping), [Pivoteando os dados](#pivoting), e [Tabelas descritivas](#tables-descriptive) para criar um conjunto de dados com quantidades de eventos e população por estrato idade-sexo.

Nós também precisamos de uma população de referência, a população padrão. Para os propósitos deste exercício, nós iremos utilizar o `world_standard_population_by_sex`. A "população padrão mundial" é baseada nas populações de 46 países e foi criada em 1960. Existem muitas populações "padrão" - por exemplo, o site do [NHS Scotland](https://www.opendata.nhs.scot/dataset/standard-populations) possui muitas informações sobre a População Padrão Européia, População Padrão Mundial, e População Padrão Escocesa.

<!-- ======================================================= -->
### Carregue os pacotes R {.unnumbered}

O código abaixo realiza o carregamento dos pacotes necessários para a análise dos dados. Neste manual, enfatizamos o uso da função `p_load()`, do **pacman**, que instala os pacotes, caso não estejam instalados, *e* os carrega no R para utilização. Também é possível carregar pacotes instalados utilizando a função `library()`, do R **base**. Para mais informações sobre os pacotes do R, veja a página [Introdução ao R](#basics).  

```{r}
pacman::p_load(
     rio,                 # importar/exportar dados
     here,                # localizar arquivos
     tidyverse,           # gerenciamento e visualização dos dados
     stringr,             # limpar caracteres e strings
     frailtypack,         # necessário para dsr, para modelos de fragilidade
     PHEindicatormethods) # alternativa para padronização das taxas

pacman::p_load_gh("cran/dsr") # foi removido do CRAN
```


<span style="color: orange;">**_CUIDADO:_** Se você tem uma versão mais nova do R, o pacote **dsr** não pode ser diretamente baixado do CRAN. Entretanto, ainda está disponível do arquivo do CRAN. Você pode instalar e utilizar esta versão do arquivo. </span>

Para os que não utilizam Mac:

```{r, eval=F} 
packageurl <- "https://cran.r-project.org/src/contrib/Archive/dsr/dsr_0.2.2.tar.gz"
install.packages(packageurl, repos=NULL, type="source")
```

```{r, eval=FALSE}
# Outra solução que pode funcionar
require(devtools)
devtools::install_version("dsr", version="0.2.2", repos="http:/cran.us.r.project.org")
```

Para usuários de Mac:

```{r, eval=FALSE}
require(devtools)
devtools::install_version("dsr", version="0.2.2", repos="https://mac.R-project.org")
```




### Carregue os dados populacionais {.unnumbered}  

Veja a página [Download do manual e dados](#data-used) para instruções sobre como baixar todos os dados de exemplos utilizados neste manual. Você pode importar os dados da página de Padronização dos dados diretamente no R, do nosso repositório Github, ao executar os comandos `import()` abaixo:

```{r, eval=F}
# importe dados demográficos do país A diretamente do Github
A_demo <- import("https://github.com/appliedepi/epirhandbook_eng/raw/master/data/standardization/country_demographics.csv")

# importe dados de óbitos do país A diretamente do Github
A_deaths <- import("https://github.com/appliedepi/epirhandbook_eng/raw/master/data/standardization/deaths_countryA.csv")

# importe dados demográficos do país B diretamente do Github
B_demo <- import("https://github.com/appliedepi/epirhandbook_eng/raw/master/data/standardization/country_demographics_2.csv")

# importe dados de óbitos do país B diretamente do Github
B_deaths <- import("https://github.com/appliedepi/epirhandbook_eng/raw/master/data/standardization/deaths_countryB.csv")

# importe dados demográficos da População padrão mundial diretamente do Github
standard_pop_data <- import("https://github.com/appliedepi/epirhandbook_eng/raw/master/data/standardization/world_standard_population_by_sex.csv")

```


Primeiro, nós carregamos os dados demográficos (contanges de homens e mulheres por categorias de 5 em 5 anos) para os países que iremos comparar, "País A" e "País B".  

```{r, echo=F}
# País A
A_demo <- rio::import(here::here("data", "standardization", "country_demographics.csv"))%>% 
     mutate(Country = "A") %>% 
     select(Country, everything()) %>% # reorganiza os dados
     mutate(age_cat5 = str_replace_all(age_cat5, "\\+", "")) # remoção + simbologia
```

```{r, eval=F}
# País A
A_demo <- import("country_demographics.csv")
```

```{r message=FALSE, echo=F}
DT::datatable(A_demo, rownames = FALSE, options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```


```{r, echo=F}
# País B
B_demo <- rio::import(here::here("data", "standardization", "country_demographics_2.csv")) %>% 
     mutate(Country = "B") %>% 
     select(Country, everything()) # Reorganiza
```

```{r, eval=F}
# País B
B_demo <- import("country_demographics_2.csv")
```

```{r message=FALSE, echo=F}
DT::datatable(B_demo, rownames = FALSE, options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```





### Carregue a quantidade de óbitos {.unnumbered}  

Convenientemente, a quantidade de óbitos, por idade e sexo durante o período de interesse, também está disponível. Cada contagem por país está em arquivos separados, como mostrado abaixo.

```{r, echo=F}
A_males <- c(224, 257, 251, 245, 334, 245, 154, 189, 334, 342, 565, 432, 543, 432, 245, 543, 234, 354) # para homens do país A
B_males <- c(34, 37, 51, 145, 434, 120, 100, 143, 307, 354, 463, 639, 706, 232, 275, 543, 234, 274) # para homens do país B
A_females <- c(194, 254, 232, 214, 316, 224, 163, 167, 354, 354, 463, 574, 493, 295, 175, 380, 177, 392) # para mulheres do país A
B_females <- c(54, 24, 32, 154, 276, 254, 123, 164, 254, 354, 453, 654, 435, 354, 165, 432, 287, 395) # para mulheres do país B

age_cat5 <- c("0-4", "5-9", "10-14", "15-19", "20-24", "25-29",  "30-34", "35-39", "40-44",
                                                                                "45-49", "50-54", "55-59",
                                                                                "60-64", "65-69", "70-74",
                                                                                "75-79", "80-84", "85")
A_deaths <- data.frame(Country = "A", AgeCat = age_cat5, Male = A_males, Female = A_females)
B_deaths <- data.frame(Country = "B", AgeCat = age_cat5, Male = B_males, Female = B_females)
```

Óbitos no país A
```{r message=FALSE, echo=F}
DT::datatable(A_deaths, rownames = FALSE, options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```

Óbitos no país B

```{r message=FALSE, echo=F}
DT::datatable(B_deaths, rownames = FALSE, options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```


```{r, echo=F}
rio::export(A_deaths, here::here("data", "standardization", "deaths_countryA.csv"))
rio::export(B_deaths, here::here("data", "standardization", "deaths_countryB.csv"))
```



### Limpe os dados populacionais e de óbitos {.unnumbered}  


Nós precisamos unir e transformar estes dados da seguinte maneira:

* Combine as populações dos países em um conjunto de dados e o transforme para o formato "longo", de forma que cada estrato idade-sexo esteja em uma linha
* Combine a quantidade de óbitos dos países em um conjunto de dados e o transforme para o formato "longo", de forma que cada estrato idade-sexo esteja em uma linha
* Una os óbitos com as populações

Primeiro, nós iremos unir os dados de população por país, transformar para o formato longo, e realizar uma limpeza mínima dos dados. Veja a página sobre [Pivoteando os dados](#pivoting) para mais detalhes.

```{r}
pop_countries <- A_demo %>%  # inicie com os dados do país A
     bind_rows(B_demo) %>%        # una as linhas, uma vez que as colunas têm o mesmo nome
     pivot_longer(                       # transforme (pivot) para o formato longo
          cols = c(m, f),                   # colunas para combinar em uma
          names_to = "Sex",                 # nome para a nova coluna contendo a categoria ("m" ou "f") 
          values_to = "Population") %>%     # nome para a nova coluna contendo os valores numéricos transformados (pivoted)
     mutate(Sex = recode(Sex,            # re-codifique os valores para clareza
          "m" = "Male",
          "f" = "Female"))
```

Agora, os dados populacionais combinados estão assim (clique para ver os países A e B)  

```{r message=FALSE, echo=F}
DT::datatable(pop_countries, rownames = FALSE, options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```

E, agora, nós iremos realizar operações similares nos dois bancos de óbitos.

```{r}
deaths_countries <- A_deaths %>%    # inicie com os dados de óbitos do país A
     bind_rows(B_deaths) %>%        # una as linhas com os dados do país B, uma vez que o nome das colunas é igual
     pivot_longer(                  # transforme para formato longo
          cols = c(Male, Female),        # colunas para transformar em uma
          names_to = "Sex",              # nome da nova coluna contendo a categoria ("m" ou "f") 
          values_to = "Deaths") %>%      # nome da nova coluna contendo os valores numéricos transformados
     rename(age_cat5 = AgeCat)      # renomeie para mais clareza
```

Agora, os dados de óbitos estão da seguinte forma, e contêm dados de ambos países:

```{r message=FALSE, echo=F}
DT::datatable(deaths_countries, rownames = FALSE, options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```


Agora, nós uniremos os dados populacionais e de óbitos, baseado nas colunas em comum `Country`, `age_cat5`, e `Sex`. O processo também adiciona a coluna `Deaths`.  

```{r}
country_data <- pop_countries %>% 
     left_join(deaths_countries, by = c("Country", "age_cat5", "Sex"))
```

Então, podemos classificar `Sex`, `age_cat5`, e `Country` como factors, e ajustar a ordem dos níveis com a função `fct_relevel()` do pacote **forcats**, como descrito na página [Fatores](#factors). Nota, visivelmente, classificar os níveis dos factors não altera os dados, mas o comando `arrange()` ordena os dados por país (Country), categoria de idade (age), e sexo (sex).  

```{r, warning=F, message=F}
country_data <- country_data %>% 
  mutate(
    Country = fct_relevel(Country, "A", "B"),
      
    Sex = fct_relevel(Sex, "Male", "Female"),
        
    age_cat5 = fct_relevel(
      age_cat5,
      "0-4", "5-9", "10-14", "15-19",
      "20-24", "25-29",  "30-34", "35-39",
      "40-44", "45-49", "50-54", "55-59",
      "60-64", "65-69", "70-74",
      "75-79", "80-84", "85")) %>% 
          
  arrange(Country, age_cat5, Sex)

```

```{r message=FALSE, echo=F}
DT::datatable(country_data, rownames = FALSE, options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```

<span style="color: orange;">**_CUIDADO:_** Se você possuir poucos óbitos por estrato, considere utilizar categorias com intervalos de 10 ou 15 anos, em vez de 5 anos.</span>




### Carregue os dados populacionais de referência {.unnumbered}  

Por último, para realizar a padronização direta, nós iremos importar a população de referência ("população mundial de referência" por sexo)

```{r, echo=F}
# População de referência
standard_pop_data <- rio::import(here::here("data", "standardization", "world_standard_population_by_sex.csv")) %>% 
     rename(age_cat5 = AgeGroup)
```

```{r, eval=F}
# População de referência
standard_pop_data <- import("world_standard_population_by_sex.csv")
```

```{r message=FALSE, echo=F}
DT::datatable(standard_pop_data, rownames = FALSE, options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```



<!-- ======================================================= -->
### Limpe os dados da população de referência {.unnumbered}

Os valores por categorias de idade nos conjuntos de dados `country_data` e `standard_pop_data` precisam ser alinhados.

No momento, os valores da coluna `age_cat5`, do conjunto `standard_pop_data`, contém as palavras "years" e "plus", enquanto os dados em `country_data` não possuem essas palavras. Nós precisamos garantir que os valores da categoria "age" coincidam. Para tanto, utilizaremos a função `str_replace_all()`, do pacote **stringr**, como descrito na página sobre [Caracteres e strings](#characters-strings), para substituir estes padrões para "sem espaço" `""`.  

Além disso, o pacote **dsr** espera que, na população de referência, a coluna contendo as contagens será chamada de `"pop"`. Então, iremos renomear essa coluna desta forma.

```{r}
# Remova palavras específicas da coluna valores ("values")
standard_pop_clean <- standard_pop_data %>%
     mutate(
          age_cat5 = str_replace_all(age_cat5, "years", ""),   # remova "year"
          age_cat5 = str_replace_all(age_cat5, "plus", ""),    # remova "plus"
          age_cat5 = str_replace_all(age_cat5, " ", "")) %>%   # remova " " espaço
     
     rename(pop = WorldStandardPopulation)   # mude o nome da coluna para "pop", como o pacote dsr solicita
```

<span style="color: orange;">**_CUIDADO:_** Se você tentar utilizar a função `str_replace_all()` para remover o *símbolo* de adição, ele não irá funcionar pois é um símbolo especial. "Ignore" o caráter especial ao colocar duas barras invertidas na frente, como em `str_replace_call(column, "\\+", "")`. </span>

### Crie um conjunto de dados com uma população padrão {#standard_all .unnumbered}  

Finalmente, o pacote **PHEindicatormethods**, detalhado [abaixo](#standard_phe), trabalha com as populações padrões unidas aos dados dos países e contagens da população. Então, nós iremos criar um banco de dados chamado `all_data` para isto.

```{r}
all_data <- left_join(country_data, standard_pop_clean, by=c("age_cat5", "Sex"))
```

O conjunto de dados inteiro ficou assim:

```{r message=FALSE, echo=F}
DT::datatable(all_data, rownames = FALSE, options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```



<!-- ======================================================= -->
## pacote **dsr** {  }
 
Abaixo, nós demonstramos como calcular e comparar taxas normalizadas diretamente, utilizando o pacote **dsr**. O pacote **dsr** permite o cálculo e comparação de taxas normalizadas diretamente (mas não taxas normalizadas indiretamente!).
  
Na seção sobre Preparação dos dados, nós construímos diferentes conjuntos de dados para contagens dos países e da população padrão:

1) o objeto `country_data` contém uma tabela populacional com a quantidade da população e o número de mortes por estrato por país
2) o objeto `standard_pop_clean` contém o número da população por estrato da população padrão, a População Mundial Padrão

Nós iremos utilizar estes dados separados na abordagem do **dsr**.  


<!-- ======================================================= -->
### Taxas normalizadas {.unnumbered}

Abaixo, nós calculamos as taxas por país normalizadas diretamente para idade e sexo. Nós utilizamos a função `dsr()`. 

De nota - a função `dsr()` espera uma tabela de dados para as populações do país e as contagens dos eventos (mortes), *e um data frame **separado** contendo a população padrão*. Ela também considera que no banco de dados da população padrão, o nome da coluna com a unidade-tempo é "pop" (nós garantimos isto na seção sobre Preparação de dados).

Existem muitos argumentos possíveis, como anotado no código abaixo. Notavelmente, a coluna `Deaths` está selecionada em `event = `, e a coluna `Population` está selecionada para `fu = ` ("acompanhamento"). Nós selecionamos os subgrupos de comparação como sendo da coluna `Country`, e padronizamos baseado em `age_cat5` e `Sex`. Estas últimas duas colunas não foram utilizadas em nenhum argumento em particular. Veja `?dsr` para detalhes.

```{r, warning=F, message=F}
# Calcula as taxas por país normalizadas diretamente por idade (age) e sexo (sex)
mortality_rate <- dsr::dsr(
     data = country_data,  # especifique o objeto contendo o número de mortes por estrato
     event = Deaths,       # coluna contendo o número de mortes por estrato
     fu = Population,      # coluna contendo o número da população por estrato
     subgroup = Country,   # unidades que gostaríamos de comparar
     age_cat5,             # outras colunas - taxas serão normalizadas por estas colunas
     Sex,
     refdata = standard_pop_clean, # data frame contendo a população de referência, com a coluna chamada pop
     method = "gamma",      # método para calcular o IC 95%
     sig = 0.95,            # nível de significância
     mp = 100000,           # nós queremos taxas por 100.000 habitantes
     decimals = 2)          # quantidade de decimais


# Printa o output como uma tabela em HTML
knitr::kable(mortality_rate) # mostra as taxas de mortalidade antes e após padronização direta
```

Acima, nós vemos que enquanto o país A possui uma menor taxa de mortalidade bruta do que o país B, ele possui uma maior taxa normalizada de mortalidade após normalizar utilizando a idade e o sexo.




<!-- ======================================================= -->
### Relação entre taxas normalizadas {.unnumbered}

```{r,warning=F, message=F}
# Calcule a razão entre as taxas (rates ratio)
mortality_rr <- dsr::dsrr(
     data = country_data, # especifique o objeto que contém o número de mortes por estrato
     event = Deaths,      # coluna contendo o número de óbitos por estrato
     fu = Population,     # coluna contendo o número da população por estrato
     subgroup = Country,  # unidades que queremos comparar
     age_cat5,
     Sex,                 # características para as quais gostaríamos de normalizar
     refdata = standard_pop_clean, # população de referência, com números em uma coluna chamada pop
     refgroup = "B",      # referência para comparação
     estimate = "ratio",  # tipo de estimativa
     sig = 0.95,          # nível de significância
     mp = 100000,         # nós queremos taxas por 100.000 habitantes
     decimals = 2)        # quantidade de decimais

# Printa a tabela
knitr::kable(mortality_rr) 
```

A taxa de mortalidade normalizada é 1.22 vezes maior no país A em relação ao país B (IC 95% 1.17-1.27).

<!-- ======================================================= -->
### Diferença entre taxas normalizadas {.unnumbered}

```{r, warning=F, message=F}
# Calcule a diferença entre taxas normalizadas (Rates Difference)
mortality_rd <- dsr::dsrr(
     data = country_data,       # especifique o objeto contendo o número de mortes por estrato
     event = Deaths,            # coluna contendo o número de óbitos por estrato
     fu = Population,           # coluna contendo a quantidade de população por estrato
     subgroup = Country,        # unidades que gostaríamos de comparar
     age_cat5,                  # características para as quais gostaríamos de normalizar
     Sex,                        
     refdata = standard_pop_clean, # população de referência, com números na coluna chamada pop
     refgroup = "B",            # refência para comparação
     estimate = "difference",   # tipo de estimativa
     sig = 0.95,                # nível de significância
     mp = 100000,               # nós queremos taxas por 100.000 habitantes
     decimals = 2)              # quantidade de decimais

# Printa a tabela
knitr::kable(mortality_rd) 
```

Quando comparado ao país B, o país A possui 4.24 óbitos adicionais por 100.000 habitantes (IC 95% 3.24-5.24).







<!-- ======================================================= -->
## pacote **PHEindicatormethods** {#standard_phe  }

Outra forma de calcular as taxas normalizadas é com o pacote **PHEindicatormethods**. Este pacote permite calcular tanto taxas normalizadas diretamente, como taxas normalizadas indiretamente. Nós iremos mostrar como realizar ambos cálculos.

Neste seção, iremos utilizar os dados no objeto `all_data`, criado no fim da seção de Preparação. Estes dados possuem a população dos países, quantidade de mortes, e a população padrão mundial. Você pode vê-lo [aqui](#standard_all).  



<!-- ======================================================= -->
### Taxas normalizadas diretamente {.unnumbered}

Abaixo, primeiro agrupamos os dados por País, e então aplicamos a função `phe_dsr()` para obter taxas diretamente normalizadas por país.

De nota - a população de referência (padrão) pode ser fornecida como uma **coluna dentro de uma tabela de dados específica para cada país** ou como um **vetor separado**. Se fornecida dentro de uma tabela específica para um país, você precisa ajustar `stdpoptype = "field"`. Se fornecido como um vetor, ajuste `stdpoptype = "vector"`. Neste último caso, você precisa garantir que a ordem das linhas por estrato é similar em ambas tabelas dos países e população de referência, pois os registros serão ligados por posição. No exemplo abaixo, fornecemos a população de referência como uma coluna dentro de uma tabela específica de um páís.

Para mais informações, utilize `?phr_dsr`, ou acesse os links na seção de Referências.

```{r}
# Calcule as taxas por país diretamente normalizadas para idade e sexo
mortality_ds_rate_phe <- all_data %>%
     group_by(Country) %>%
     PHEindicatormethods::phe_dsr(
          x = Deaths,                 # coluna com o número observado de eventos
          n = Population,             # coluna com a população não-normalizada para cada estrato
          stdpop = pop,               # populações padronizadas para cada estrato
          stdpoptype = "field")       # ou "vector" para vetor autônomo ou "field" para populações padronizadas nos dados

# Printa a tabela
knitr::kable(mortality_ds_rate_phe)
```

<!-- ======================================================= -->
### Taxas normalizadas indiretamente {#standard_indirect .unnumbered}

Para normalização indireta, você precisa de uma população de referência com o número de óbitos e a quantidade da população por estrato. Neste exemplo, nós iremos calcular as taxas para o país A *utilizando o país B como população de referência*, uma vez que a população de referência em `standard_pop_clean` não possui a quantidade de mortes por estrato.

Abaixo, primeiro criamos a população de referência do país B. Então, passamos os dados populacionais e de mortalidade do país A, combinamos ele com a população de referência, e passamos para a função `calculate_ISRate()`, para obter taxas indiretamente normalizadas. Claro, você pode fazer isto vice versa.

De nota - no exemplo abaixo, a população de referência é fornecida como um data frame separado. Neste caso, nós garantimos que os vetores `x = `, `n = `, `x_ref = ` e `n_ref = ` são todos ordenados pelos mesmos valores da categoria de padronização (estrato) como nos nossos dados específicos dos países, uma vez que os registros serão ligados pela posição na tabela.

Para mais informações, utilize `?phr_isr`, ou acesse os links na seção de Referências.

```{r}
# Crie a população de referência
refpopCountryB <- country_data %>% 
  filter(Country == "B") 

# Calcule taxas para o país A indiretamente normalizada por idade e sexo
mortality_is_rate_phe_A <- country_data %>%
     filter(Country == "A") %>%
     PHEindicatormethods::calculate_ISRate(
          x = Deaths,                 # coluna com o número observado de eventos
          n = Population,             # coluna com população não padronizada para cada estrato
          x_ref = refpopCountryB$Deaths,  # quantidade referência de mortes  para cada estrato
          n_ref = refpopCountryB$Population)  # população de referência para cada estrato

# Printa a tabela
knitr::kable(mortality_is_rate_phe_A)
```

<!-- ======================================================= -->
## Recursos {  }

Se você quiser ver outros exemplos reproduzíveis utilizando **dsr**, por favor veja [esse tutorial]( https://mran.microsoft.com/snapshot/2020-02-12/web/packages/dsr/vignettes/dsr.html)  

Para outro exemplo utilizando **PHEindicatormethods**, por favor vá a [esse website](https://mran.microsoft.com/snapshot/2018-10-22/web/packages/PHEindicatormethods/vignettes/IntroductiontoPHEindicatormethods.html)  

Veja o arquivo de referência do **PHEindicatormethods** [em pdf](https://cran.r-project.org/web/packages/PHEindicatormethods/PHEindicatormethods.pdf)  


```{r include=FALSE, cache=FALSE}

# clear workspace
rm(list = ls(all = TRUE))

# clear all packages except base
#lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))

# to ensure that tidyverse packages prevail
filter <- dplyr::filter
select <- dplyr::select
summarise <- dplyr::summarise
summary <- base::summary
incidence <- incidence2::incidence

#load core packages
pacman::p_load(
     rio,
     here,
     DT,
     stringr,
     lubridate,
     tidyverse
)

# import the cleaned ebola linelist
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

# import the count data - facility level
#count_data <- rio::import(here::here("data", "facility_count_data.rds"))

# Settings

options(scipen=1, digits=7)

# print only text (not code)
# library(knitr)
# opts_chunk$set(list(echo = FALSE, eval = FALSE))
```

<!--chapter:end:new_pages/standardization.Rmd-->

# Médias móveis {#moving-average}

```{r, out.width=c("100%"), echo=F}
knitr::include_graphics(here::here("images", "moving_avg_epicurve.png"))
```

Nesta página, dois métodos para calcular e visualizar médias móveis serão abordados:

1)  Calcule com o pacote **slider**\
2)  Calcule com um comando *dentro* da função `ggplot()`, utilizando o pacote **tidyquant**

<!-- ======================================================= -->

## Preparação

### Carregue os pacotes {.unnumbered}

O código abaixo realiza o carregamento dos pacotes necessários para a análise dos dados. Neste manual, enfatizamos o uso da função `p_load()`, do **pacman**, que instala os pacotes, caso não estejam instalados, *e* os carrega no R para utilização. Também é possível carregar pacotes instalados utilizando a função `library()`, do R **base**. Para mais informações sobre os pacotes do R, veja a página [Introdução ao R](#basics).

```{r}
pacman::p_load(
  tidyverse,      # para gerenciamento e visualização dos dados
  slider,         # para calcular médias móveis
  tidyquant       # para calcular médias móveis dentro do ggplot
)
```

### Importe os dados para R {.unnumbered}

Nós iremos importar o banco de dados de casos de uma simulação de epidemia de Ebola. Se você quiser acompanhar os passos abaixo, <a href='https://github.com/epirhandbook/Epi_R_handbook/raw/master/data/case_linelists/linelist_cleaned.rds' class='download-button'>clique aqui para fazer o download do banco de dados 'limpo'</a> (como arquivo .rds). Importe seus dados utilizando a função `import()` do pacote **rio** (esta função importa muitos tipos de arquivos, como .xlsx, .rds, .csv - veja a página [Importar e exportar](#importing) para detalhes).

```{r, echo=F}
# importe o banco de dados para o R
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))
```

```{r, eval=F}
# importe o *linelist*
linelist <- import("linelist_cleaned.xlsx")
```

As primeiras 50 linhas do banco de dados são mostradas abaixo.

```{r, message=FALSE, echo=F}
# mostre os dados como tabela
DT::datatable(head(linelist, 50), rownames = FALSE, filter="top", options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```

<!-- ======================================================= -->

## Calculando com o pacote **slider**

**Utilize esta abordagem para calcular uma média móvel em um conjunto de dados antes de traçar o gráfico.**

O pacote **slider** fornece diferentes funções que utilizam a abordagem de "janelas deslizantes" (do inglês, *sliding window*) para calcular médias móveis, somas cumulativas, regressões móveis, etc. Este pacote trata o conjunto de dados como um vetor de linhas, permitindo a iteração entre as linhas do conjunto de dados.

Aqui estão algumas das funções mais comuns:

-   `slide_dbl()` - realiza a iteração de uma coluna *numérica* (logo "\_dbl") enquanto executa uma operação usando o protocolo das janelas deslizantes

    -   `slide_sum()` - função atalho para realizar a soma móvel para a função `slide_dbl()`\
    -   `slide_mean()` - função atalho para realizar a média móvel para a função `slide_dbl()`

-   `slide_index_dbl()` - aplica as janelas deslizantes em uma coluna numérica, utilizando uma coluna separada para *indexar* a progressão das janelas (útil se a progressão estiver sendo por datas e algumas estiverem ausentes)

    -   `slide_index_sum()` - função atalho para realizar a soma móvel usando indexador\
    -   `slide_index_mean()` - função atalho para realizar a média móvel usando indexador

O pacote **slider** possui muitas outras funções que são cobertas na seção sobre Recursos extras desta página. Aqui, nós abordamos brevemente as funções mais comuns.

**Argumentos essenciais**

-   `.x`, por padrão, o primeiro argumento é o vetor sobre o qual serão realizadas as iterarações e sobre o qual será aplicada a função \

-   `.i =` para as versões "index" das funções do pacote **slider** - indique a coluna para "indexar" o "delizamento" (veja a seção [abaixo](#roll_index))\

-   `.f =`, por padrão, o segundo argumento é:

    -   Uma função, escrita sem parênteses, como `mean`, ou\
    -   Uma fórmula, que será convertida em uma função. Por exemplo, `~ .x - mean(.x)` irá gerar o resultado do valor corrente menos a média do valor da janela

-   Para mais detalhes, veja esse [material de referência](https://davisvaughan.github.io/slider/reference/slide.html)

**Tamanho da janela**

Especifique a extensão da janela ao usar `.before`, `.after`, ou ambos argumentos:

-   `.before =` - Forneça um número inteiro\
-   `.after =` - Forneça um número inteiro\
-   `.complete =` - Ajuste isso para `TRUE` se você apenas quiser realizar os cálculos em janelas completas

Por exemplo, para atingir uma janela de 7 dias incluindo o valor corrente e os seis anteriores, utilize `.before = 6`. Para obter uma janela "central", forneça o mesmo número tanto para `.before =` quanto para `.after =`.

Por padrão, `.complete =` será FALSE. Então, se a janela inteira de linhas não existir, as funções irão utilizar linhas disponíveis para executar os cálculos. Alterar para TRUE restringue isso, de forma que os cálculos serão realizados apenas em janelas completas.

**Janelas em expansão**

Para obter operações *cumulativas*, ajuste o argumento `.before =` para `Inf`. Isto irá realizar a operação no valor corrente e em todos os valores anteriores.

### Deslizando por data {#roll_index .unnumbered}

A aplicação mais provável de cálculos móveis em epidemiologia aplicada é para examinar um indicador *ao longo do tempo*. Por exemplo, uma medida móvel da incidência de casos, baseado na contagem diária dos casos.

Se você possuir dados com séries cronológicas limpas, com valores para cada data, você pode estar OK para utilizar a função `slide_dbl()`, como demonstrado aqui na página sobre [Séries temporais e detecção de surtos](#timeseries_moving).

Entretanto, em muitas situações da epidemiologia aplicada, você pode não ter algumas datas nos seus dados, em que os eventos não foram registrados. Nestes casos, é melhor utilizar as versões "index" das funções do **slider**.

### Dados indexados {.unnumbered}

Abaixo, nós mostramos um exemplo utilizando a função `slide_index_dbl()` no objeto linelist criado acima. Digamos que nosso objetivo é calcular uma incidência móvel de 7 dias - a soma dos casos utilizando uma janela de 7 dias. Se você estiver procurando por um exemplo de média móvel, veja a seção abaixo sobre [deslocamento agrupado](#roll_slider_group).

Para iniciar, o conjunto de dados `daily_counts` é criado para refletir a contagem diária de casos do `linelist`, sendo calculado com a função `count()` do **dplyr**.

```{r}
# crie um conjunto de dados das contagens diárias
daily_counts <- linelist %>% 
  count(date_hospitalisation, name = "new_cases")
```

Aqui estão os dados do `daily_counts` - existem `nrow(daily_counts)` linhas, onde cada dia é representado por uma linha mas, especialmente no início da epidemia, *alguns dias não estão presentes (não existem casos admitidos nestes dias)*.

```{r, echo=F}
DT::datatable(daily_counts, rownames = FALSE, options = list(pageLength = 6, scrollX=T) )
```

É crucial reconhecer que uma função móvel padrão (como `slide_dbl()`) iria utilizar uma janela de 7 *linhas*, não de 7 *dias*. Logo, se existirem datas ausentes, algumas janelas irão abrangir mais do que 7 dias de um calendário!

Uma janela móvel "inteligente" pode ser obtida com a função `slide_index_dbl()`. O "index" significa que a função utiliza uma *coluna separada* como "indexador" para a janela deslizante. Assim, a janela não é simplesmente baseada nas linhas do conjunto de dados.

Se a coluna indexadora for uma data, você possui a habilidade para especificar a extensão da janela em `.before =` e/ou `.after =` em diferentes unidades, utilizando as funções `days()` ou `months()` do pacote **lubridate**. Se você fizer isto, a função irá incluir os dias ausentes nas janelas como se lá estivessem (com valores `NA`).

Vamos mostrar uma comparação. Abaixo, nós calculamos a incidência móvel de casos por 7 dias, utilizando uma janela regular e uma indexada.

```{r}
rolling <- daily_counts %>% 
  mutate(                                # crie novas colunas
    # Utilizando slide_dbl()
    ###################
    reg_7day = slide_dbl(
      new_cases,                         # calcule utilizando new_cases
      .f = ~sum(.x, na.rm = T),          # função sum() com os campos em branco removidos
      .before = 6),                      # a janela é a LINHA corrente e as 6 LINHAS anteriores
    
    # Utilizando slide_index_dbl()
    #########################
    indexed_7day = slide_index_dbl(
        new_cases,                       # calcule com new_cases
        .i = date_hospitalisation,       # indexado com date_onset 
        .f = ~sum(.x, na.rm = TRUE),     # função sum() com os campos em branco removidos
        .before = days(6))               # a janela é o DIA e os 6 DIAS anteriores
    )

```

Observe como, na coluna regular, a contagem aumenta constantemente nas primeiras 7 linhas, *mesmo com estas linhas estando fora do intervalo de 7 dias entre elas*! A coluna adjacente "indexada" leva em consideração estes dias ausentes do calendário, então suas somas móveis de 7 dias são muito menores, pelo menos neste período da epidemia, quando os casos estão mais distantes uns dos outros.

```{r, echo=F}
DT::datatable(rolling, rownames = FALSE, options = list(pageLength = 12, scrollX=T) )
```

Agora você pode traçar um gráfico desses dados utilizando o `ggplot()`:

```{r}
ggplot(data = rolling)+
  geom_line(mapping = aes(x = date_hospitalisation, y = indexed_7day), size = 1)
```

<!-- ### Deslizando por mês {.unnumbered}   -->

<!-- Se você quiser calcular estatísticas por mês (ex.: soma, média, máximo), você pode fazer isso com o **dplyr**, como descrito na página sobre [agrupamento dos dados]. Simplesmente crie uma coluna chamada "month" (mês), agrupe os dados, e execute seus cálculos com `summarise()`.   -->

<!-- Se, entretanto, você quiser calcular estatísticas móveis com diferentes meses (ex.: uma janela deslizante de 2 meses), você pode usar a função `slide_period()` do pacote **slider**.   -->

<!-- ```{r} -->

<!-- monthly_mean = function(data){ -->

<!--   summarise(data, mean = mean(new_cases, na.rm=T)) -->

<!-- } -->

<!-- linelist %>%  -->

<!--   count(date_hospitalisation, name = "new_cases") %>%  -->

<!--   mutate( -->

<!--     slide_period_dfr( -->

<!--       new_cases,  -->

<!--       .i = date_hospitalisation, -->

<!--       .period = "month", -->

<!--       .f = monthly_mean))  #~mean(.x, na.rm=T))) -->

<!--       #values_col = new_cases, -->

<!--       #index_col = date_hospitalisation -->

<!--     )) -->

<!-- ``` -->

### Deslizando por grupo {#roll_slider_group .unnumbered}

Se você agrupar seus dados antes de utilizar uma função do **slider**, as janelas deslizantes serão aplicadas por grupos. Tenha cuidado para organizar suas linhas na ordem desejada *por grupo*.

A cada momento que um novo grupo se inicia, as janelas deslizantes irão reiniciar. Logo, um detalhe para se ter em mente é, se seus dados são agrupados *e* você realizou o ajuste `.complete = TRUE`, você terá valores em branco a cada transição entre os grupos. Enquanto a função se desloca para baixo ao longo das linhas, cada transição na coluna de agrupamento irá reiniciar o acúmulo do tamanho mínimo da janela, de forma a permitir a realização do cálculo.

Veja a página sobre [Agrupamento dos dados](#grouping), deste manual, para detalhes sobre agrupamento dos dados.

Abaixo, nós contamos os casos do linelist por dia *e* por hospital. Então, ordenamos as linhas em ordem ascendente, primeiro ordenando por hospital, e então por dia (dentro da ordem dos hospitais). Por fim, nós ajustamos a função `group_by()`, e assim criamos a nossa nova média móvel.

```{r}
grouped_roll <- linelist %>%

  count(hospital, date_hospitalisation, name = "new_cases") %>% 

  arrange(hospital, date_hospitalisation) %>%   # organize as linhas por hospital, e então por datas
  
  group_by(hospital) %>%              # agrupe por hospital
    
  mutate(                             # média móvel
    mean_7day_hosp = slide_index_dbl(
      .x = new_cases,                 # a contagem de casos por hospital-dia
      .i = date_hospitalisation,      # indexe por dia de admissão
      .f = mean,                      # utilize mean()                   
      .before = days(6)               # utilize o dia corrente e os 6 dias anteriores
      )
  )

```

Aqui está o novo conjunto de dados:

```{r, echo=F}
DT::datatable(grouped_roll, rownames = FALSE, options = list(pageLength = 12, scrollX=T) )
```

Agora, nós podemos traçar os gráficos das médias móveis, mostrando os dados por grupo ao especificar `~ hospital` para `facet_wrap()` no `ggplot()`. Por diversão, incluímos dois tipos de visualização - uma `geom_col()`, mostrando a contagem diária de casos, e uma `geom_line()`, mostrando a média móvel de 7 dias.

```{r, warning=F, message=F}
ggplot(data = grouped_roll)+
  geom_col(                       # adicione a contagem diária de casos como barras cinzas
    mapping = aes(
      x = date_hospitalisation,
      y = new_cases),
    fill = "grey",
    width = 1)+
  geom_line(                      # adicione a média móvel como linhas coloridas por hospital
    mapping = aes(
      x = date_hospitalisation,
      y = mean_7day_hosp,
      color = hospital),
    size = 1)+
  facet_wrap(~hospital, ncol = 2)+ # crie pequenos gráficos por hospital
  theme_classic()+                 # simplifique o plano de fundo
  theme(legend.position = "none")+ # remova a legenda
  labs(                            # adicione legendas aos eixos e título do gráfico
    title = "7-day rolling average of daily case incidence",
    x = "Date of admission",
    y = "Case incidence")
```

[***PERIGO:*** Se você obtiver um erro dizendo *"slide() was deprecated in tsibble 0.9.0 and is now defunct. Please use slider::slide() instead."*, significa que a função `slide()`, do pacote **tsibble**, está mascarando a função `slide()`, do pacote **slider**. Corrija isso ao especificar o pacote no comando, como em `slider::slide_dbl()`.]{style="color: red;"}

<!-- Você pode agrupar os dados antes de utilizar a função **slider**. Por exemplo, se você quer calcular a mesma soma móvel por 7 dias, como feito acima, mas por hospital, para o tempo entre o início dos sintomas e a adimissão no hospital.  (column `days_onset_hosp`). -->

<!-- Você pode agrupar os dados pelo mês de início dos sintomas utilizando a função `floor_date()`, do pacote **lubridate**, como descrito na página sobre [Agrupando dados]. Então, use a função `slide_index_dbl()`, como antes, mas ajuste a extensão da janela, utilizando a função `months()` (também do pacote **lubridate**).  -->

<!-- Se você quiser obter a média móvel por *meses*, é possível utilizar o pacote **lubridate** para agrupar os dados por mês, e então aplicar a função `slide_index_dbl()`, como mostrado abaixo, para o cálculo da média móvel por três meses:   -->

<!-- ```{r} -->

<!-- months_delay <- linelist %>% -->

<!--   arrange(date_onset) %>%    # exclua linhas sem as datas de início dos sintomas -->

<!--   group_by(hospital) %>%  -->

<!--   #group_by(month_onset = floor_date(date_onset, "month")) %>% # crie e agrupe por mês de início dos sintomas  -->

<!--   mutate( -->

<!--     delay_7d = slide_index_dbl( -->

<!--       days_onset_hosp,                  # calcule a média baseado nos valores da coluna new_cases -->

<!--       .i = date_onset,                 # a coluna para indexar é a date_onset, então datas ausentes são incluídas na janela de 7 dias  -->

<!--       .f = ~mean(.x, na.rm = TRUE),     # função é mean() com campos em branco removidos -->

<!--       .before = days(7)), -->

<!--     delay_month = slide_index_dbl( -->

<!--       days_onset_hosp,                  # calcule a média baseado nos valores da coluna new_cases -->

<!--       .i = date_onset,                 # a coluna indexadora é a date_onset, então datas ausentes são incluídas na janela de 7 dias -->

<!--       .f = ~mean(.x, na.rm = TRUE),     # função é a mean() com os campos em branco removidos -->

<!--       .before = months(1)))               # a janela é o mês corrente e o mês anterior -->

<!-- # o intervalo da janela é o mês corrente e o mês anterior -->

<!-- ``` -->

<!-- ```{r} -->

<!-- ggplot(data = months_delay, mapping = aes(x = month_onset))+ -->

<!--   geom_line(mapping = aes(y = )) -->

<!-- ``` -->

<!-- ======================================================= -->

## Calcule com o pacote **tidyquant** dentro da função `ggplot()`

O pacote **tidyquant** oferece outra abordagem para calcular médias móveis - desta vez, de *dentro* de um comando `ggplot()`.

Abaixo, os dados do `linelist` são contados por dia do início de sintomas, e isto é adicionado ao gráfico como uma linha desbotada (`alpha` \< 1). Em frente à essa linha, está uma outra linha criada com a função `geom_ma()`, do pacote **tidyquant**, com uma janela de 7 dias (`n = 7`), cor e espessura especificados.

Por padrão, `geom_ma()` utiliza uma média móvel simples (`ma_fun = "SMA"`), mas outros tipos podem ser especificados, como:

-   "EMA" - média móvel exponencial (mais peso para observações recentes)\
-   "WMA" - média móvel ponderada (`wts` são utilizadas para ponder observações na média móvel)\
-   Outros tipos podem ser encontrados na documentação da função

```{r}
linelist %>% 
  count(date_onset) %>%                 # conte os casos por dia
  drop_na(date_onset) %>%               # remova casos sem a data de início dos sintomas
  ggplot(aes(x = date_onset, y = n))+   # inicie o ggplot
    geom_line(                          # adicione uma linha com os valores brutos
      size = 1,
      alpha = 0.2                       # linha semi-transparente
      )+             
    tidyquant::geom_ma(                 # adicione a média móvel
      n = 7,           
      size = 1,
      color = "blue")+ 
  theme_minimal()                       # plano de fundo simples
```

Veja esse [tutorial](https://cran.r-project.org/web/packages/tidyquant/vignettes/TQ04-charting-with-tidyquant.html) para mais detalhes das opções disponíveis dentro do pacote **tidyquant**.

<!-- ## Regressão móvel  -->

<!-- ```{r} -->

<!-- a <- linelist %>% -->

<!--   separate(time_admission, into = c("hour", "minute"), sep = ":") %>%  -->

<!--   count(days_onset_hosp, hour) %>%  -->

<!--   mutate(reg_admit_hour = slide(., ~lm(days_onset_hosp ~ hour), .before = 3, .complete = T)) %>%  -->

<!--   mutate(coeff = reg_admit_hour[[1]]) -->

<!-- ggplot()+ -->

<!--   geom_point(aes(x = hour, y = days_onset_hosp)) -->

<!-- ``` -->

<!-- ```{r} -->

<!-- linelist %>%  -->

<!--   mutate( -->

<!--   ) -->

<!-- ``` -->

<!-- ======================================================= -->

## Recursos extras

Veja este útil [tutorial online do pacote **slider**](https://cran.r-project.org/web/packages/slider/vignettes/slider.html)

A página do pacote **slider** no [github](https://github.com/DavisVaughan/slider)

Um [tutorial do **slider**](https://davisvaughan.github.io/slider/articles/slider.html)

[Tutorial do tidyquant](https://cran.r-project.org/web/packages/tidyquant/vignettes/TQ04-charting-with-tidyquant.html)

Se seus casos necessitam que você "pule" fins de semana, ou até mesmo feriados, você pode gostar do pacote **almanac**.
```{r include=FALSE, cache=FALSE}

# clear workspace
rm(list = ls(all = TRUE))

# clear all packages except base
#lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))

# to ensure that tidyverse packages prevail
filter <- dplyr::filter
select <- dplyr::select
summarise <- dplyr::summarise
summary <- base::summary
incidence <- incidence2::incidence

#load core packages
pacman::p_load(
     rio,
     here,
     DT,
     stringr,
     lubridate,
     tidyverse
)

# import the cleaned ebola linelist
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

# import the count data - facility level
#count_data <- rio::import(here::here("data", "facility_count_data.rds"))

# Settings

options(scipen=1, digits=7)

# print only text (not code)
# library(knitr)
# opts_chunk$set(list(echo = FALSE, eval = FALSE))
```

<!--chapter:end:new_pages/moving_average.Rmd-->


# Modelagem de epidemias {#epidemic-models}  


<!-- ======================================================= -->
## Visão geral do tópico {  }

Existe um conjunto crescente de ferramentas para modelagem em epidemiologia que nos permite desenvolver
análises complexas com esforço mínimo. Este capítulo apresenta
uma síntese sobre como usar essas ferramentas para:

* estimar o número efetivo de reprodução R<sub>t</sub> e estatísticas relacionadas como tempo de duplicação
  
* produzir projeções de curto prazo da incidência futura

Tenha em mente que esta página *não* é uma revisão das metodologias e métodos estatísticos
empregados por estas ferramentas. Para tanto, utilize os links disponíveis no subtópico Recursos extras para
encontrar artigos detalhando essas metodologias. Antes de utilizar as ferramentas a seguir, garanta que você
compreenda os métodos subjacentes empregados; isto garantirá que você possa interpretar
adequadamente os resultados.

Abaixo está um exemplo de uma das análises que construíremos neste capítulo.

```{r out.width=c('100%', '100%'), fig.show='hold', echo=F, fig.width = 12, fig.height = 9, message=F, warning=F}

## instale e carregue os pacotes
pacman::p_load(tidyverse, EpiNow2, EpiEstim, here, incidence2, epicontacts, rio, projections)

## carregue a linelist
linelist <- import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

## crie o objeto contacts (contatos)
contacts <- linelist %>%
  transmute(
    from = infector,
    to = case_id
  ) %>%
  drop_na()

## crie o objeto epicontacts
epic <- make_epicontacts(
  linelist = linelist,
  contacts = contacts, 
  directed = TRUE
)

## ## estime o tempo de geração gamma
## generation_time <- bootstrapped_dist_fit(
##   get_pairwise(epic, "date_infection"),
##   dist = "gamma",
##   max_value = 20,
##   bootstraps = 1
## )

## ## exportar para o cache
## export(
##   generation_time,
##   here("data/cache/epidemic_models/generation_time.rds")
## )

## importar do cache o tempo de geração
generation_time <- import(here("data/cache/epidemic_models/generation_time.rds"))

## ## estimar o tempo de incubação
## incubation_period <- bootstrapped_dist_fit(
##   linelist$date_onset - linelist$date_infection,
##   dist = "lognormal",
##   max_value = 100,
##   bootstraps = 1
## )

## ## exportar para o cache
## export(
##   incubation_period,
##   here("data/cache/epidemic_models/incubation_period.rds")
## )

## importar do cache o tempo de incubação
incubation_period <- import(here("data/cache/epidemic_models/incubation_period.rds"))

## obtenha a incidência a partir da data de início dos sintomas
cases <- linelist %>%
  group_by(date = date_onset) %>%
  summarise(confirm = n())

## ## execute o epinow
## epinow_res <- epinow(
##   reported_cases = cases,
##   generation_time = generation_time,
##   delays = delay_opts(incubation_period),
##   target_folder = here("data/cache/epidemic_models"),
##   return_output = TRUE,
##   output = "samples",
##   verbose = TRUE,
##   stan = stan_opts(samples = 750, chains = 4),
##   horizon = 21
## )

## ## exporte para o cache
## export(
##   epinow_res,
##   here("data/cache/epidemic_models/epinow_res.rds")
## )

## importe do cache os resultados do epinow
epinow_res <- import(here("data/cache/epidemic_models/epinow_res.rds"))

## crie um gráfico com o sumário da análise
plot(epinow_res)

```

<!-- ======================================================= -->
## Preparação {  }

Iremos utilizar dois métodos e pacotes diferentes para estimar o R<sub>t</sub>,
chamados de **EpiNow** e **EpiEstim**, assim como o pacote **projections** para
fazer previsões da incidência de casos.

Este pedaço de código mostra o carregamento dos pacotes necessários para as análises.
Neste manual, enfatizamos o uso de `p_load()`, do pacote **pacman**, que instala o pacote, caso necessário, *e* o inicia para uso.
Você também pode carregar pacotes instalados com `library()`, do R **base**. Veja a página sobre [Introdução ao R](#basics) para mais informações sobre pacotes no R.

	
```{r epidemic_models_packages, }
pacman::p_load(
   rio,          # Importar arquivos
   here,         # Localizar arquivos
   tidyverse,    # Gerenciamento dos dados + gráficos ggplot2
   epicontacts,  # Analisar as redes de transmissão
   EpiNow2,      # Estimar o Rt
   EpiEstim,     # Estimar Rt
   projections,  # Projeções da incidência
   incidence2,   # Trabalhando com dados de incidência
   epitrix,      # Funções uteis de epi
   distcrete     # Distribuições discretas .;
)
```
	
Nesta seção, iremos utilizar a linelist dos casos limpa para todas as análises. Se você quiser acomapnhar, <a href='https://github.com/appliedepi/epirhandbook_eng/raw/master/data/case_linelists/linelist_cleaned.rds' class='download-button'>clique para baixar a linelist "limpa"</a> (como arquivo .rds). Veja a página [Download do manual e dados](#data-used) para baixar todos os dados utilizados como exemplo neste manual.

```{r, echo=F}
# importe a linelist para o R
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))
```

```{r eval=F}
# importe a linelist limpa
linelist <- import("linelist_cleaned.rds")
```


<!-- ======================================================= -->
## Estimando o R<sub>t</sub> {  }

### EpiNow2 vs. EpiEstim {.unnumbered}

O número de reprodução R é uma medida da capacidade de transmissão de uma doença e
é definido como a quantidade esperada de casos secundários para cada caso infectado. Em uma
população totalmente susceptível, este valor representa o número básico 
de reprodução R<sub>0</sub>. Entretanto, conforme o número de indivíduos susceptíveis em uma
população muda no decorrer de um surto ou pandemia, e conforme várias
medidas de resposta e controle são implementadas, a medida mais comumente utilizada de 
transmissibilidade é o número efetivo de reprodução R<sub>t</sub>; este é
definido como a quantidade de casos secundários por cada caso infectado em um determinando 
ponto no tempo _t_.

O pacote **EpiNow2** fornece a estrutura mais sofisticada para estimar o
R<sub>t</sub>. Ele tem duas vantagens chave sobre o outro pacote comumente utilizado,
**EpiEstim**:

* Ele leva em consideração as demoras nas notificações ao estimar o R<sub>t</sub>,
  mesmo quando dados recentes são incompletos.
* Ele estima o R<sub>t</sub> a partir das _datas de infecção_, em vez das datas
  de início das notificações, o que significa que o efeito de uma intervenção irá
  imediatamente refletir em mudanças no  R<sub>t</sub>, em vez de demorar
  para alterar.

Entretanto, ele também possuí duas desvantagens chave:

* Ele necessita de conhecimento da distribuição do tempo de geração (ex.: distribuição 
  dos intervalos de infecção entre casos primários e secundários), distribuição do 
  tempo de incubação (ex.: distribuição dos intervalos entre a infecção e o início dos
  sintomas) e qualquer outra distribuição de intervalos relevante para os seus dados (ex.: se você
  tiver datas de notificação, você precisa da distribuição dos intervalos entre início dos sintomas
  e notificação dos casos). Enquanto isto irá permitir estimativas mais acuradas do
  R<sub>t</sub>, **EpiEstim** apenas requer a distribuição seriada dos intervalos
  (ex.: a distribuição de intervalos entre o início dos sintomas de casos primários
  e secundários), que pode ser a única distribuição disponível para você.
* **EpiNow2** é significamente mais devagar do que **EpiEstim**, por fatores entre
  100-1000 mais lento! Por exemplo, estimar o R<sub>t</sub> para a amostra do surto
  trabalhada nesta seção levou por volta de quatro horas (esta estimativa rodou por um elevado
  número de iterações para garantir elevada acurácia, e provavelmente poderia ser reduzida caso
  necessário. Entretanto, o ponto é que este algoritmo é mais devagar,
  no geral). Logo, este pacote pode ser inviável caso você esteja atualizando regularmente suas estimativas
  do R<sub>t</sub>.
  
Qual pacote você irá escolher irá depender dos seus dados, tempo e 
recursos computacionais disponíveis.

### EpiNow2 {.unnumbered}

#### Estimando a distribuição dos intervalos {.unnumbered}

As distribuições dos intervalos necessárias para utilizar o **EpiNow2** variam de acordo com os
seus dados. Essencialmente, você precisar ser capaz de descrever o intervalo entre a data
de infecção e a data do evento que você quer utilizar para estimar o R<sub>t</sub>. Caso
você esteha utilizando as datas de início dos sintomas, isto seria simplesmente a distribuição do período de
incubação. Se você estiver utilizando as datas de notificação, você utiliza o
intervalo entre infecção à notificação. Como é improvável que esta distribuição seja conhecida
diretamente, **EpiNow2** permite conectar múltiplas distribuições de intervalo; neste
caso, os intervalos entre a infecção e o aparecimento dos sintomas (ex.: o período
de incubação, que provavelmente é conhecido) e entre o início dos sintomas e a notificação (que você pode
frequentemente estimar a partir dos seus dados).

Como temos as datas de início dos sintomas para todos os nossos casos em nossa linelist de exemplo, nós
apenas precisamos da distribuição do período de incubação para conectar os nossos dados (ex.: datas de
início dos sintomas) para a data de infecção. Nós podemos ou estimar esta distribuição
a partir dos dados, ou utilizar valores da literatura.

Uma estimativa do período de incubação da Ebola encontrada na literatura (obtida [deste artigo](https://www.nejm.org/doi/full/10.1056/nejmoa1411100)) possuí uma
média de 9.1, desvio padrão de 7.3, e o valor máximo de 30. Isto pode ser
especificado no R como mostrado a seguir:

```{r epidemic_models_incubation_literature, eval=F}
incubation_period_lit <- list(
  mean = log(9.1),
  mean_sd = log(0.1),
  sd = log(7.3),
  sd_sd = log(0.1),
  max = 30
)
```
Observe que o **EpiNow2** pede que a distribuição destes intervalos seja fornecida em uma escala **log**
(logarítmica), por isso chamamos `log` ao redor de cada valor (exceto o parâmetro `max` que,
de forma confusa, precisa ser fornecido em uma escala natural). Os `mean_sd` e `sd_sd`
definem o desvio padrão da média e as estimativas do desvio padrão. Como
neste caso estes valores não são conhecidos, nós escolhemos um valor bastante arbitrário, 0.1.

Nesta análise, nós estimamos a distribuição do período de incubação
a partir da própria linelist utilizando a função `bootstrapped_dist_fit`, que irá
ajustar uma distribuição log-normal para os intervalos observados entre a infecção e o aparecimento dos sintomas
na linelist.

```{r epidemic_models_incubation_estimate, eval=F}
## estime o período de incubação
incubation_period <- bootstrapped_dist_fit(
  linelist$date_onset - linelist$date_infection,
  dist = "lognormal",
  max_value = 100,
  bootstraps = 1
)
```

A outra distribuição que precisamos é o tempo de geração. Como temos dados sober
os tempos de infecção __and__ os links de transmissão, nós podemos estimar esta
distribuição a partir da linelist ao calcular o intervalo entre o tempo de infecção
de pares infectores-infectados. Para fazer isto, nós utilizamos a função `get_pairwise`
do pacote **epicontacts**, que nos permite calcular diferenças
entre os pares a partir das propriedades da linelist sobre os pares de transmissão. Nós primeiro criamos um
objeto epicontact (veja a página [Cadeias de transmissão](#transmission-chains) para mais
detalhes):

```{r epidemic_models_epicontacts, eval=F}
## gere o objeto contatos
contacts <- linelist %>%
  transmute(
    from = infector,
    to = case_id
  ) %>%
  drop_na()

## gere o objeto epicontact
epic <- make_epicontacts(
  linelist = linelist,
  contacts = contacts, 
  directed = TRUE
)
```

Então, ajustamos a diferença no tempo de incubação entre os pares da transmissão, 
calculado com `get_pairwise`, em uma distribuição gamma:

```{r epidemic_models_generation_estimate, eval=F}
## estime o tempo de geração gamma
generation_time <- bootstrapped_dist_fit(
  get_pairwise(epic, "date_infection"),
  dist = "gamma",
  max_value = 20,
  bootstraps = 1
)
```

#### Executando o **EpiNow2** {.unnumbered}

Agora nós só precisamos calcular a incidência diária a partir da linelist, que podemos fazer
facilmente com as funções `group_by()` e `n()`, do **dplyr**. Note
que o **EpiNow2** requer que os nomes das colunas sejam `date` e `confirm`.

```{r epidemic_models_cases, eval=F}
## obtenha a incidência a partir da data de início dos sintomas
cases <- linelist %>%
  group_by(date = date_onset) %>%
  summarise(confirm = n())
```

Podemos, então, estimar o R<sub>t</sub> utilizando a função `epinow`. Algumas notas sobre
os dados usados:

* Nós podemos fornecer qualquer quantidade de distribuições de intervalos 'encadeados' para o argumento
  `delays`; simplesmente iríamos inserí-los junto com o objeto `incubation_period`
  dentro da função `delay_opts`.
* `return_output` garante que o resultado da análise é obtido dentro do R, e não apenas salvo
  em um arquivo.
* `verbose` especifica que queremos uma leitura/update do progresso.
* `horizon` indica em quantos dias queremos estimar a incidência futura.
* Nós adicionamos outras opções no argumento `stan` para especificar por quanto tempo
  queremos executar a inferência. Aumentar o `samples` e `chains` irá te
  dar uma estimativa mais precisa que melhor caracteriza a incerteza, entretanto
  irá demorar mais para ser calculada.

```{r epidemic_models_run_epinow, eval=F}
## execute o epinow
epinow_res <- epinow(
  reported_cases = cases,
  generation_time = generation_time,
  delays = delay_opts(incubation_period),
  return_output = TRUE,
  verbose = TRUE,
  horizon = 21,
  stan = stan_opts(samples = 750, chains = 4)
)
```

#### Analisando o resultado da análise {.unnumbered}

Assim que o código terminar de ser executado, nós podemos criar um resumo da análise facilmente, da seguinte maneira. Role a imagem para ver a sua real extensão.


```{r out.width=c('100%', '100%'), fig.show='hold', fig.width = 12, fig.height = 9, message=F, warning=F }
## faça uma figura do sumário da análise
plot(epinow_res)
```

Nós também podemos olher diferentes resumos estatísticos:

```{r epidemic_models_epinow_summary,}
## tabela resumo
epinow_res$summary
```

Para mais análise e customização do gráfico, você pode acessar as estimativas diárias
resumidas através de `$estimates$summarised`. Nós iremos converter isto do padrão
`data.table` para um `tibble`, facilitando o uso com **dplyr**.

```{r epidemic_models_to_tibble, eval=F}
## extraia o resumo e converta para formato tibble
estimates <- as_tibble(epinow_res$estimates$summarised)
estimates
```

```{r epidemic_models_tibble_show,  echo = F}
## mostre os resultados da análise
estimates <- as_tibble(epinow_res$estimates$summarised)
DT::datatable(
  estimates,
  rownames = FALSE,
  filter = "top",
  options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap'
)
```

Como um exemplo, vamos criar um gráfico do tempo de duplicação e do R<sub>t</sub>. Nós iremos
apenas olhar os primeiros meses do surto, quando o R<sub>t</sub> está bem
acima de um, para evitar traçar tempos de duplicação extremamente elevados.

Nós utilizamos a fórmula `log(2)/growth_rate` para calcular o tempo de duplicação a partir da
taxa de crescimento estimada.

```{r epidemic_models_plot_epinow_cusotom, out.width=c('100%', '100%'), fig.show='hold', fig.width = 12, fig.height = 9, message=F, warning=F}

## crie amplas df para um gráfico mediano
df_wide <- estimates %>%
  filter(
    variable %in% c("growth_rate", "R"),
    date < as.Date("2014-09-01")
  ) %>%
  ## converta as taxas de crescimento para o tempo de duplicação
  mutate(
    across(
      c(median, lower_90:upper_90),
      ~ case_when(
        variable == "growth_rate" ~ log(2)/.x,
        TRUE ~ .x
      )
    ),
    ## renomeie a variável para refletir na transformação de taxa de crescimento para tempo de duplicação
    variable = replace(variable, variable == "growth_rate", "doubling_time")
  )

## crie um data frame longo para criar gráfico de quantis
df_long <- df_wide %>%
  ## aqui nós combinamos quantis correspondentes (ex.: lower_90 para upper_90)
  pivot_longer(
    lower_90:upper_90,
    names_to = c(".value", "quantile"),
    names_pattern = "(.+)_(.+)"
  )

## crie um gráfico
ggplot() +
  geom_ribbon(
    data = df_long,
    aes(x = date, ymin = lower, ymax = upper, alpha = quantile),
    color = NA
  ) +
  geom_line(
    data = df_wide,
    aes(x = date, y = median)
  ) +
  ## utilize label_parsed para conseguir subscrever o rótulo
  facet_wrap(
    ~ variable,
    ncol = 1,
    scales = "free_y",
    labeller = as_labeller(c(R = "R[t]", doubling_time = "Doubling~time"), label_parsed),
    strip.position = 'left'
  ) +
  ## defina manualmente a transparência do quantil
  scale_alpha_manual(
    values = c(`20` = 0.7, `50` = 0.4, `90` = 0.2),
    labels = function(x) paste0(x, "%")
  ) +
  labs(
    x = NULL,
    y = NULL,
    alpha = "Credibel\ninterval"
  ) +
  scale_x_date(
    date_breaks = "1 month",
    date_labels = "%b %d\n%Y"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    strip.background = element_blank(),
    strip.placement = 'outside'
  )

```

<!-- ======================================================= -->
### EpiEstim {.unnumbered}

Para executar **EpiEstim**, nós precisamos fornecer dados de incidência diária, e especificar
o intervalo seriado (i.e.: a distribuição dos intervalos entre o início dos sintomas dos
casos primários e secundários). 

Dados de incidência podem ser fornecidos para o **EpiEstim** como um vetor, um quadro de dados, ou um objeto
`incidence` do pacote original **incidence**. Você consegue até distinguir entre importados
e infecções adquiridas localmente; veja a documentação em `?estimate_R` para
mais detalhes.

Nós iremos criar a entrada de dados usando **incidence2**. Veja a página sobre [Curvas epidêmicas](#epicurves) para mais exemplos com o pacote **incidence2**. Já que existem updates no pacote **incidence2** que não fornecem a entrada necessária do `estimateR()`, existem algumas pequenas etapas adicionais necessárias. O objeto incidence consiste de uma tabela tibble com as datas e as respectivas contagens. Nós usamos `complete()`, do pacote **tidyr**, para garantir que todas as datas sejam incluídas (até as datas sem casos), e então `rename()` as colunas para gerarem o que é esperado pela função  `estimate_R()` em uma etapa posterior.

```{r epidemic_models_epiestim_incidence,}
## obtenha a incidência a partir da data de início dos sintomas
cases <- incidence2::incidence(linelist, date_index = "date_onset") %>% # obtenha a quantidade de casos por dia
  tidyr::complete(date_index = seq.Date(                              # garanta que todas as datas estão presentes
    from = min(date_index, na.rm = T),
    to = max(date_index, na.rm=T),
    by = "day"),
    fill = list(count = 0)) %>%                                       # converta contagens NA para 0
  rename(I = count,                                                   # renomeie para os nomes utilizados no estimateR
         dates = date_index)
```

O pacote fornece diferentes opções para especificar os intervalos seriados, os 
detalhes são fornecidos na documentação em `?estimate_R`. Nós iremos
cobrir duas das opções aqui.

#### Utilizando estimativas de intervalos seriados da literatura {.unnumbered}

Ao usar a opção `method = "parametric_si"`, podemos especificar manualmente a média e
desvio padrão do intervalo seriado em um objeto `config` criado usando a
função `make_config`. Nós usamos uma média e um desvio padrão de 12.0 e 5.2, respectivamente, definidos neste
[artigo](https://bmcmedicine.biomedcentral.com/articles/10.1186/s12916-014-0196-0):

```{r epidemic_models_epiestim_config,}
## crie o config
config_lit <- make_config(
  mean_si = 12.0,
  std_si = 5.2
)
```

Então, nós podemos estimar o R<sub>t</sub> com a função `estimate_R`:

```{r epidemic_models_epiestim_lit,  warning = FALSE}
cases <- cases %>% 
     filter(!is.na(date))
#create a dataframe for the function estimate_R()
cases_incidence <- data.frame(dates = seq.Date(from = min(cases$dates),
                               to = max(cases$dates), 
                               by = 1))
cases_incidence <- left_join(cases_incidence, cases) %>% 
     select(dates, I) %>% 
     mutate(I = ifelse(is.na(I), 0, I))


epiestim_res_lit <- estimate_R(
  incid = cases_incidence,
  method = "parametric_si",
  config = config_lit
)
```

e criar um gráfico resumindo os resultados da análise:

```{r epidemic_models_epiestim_lit_plot,  warning = FALSE}
plot(epiestim_res_lit)
```

#### Utilizando estimativas de intervalos seriados dos dados {.unnumbered}

Conforme obtemos dados sobre as datas de início dos sintomas _and_ e links de transmissão, nós podemos
também estimar o intervalo seriado a partir da linelist ao calcular o intervalo
entre as datas de início dos sintomas dos pares infectante-infectado.Como fizemos na seção do **EpiNow2**,
nós iremos agora utilizar a função `get_pairwise`, do pacote **epicontacts**,
que nos permite calcular as diferenças entre os pares de transmissão nas
características na linelsit. Primeiro, criamos um objeto epicontact
(veja a página [Cadeias de transmissão](#transmission-chains) para mais detalhes):

```{r epidemic_models_epicontacts_epiestim, eval=F}
## gere os contatos
contacts <- linelist %>%
  transmute(
    from = infector,
    to = case_id
  ) %>%
  drop_na()

## gere um objeto epicontact
epic <- make_epicontacts(
  linelist = linelist,
  contacts = contacts, 
  directed = TRUE
)
```

Então ajustamos a diferença entre as datas de início dos sintomas dos pares de transmissão, calculado
usando `get_pairwise`, para uma distribuição gamma. Utilizamos a função `fit_disc_gamma`,
do pacote **epitrix**, para fazer este procedimento de ajuste, uma vez que precisamos
de uma distribuição _discreta_.

```{r epidemic_models_incubation_estimate_epiestim,  warning = FALSE}
## estime o intervalo seriado gamma
serial_interval <- fit_disc_gamma(get_pairwise(epic, "date_onset"))
```

Então aplicamos esta informação no objeto `config`, executamos o **EpiEstim**
novamente, e criamos um gráfico dos resultados:

```{r epidemic_models_epiestim_emp,  warning = FALSE}
## crie o config
config_emp <- make_config(
  mean_si = serial_interval$mu,
  std_si = serial_interval$sd
)

## execute o epiestim
epiestim_res_emp <- estimate_R(
  incid = cases_incidence,
  method = "parametric_si",
  config = config_emp
)

## crie um gráfico dos resultados
plot(epiestim_res_emp)
```

#### Especificando as janelas de estimação do tempo {.unnumbered}

Estas opções padrão irão fornecer uma estimativa semanal móvel, e podem atuar como um
aviso que você está estimando o R<sub>t</sub> mutio precocemente no surto, para uma
estimativa precisa. Você pode mudar isto ao ajustar uma data de início posterior para a 
estimativa, como mostrado abaixo. Infelizmente, o **EpiEstim** apenas fornece um método
bem desajeitado de especificar estes tempos de estimativas, em que você precisa fornecer um
vetor de __números inteiros__ referentes as datas de início e fim para cada
intervalo de tempo.

```{r epidemic_models_epiestim_config_late,}

## defina um vetor de datas iniciando em 1o de junho
start_dates <- seq.Date(
  as.Date("2014-06-01"),
  max(cases$dates) - 7,
  by = 1
) %>%
  ## substraia a data de início para converto para numérico
  `-`(min(cases$dates)) %>%
  ## converta para número inteiro
  as.integer()

## adicione seis dias para um intervalo móvel de uma semana
end_dates <- start_dates + 6
  
## crie o config
config_partial <- make_config(
  mean_si = 12.0,
  std_si = 5.2,
  t_start = start_dates,
  t_end = end_dates
)
```
Agora re-executamos o **EpiEstim**, e podemos ver as estimativas apenas a partir de junho:

```{r epidemic_models_epiestim_config_late_run,}

## rode o epiestim
epiestim_res_partial <- estimate_R(
  incid = cases_incidence,
  method = "parametric_si",
  config = config_partial
)

## crie um gráfico dos resultados
plot(epiestim_res_partial)

```

#### Analisando os resultados {.unnumbered}

Os principais resultados podem ser acessados através de `$R`. Como um exemplo, nós iremos criar um gráfico do
R<sub>t</sub> e uma medida de "potencial de transmissão", dada pelo produto de 
R<sub>t</sub> e o número de casos notificados naquele dia; isto representa o
número esperado de casos na próxima geração da infecção.

```{r epidemic_models_epiestim_plot_full, out.width=c('100%', '100%'), fig.show='hold', fig.width = 12, fig.height = 9, message=F, warning=F}

## crie um quadro de dados amplo para a mediana
df_wide <- epiestim_res_lit$R %>%
  rename_all(clean_labels) %>%
  rename(
    lower_95_r = quantile_0_025_r,
    lower_90_r = quantile_0_05_r,
    lower_50_r = quantile_0_25_r,
    upper_50_r = quantile_0_75_r,
    upper_90_r = quantile_0_95_r,
    upper_95_r = quantile_0_975_r,
    ) %>%
  mutate(
    ## extraia a data média de t_start e t_end
    dates = epiestim_res_emp$dates[round(map2_dbl(t_start, t_end, median))],
    var = "R[t]"
  ) %>%
  ## una com os dados de incidência diária
  left_join(cases, "dates") %>%
  ## calcule o risco através de todas as estimativas de r
  mutate(
    across(
      lower_95_r:upper_95_r,
      ~ .x*I,
      .names = "{str_replace(.col, '_r', '_risk')}"
    )
  ) %>%
  ## separe as estimativas de r e as estimativas de risco
  pivot_longer(
    contains("median"),
    names_to = c(".value", "variable"),
    names_pattern = "(.+)_(.+)"
  ) %>%
  ## atribua os níveis do fator
  mutate(variable = factor(variable, c("risk", "r")))

## crie um data frame longo a partir dos quantis
df_long <- df_wide %>%
  select(-variable, -median) %>%
  ## separe o r/estimativas de risco e níveis de quantis
  pivot_longer(
    contains(c("lower", "upper")),
    names_to = c(".value", "quantile", "variable"),
    names_pattern = "(.+)_(.+)_(.+)"
  ) %>%
  mutate(variable = factor(variable, c("risk", "r")))

## crie o gráfico
ggplot() +
  geom_ribbon(
    data = df_long,
    aes(x = dates, ymin = lower, ymax = upper, alpha = quantile),
    color = NA
  ) +
  geom_line(
    data = df_wide,
    aes(x = dates, y = median),
    alpha = 0.2
  ) +
  ## use label_parsed para permitir rótulos subescritos
  facet_wrap(
    ~ variable,
    ncol = 1,
    scales = "free_y",
    labeller = as_labeller(c(r = "R[t]", risk = "Transmission~potential"), label_parsed),
    strip.position = 'left'
  ) +
  ## defina manualmente a transparência do quantil
  scale_alpha_manual(
    values = c(`50` = 0.7, `90` = 0.4, `95` = 0.2),
    labels = function(x) paste0(x, "%")
  ) +
  labs(
    x = NULL,
    y = NULL,
    alpha = "Credible\ninterval"
  ) +
  scale_x_date(
    date_breaks = "1 month",
    date_labels = "%b %d\n%Y"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    strip.background = element_blank(),
    strip.placement = 'outside'
  )
  
```

<!-- ======================================================= -->
## Projeções da incidência {  }

### EpiNow2 {.unnumbered}

Além de estimar o R<sub>t</sub>, **EpiNow2** também é capaz de prever o
R<sub>t</sub> e projetar o número de casos ao ser integrado com o
pacote **EpiSoon**. Tudo o que você precisa fazer é especificar o argumento `horizon`
ao usar a função `epinow`, indicando quantos dias você quer
projetar no futuro; veja a seção do **EpiNow2** em "Estimando o
R<sub>t</sub>" para detalhes sobre como configurar e executar o **EpiNow2**. Nesta seção,
nós iremos apenas fazer o gráfico dos resultados desta análise, salvos no
objeto `epinow_res`.

```{r epidemic_models_episoon, out.width=c('100%', '100%'), fig.show='hold', fig.width = 12, fig.height = 9, message=F, warning=F}

## defina a data mínima do gráfico
min_date <- as.Date("2015-03-01")

## extraia as estimativas resumidas
estimates <-  as_tibble(epinow_res$estimates$summarised)

## extraia os dados brutos da incidência de casos
observations <- as_tibble(epinow_res$estimates$observations) %>%
  filter(date > min_date)

## extraia as estimativas previstas do número de caso
df_wide <- estimates %>%
  filter(
    variable == "reported_cases",
    type == "forecast",
    date > min_date
  )

## converta para o formato longo para criar o gráfico de quantil
df_long <- df_wide %>%
  ## aqui combinamos os quantis correspondentes (ex.: lower_90 to upper_90)
  pivot_longer(
    lower_90:upper_90,
    names_to = c(".value", "quantile"),
    names_pattern = "(.+)_(.+)"
  )

## crie o gráfico
ggplot() +
  geom_histogram(
    data = observations,
    aes(x = date, y = confirm),
    stat = 'identity',
    binwidth = 1
  ) +
  geom_ribbon(
    data = df_long,
    aes(x = date, ymin = lower, ymax = upper, alpha = quantile),
    color = NA
  ) +
  geom_line(
    data = df_wide,
    aes(x = date, y = median)
  ) +
  geom_vline(xintercept = min(df_long$date), linetype = 2) +
  ## defina manualmente a transparência do quantil
  scale_alpha_manual(
    values = c(`20` = 0.7, `50` = 0.4, `90` = 0.2),
    labels = function(x) paste0(x, "%")
  ) +
  labs(
    x = NULL,
    y = "Casos notificados diariamente",
    alpha = "Credible\ninterval"
  ) +
  scale_x_date(
    date_breaks = "1 month",
    date_labels = "%b %d\n%Y"
  ) +
  theme_minimal(base_size = 14)

```

### Pacote projections {.unnumbered}

O pacote **projections**, desenvolvido pela RECON, torna bem fácil o ato de
prever incidências no curto prazo, requerindo apenas conhecimento do número efetivo de 
reprodução R<sub>t</sub>, e o intervalo seriado. Aqui, nós iremos abordar como usar
estimativas seriadas de intervalo da literatura e como usar nossas próprias estimativas
baseadas na linelist.

#### Utilizando estimativas de intervalo seriado da literatura {.unnumbered}

O pacote **projections** precise de uma distribuição seriada discreta de intervalos da classe
`distcrete`, do pacote **distcrete**. Nós iremos utilizar uma distribuição gamma
com uma média de 12.0 e desvio padrão de 5.2 definido neste
[artigo](https://bmcmedicine.biomedcentral.com/articles/10.1186/s12916-014-0196-0). Para
converter estes valores para os parâmetros de formato e escala requiridos para a distribuição
gamma, iremos utilizar a função `gamma_mucv2shapescale` do pacote
**epitrix**.

```{r epidemic_models_projections_distcrete,}

## obtenha os parâmetros de formato e escala da média mu e o coeficiente de
## variação (ex.: a razão do desvio padrão para a média)
shapescale <- epitrix::gamma_mucv2shapescale(mu = 12.0, cv = 5.2/12)

## crie um objeto do tipo *distcrete*
serial_interval_lit <- distcrete::distcrete(
  name = "gamma",
  interval = 1,
  shape = shapescale$shape,
  scale = shapescale$scale
)

```

Aqui está uma checagem rápida para garantir que o intervalo seriado está correto. Nós
acessamos a densidade da distribuição gamma que acabamos de definir com `$d`, que
é equivalente a chamar `dgamma`:

```{r epidemic_models_projections_distcrete_plot,}

## cheque para garantir que o intervalo seriado está correto
qplot(
  x = 0:50, y = serial_interval_lit$d(0:50), geom = "area",
  xlab = "Intervalo seriado", ylab = "Densidade"
)

```

#### Utilizando estivamitvas de intervalo seriadas a partir dos dados {.unnumbered}

Como temos dados com as datas de início dos sintomas _e_ links de transmissão, nós podemos
também estimar o intervalo seriado a partir da linelist ao calcular o intervalo
entre as datas de início dos sintomas dos pares infectante-infectado. Como fizemos na seção do **EpiNow2**,
nós iremos utilizar a função `get_pairwise` do pacote **epicontacts**, que nos permite calcular diferenças em pares das propriedades
da linelist nos pares de transmissão. Primeiro, criamos um objeto epicontact
(veja a página [Cadeias de transmissão](#transmission-chains) para mais detalhes):

```{r epidemic_models_epicontacts_projections, eval=F}
## crie os contacts
contacts <- linelist %>%
  transmute(
    from = infector,
    to = case_id
  ) %>%
  drop_na()

## crie o objeto epicontacts
epic <- make_epicontacts(
  linelist = linelist,
  contacts = contacts, 
  directed = TRUE
)
```

Então ajustamos a diferença no início de sintomas entre os pares de transmissão, calculando
usando `get_pairwise`, para uma distriuição gamma. Nós usamos a função `fit_disc_gamma`,
do pacote **epitrix**, para realizar este procedimento de ajuste, uma vez que precisamos de
uma distribuição _discreta_.

```{r epidemic_models_incubation_estimate_projections,  warning = FALSE}
## estime o intervalo seriado gamma
serial_interval <- fit_disc_gamma(get_pairwise(epic, "date_onset"))

## inspecione a estimativa
serial_interval[c("mu", "sd")]
```

#### Projeções da incidência {.unnumbered}

Para prever a incidência futura, nós ainda precisamos fornecer a incidência histórica na
forma de um objeto `incidence`, assim como uma amostra de valores plausíveis de
R<sub>t</sub>. Nós iremos gerar estes valores utilizando as estimativas de R<sub>t</sub>
geradas pelo **EpiEstim** na seção anterior (na subseção "Estimando
R<sub>t</sub>") e salvo no objeto `epiestim_res_emp`. No código abaixo, 
nós extraímos a média e as estimativas de desvio padrão do R<sub>t</sub> para a
última janela de tempo do surto (usando a função `tail` para acessar o último
elemento em um vetor), e simulamos 1000 valores de uma distribuição gamma utilizando
`rgamma`. Você também pode fornecer seu própria vetor de valores R<sub>t</sub> que você
quer usar para projeções futuras.

```{r epidemic_models_projection_setup,  warning = FALSE}

## crie um objeto incidence a partir das datas de início dos sintomas
inc <- incidence::incidence(linelist$date_onset)

## extraia valores plausíveis de r para maior parte das estimativas recentes
mean_r <- tail(epiestim_res_emp$R$`Mean(R)`, 1)
sd_r <- tail(epiestim_res_emp$R$`Std(R)`, 1)
shapescale <- gamma_mucv2shapescale(mu = mean_r, cv = sd_r/mean_r)
plausible_r <- rgamma(1000, shape = shapescale$shape, scale = shapescale$scale)

## cheque a distribuição
qplot(x = plausible_r, geom = "histogram", xlab = expression(R[t]), ylab = "Contagens")

```

Nós então usamos a função `project()` para criar a previsão atual.  Nós especificamos quantos
dias queremos prever através dos argumentos `n_days`, e especificamos o
número de simulações usando o argumento `n_sim`.

```{r epidemic_models_make_projection,}

## crie a projeção
proj <- project(
  x = inc,
  R = plausible_r,
  si = serial_interval$distribution,
  n_days = 21,
  n_sim = 1000
)

```

Nós podemos, então, criar um gráfico da incidência e projeções usando as funções `plot()` e
`add_projections()`. Nós podemos facilmente criar subconjuntos do objeto `incidence` para apenas
mostrar os casos mais recentes ao utilizar o operador de colchetes retos.

```{r epidemic_models_plot_projection, out.width=c('100%', '100%'), fig.show='hold', fig.width = 12, fig.height = 9, message=F, warning=F}

## crie um gráfico da incidência e projeções
plot(inc[inc$dates > as.Date("2015-03-01")]) %>%
  add_projections(proj)

```

Você pode também facilmente extrair as novas estimativas brutas do número diário de casos ao
converter o resultado da análise para um quadro de dados.

```{r epidemic_models_projection_df, eval=F, warning = FALSE}
## converta para um quadro de dados os dados brutos
proj_df <- as.data.frame(proj)
proj_df
```

```{r epidemic_models_projection_dt,  echo = F}

## converta para um quadro de dados os dados brutos
proj_df <- as.data.frame(proj)

## resultado da tabela de dados
DT::datatable(
  proj_df[1:11],
  rownames = FALSE,
  filter = "top",
  options = list(pageLength = 10, scrollX=T), class = 'white-space: nowrap'
)

```


<!-- ======================================================= -->
## Recursos extras {  }

* [Aqui está o artigo](https://www.sciencedirect.com/science/article/pii/S1755436519300350) descrevendo
  a metodologia empregada no **EpiEstim**.
* [Aqui está o artigo](https://wellcomeopenresearch.org/articles/5-112/v1) descrevendo
  a metodologia implementada no **EpiNow2**.
* [Aqui está um artigo](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008409) descrevendo
  diferentes considerações dos metodológicas e práticas para estimar o R<sub>t</sub>.
```{r include=FALSE, cache=FALSE}

# clear workspace
rm(list = ls(all = TRUE))

# clear all packages except base
#lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))

# to ensure that tidyverse packages prevail
filter <- dplyr::filter
select <- dplyr::select
summarise <- dplyr::summarise
summary <- base::summary
incidence <- incidence2::incidence

#load core packages
pacman::p_load(
     rio,
     here,
     DT,
     stringr,
     lubridate,
     tidyverse
)

# import the cleaned ebola linelist
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

# import the count data - facility level
#count_data <- rio::import(here::here("data", "facility_count_data.rds"))

# Settings

options(scipen=1, digits=7)

# print only text (not code)
# library(knitr)
# opts_chunk$set(list(echo = FALSE, eval = FALSE))
```

<!--chapter:end:new_pages/epidemic_models.Rmd-->


# Rastreamento de contatos {#contact-tracing}

Esta página demonstra uma análise descritiva dos dados de rastreio de contatos, acrescentando algumas considerações-chave e abordagens únicas a este tipo de dados.

Esta página faz referência a muitas das competências centrais de gestão e visualização de dados em R, cobertas em outras páginas (por exemplo, limpeza de dados, pivoteamento, tabelas, análises de séries temporais). Contudo, destacaremos exemplos específicos de rastreio de contatos que têm sido úteis para a tomada de decisões operacionais. Por exemplo, está inclusa a visualização de dados de seguimento de rastreio de contatos ao longo do tempo ou através de áreas geográficas, ou a produção de tabelas de Indicadores de Desempenho Chave (KPI, do inglês *Key Performance Indicator*) limpas para supervisores de rastreio de contatos.

Para fins de demonstração, utilizaremos amostras de dados de rastreio de contatos da plataforma [Go.Data](https://www.who.int/tools/godata). Os princípios aqui abordados serão aplicados aos dados de rastreio de contatos de outras plataformas - você poderá apenas precisar passar por diferentes etapas de pré-processamento de dados, dependendo da estrutura da base.

Leia mais sobre o projeto Go.Data no site [Github Documentation site](https://worldhealthorganization.github.io/godata/) ou [Community of Practice](https://community-godata.who.int/).

## Preparação

### Carregar pacotes {.unnumbered}

Esta chunck mostra o carregamento dos pacotes necessários para as análises. Neste manual damos ênfase a função `p_load()` do **pacman**,
que instala o pacote se necessário *e* carrega-o para utilização. Também se pode carregar pacotes instalados com `library()` a partir do **R base**. Veja a página [Introdução ao R](#basics) para mais informações sobre pacotes R.

```{r, message = F}
pacman::p_load(
  rio,          # importar dados  
  here,         # caminhos relativos de arquivos 
  janitor,      # limpeza dos dados e tabelas
  lubridate,    # trabalhar com datas
  epikit,       # função age_categories()
  apyramid,     # piramides etárias
  tidyverse,    # manipulação e visualização de dados
  RColorBrewer, # paletas de cores
  formattable,  # formatação de tabelas
  kableExtra    # formatação de tabelas
)
```

### Importação de dados {.unnumbered}

Importaremos amostras de conjuntos de dados de contatos e de seus "acompanhamentos". Estes dados foram recuperados e separados da API Go.Data e armazenados como arquivos ".rds".

Você pode fazer o download de todos os dados de exemplo para este manual a partir da página [Download do manual e dados](#data-used).

Se desejar fazer o download do exemplo de dados de rastreio de contatos específicos para esta página, utilize os três links de download abaixo:

<a href='https://github.com/WorldHealthOrganization/godata/blob/master/analytics/r-reporting/data/cases_clean.rds?raw=true' class='download-button'>
Clique para fazer o download dos dados da investigação do caso (arquivo
.rds) </a>

<a href='https://github.com/WorldHealthOrganization/godata/blob/master/analytics/r-reporting/data/contacts_clean.rds?raw=true' class='download-button'>
Clique para fazer o download dos dados de registo de contato (arquivo
.rds) </a>

<a href='https://github.com/WorldHealthOrganization/godata/blob/master/analytics/r-reporting/data/followups_clean.rds?raw=true' class='download-button'>
Clique para fazer o download dos dados de acompanhamento dos contatos
(arquivo .rds) </a>

<!-- ```{r out.width = "100%", fig.align = "center", echo=F} -->

<!-- knitr::include_graphics(here::here("images", "godata_api_github.png")) -->

<!-- ``` -->

Na sua forma original nos arquivos passíveis de download, os dados são exibidos como fornecidos pela API do Go.Data (saiba mais sobre [APIs aqui](#import_api)). Para fins de exemplo, aqui vamos limpar os dados para facilitar a leitura nesta página. Se estiver usando uma extensão Go.Data, pode ver instruções completas sobre como recuperar os seus dados [aqui](https://github.com/WorldHealthOrganization/godata/tree/master/analytics/r-reporting).

Abaixo, os conjuntos de dados são importados utilizando a função `import()` do pacote **rio**. Veja a página [Importar e exportar](#importing) para várias formas de importação de dados. Utilizamos `here()` para especificar o caminho do arquivo - forneça o caminho específico do arquivo para o seu computador. Em seguida, utilizamos `select()` para selecionar apenas certas colunas dos dados, simplificando para efeitos de demonstração.

#### Dados do caso {.unnumbered}

Estes dados são uma tabela com informações sobre os casos.

```{r}
cases <- import(here("data", "godata", "cases_clean.rds")) %>% 
  select(case_id, firstName, lastName, gender, age, age_class,
         occupation, classification, was_contact, hospitalization_typeid)
```

Aqui estão os casos `nrow(cases)`:

```{r, message=FALSE, echo=F}
DT::datatable(cases, rownames = FALSE, options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```

#### Dados de contatos {.unnumbered}

Estes dados são uma tabela de todos os contatos e suas informações. Mais uma vez, forneça o seu próprio caminho para o arquivo. Após a importação, realizamos alguns passos preliminares de limpeza de dados, incluindo:

-   Definir a age_class (faixa-etária) como fator e inverter a ordem desses níveis, de modo que as idades menores sejam as primeiras a aparecer;
-   Selecionar apenas algumas colunas específicas, ao mesmo tempo que se
    renomeia uma delas;
-   Atribuir artificialmente às linhas cuja coluna `admin_2_name` estiver o nome "Djembe", melhorando a clareza da visualização de alguns exemplos;

```{r}
contacts <- import(here("data", "godata", "contacts_clean.rds")) %>% 
  mutate(age_class = forcats::fct_rev(age_class)) %>% 
  select(contact_id, contact_status, firstName, lastName, gender, age,
         age_class, occupation, date_of_reporting, date_of_data_entry,
         date_of_last_exposure = date_of_last_contact,
         date_of_followup_start, date_of_followup_end, risk_level, was_case, admin_2_name) %>% 
  mutate(admin_2_name = replace_na(admin_2_name, "Djembe"))
```

Aqui estão as linhas `nrow(contacts)` da base de dados `contacts`:

```{r, message=FALSE, echo=F}
DT::datatable(contacts, rownames = FALSE, options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```

#### Dados de acompanhamento {.unnumbered}

Esses dados são registros das interações de "acompanhamento" (follow-up) com os contatos. Espera-se que cada contato tenha um encontro de onitoramento a cada dia durante 14 dias após sua exposição.

Importamos a base e executamos algumas etapas de limpeza. Selecionamos certas colunas e também convertemos uma coluna de caracteres em todos os valores em minúsculas.

```{r}
followups <- rio::import(here::here("data", "godata", "followups_clean.rds")) %>% 
  select(contact_id, followup_status, followup_number,
         date_of_followup, admin_2_name, admin_1_name) %>% 
  mutate(followup_status = str_to_lower(followup_status))
```

Aqui estão as primeiras 50 linhas do conjunto de dados da fila de acompanhamento (`nrow(followups)`). Cada linha é uma interação de acompanhamento, com o status do resultado na coluna `followup_status`:

```{r, message=FALSE, echo=F}
DT::datatable(head(followups, 50), rownames = FALSE, options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```

#### Dados de relação {.unnumbered}

Aqui importamos os dados mostrando a relação entre os casos e contatos. Selecionamos certas colunas para demonstrar.

```{r}
relationships <- rio::import(here::here("data", "godata", "relationships_clean.rds")) %>% 
  select(source_visualid, source_gender, source_age, date_of_last_contact,
         date_of_data_entry, target_visualid, target_gender,
         target_age, exposure_type)
```

Abaixo estão as primeiras 50 linhas da base de dados `relationships`, que contém todas as relações entre casos e contatos.

```{r, message=FALSE, echo=F}
DT::datatable(head(relationships, 50), rownames = FALSE, options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```

## Análises descritivas

Você pode utilizar as técnicas abordadas em outras páginas deste manual para realizar análises descritivas dos seus casos, contatos e respectivas relações. Abaixo estão alguns exemplos.

### Demográficos {.unnumbered}

Como demonstrado neste manual [Pirâmides demográficas](#age-pyramid), é possível visualizar a idade e a distribuição por sexo (aqui utilizamos o pacote **apyramid**).

#### Idade e Gênero dos contatos {.unnumbered}

A pirâmide abaixo compara a distribuição etária dos contatos, por sexo. Note que contatos com idades faltosas (*missing*) estão inclusos em uma
barra no topo. Você pode alterar este comportamento padrão, mas depois considere listar os valores ausentes ("missing") em uma legenda.

```{r, warning=F, message=F}
apyramid::age_pyramid(
  data = contacts,                                   # usar base de dados de contatos
  age_group = "age_class",                           # coluna de faixa-etária
  split_by = "gender") +                             # lados da pirâmide divididos por gênero
  labs(
    fill = "Gender",                                 # título da legenda
    title = "Age/Sex Pyramid of COVID-19 contacts")+ # título da figura
  theme_minimal()                                    # plano de fundo simples
```

Com a estrutura de dados Go.Data, o conjunto de dados `relationships` contém as idades de ambos os casos e contatos, para que você pudesse
utilizar esse conjunto de dados e criar uma pirâmide de idades mostrando as diferenças entre esses dois grupos de pessoas. A base `relationships` será alterada para transformar as colunas numéricas de idade em categorias, ou seja, faixas-etárias (veja a página [Dados de limpeza e principais funções](#cleaning)). Também pivotamos a base de dados de forma mais longa, para facilitar a criaçãodo gráfico com **ggplot2** (ver [Pivotando dados](#pivoting)).

```{r}
relation_age <- relationships %>% 
  select(source_age, target_age) %>% 
  transmute(                              # transmute é como a função mutate(), mas remove todas as outras colunas não mencionadas
    source_age_class = epikit::age_categories(source_age, breakers = seq(0, 80, 5)),
    target_age_class = epikit::age_categories(target_age, breakers = seq(0, 80, 5)),
    ) %>% 
  pivot_longer(cols = contains("class"), names_to = "category", values_to = "age_class")# pivotação longa


relation_age
```

Agora podemos traçar este conjunto de dados transformados com a função `age_pyramid()` como antes, mas substituindo `gênder` por `category`
(Caso, ou Contato).

```{r, warning=F, message=F}
apyramid::age_pyramid(
  data = relation_age,                               # usar a base de dados modificada `reltionship`
  age_group = "age_class",                           # coluna categórica de idade
  split_by = "category") +                           # dividir por casos e contatos
  scale_fill_manual(
    values = c("orange", "purple"),                  # para especificar cores E nomes
    labels = c("Caso", "Contato"))+
  labs(
    fill = "Legend",                                           # título da legenda
    title = "Pirâmide Idade/Sexo de casos e contatos de COVID-19")+ # título da figura
  theme_minimal()                                              # plano de fundo simples
```

Também podemos ver outras características, como a discriminação por ocupação (ex. em forma de gráfico de setores).

```{r, warning=F, message=F}
# Limpar a base de dados e contar as ocupações
occ_plot_data <- cases %>% 
  mutate(occupation = forcats::fct_explicit_na(occupation),  # fazer valores NA e vazios uma categoria
         occupation = forcats::fct_infreq(occupation)) %>%   # ordenar em níveis, em ordem de frequência
  count(occupation)                                          # contagens por ocupação
  
# fazer gráfico de setores
ggplot(data = occ_plot_data, mapping = aes(x = "", y = n, fill = occupation))+
  geom_bar(width = 1, stat = "identity") +
  coord_polar("y", start = 0) +
  labs(
    fill = "Ocupação",
    title = "Ocupações conhecidadas de casos de COVID-19")+
  theme_minimal() +                    
  theme(axis.line = element_blank(),
        axis.title = element_blank(),
        axis.text = element_blank())
```

### Contatos por caso {.unnumbered}

O número de contatos por caso pode ser uma métrica importante para avaliar qualidade da contagem de contatos e a conformidade da população para uma resposta de saúde pública.

Dependendo de sua estrutura de dados, isto pode ser avaliado com um conjunto de dados que contém todos os casos e contatos. Nos conjuntos de
dados Go.Data, os links entre os casos ("fontes") e os contatos ("alvos") é armazenado no conjunto de dados `relationships`.

Neste conjunto de dados, cada linha é um contato, e o caso da fonte é listado em uma linha. Não há contatos que tenham relações com múltiplos
casos, mas se isso existir, você pode precisar computá-los antes de criar o gráfico.

Começamos contando o número de linhas (contatos) por caso de origem. Isto é salvo como um *data frame*.

```{r}
contacts_per_case <- relationships %>% 
  count(source_visualid)

contacts_per_case
```

Podemos usar `geom_histogram()` para fazer um histograma a partir desses dados.

```{r, warning=F, message=F}
ggplot(data = contacts_per_case)+        # começar com a contagem da base de dados criada anteriormente
  geom_histogram(mapping = aes(x = n))+  # criar o histograma do número de contatos por caso
  scale_y_continuous(expand = c(0,0))+   # remover o espaço em excesso abaixo de 0 no eixo y
  theme_light()+                         # simplificar o plano de fundo
  labs(
    title = "Número de contatos por caso",
    y = "Casus",
    x = "Contatos por caso"
  )
  

```

## Acompanhamento de contato

Os dados de rastreamento de contatos geralmente contêm dados de "acompanhamento", que registram resultados das verificações diárias dos sintomas das pessoas em quarentena. Análises destes dados podem informar a estratégia de resposta, identificar contatos em risco de perda no acompanhamento ou risco de desenvolver doenças.

### Limpeza do dados {.unnumbered}

Estes dados podem existir em uma variedade de formatos, como um formato Excel "largo/amplo", com uma linha por contato e uma coluna por dia de acompanhamento. Veja [Pivoteando dados](#pivoting) para descrições de dados "longos" e "largos", e como pivotar dados mais amplos/largos ou mais longos.

Em nosso exemplo com Go.Data, estes dados são armazenados nos dados de acompanhamento (`followups`), em um formato "longo", com uma linha por acompanhamento interação. As primeiras 50 filas são dessa forma:

```{r, message=FALSE, echo=FALSE}
# exibir, como tabela, as primeiras 50 linhas da lista de contatos
DT::datatable(head(followups, 50), rownames = FALSE, options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```

[**CUIDADO:** Cuidado com as duplicatas ao lidar com dados de acompanhamento; podem haver vários seguimentos errôneos no mesmo dia para um determinado contato. Talvez pareça um erro, mas reflete a realidade - por exemplo, um investigador poderia submeter um formulário de acompanhamento no início do dia, quando não foi possível contactar o indivíduo e, mais tarde, submeter um segundo formulário quando conseguir contato. Dependerá do contexto operacional a forma como você quer lida com duplicatas - apenas certifique-se de documentar sua abordagem claramente.]{style="color: orange;"}

Vamos *ver* quantas linhas "duplicadas" nós temos:

```{r}
followups %>% 
  count(contact_id, date_of_followup) %>%   # obter valores únicos para dias de contato (contact_days)
  filter(n > 1)                             # ver registros onde a contagem é maior que 1
```

Em nossos dados de exemplo, os únicos registros aos quais isto se aplica são os que faltam um ID! Podemos removê-los. Mas, para fins de demonstração vamos mostrar os passos para remoção de duplicidades, de forma que haja apenas um acompanhamento por pessoa por dia. Para mais detalhes, veja a página [Eliminando duplicidades](#deduplication). Vamos supor que o registro mais recente é o correto. Também aproveitamos a oportunidade para limpar a coluna `followup_number` (o "dia" de acompanhamento que deve variar de 1 - 14).

```{r, warning=F, message=F}
followups_clean <- followups %>%
  
  # Remover duplicidades
  group_by(contact_id, date_of_followup) %>%        # agrupar linhas por dia de contato (contact-day)
  arrange(contact_id, desc(date_of_followup)) %>%   # organizar linhas por dia de contato, data de acompanhamento (date of follow-up), trazendo o mais recente para o topo
  slice_head() %>%                                  # manter apenas a primeira linha por valor único de ID do contato (contact id)
  ungroup() %>% 
  
  # Outras limpezas
  mutate(followup_number = replace(followup_number, followup_number > 14, NA)) %>% # limpar dados errados
  drop_na(contact_id)                               # remover linhas com valor em branco para contact_id
```

Para cada encontro de acompanhamento, temos um status de acompanhamento (por exemplo se o encontro ocorreu e se o contato teve sintomas ou não).
Para ver todos os valores, podemos executar um rápido `tabyl()` (do **janitor**) ou `table()` (do **R Base**) (ver [Tabelas descritivas](#tables-descriptive)) por 'followup_status' para ver a frequência de cada um dos resultados.

Neste conjunto de dados, "seen_not_ok" significa "visto com sintomas" e "seen_ok" significa "visto sem sintomas"

```{r}
followups_clean %>% 
  tabyl(followup_status)
```

### Gráfico ao longo do tempo {.unnumbered}

Como os dados das datas são contínuos, usaremos um histograma para representá-los com a data de acompanhamento (`date_of_followup`) atribuída ao eixo x. Podemos produzir um histograma "empilhado", especificando um argumento `fill =` dentro de `aes()`, que atribuímos à coluna de status do acompanhamento (`followup_status`).
Consequentemente, você pode definir o título da legenda utilizando o argumento `fill =` do `labs()`.

Podemos ver que os contatos foram identificados em ondas (presumivelmente correspondente às ondas epidêmicas de casos), e que a conclusão do acompanhamento não parece ter melhorado ao longo do curso da epidemia.

```{r, warning=F, message=F}
ggplot(data = followups_clean)+
  geom_histogram(mapping = aes(x = date_of_followup, fill = followup_status)) +
  scale_fill_discrete(drop = FALSE)+   # exibir todos os níveis de fatores (followup_status) na legenda, mesmo os não utilizados
  theme_classic() +
  labs(
    x = "",
    y = "Número de contatos",
    title = "Status de acompanhamento de contato diário",
    fill = "Status de acompanhamento",
    subtitle = str_glue("Dados de {max(followups$date_of_followup, na.rm=T)}"))   # subtítulo dinâmico subtitle
  
```

[**CUIDADO:** Se você estiver preparando muitos gráficos (por exemplo, para múltiplas jurisdições) é preferível que as legendas apareçam de forma idêntica, mesmo com diferentes níveis de preenchimento ou composição de dados. Podem haver gráficos para os quais nem todos os status de acompanhamento estão presentes nos dados, mas você ainda quer que essas categorias apareçam nas legendas. Em ggplots (como acima), você pode especificar o argumento `drop = FALSE` do `scale_fill_discrete()`. Nas tabelas, utilize `tabyl()` que mostra contagens para todos os níveis de fatores, ou se utilizando`count()` do **dplyr** adicione o argumento `.drop = FALSE` para incluir contagens para todos os níveis de fatores.]{style="color: orange;"}

### Rastreamento individual diário {.unnumbered}

Se seu surto for pequeno o suficiente, pode ser interessante olhar para cada contato individualmente e ver seu status ao longo de seu acompanhamento. Felizmente, este conjunto de dados `followups` já contém uma coluna com o "número" do dia de acompanhamento (de 1 a 14). Se isto não existir em seus dados, você poderia criá-lo calculando a diferença entre a data do contato e a data que o acompanhamento foi planejado para começar.

Um mecanismo de visualização conveniente (se o número de casos não for muito grande) pode ser um gráfico de calor, feito com `geom_tile()`.
Veja mais detalhes na página [Gráfico de calor](#heatmaps).

```{r, warning=F, message=F}
ggplot(data = followups_clean)+
  geom_tile(mapping = aes(x = followup_number, y = contact_id, fill = followup_status),
            color = "grey")+       # linhas de grade na cor cinza
  scale_fill_manual( values = c("yellow", "grey", "orange", "darkred", "darkgreen"))+
  theme_minimal()+
  scale_x_continuous(breaks = seq(from = 1, to = 14, by = 1))
```

### Análises por grupo {.unnumbered}

Talvez esses dados de acompanhamento estejam sendo vistos diariamente ou semanalmente para a tomada de decisões operacionais. Você pode considerar mais significativo a desagregação por área geográfica ou por equipe de rastreamento de contatos. Podemos fazer isso ajustando as colunas fornecidas no `group_by()`.

```{r, warning=F, message=F}

plot_by_region <- followups_clean %>%        # começar com a base de dados de acompanhamento
  count(admin_1_name, admin_2_name, followup_status) %>% # contagem por valores únicos no "region-status" (cria coluna 'n' com a contagem )
  
  # iniciar o ggplot()
  ggplot(                                         # iniciar o ggplot
    mapping = aes(x = reorder(admin_2_name, n),   # reordenar os níveis dos fatores de administração pelos valores numéricos na coluna 'n'
                  y = n,                            # altura das barras segundo coluna 'n'
                  fill = followup_status,           # cor da barra empilhada segundo seu status
                  label = n))+                      # transição para o geom_label()              
  geom_col()+                              # barras empilhadas, vindo do mapeamento anterior
  geom_text(                               # adicionar texto, vindo do mapeamento anterior
    size = 3,                                         
    position = position_stack(vjust = 0.5), 
    color = "white",           
    check_overlap = TRUE,
    fontface = "bold")+
  coord_flip()+
  labs(
    x = "",
    y = "Número de contatos",
    title = "Status do acompanhamento do contato, por Região",
    fill = "Status do acompanhamento",
    subtitle = str_glue("Dados de {max(followups_clean$date_of_followup, na.rm=T)}")) +
  theme_classic()+                                               # Plano de fundo simplificado
  facet_wrap(~admin_1_name, strip.position = "right", scales = "free_y", ncol = 1) # introduzir facetas 

plot_by_region
```

<!-- Se isso fosse desagregado pelo marcador de contatos, talvez quiséssemos adicionar uma linha limite para exibir o total de contatos # que normalmente uma pessoa ou área/equipe pode lidar, e como a carga de trabalho atual se compara. Fazemos isso apenas usando a função `geom_hline()`. -->

<!-- ```{r, warning=F, message=F} -->

<!-- plot_by_region +  -->

<!--      geom_hline(aes(yintercept=25), color="#C70039", linetype = "dashed") # limiar fictício em 25 contatos -->

<!-- ``` -->

## Tabelas KPI

Há uma série de diferentes indicadores-Chave de Desempenho (KPIs, de *Key Performance Indicators* em inglês) que podem ser calculados e rastreados em diferentes níveis de desagregação e ao longo de diferentes períodos de tempo para monitorar o desempenho do rastreamento de contatos. Uma vez que você tenha os cálculos e o formato básico da tabela; é bastante fácil trocar por diferentes KPIs.

Existem várias fontes de rastreamento de contatos KPIs, tais como este (de [ResolveToSaveLives.org](https://contacttracingplaybook.resolvetosavelives.org/checklists/metrics)).A maior parte do trabalho será caminhar através de sua estrutura de dados e pensar em todos os critérios de inclusão/exclusão. Mostramos alguns exemplos abaixo; usando a estrutura de metadados Go.Data:

+-------------+-------------------+--------------------+--------------+
| Categoria   | Indicador         | Numerador Go.Data  | Denominador  |
|             |                   |                    | Go.Data      |
+=============+===================+====================+==============+
| Indicador   | \% casos          | COUNT OF `case_id` | COUNT OF     |
| de processo | entrevistados e   | WHERE              | `case_id`    |
| (Velocidade | isolados em até   | (`                 |              |
| de rastreio | 24h da informação | date_of_reporting` |              |
| do contato) |                   | -                  |              |
|             |                   | `da                |              |
|             |                   | te_of_data_entry`) |              |
|             |                   | \< 1 dia E         |              |
|             |                   | (`is               |              |
|             |                   | olation_startdate` |              |
|             |                   | -                  |              |
|             |                   | `da                |              |
|             |                   | te_of_data_entry`) |              |
|             |                   | \< 1 day           |              |
+-------------+-------------------+--------------------+--------------+
| Indicador   | \% de contatos    | COUNT OF           |  COUNT OF    |
| de processo | notificados e em  | `contact_id` WHERE | `contact_id` |
| -           | quarentena em até | `followup_status`  |              |
| velocidade  | 24h da exposição  | == "SEEN_NOT_OK"   |              |
| de rastreio |                   | OR "SEEN_OK" AND   |              |
| do contato  |                   | `date_of_followup` |              |
|             |                   | -                  |              |
|             |                   | `                  |              |
|             |                   | date_of_reporting` |              |
|             |                   | \< 1 day           |              |
+-------------+-------------------+--------------------+--------------+
| Indicador   | \% de novos casos | COUNT OF `case_id` | COUNT OF     |
| de processo | sintomaticos      | WHERE              | `case_id`    |
| -           | testados e        | (`                 |              |
| Completude  | entrevistados em  | date_of_reporting` |              |
| da testagem | até 3 dias do     | - `date_of_onset`) |              |
|             | início de         | \< =3 days         |              |
|             | sintomas          |                    |              |
+-------------+-------------------+--------------------+--------------+
| Indicador   | \% novos casos    | COUNT OF `case_id` | COUNT OF     |
| de          | entre lista de    | WHERE              | `case_id`    |
| resultados  | contatos          | `was_contact` ==   |              |
| - Geral     | existente         | "TRUE"             |              |
+-------------+-------------------+--------------------+--------------+

Abaixo, iremos passar por um exercício de exemplo de criação de uma tabela que mostra o acompanhamento dos contatos ao longo de áreas administrativas. No final, tornaremos essa tabela apresentável com o pacote **formattable** (mas você poderia usar outros pacotes, como **flextable** - veja [Tabelas para apresentação](#tables-presentation)).

A criação de tabelas como esta, dependerá da sua estrutura de dados de rastreamento de contatos. Visite a página [Tabelas descritivas](#tables-descriptive) para aprender como resumir os dados usando as funções do **dplyr**.

Criaremos uma tabela que será dinâmica e mudará de acordo com a mudança dos dados. Para tornar os resultados interessantes, estabeleceremos uma data de relato (`report_date`), que nos permite simular o funcionamento da tabela em um determinado dia (escolhemos 10 de Junho de 2020). Os dados são filtrados até essa data.

```{r, warning=F, message=F}
# Criar a "Report date" para simular simular a execução do relatório com dados "a partir" desta data
report_date <- as.Date("2020-06-10")

# Criar dados de acompanhamento para refletir a data do relatório
table_data <- followups_clean %>% 
  filter(date_of_followup <= report_date)
```

Agora, com base em nossa estrutura de dados, faremos o seguinte:

1)  Comece com os `followups` e use o *summarise* para que contenha, em cada contato único:

- A data do último registro (não importa o status do encontro)
- A data do último encontro em que o contato foi "visto"
- O status do encontro naquela última vez em que o contato foi "visto" (por exemplo, com sintomas ou sem sintomas)

2)  Junte estes dados aos dados de contato, que contêm outras informações como o status geral de contato, data do último exposição a um caso, etc. Também calcularemos as métricas de interesse para cada contato, tais como dias desde a última exposição 
3)  Agrupamos os dados de contato melhorados por região geográfica (`admin_2_name`) e calculamos estatísticas resumidas por região
5)  Finalmente, formatamos a tabela para apresentação

Primeiro resumimos os dados de acompanhamento para obter as informações de interesse:

```{r, warning=F, message=F}
followup_info <- table_data %>% 
  group_by(contact_id) %>% 
  summarise(
    date_last_record   = max(date_of_followup, na.rm=T),
    date_last_seen     = max(date_of_followup[followup_status %in% c("seen_ok", "seen_not_ok")], na.rm=T),
    status_last_record = followup_status[which(date_of_followup == date_last_record)]) %>% 
  ungroup()
```

Aqui vemos os dados:

```{r, echo=F}
DT::datatable(followup_info, rownames = FALSE, options = list(pageLength = 12, scrollX=T), class = 'white-space: nowrap' )
```

Agora vamos adicionar essas informações à base de dados `contacts` e calcular algumas colunas adicionais

```{r}
contacts_info <- followup_info %>% 
  right_join(contacts, by = "contact_id") %>% 
  mutate(
    database_date       = max(date_last_record, na.rm=T),
    days_since_seen     = database_date - date_last_seen,
    days_since_exposure = database_date - date_of_last_exposure
    )
```

Aqui vemos a aparência dos dados. Observe a coluna `contacts` à direita e a nova coluna calculada na extrema direita.

```{r, echo=F}
DT::datatable(contacts_info, rownames = FALSE, options = list(pageLength = 12, scrollX=T), class = 'white-space: nowrap' )
```

A seguir, resumimos os dados de contato por região, para obter uma base concisa de colunas estatísticas resumidas.

```{r}
contacts_table <- contacts_info %>% 
  
  group_by(`Admin 2` = admin_2_name) %>%
  
  summarise(
    `Registered contacts` = n(),
    `Active contacts`     = sum(contact_status == "UNDER_FOLLOW_UP", na.rm=T),
    `In first week`       = sum(days_since_exposure < 8, na.rm=T),
    `In second week`      = sum(days_since_exposure >= 8 & days_since_exposure < 15, na.rm=T),
    `Became case`         = sum(contact_status == "BECAME_CASE", na.rm=T),
    `Lost to follow up`   = sum(days_since_seen >= 3, na.rm=T),
    `Never seen`          = sum(is.na(date_last_seen)),
    `Followed up - signs` = sum(status_last_record == "Seen_not_ok" & date_last_record == database_date, na.rm=T),
    `Followed up - no signs` = sum(status_last_record == "Seen_ok" & date_last_record == database_date, na.rm=T),
    `Not Followed up`     = sum(
      (status_last_record == "NOT_ATTEMPTED" | status_last_record == "NOT_PERFORMED") &
        date_last_record == database_date, na.rm=T)) %>% 
    
  arrange(desc(`Registered contacts`))

```

```{r, echo=F}
DT::datatable(contacts_table, rownames = FALSE, options = list(pageLength = 12, scrollX=T), class = 'white-space: nowrap' )
```

E agora aplicamos estilos dos pacotes **formattable** e **knitr**, incluindo uma nota de rodapé que mostra a data "a partir de".

```{r}
contacts_table %>%
  mutate(
    `Admin 2` = formatter("span", style = ~ formattable::style(
      color = ifelse(`Admin 2` == NA, "red", "grey"),
      font.weight = "bold",font.style = "italic"))(`Admin 2`),
    `Followed up - signs`= color_tile("white", "orange")(`Followed up - signs`),
    `Followed up - no signs`= color_tile("white", "#A0E2BD")(`Followed up - no signs`),
    `Became case`= color_tile("white", "grey")(`Became case`),
    `Lost to follow up`= color_tile("white", "grey")(`Lost to follow up`), 
    `Never seen`= color_tile("white", "red")(`Never seen`),
    `Active contacts` = color_tile("white", "#81A4CE")(`Active contacts`)
  ) %>%
  kable("html", escape = F, align =c("l","c","c","c","c","c","c","c","c","c","c")) %>%
  kable_styling("hover", full_width = FALSE) %>%
  add_header_above(c(" " = 3, 
                     "Contatos atualmente em acompanhamento" = 5,
                     "Status na última visita" = 3)) %>% 
  kableExtra::footnote(general = str_glue("Data are current to {format(report_date, '%b %d %Y')}"))

```

## Matrizes de transmissão

Como foi discutido na página [Gráficos de calor](#heatmaps), você pode criar uma matriz de "quem infectou quem" utilizando `geom_tile()`.

Quando novos contatos são criados, o Go.Data armazena essa informação de relações no ponto final da API `relationships`; e podemos ver o primeiras 50 filas deste conjunto de dados abaixo. Isto significa que podemos criar um gráfico de calor com relativamente poucas etapas, dado que cada contato já está unido ao seu caso de origem.

```{r, warning=F, message=F, echo=F}
# exibir, como tabela, as 50 primeiras linhas da base de dados `relationships`
DT::datatable(head(relationships, 50), rownames = FALSE, options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```

Como feito anteriormente para a pirâmide etária comparando casos e contatos, podemos selecionar as poucas variáveis necessárias e criar colunas com faixas etárias categóricas, tanto para fontes (casos) quanto para alvos (contatos).

```{r}
heatmap_ages <- relationships %>% 
  select(source_age, target_age) %>% 
  mutate(   # a função transmute é como a função mutate(), mas remove todas as outras colunas
    source_age_class = epikit::age_categories(source_age, breakers = seq(0, 80, 5)),
    target_age_class = epikit::age_categories(target_age, breakers = seq(0, 80, 5))) 
```

Como descrito anteriormente, criamos uma tabulação cruzada;

```{r, warning=F, message=FALSE}

cross_tab <- table(
  source_cases = heatmap_ages$source_age_class,
  target_cases = heatmap_ages$target_age_class)

cross_tab
```

converter em formato longo com proporções;

```{r, warning=FALSE, message=FALSE}

long_prop <- data.frame(prop.table(cross_tab))

```

e criar um gráfico de calor para a idade.

```{r, warning=F, message=F}

ggplot(data = long_prop)+       # usar dados longos, com proporção como Freq
  geom_tile(                    # visualizar quadrantes
    aes(
      x = target_cases,         # eixo X é a idade do Alvo
      y = source_cases,         # eixo Y é a idade da Fonte
      fill = Freq))+            # cor dos quadrantes é de acordo com a coluna Freq da base de dados
  scale_fill_gradient(          # ajustar a cor de enchimento das quadrantes
    low = "blue",
    high = "orange")+
  theme(axis.text.x = element_text(angle = 90))+
  labs(                         # rótulos
    x = "Idade dos casos alvo",
    y = "Idade dos casos fonte",
    title = "Quem infectou quem",
    subtitle = "Matriz de frequências de eventos de transmissão",
    fill = "Porporção de todos\neventos de transmissão"     # título da legenda
  )

```

## Fontes

<https://github.com/WorldHealthOrganization/godata/tree/master/analytics/r-reporting>

<https://worldhealthorganization.github.io/godata/>

<https://community-godata.who.int/>
```{r include=FALSE, cache=FALSE}

# clear workspace
rm(list = ls(all = TRUE))

# clear all packages except base
#lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))

# to ensure that tidyverse packages prevail
filter <- dplyr::filter
select <- dplyr::select
summarise <- dplyr::summarise
summary <- base::summary
incidence <- incidence2::incidence

#load core packages
pacman::p_load(
     rio,
     here,
     DT,
     stringr,
     lubridate,
     tidyverse
)

# import the cleaned ebola linelist
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

# import the count data - facility level
#count_data <- rio::import(here::here("data", "facility_count_data.rds"))

# Settings

options(scipen=1, digits=7)

# print only text (not code)
# library(knitr)
# opts_chunk$set(list(echo = FALSE, eval = FALSE))
```

<!--chapter:end:new_pages/contact_tracing.Rmd-->


# Analises de pesquisa de questionários (*survey*) {#survey-analysis}

<!-- ======================================================= -->

## Visão Geral

Esta página demonstra o uso de vários pacotes para análise de pesquisas de questionários (do tipo *survey*).

A maioria dos pacotes de pesquisa R depende do [pacote **survey**](https://cran.r-project.org/web/packages/survey/index.html) para fazer análises ponderadas.
Utilizaremos **survey** assim como [**srvyr**](https://cran.r-project.org/web/packages/srvyr/index.html)(que funciona como uma roupagem (*wrapper*) 
para o pacote **survey**, isto é, simplificando seu uso e permitindo uma codificação em estilo "tidyverse") e [**gtsummary**](<https://cran.r-project.org/web/packages/gtsummary/index.html>) (que funciona como uma roupagem (*wrapper*) para o pacote **survey**, permitindo a publicação de tabelas prontas).

Embora o pacote original de **survey** não permita uma codificação em estilo "tidyverse", ele tem o benefício adicional de permitir modelos lineares generalizados
ponderados (que serão adicionados a esta página posteriormente). Também demonstraremos usando uma função do pacote [**sitrep**](https://github.com/R4EPI/sitrep),
para criar pesos de amostragem (*n.b* este pacote ainda não está atualmente no CRAN, mas pode ser instalado a partir do github).

A maior parte desta página é baseada no trabalho feito para o projeto ["R4Epis"](https://r4epis.netlify.app/); para obter o código detalhado e modelos R-markdown 
veja a página do github ["R4Epis"](https://github.com/R4EPI/sitrep). Alguns dos códigos **survey** baseados em pacotes são baseados nas primeiras versões do 
[EPIET case studies](https://github.com/EPIET/RapidAssessmentSurveys).

No momento, esta página não aborda os cálculos de tamanho de amostra ou amostragem. Para uma calculadora de tamanho de amostra simples de usar, consulte 
[OpenEpi](https://www.openepi.com/Menu/OE_Menu.htm). A página [Introdução do GIS](#gis) (<https://epirhandbook.com/gis-basics.html>) do manual terá eventualmente uma seção sobre 
amostragem espacial aleatória, e esta página terá eventualmente uma seção sobre estruturas de amostragem, bem como cálculos de tamanho de amostra.

1.  Dados da pesquisa
2.  Tempo de observação
3.  Ponderação
4.  Objetos de projeto de pesquisa
5.  Análise descritiva
6.  Proporções ponderadas
7.  Taxas ponderadas

<!-- ======================================================= -->

## Preparação

### Pacotes {.unnumbered}

Este trecho de código mostra o carregamento dos pacotes necessários para as análises. Neste manual, enfatizamos `p_load()` do **pacman**, que instala o pacote 
se necessário *e* o carrega para utilização. Você também pode carregar pacotes usando `library()` do **R Base**. Veja a página [Introdução ao R](#basics) para mais informações
sobre os pacotes R.
Aqui também demonstramos utilizando a função `p_load_gh()` de **pacman** para instalar e carregar pacote do github que ainda não foi publicado no
CRAN.

```{r}

## carregar pacotes do CRAN
pacman::p_load(rio,          # Importar arquivo
               here,         # Local do arquivo
               tidyverse,    # manipulação de dados + gráficos com ggplot2
               tsibble,      # manipulação de bases de séries temporais
               survey,       # funções de pesquisa
               srvyr,        # roupagem (wraper) para o pacote survey
               gtsummary,    # wrapper para o pacote survey, para produzir tabelas
               apyramid,     # pacote destinado a criação de pirâmides etárias
               patchwork,    # combinação de gráficos ggplots
               ggforce       # para diagramas aluviais e de sankey
               ) 

## carregar pacotes do github
pacman::p_load_gh(
     "R4EPI/sitrep"          # para funções de tempo de observação / ponderação
)

```

### Carregar dados {.unnumbered}

O conjunto de dados de exemplo utilizado nesta seção:

-   dados fictícios da pesquisa de mortalidade.
-   população fictícia conta para a área de pesquisa.
-   dicionário de dados para os dados fictícios da pesquisa de
    mortalidade.

Isto é baseado na pesquisa pré-aprovada pelo conselho de análise ética da MSF OCA. O conjunto de dados fictício foi produzido como parte do [projeto "R4Epis"](https://r4epis.netlify.app/). Baseado em dados coletados usando [KoboToolbox](https://www.kobotoolbox.org/), que é um software de coleta de dados baseado em 
[Open Data Kit](https://opendatakit.org/).

Kobo lhe permite exportar tanto os dados coletados quanto o dicionário para esse conjunto de dados. Recomendamos fortemente que se faça isso, pois simplifica a limpeza de dados e é útil para a pesquisa devariáveis/questões.

[**DICA:** O dicionário de dados Kobo tem nomes de variáveis na coluna"name" da planilha de pesquisa. Os valores possíveis para cada variável
são especificado na planilha de escolhas. Na planilha de escolhas, a coluna "name" tem o nome abreviado e as colunas "label::english" e "label::french" têm nome completo. Use o pacote **epidict**, função `msf_dict_survey()` para importar um arquivo excel do dicionário Kobo e formatá-lo para que possa ser usado facilmente
em uma recodificação.]{style="color: darkgreen;"}

[**CUIDADO:** O conjunto de dados do exemplo não é o mesmo que uma exportação (como em Kobo você exporta diferentes níveis de questionários individualmente) - 
veja o seção de dados da pesquisa abaixo para fundir as diferentes níveis]{style="color: orange;"}

O conjunto de dados é importado utilizando a função `import()` do pacote **rio**. Veja a página [Importar e exportação](#importing) para outrasmaneiras de importar dados.

```{r echo = FALSE}
# importar a pesquisa para o R
survey_data <- rio::import(here::here("data", "surveys", "survey_data.xlsx"))

# importar o dicionário para o R
survey_dict <- rio::import(here::here("data", "surveys", "survey_dict.xlsx")) 

# importar a população para o R
population <- rio::import(here::here("data", "surveys", "population.xlsx"))
```

```{r eval = FALSE}
# importar os dados da pesquisa
survey_data <- rio::import("survey_data.xlsx")

# importar o dicionário para o R
survey_dict <- rio::import("survey_dict.xlsx") 
```

As primeiras 10 linhas da pesquisa são exibidas abaixo.

```{r, message = FALSE, echo = FALSE}
# exibir os dados da pesquisa como tabela
DT::datatable(head(survey_data, 10), rownames = FALSE, options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```

Também queremos importar os dados sobre a população de amostragem para que possamos produzir pesos adequados. Estes dados podem estar em diferentes formatos, 
no entanto, sugerimos que seja como visto abaixo (podendo ser apenas digitado numa planilha).

```{r read_data_pop_show, eval = FALSE}
# importar os dados da população
population <- rio::import("population.xlsx")
```

As primeiras 10 linhas da pesquisa são exibidas abaixo.

```{r message=FALSE, echo=F}
# exibir os dados da pesquisa como tabela
DT::datatable(head(population, 10), rownames = FALSE, options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```

Para pesquisas de *cluster* (grupos, agregados) você pode querer adicionar pesos de pesquisa no nível do cluster. Você poderia ler estes
dados como acima.  Alternativamente, se houver apenas algumas contagens, estas poderiam ser inseridas como abaixo em um *tibble* (data frame com alguns ajustes
para deixá-lo mais amigável). Em qualquer caso você precisará ter uma coluna com um identificador de cluster, que corresponde aos dados de sua pesquisa, e outra
coluna com o número de agregados familiares em cada grupo.

```{r cluster_counts}

## definir o número de agregados familiares em cada cluster
cluster_counts <- tibble(cluster = c("village_1", "village_2", "village_3", "village_4", 
                                     "village_5", "village_6", "village_7", "village_8",
                                     "village_9", "village_10"), 
                         households = c(700, 400, 600, 500, 300, 
                                        800, 700, 400, 500, 500))

```

### Limpar dados {.unnumbered}

Abaixo, garantimos que a coluna de datas esteja no formato apropriado. Há várias outras maneiras de fazer isso (veja a página [Trabalhando com datas](#dates) para mais detalhes), porém a utilização do dicionário para definir datas é rápida e fácil.

Também criamos uma variável de faixa etária utilizando a função `age_categories()` do pacote **epikit** - veja a seção [limpeza de dados](#cleaning) para mais detalhes. Além disso, criamos uma variável do tipo caractere, que define em
qual distrito se encontram os vários agrupamentos.

Finalmente, recodificamos todas as variáveis yes/no (sim/não) para variáveis TRUE/FALSE (Verdadeiro/Falso) - caso contrário, estas não poderão ser utilizadas pelas funções de proporção **survey**.

```{r cleaning}

## selecione os nomes das variáveis de data no dicionário 
DATEVARS <- survey_dict %>% 
  filter(type == "date") %>% 
  filter(name %in% names(survey_data)) %>% 
  ## filtro para corresponder aos nomes das colunas de seus dados
  pull(name) # selecione variáveis de data
  
## mudança para data
survey_data <- survey_data %>%
  mutate(across(all_of(DATEVARS), as.Date))


## adicionar aqueles com apenas idade em meses à variável ano (dividir por doze)
survey_data <- survey_data %>% 
  mutate(age_years = if_else(is.na(age_years), 
                             age_months / 12, 
                             age_years))

## definir a variável de faixa etária
survey_data <- survey_data %>% 
     mutate(age_group = epikit::age_categories(age_years, 
                                    breakers = c(0, 3, 15, 30, 45)
                                    ))


## criar uma variável do tipo caractere baseada em grupos de uma variável diferente
survey_data <- survey_data %>% 
  mutate(health_district = case_when(
    cluster_number %in% c(1:5) ~ "district_a", 
    TRUE ~ "district_b"
  ))


## selecionar nomes de variáveis yes/no do dicionário
YNVARS <- survey_dict %>% 
  filter(type == "yn") %>% 
  filter(name %in% names(survey_data)) %>% 
  ## filtro para corresponder aos nomes das colunas de seus dados
  pull(name) # selecionar variáveis yn (yes/no)
  
## recodificação
survey_data <- survey_data %>%
  mutate(across(all_of(YNVARS), 
                str_detect, 
                pattern = "yes"))

```

<!-- ======================================================= -->

## Dados da pesquisa

Existem inúmeras técnicas de amostragem que podem ser usados para pesquisas. Aqui demonstraremos o código para: - Estratificado -
Conglomerados (Cluster) - Estratificado e Conglomerados

Como descrito acima (dependendo de como você projeta seu questionário) os dados para cada nível seriam exportados como um conjunto separado de dados do Kobo.
Em nosso exemplo, há um nível para domicílio e um nível para indivíduos dentro desses domicílios.

Estes dois níveis estão ligados por um identificador único. Para um conjunto de dados Kobo esta variável é "\_index" a nível de domicílios, que corresponde
ao "\_parent_index" a nível individual. Isto criará novas linhas para domicílio com cada indivíduo correspondente. Para maiores detalhes, veja a seção do manual sobre união de bases (<https://epirhandbook.com/joining-data.html>).

```{r merge_data_levels, eval = FALSE}

## juntar os dados individuais e de domicílio para formar um conjunto completo de dados
survey_data <- left_join(survey_data_hh, 
                         survey_data_indiv,
                         by = c("_index" = "_parent_index"))


## criar um identificador único, combinando as peças dos dois níveis 
survey_data <- survey_data %>% 
     mutate(uid = str_glue("{index}_{index_y}"))

```

<!-- ======================================================= -->

## Tempo de observação

Para pesquisas de mortalidade, queremos agora saber quanto tempo cada indivíduo esteve presente no local, para podermos calcular um taxa de mortalidade para nosso
período de interesse. Isto não é relevante para todas, mas particularmente para pesquisas de mortalidade, isso é importante, pois são conduzidas frequentemente
entre populações móveis ou deslocadas.

Para isso, definimos primeiro nosso período de tempo de interesse, também conhecido como período de retordo, ou período de *recall* (i.e. o tempo que os participantes
são instruídos a se reportarem quando respondem as perguntas). Podemos então utilizar este período para definir datas inadequadas para o ausência, ou seja, se as mortes forem relatadas fora do período de interesse.

```{r recall_period}

## definir o início/fim do período de recall
## pode ser alterado para variáveis de data do conjunto de dados 
## (por exemplo, questionário de data de chegada e data)
survey_data <- survey_data %>% 
  mutate(recall_start = as.Date("2018-01-01"), 
         recall_end   = as.Date("2018-05-01")
  )


# estabelecer datas inadequadas para NA com base em regras 
## por exemplo, chegadas antes do início, partidas após o fim
survey_data <- survey_data %>%
      mutate(
           arrived_date = if_else(arrived_date < recall_start, 
                                 as.Date(NA),
                                  arrived_date),
           birthday_date = if_else(birthday_date < recall_start,
                                  as.Date(NA),
                                  birthday_date),
           left_date = if_else(left_date > recall_end,
                              as.Date(NA),
                               left_date),
           death_date = if_else(death_date > recall_end,
                               as.Date(NA),
                               death_date)
           )

```

Podemos usar nossas variáveis de data para definir datas de inicio e fim para cada individuo. Usamos a função `find_start_date()` do **sitrep** para apurar as causas
para as datas e depois usar isso para calcular a diferença entre os dias (pessoa - tempo).

Data de início: Primeiro evento de chegada apropriado dentro de seu período de recall, ou o início de seu período de recall (que você define em previamente), ou uma
data após o início do recall, se aplicável (por exemplo chegadas ou nascimentos).

Data final: Primeiro evento de partida apropriado dentro de seu período de recall, ou o final de seu período de recall, ou uma data antes do final do recall se
aplicável (por exemplo, partidas e mortes).

```{r observation_time}

## criar novas variáveis para datas/causas de início e fim
survey_data <- survey_data %>% 
     ## escolher a data mais próxima informada na pesquisa
     ## de nascimentos, chegadas ao domicílio e chegadas ao local
     find_start_date("birthday_date",
                  "arrived_date",
                  period_start = "recall_start",
                  period_end   = "recall_end",
                  datecol      = "startdate",
                  datereason   = "startcause" 
                 ) %>%
     ## escolher a data mais próxima informada na pesquisa
     ## das partidas do local, morte e fim do estudo
     find_end_date("left_date",
                "death_date",
                period_start = "recall_start",
                period_end   = "recall_end",
                datecol      = "enddate",
                datereason   = "endcause" 
               )


## rotular aqueles que estavam presentes no início/fim (exceto nascimentos/mortes)
survey_data <- survey_data %>% 
     mutate(
       ## preencher a data de início para ser o início do período de recall (para aqueles vazios) 
       startdate = if_else(is.na(startdate), recall_start, startdate), 
       ## definir a causa inicial para apresentar no início se for igual ao período de recall 
       ## a menos que seja igual à data de nascimento 
       startcause = if_else(startdate == recall_start & startcause != "birthday_date",
                              "Present at start", startcause), 
       ## preencher a data final para ser o fim do período de recall (para aqueles vazios) 
       enddate = if_else(is.na(enddate), recall_end, enddate), 
       ## definir a causa final a apresentar ao fim se for igual ao recall final 
       ## a menos que seja igual à data da morte
       endcause = if_else(enddate == recall_end & endcause != "death_date", 
                            "Present at end", endcause))


## Define o tempo de observação em dias
survey_data <- survey_data %>% 
  mutate(obstime = as.numeric(enddate - startdate))

```

<!-- ======================================================= -->

## Ponderação

É importante que você remova observações errôneas antes de acrescentar pesos à pesquisa. Por exemplo, se você tiver registros com tempos de observação negativos,
precisará verificá-los (você pode fazer isso com a função`assert_positive_timespan()` do pacote **sitrep**. Outra questão é se você quiser eliminar linhas vazias (por
exemplo, com `drop_na(uid)`) ou remover duplicidades (consulte a seção do manual sobre [Eliminando duplicidades](#deduplication) para maiores detalhes). Aqueles sem consentimento
também precisarão ser removidos.

Neste exemplo, filtramos para os casos que queremos remover e os armazenamos em um data frame separado - desta forma podemos descrever aqueles que foram excluídos da
pesquisa. Em seguida, utilizamos a função `anti_join()` do **dplyr** para remover estes casos descartados de nossos dados de pesquisa.

[**PERIGO:** Você não pode ter valores ausentes em sua variável de peso, ou qualquer uma das variáveis relevantes para o projeto de sua pesquisa (por exemplo, idade, sexo, estratos ou variáveis de agrupamento).]{style="color: red;"}

```{r remove_unused_data}

## armazene os casos que deseja remover para que possa descrevê-los (por exemplo, sem consentimento) 
## ou local/cluster errados)
dropped <- survey_data %>% 
  filter(!consent | is.na(startdate) | is.na(enddate) | village_name == "other")

## usar os casos descartados para remover as linhas não utilizadas do conjunto de dados da pesquisa 
survey_data <- anti_join(survey_data, dropped, by = names(dropped))

```

Como mencionado acima, demonstramos como adicionar pesos para as três formas de amostragem (estratificado, conglomerado e conglomerado estratificado). Estas exigem informações sobre a população de origem e/ou os aglomerados pesquisados. Usaremos o código do "conglomerado estratificado" para este exemplo, mas escolha o que for mais apropriado para seu modelo de estudo.

```{r survey_weights}

# estratificado ----------------------------------------------------------------
# criar uma variável chamada "surv_weight_strata
# contém pesos para cada indivíduo - por faixa etária, sexo e distrito de saúde
survey_data <- add_weights_strata(x = survey_data,
                                         p = population,
                                         surv_weight = "surv_weight_strata",
                                         surv_weight_ID = "surv_weight_ID_strata",
                                         age_group, sex, health_district)

## por conglomerados (cluster) ---------------------------------------------------------------------

# obter o número de pessoas entrevistadas por domicílio
# adiciona uma variável com contagens da variável de índice doméstico
survey_data <- survey_data %>%
  add_count(index, name = "interviewed")


## criar pesos para o conglomerados (cluster)
survey_data <- add_weights_cluster(x = survey_data,
                                          cl = cluster_counts,
                                          eligible = member_number,
                                          interviewed = interviewed,
                                          cluster_x = village_name,
                                          cluster_cl = cluster,
                                          household_x = index,
                                          household_cl = households,
                                          surv_weight = "surv_weight_cluster",
                                          surv_weight_ID = "surv_weight_ID_cluster",
                                          ignore_cluster = FALSE,
                                          ignore_household = FALSE)


# estratificado e conglomerado (cluster) ------------------------------------------------------
# criar um peso de pesquisa para o cluster e os estratos
survey_data <- survey_data %>%
  mutate(surv_weight_cluster_strata = surv_weight_strata * surv_weight_cluster)

```

<!-- ======================================================= -->

## Objetos de delineamento de pesquisa

Crie um objeto de pesquisa de acordo com seu projeto de estudo. Utilizado da mesma forma que os *data frames* para calcular as proporções de peso etc.
Certifique-se de que todas as variáveis necessárias sejam criadas antes disso.

Há quatro opções, comente aquelas que você não utiliza: - Aleatório simples - Estratificado - Conglomerado (*cluster*) - Conglomerado estratificado

Para este modelo - vamos fingir que agrupamos as pesquisas em dois estratos separados (distritos de saúde A e B). Portanto, para obter estimativas gerais, precisamos ter pesos combinados de conglomerados e estratos.

Como mencionado anteriormente, há dois pacotes disponíveis para fazer isto. O clássico é o **survey** e depois há um pacote de "roupagem" (*wrapper*) chamado
**srvyr** que torna os objetos e funções mais fáceis de arrumar. Demonstraremos ambos, mas observe que a maioria dos códigos neste capítulo utilizará objetos 
baseados no **srvyr**. A única exceção é que o pacote **gtsummary** só aceita objetos do **survey**.

### Pacote **survey**

O pacote **survey** utiliza, do forma eficaz, codificação em **R base**, e por isso não é possível utilizar os *pipes* (`%>%`) ou outra sintaxe do **dplyr**. 
Com o pacote **survey**, utilizamos a função `svydesign()` para definir um objeto de pesquisa com agrupamentos (cluster), pesos e estratificações apropriados.

[**NOTA:** precisamos utilizar o til (`~`) em frente às variáveis, pois o pacote usa a sintaxe **R base** para atribuição variáveis baseada em fórmulas.]{style="color: black;"}

```{r survey_design}

# aleatório simples ------------------------------------------------------------
base_survey_design_simple <- svydesign(ids = ~1, # 1 para nenhuma identificação de cluster
                   weights = NULL,               # sem adição de pesos
                   strata = NULL,                # amostragem simples (não estratificada)
                   data = survey_data            # especificar a base de dados
                  )

## estratificado ---------------------------------------------------------------
base_survey_design_strata <- svydesign(ids = ~1,  # 1 para nenhuma identificação de cluster
                   weights = ~surv_weight_strata, # variável de peso criada acima
                   strata = ~health_district,     # amostragem estratificada por distrito
                   data = survey_data             # especificar a base de dados
                  )

# conglomerado ---------------------------------------------------------------------
base_survey_design_cluster <- svydesign(ids = ~village_name, # identificação do cluster
                   weights = ~surv_weight_cluster, # variável de peso criada acima
                   strata = NULL,                 # amostragem simples (não estratificada)
                   data = survey_data              # especificar a base de dados
                  )

# conglomerado estratificado --------------------------------------------------------
base_survey_design <- svydesign(ids = ~village_name,      # identificação do conglomerado
                   weights = ~surv_weight_cluster_strata, # variável de peso criada acima
                   strata = ~health_district,             # amostragem estratificada por distrito
                   data = survey_data                     # especificar a base de dados
                  )
```

### Pacote **srvyr**

Com o pacote **srvyr**\* podemos utilizar a função `as_survey_design()`, que tem os mesmos argumentos exemplificados acima, mas permite *pipes* (`%>%`), 
e assim não precisamos utilizar o til (`~`).

```{r survey_design_srvyr}
# aleatório simples ------------------------------------------------------------
survey_design_simple <- survey_data %>% 
  as_survey_design(ids = 1, # 1 para nenhuma identificação de cluster
                   weights = NULL, # sem adição de pesos
                   strata = NULL # amostragem simples (não estratificada)
                  )
## estratificado ---------------------------------------------------------------
survey_design_strata <- survey_data %>%
  as_survey_design(ids = 1, # 1 para nenhuma identificação de cluster
                   weights = surv_weight_strata, # variável de peso criada acima
                   strata = health_district # amostragem estratificada por distrito
                  )
## cluster ---------------------------------------------------------------------
survey_design_cluster <- survey_data %>%
  as_survey_design(ids = village_name, # identificação do cluster
                   weights = surv_weight_cluster, # variável de peso criada acima
                   strata = NULL # amostragem simples (não estratificada)
                  )

# cluster estratificado --------------------------------------------------------
survey_design <- survey_data %>%
  as_survey_design(ids = village_name, # identificação do cluster
                   weights = surv_weight_cluster_strata, # variável de peso criada acima
                   strata = health_district # amostragem estratificada por distrito
                  )
```

<!-- ======================================================= -->

## Análise descritiva

A análise descritiva básica e a visualização são amplamente cobertas em outros capítulos do manual, portanto, não vamos nos deter aqui. Para detalhes veja os
capítulos [Tabelas Descritivas](#tables-descriptive), [Testes Estatísticos](#stat-tests),
[Tabelas para Apresentação](#tables-presentation),[Introdução ao ggplot](#ggplot-basics) e [Relatórios em R markdown](#rmarkdown).

Nesta seção, vamos nos concentrar em como investigar o viés em sua amostra e em como visualizá-lo. Também vamos visualizar o fluxo populacional em um ambiente de pesquisa usando diagramas aluviais/sankey.

Em geral, você deve considerar incluir as seguintes análises descritivas:

-   Número final de agrupamentos, domicílios e indivíduos incluídos.
-   Número de indivíduos excluídos e os motivos de exclusão
-   Número médio (intervalo) de domicílios por agrupamento e de indivíduos por doméstico

### Viés de amostras

Compare as proporções em cada faixa etária entre sua amostra e a população de origem. Isto é importante para poder destacar um potencial viés de amostragem. 
Da mesma forma, você poderia repetir esta análise nas distribuições por sexo.

Note que estes p-valores são apenas indicativos e uma discussão descritiva (ou visualização em pirâmides etárias abaixo) dadistribuições de sua amostra de estudo,
em comparação com a população de origem, é mais importante do que o próprio teste binomial. Isto se deve ao fato de que o tamanho da amostra levará, na maioria 
das vezes, a diferenças que podem ser irrelevantes após a ponderação dos dados.

```{r descriptive_sampling_bias, warning = FALSE}

## contagem e proporção da população estudada
ag <- survey_data %>% 
  group_by(age_group) %>% 
  drop_na(age_group) %>% 
  tally() %>% 
  mutate(proportion = n / sum(n), 
         n_total = sum(n))

## contagem e proporção da população original
propcount <- population %>% 
  group_by(age_group) %>%
    tally(population) %>%
    mutate(proportion = n / sum(n))

## unir as colunas de duas tabelas, agrupar por idade, e executar um 
## teste binomial para ver se n/total é significativamente diferente da 
## proporção populacional.
  ## sufixo aqui adicionado ao texto no final das colunas em cada um dos dois 
  ## conjuntos de dados
left_join(ag, propcount, by = "age_group", suffix = c("", "_pop")) %>%
  group_by(age_group) %>%
  ## broom::tidy(binom.test()) faz um data frame a partir do teste binomial e
  ## adicionará as variáveis p.value (p-valor), parameter (parâmetro), 
  ## conf.low (intervalo de confiança inferior), method (método, o tipo de teste),
  ## conf.high (intervalo de confiança superior) e alternative (alternativa à hipotese nula).
  ## Aqui usaremos apenas p.value. Você pode incluir outras colunas se quiser
  ## informar intervalos de confiança
  mutate(binom = list(broom::tidy(binom.test(n, n_total, proportion_pop)))) %>%
  unnest(cols = c(binom)) %>% # important for expanding the binom.test data frame
  mutate(proportion_pop = proportion_pop * 100) %>%
  ## Ajustando os p-valor para corrigir os falsos positivos 
  ## (testando várias faixas etárias). Isto só fará diferença
  ## se você tem muitas categorias etárias
  mutate(p.value = p.adjust(p.value, method = "holm")) %>%
                      
  ## somente mostrar o p-valor acima de  0.001 (inferiores, mostrar como 0.001)
  mutate(p.value = ifelse(p.value < 0.001, 
                          "<0.001", 
                          as.character(round(p.value, 3)))) %>% 
  
  ## renomear as colunas de forma apropriada
  select(
    "Faixa-etária" = age_group,
    "População de estudo (n)" = n,
    "População de estudo (%)" = proportion,
    "População fonte (n)" = n_pop,
    "População fonte (%)" = proportion_pop,
    "P-valor" = p.value
  )
```

### Pirâmides demográficas

As pirâmides demográficas (ou de idade-sexo) são uma maneira fácil de visualizar a distribuição em sua população pesquisada. Também vale a pena considerar a criação 
de [Tabelas Descritivas](#tables-descriptive) de idade e sexo por estratos de pesquisa. Demonstraremos utilizando o pacote **apyramid**,
pois ele permite proporções ponderadas utilizando nosso objeto de pesquisa criado acima. Outras opções para criar [Pirâmides Demográficas](#age-pyramid) são amplamente cobertas nesse capítulo do manual. Também utilizaremos uma função *wrapper* da
**apyramid** chamada `age_pyramid()` que economiza algumas linhas de código para produzir um gráfico comproporções.

Como no teste binomial formal de diferença, visto acima na seção de viés de amostragem, estamos interessados aqui em visualizar se nossa população amostrada é 
substancialmente diferente da população original e se a ponderação corrige esta diferença. Para isso, usaremos o pacote **patchwork** para mostrar nossas visualizações **ggplot** lado a lado; para detalhes, veja a seção sobre combinação de lotes no capítulo [dicas ggplot](#ggplot-tips) do manual. Visualizaremos nossa população original, nossa população não ponderada de pesquisa e nossa população ponderada de pesquisa. Você
também pode considerar a visualização por cada estrato de sua pesquisa - em nosso exemplo aqui, isso seria utilizando o argumento
`stack_by = "health_district"` (veja \`?age_pyramid' para detalhes).

[**NOTA:** Os eixos x e y são invertidos em pirâmides]{style="color: black;"}

```{r weighted_age_pyramid, warning = FALSE, message = FALSE, fig.show = "hold", fig.width = 15}

## definir limites e rótulos do eixo x -----------------------------------------
## (atualize estes números para serem os valores adequado ao seu gráfico)
max_prop <- 35      # escolha a maior proporção que quer mostrar
step <- 5           # escolha o espaço que quer mostrar entre as legendas

## esta parte define o vetor usando os números acima com quebras de eixo
breaks <- c(
    seq(max_prop/100 * -1, 0 - step/100, step/100), 
    0, 
    seq(0 + step / 100, max_prop/100, step/100)
    )

## esta parte define o vetor usando os números acima com limites de eixo
limits <- c(max_prop/100 * -1, max_prop/100)

## esta parte define o vetor usando os números acima com legendas de eixo
labels <-  c(
      seq(max_prop, step, -step), 
      0, 
      seq(step, max_prop, step)
    )


## criar gráficos individualmente ---------------------------------------------

## Traçar a população de original 
## nb: precisa de ser comprimido para a população em geral (isto é, removendo distritos de saúde)
source_population <- population %>%
  ## garantir que a idade e o sexo sejam fatores
  mutate(age_group = factor(age_group, 
                            levels = c("0-2", 
                                       "3-14", 
                                       "15-29",
                                       "30-44", 
                                       "45+")), 
         sex = factor(sex)) %>% 
  group_by(age_group, sex) %>% 
  ## somar as contagens para cada distrito sanitário em conjunto
  summarise(population = sum(population)) %>% 
  ## remover o agrupamento para poder calcular a proporção total
  ungroup() %>% 
  mutate(proportion = population / sum(population)) %>% 
  ## exibir a pirâmide 
  age_pyramid(
            age_group = age_group, 
            split_by = sex, 
            count = proportion, 
            proportional = TRUE) +
  ## mostrar apenas a legenda do eixo y (caso contrário será repetida nos três gráficos)
  labs(title = "População de origem", 
       y = "", 
       x = "Faixa-etária (anos)") + 
  ## fazer o eixo x o mesmo para todas os gráfcos
  scale_y_continuous(breaks = breaks, 
    limits = limits, 
    labels = labels)
  
  
## Traçar a população não ponderada da amostra 
sample_population <- age_pyramid(survey_data, 
                 age_group = "age_group", 
                 split_by = "sex",
                 proportion = TRUE) + 
  ## mostrar apenas a legenda do eixo x (caso contrário será repetida nos três gráficos)
  labs(title = "População amostrada sem ponderação", 
       y = "Proporção (%)", 
       x = "") + 
  ## fazer o eixo x o mesmo para todas os gráfcos
  scale_y_continuous(breaks = breaks, 
    limits = limits, 
    labels = labels)


## Traçar a população de amostra ponderada 
weighted_population <- survey_design %>% 
  ## garantir que as variáveis sejam fatores
  mutate(age_group = factor(age_group), 
         sex = factor(sex)) %>%
  age_pyramid(
    age_group = "age_group",
    split_by = "sex", 
    proportion = TRUE) +
  ## mostrar apenas a legenda do eixo x (caso contrário será repetida nos três gráficos)
  labs(title = "População amostrada ponderada", 
       y = "", 
       x = "")  + 
  ## fazer o eixo x o mesmo para todas os gráfcos
  scale_y_continuous(breaks = breaks, 
    limits = limits, 
    labels = labels)

## ccombinar os três gráficos   ------------------------------------------------
## combinar três gráficos próximos uns aos outros usando + 
source_population + sample_population + weighted_population + 
  ## mostrar apenas uma legenda e definir o tema
  ## observe o uso de & para combinar o tema com o plot_layout()
  plot_layout(guides = "collect") & 
  theme(legend.position = "bottom",                    # mover legenda para baixo
        legend.title = element_blank(),                # remover o título
        text = element_text(size = 18),                # dimensionar o texto
        axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1) # girar texto do eixo x
       )
```

### Diagrama aluvial/sankey

A visualização de pontos de partida e resultados para indivíduos pode ser muito útil para se ter uma visão geral. Há uma aplicação bastante óbvia para populações
móveis, porém existem inúmeras outras aplicações, tais como coortes ou qualquer outra situação em que há transições nos estados para indivíduos. Estes diagramas são
conhecidos por vários nomes diferentes, incluindo aluvial, sankey e conjuntos paralelos - os detalhes estão no capítulo sobre [Diagramas e Gráficos](#diagrams).

```{r visualise_population_flow}

## resuma os dados 
flow_table <- survey_data %>%
  count(startcause, endcause, sex) %>%  # faz contagem
  gather_set_data(x = c("startcause", "endcause"))     # muda o formato para gráfico


## trace um gráfico 
  ## no eixo x estão as causas do início e fim
  ## a função gather_set_datagera um ID para cada combinação
  ## dividindo (splitting) pelo y te da um combo de possibilidades de início/fim 
  ## valor (value) como "n" fornece a contagem (também pode ser usado com proporção)
ggplot(flow_table, aes(x, id = id, split = y, value = n)) +
  ##linhas coloridas segundo sexo
  geom_parallel_sets(aes(fill = sex), alpha = 0.5, axis.width = 0.2) +
  ## preenche as caixas de rotulagem com cinza
  geom_parallel_sets_axes(axis.width = 0.15, fill = "grey80", color = "grey80") +
  ## muda a cor do tetxo e ângulo (precisa ser ajustado)
  geom_parallel_sets_labels(color = "black", angle = 0, size = 5) +
  ## remove rótulos dos eixos
  theme_void()+
  ## move a legenda para baixo
  theme(legend.position = "bottom")               

```

<!-- ======================================================= -->

## Proporções ponderadas

Esta seção detalha como produzir tabelas para contagens e proporções ponderadas, com os intervalos de confiança associados e delineamento.
Existem quatro opções diferentes, utilizando funções dos seguintes pacotes: **survey**, **srvyr**, **sitrep** e **gtsummary**. Para para
produzir uma tabela de estilo epidemiológico padrão com mínimo de código, nós recomendamos a função **sitrep** - que é um *wrapper* para códigos **srvyr**; note, 
entretanto, que isso ainda não está no CRAN e pode mudar no futuro. Caso contrário, o código **survey** será provavelmente o mais estável a longo prazo, enquanto 
**srvyr** caberá melhor dentro do fluxos de trabalho. Embora as funções **gtsummary** tenham um grande potencial, elas parecem ser experimentais e incompletas
no momento em que da escrita deste manual.

### Pacote **survey**

Podemos utilizar a função `svyciprop()` do **survey** para obter proporções ponderadas e intervalos de confiança de 95%. Um delineamento apropriado pode ser extraído
utilizando o `svymean()` em vez da função `svyprop()`. Vale notar que a função `svyprop()` parece apenas aceitar variáveis entre 0 e 1 (ou TRUE/FALSE), então, variáveis categóricas não funcionarão.

[**NOTA:** Funções do **survey** também aceitam objetos **srvyr** mas aqui usamos o objeto de delineamento **survey** apenas por uma questão de consistência]{style="color: black;"}

```{r survey_props}

##  produção contagens ponderadas 
svytable(~died, base_survey_design)

##  produção proporções ponderadas 
svyciprop(~died, base_survey_design, na.rm = T)

## obtem o efeito de delineamento  
svymean(~died, base_survey_design, na.rm = T, deff = T) %>% 
  deff()

```

Podemos combinar as funções de **survey** mostradas acima em um função chamada `svy_prop`; e podemos então utilize essa função junto com o `map()` do pacote purrr
para repetir sobre várias variáveis e criar uma tabela. Veja o capítulo [Iterações e loops](#iteration) para mais detalhes do
pacote **purrr**.

```{r survey_prop_fun}
# Definir função para calcular contagens ponderadas, proporções, IC e efeito de delineamento
# x é a variável entre aspas 
# O delineamento é seu objeto de desenho de pesquisa

svy_prop <- function(design, x) {
  
  ## colocar as variáveis de interesse em uma fórmula
  form <- as.formula(paste0( "~" , x))
  ## manter apenas a coluna TRUE do svytable
  weighted_counts <- svytable(form, design)[[2]]
  ## calcular proporções (multiplicar por 100 para obter porcentagens)
  weighted_props <- svyciprop(form, design, na.rm = TRUE) * 100
  ## extrair os intervalos de confiança e multiplicar para obter porcentagens
  weighted_confint <- confint(weighted_props) * 100
  ## use svymean para calcular o efeito do delinemanto e mantenha apenas a coluna TRUE
  design_eff <- deff(svymean(form, design, na.rm = TRUE, deff = TRUE))[[TRUE]]
  
  ## combinar em um único dataframe
  full_table <- cbind(
    "Variável"        = x,
    "Contagens"           = weighted_counts,
    "Proporção"      = weighted_props,
    weighted_confint, 
    "Efeito de delineamento"   = design_eff
    )
  
  ## retorna tabela como um dataframe
  full_table <- data.frame(full_table, 
             ## remover os nomes das variáveis das linhas (é uma coluna separada agora)
             row.names = NULL)
  
  ## mudar números de volta ao formato numérico
  full_table[ , 2:6] <- as.numeric(full_table[, 2:6])
  
  ## retornar o dataframe
  full_table
}

## repetir em diversar variáveis para criar uma tabela  
purrr::map(
  ## definir variáveis de interesse
  c("left", "died", "arrived"), 
  ## função de estado usando e argumentos para essa função (delineamento)
  svy_prop, design = base_survey_design) %>% 
  ## fundir lista em um único data frame
  bind_rows() %>% 
  ## arredondar 
  mutate(across(where(is.numeric), round, digits = 1))

```

### Pacote **srvyr**

Com **srvyr** podemos usar a sintaxe **dplyr** para criar uma tabela. Note que a função `survey_mean()` é utilizada e o argumento da proporção é especificado, e 
também que a mesma função é utilizada para calcular o efeito do delineamento. Isto porque **srvyr** envolve ambas as funções do pacote **survey** `svyciprop()` 
e `svymean()`, que são utilizadas na seção acima.

[**NOTA:** Não parece ser possível obter proporções a partir de variáveis categóricas utilizando **srvyr**, se você precisar disto então verifique a seção abaixo usando **sitrep**]{style="color: black;"}

```{r srvyr_prop}

## usar o objeto delineado srvyr
survey_design %>% 
  summarise(
    ## produzir as contagens ponderadas
    counts = survey_total(died), 
    ## produzir proporções ponderadas e intervalos de confiança 
    ## multiplicar por 100 para obter uma porcentagem 
    props = survey_mean(died, 
                        proportion = TRUE, 
                        vartype = "ci") * 100, 
    ## produzir o efeito de delineamento
    deff = survey_mean(died, deff = TRUE)) %>% 
  ## manter apenas as fileiras de interesse
  ## (remove erros padrão e repete o cálculo de proporção)
  select(counts, props, props_low, props_upp, deff_deff)

```

Também aqui poderíamos escrever uma função para então reiterar sobre múltiplas variáveis usando o pacote **purrr**. Veja o capítulo do manual [Iterações e loops](#iteration) para detalhes sobre **purrr**.

```{r srvyr_prop_fun}

# definir função para calcular contagens ponderadas, proporções, IC e delineamento
# o desenho é seu objeto de desenho de pesquisa
# x é a variável entre aspas 


srvyr_prop <- function(design, x) {
  
  summarise(
    ## usando o objeto delimitado de pesquisa
    design, 
    ## produzir as contagens ponderadas
    counts = survey_total(.data[[x]]), 
    ## produzir as proporções e intervalos de confiaça ponderados
    ## multiplicar por 100 para obter uma porcentagem 
    props = survey_mean(.data[[x]], 
                        proportion = TRUE, 
                        vartype = "ci") * 100, 
    ## produzir o efeito de delineamento
    deff = survey_mean(.data[[x]], deff = TRUE)) %>% 
  ## adicionar na variável de nome
  mutate(variable = x) %>% 
  ## manter apenas as linhas de interesse
  ## (remove erros padrão e repete o cálculo de proporção)
  select(variable, counts, props, props_low, props_upp, deff_deff)
  
}
  

## reitera em diferentes variáveis para criar uma tabela
purrr::map(
  ## define  as variáveis de interesse
  c("left", "died", "arrived"), 
  ## função *state* e argumentos para essa função (delineamento)
  ~srvyr_prop(.x, design = survey_design)) %>% 
  ## unificar lista em uma única data frame
  bind_rows()
  

```

### Pacote **sitrep**

A função `tab_survey()` de **sitrep** é um *wrapper* para **srvyr**, permitindo a criação de tabelas ponderadas com codificação mínima.
Também permite calcular proporções ponderadas para variáveis categóricas.

```{r sitrep_props}

    ## usando o objeto delimitado de pesquisa
survey_design %>% 
  ## passe os nomes das variáveis de interesse não cotadas
  tab_survey(arrived, left, died, education_level,
             deff = TRUE,   # calcular o efeito de delineamento
             pretty = TRUE  # fundir proporção e intervalo de confiança 95%
             )

```

### Pacote **gtsummary**

Com **gtsummary** não parece haver ainda funções embutidas para acrescentar intervalos de confiança ou efeito de delineamento. Aqui mostramos como definir uma função
para adicionar intervalos de confiança e depois adicionar intervalos de confiança a uma tabela **gtsummary** criada utilizando a função `tbl_svysummary()`.

```{r gtsummary_table}


confidence_intervals <- function(data, variable, by, ...) {
  
  ## extrair os intervalos de confiança e multiplicar para obter porcentagens
  props <- svyciprop(as.formula(paste0( "~" , variable)),
              data, na.rm = TRUE)
  
  ## extrair os intervalos de confiança 
  as.numeric(confint(props) * 100) %>% ## transformar em número e multiplicar para obter o percentual
    round(., digits = 1) %>%           ## arredondar para um dígito
    c(.) %>%                           ## ## extrair os números da matriz
    paste0(., collapse = "-")          ## combinar para caracter único
}

## usando o objeto delimitado do pacote survey
tbl_svysummary(base_survey_design, 
               include = c(arrived, left, died),   ## definir variáveis a serem incluídas
               statistic = list(everything() ~ c("{n} ({p}%)"))) %>% ## definir estatísticas de interesse
  add_n() %>%  ## adicionar o peso total
  add_stat(fns = everything() ~ confidence_intervals) %>% ## adicionar intervalos de confiança
  ## modificar títulos das colunas
  modify_header(
    list(
      n ~ "**Total ponderado (N)**",
      stat_0 ~ "**Contagem ponderada**",
      add_stat_1 ~ "**95%IC**"
    )
    )

```

<!-- ======================================================= -->

## Razões ponderadas

Da mesma forma, para relações ponderadas (como para relações de mortalidade) você pode usar o pacote **survey** ou o pacote **srvyr**.
Você poderia escrever funções (semelhantes àquelas acima) para iterar sobre várias variáveis. Você também poderá criar uma função para o pacote **gtsummary**, 
como acima, mas atualmente ela não tem nenhuma funcionalidade embutida.

### Pacote **survey**

```{r survey_ratio}

ratio <- svyratio(~died, 
         denominator = ~obstime, 
         design = base_survey_design)

ci <- confint(ratio)

cbind(
  ratio$ratio * 10000, 
  ci * 10000
)

```

### Pcaote **srvyr**

```{r srvyr_ratio}

survey_design %>% 
  ## razão de pesquisa usada para contabilizar o tempo de observação 
  summarise(
    mortality = survey_ratio(
      as.numeric(died) * 10000, 
      obstime, 
      vartype = "ci")
    )

```

<!-- ======================================================= -->

## Referência

[Página de estatísticas da UCLA](https://stats.idre.ucla.edu/r/seminars/survey-data-analysis-with-r/)

[Analise dados de questioários gratuitamente](http://asdfree.com/)

[Pacote srvyr](http://gdfe.co/srvyr/)

[Pacote gtsummary](http://www.danieldsjoberg.com/gtsummary/reference/index.html)

[Estudo de caso da pesquisa EPIET](https://github.com/EPIET/RapidAssessmentSurveys)
```{r include=FALSE, cache=FALSE}

# clear workspace
rm(list = ls(all = TRUE))

# clear all packages except base
#lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))

# to ensure that tidyverse packages prevail
filter <- dplyr::filter
select <- dplyr::select
summarise <- dplyr::summarise
summary <- base::summary
incidence <- incidence2::incidence

#load core packages
pacman::p_load(
     rio,
     here,
     DT,
     stringr,
     lubridate,
     tidyverse
)

# import the cleaned ebola linelist
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

# import the count data - facility level
#count_data <- rio::import(here::here("data", "facility_count_data.rds"))

# Settings

options(scipen=1, digits=7)

# print only text (not code)
# library(knitr)
# opts_chunk$set(list(echo = FALSE, eval = FALSE))
```

<!--chapter:end:new_pages/survey_analysis.Rmd-->

<!-- ======================================================= -->

<!-- ======================================================= -->

<!-- ======================================================= -->

# Análise de sobrevivência {#survival-analysis}

```{r out.width = c('75%'), fig.align='center', fig.show='hold', echo=F}
knitr::include_graphics(here::here("images", "survival_analysis.png"))
```

<!-- ======================================================= -->

## Visão Geral

*A análise de sobrevivência* centra-se na descrição, para um determinado indivíduo ou grupo de indivíduos, de um ponto definido de evento chamado **a falha** (ocorrência de uma doença, cura de uma doença, óbito, recaída após resposta ao tratamento...) que ocorre após um período de tempo chamado **tempo de falha** (ou **tempo de seguimento** em estudos baseados em coorte/população) durante o qual os indivíduos são observados. Para determinar o tempo de falha, é então necessário definir um tempo de origem (que pode ser a data de inclusão, a data de diagnóstico...).

O alvo de inferência para a análise de sobrevivência é então o tempo entre uma origem e um evento. Na investigação médica actual, é amplamente utilizado em estudos clínicos para avaliar o efeito de um tratamento, por exemplo, ou na epidemiologia do câncer para avaliar uma grande variedade de medidas de sobrevivência ao câncer.

É normalmente expressa através da **probabilidade de sobrevivência** que é a probabilidade de o evento de interesse não ter ocorrido por uma duração t.

**Censura**: A censura ocorre quando no final do seguimento, alguns dos indivíduos não tiveram o evento de interesse, e assim o seu verdadeiro tempo para o evento é desconhecido. Aqui focaremos principalmente na censura correta, mas para mais detalhes sobre a censura e a análise de sobrevivência em geral, é possível ver referências.

```{r echo=F, eval=F, out.width = "80%", out.height="80%", fig.align = "center"}
 
# Adicionar uma figura dos seguintes chunks para a última versão da página
# não se esqueça de guardar a figura de saída em "images"
# knitr::include_graphics(here::here("images", "survanalysis.png"))

```

<!-- ======================================================= -->

## Preparação

### Carregar Pacotes {.unnumbered}

Para realizar análises de sobrevivência em R, um dos pacotes mais utilizados é o pacote **survival**. Primeiro o instalamos e depois o carregamos, bem como os outros pacotes que serão utilizados nesta secção:

Neste manual enfatizamos `p_load()` do **pacman**, que instala o pacote se necessário *e* carrega-o para utilização. Pode também carregar os pacotes instalados com `library()` do R **base** . Veja a página em [Introdução ao R](#basics) para mais informações sobre os pacotes R.

```{r, echo=F, message=FALSE, warning=FALSE}

# instala/carrega os diferentes pacotes necessários para esta página
pacman::p_load(
  survival,      # análise de sobrevivência
  survminer,     # análise de sobrevivência
  rio,           # importação de dados
  here,          # caminhos relativos de arquivos  
  janitor,       # tabulações
  SemiCompRisks, # exemplos de conjuntos de dados e ferramentas avançadas de trabalho com dados
  tidyverse,     # manipulação e visualização de dados
  Epi,           # análises estatísticas em Epi
  survival,      # análise de sobrevivência
  survminer      # análise de sobrevivência: curvas KM avançadas
)


```

Esta página explora análises de sobrevivência usando a *linelist* usada na maioria das páginas anteriores e na qual aplicamos algumas alterações para termos dados de sobrevivência adequados.

Importar conjunto de dados

Importamos o conjunto de dados de casos de uma epidemia simulada de Ebola. Se quiser acompanhar, <a href='https://github.com/epirhandbook/Epi_R_handbook/raw/master/data/case_linelists/linelist_cleaned.rds' class='download-button'>clique para fazer o download da *linelist* "limpa" </a> (as .rds file). Importe os dados com a função `import()` do pacote **rio** (suporta muitos formatos de arquivos .xlsx, .csv, .rds - veja a página [Importar e exportar](#importing) para mais detalhes).

```{r echo=F}
# importar linelist
linelist_case_data <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))
```

```{r eval=F}
# importar linelist
linelist_case_data <- rio::import("linelist_cleaned.rds")
```

### Gestão e transformação de dados {.unnumbered}

Em suma, os dados de sobrevivência podem ser descritos como tendo as três características seguintes:

1) a variável ou resposta dependente é o tempo de espera até à ocorrência de um evento bem definido,
2) as observações são censuradas, no sentido de que para algumas unidades o evento de interesse não ocorreu no momento em que os dados são analisados, e
3) existem preditores ou variáveis explicativas cujo efeito sobre o tempo de espera desejamos avaliar ou controlar.

Assim, criaremos diferentes variáveis necessárias para respeitar essa estrutura e executar a análise de sobrevivência.

Definimos:

- um novo *data frame* `linelist_surv` para esta análise
- o nosso evento de interesse como sendo "óbito" (nossa probabilidade de sobrevivência será a probabilidade de estar vivo um certo tempo após o tempo de origem),
- o tempo de seguimento (`futime`) como o tempo entre o tempo de início e o tempo do resultado *em dias*,
- pacientes censurados como aqueles que recuperaram ou para os quais o resultado final não é conhecido, ou seja, o evento "morte" não foi observado (`evento=0`).

[**CUIDADO:** Uma vez que num estudo de coorte real, a informação sobre a hora de origem e o fim do seguimento é conhecida, dado que são observados indivíduos, removeremos as observações onde a data de início ou a data do desfecho é desconhecida. Também os casos em que a data de início é posterior à data do resultado serão removidos, uma vez que são considerados errados]{estilo="color: orange;"}

[**DICA:** Dado que filtrar para maior que (\>) ou menor que (\<) uma data pode remover linhas sem valores, aplicar o filtro nas datas erradas também removerá as linhas sem datas.]{style="color: darkgreen;"}

Depois utilizamos `case_when()` para criar uma coluna `age_cat_small` na qual existem apenas 3 categorias de idade.

```{r }
#criar um novo dado chamado linelist_surv a partir do linelist_case_data

linelist_surv <-  linelist_case_data %>% 
     
  dplyr::filter(
       # remover observações com datas de início ou desfecho erradas ou vazias
       date_outcome > date_onset) %>% 
  
  dplyr::mutate(
       # criar o evento var que é 1 se o paciente morreu e 0 se ele foi censurado correctamente
       event = ifelse(is.na(outcome) | outcome == "Recover", 0, 1), 
    
       # criar o var sobre o tempo de seguimento em dias
       futime = as.double(date_outcome - date_onset), 
    
       # criar uma nova variável de categoria de idade com apenas 3 níveis de estratos
       age_cat_small = dplyr::case_when( 
            age_years < 5  ~ "0-4",
            age_years >= 5 & age_years < 20 ~ "5-19",
            age_years >= 20   ~ "20+"),
       
       # passo anterior criou age_cat_small var como caractere
       # agora o converte em fator e especifica os níveis.
       # note que os valores NA continuam a ser NA e não são colocados num nível "desconhecido", por exemplo,
       # uma vez que nas análises seguintes tem de ser removidas.
       age_cat_small = fct_relevel(age_cat_small, "0-4", "5-19", "20+")
       )
```

[**DICA:** Podemos verificar as novas colunas que criamos fazendo um resumo sobre o `futime` e uma tabulação cruzada entre o `evento` e o `resultado` de onde foi criado. Para além desta verificação, é um bom hábito comunicar o tempo médio de seguimento ao interpretar os resultados da análise de sobrevivência.]{style="color: darkgreen;"}

```{r }

summary(linelist_surv$futime)

# tabulação cruzada das novas variáveis modificadas "event" e "outcome" (desfecho) 
# para garantir que o código fazia o que se pretendia
linelist_surv %>% 
  tabyl(outcome, event)
```

Agora fazemos uma tabulação cruzada da nova variável "age_cat_small" e da antiga coluna "age_cat" para garantir atribuições corretas

```{r}
linelist_surv %>% 
  tabyl(age_cat_small, age_cat)
```

Agora  revisamos as 10 primeiras observações dos dados da `linelist_surv`, olhando para variáveis específicas (incluindo aquelas recentemente criadas).

```{r}
linelist_surv %>% 
  select(case_id, age_cat_small, date_onset, date_outcome, outcome, event, futime) %>% 
  head(10)
```

Também podemos fazer tabulações cruzadas entre as colunas  `age_cat_small` e `gender` para obter mais detalhes acercada distribuição dessas novas colunas por gênero. Usamos `tabyl()` e a função *adorn* do pacote **janitor**, como descrito na página [Tabelas descritivas](#tables-descriptive).

<!-- Para isso, usamos a função `stat.table()` do pacote **Epi**. -->

```{r}

linelist_surv %>% 
  tabyl(gender, age_cat_small, show_na = F) %>% 
  adorn_totals(where = "both") %>% 
  adorn_percentages() %>% 
  adorn_pct_formatting() %>% 
  adorn_ns(position = "front")

```

<!-- Epi::stat.table(  -->

<!--   #atribua variáveis para a tabulação cruzada -->

<!--   list( -->

<!--     gender,  -->

<!--     age_cat_small -->

<!--     ), -->

<!--   #especifique a função que deseja chamar (mean,count..) -->

<!--   list(  -->

<!--     count(), -->

<!--     percent(age_cat_small) -->

<!--     ),  -->

<!--   #adicione margens -->

<!--   margins=T,  -->

<!--   #dados utilizados -->

<!--   data = linelist_surv  -->

<!--   ) -->

<!-- ``` -->

<!-- ======================================================= -->

## Noções básicas de análise de sobrevivência

### Construir um objeto do tipo sobrevivente {.unnumbered}

Utilizaremos primeiro a função `Surv()` do pacote **survival** para construir um objeto de sobrevivência a partir das colunas de tempo e evento seguintes.

O resultado de tal passo é produzir um objeto do tipo *Surv* que condensa a informação do tempo e se o evento de interesse (óbito) foi observado. Este objeto acabará por ser utilizado no lado direito das fórmulas do modelo subsequente (ver [documentação](https://cran.r-project.org/web/packages/survival/vignettes/survival.pdf)).

```{r survobj }
# Use a sintaxe Suv() para dados censurados
survobj <- Surv(time = linelist_surv$futime,
                event = linelist_surv$event)
```

<!-- ```{r} -->

<!-- survobj <- with(linelist_surv, -->

<!--                 survival::Surv(futime, event) -->

<!--                 ) -->

<!-- ``` -->

Para rever, aqui estão as primeiras 10 linhas dos dados da `linelist_surv`, visualizando apenas algumas colunas importantes.

```{r}
linelist_surv %>% 
  select(case_id, date_onset, date_outcome, futime, outcome, event) %>% 
  head(10)
```

E aqui estão os primeiros 10 elementos do `survobj`. Imprime essencialmente como um vetor de tempo de seguimento, com "+" para representar se uma observação foi bem censurada. Veja como os números se alinham acima e abaixo.

```{r}
#imprime os 50 primeiros elementos do vetor para ver como ele se apresenta
head(survobj, 10)
```

### Rodando análises iniciais {.unnumbered}

Iniciamos então a nossa análise utilizando a função `survfit()` para produzir um *objeto survfit*, que se ajusta aos cálculos padrões de estimativas da curva de sobrevivência global (marginal) ***Kaplan Meier*** (KM) , que são na verdade uma função com saltos em tempos de eventos observados. O objeto final *survfit* contém uma ou mais curvas de sobrevivência e são criadas usando o objeto *Surv* como uma resposta variável na fórmula do modelo.

[***NOTA:*** A estimativa de Kaplan-Meier é uma estimativa não paramétrica da máxima probabilidade (MLE na sigla em inglês) da função de sobrevivência. . (ver recursos para mais informações)]{style="color: black;"}

O resumo deste *objeto survfit* dará o que se chama uma *tabela de vida*. Para cada passo do seguimento (`tempo`) em que um evento aconteceu (em ordem ascendente):

-   o número de pessoas que estavam em risco de desenvolver o evento (pessoas que ainda não tinham o evento nem foram censuradas: `n.risk`)
-   aqueles que desenvolveram o evento (`n.event`)
-   e do acima exposto: a probabilidade de *não* desenvolver o evento (probabilidade de não morrer, ou de sobreviver depois desse tempo específico)
-   finalmente, o erro padrão e o intervalo de confiança para essa probabilidade são derivados e exibidos

Encaixamos as estimativas KM usando a fórmula em que o objeto anteriormente Surv "survobj" é a variável de resposta. "~ 1" precisa que executamos o modelo para a sobrevivência global.

```{r fit}
# encaixa nas estimativas KM usando uma fórmula onde o objeto Surv "sobrevivente" é a variável de resposta.
# "~ 1" significa que executamos o modelo para a sobrevivência global   
linelistsurv_fit <-  survival::survfit(survobj ~ 1)

# imprime o resumo para mais detalhes
summary(linelistsurv_fit)

```

Enquanto usamos `summary()` podemos adicionar a opção `times` e especificar certos tempos em que queremos ver informações de sobrevivência.

```{r print_spec_times}

#imprime o resumo de tempos específicos
summary(linelistsurv_fit, times = c(5,10,20,30,60))

```

Podemos também utilizar a função `print()`. O argumento `print.rmean = TRUE` é utilizado para obter o tempo médio de sobrevivência e o seu erro padrão (SE na sigla em inglês).

[**NOTA:** O tempo médio de sobrevivência restrito (RMST na sigla em inglês) é uma medida de sobrevivência específica cada vez mais utilizada na análise de sobrevivência ao câncer e que é frequentemente definida como a área sob a curva de sobrevivência, dado que observamos pacientes até ao tempo restrito T (mais detalhes na seção Recursos).]{style="color: black;"}

```{r, mean_survtime}
# imprimir objeto linelistsurv_fit com tempo médio de sobrevivência e sua SE.
print(linelistsurv_fit, print.rmean = TRUE)

```

[**DICA:** Podemos criar o objeto *surv* diretamente na função `survfit()` e economizar uma linha de código. Ficará então: `linelistsurv_quick <-  survfit(Surv(futime, event) ~ 1, data=linelist_surv)`.]{style="color: darkgreen;"}

### Risco acumulado {.unnumbered}

Além da função `summary()`, também podemos utilizar a função `str()` que dá mais detalhes sobre a estrutura do objeto `survfit()`. É uma lista de 16 elementos.

Entre estes elementos é um importante: `cumhaz`, que é um vetor numérico. Este pode ser traçado para permitir mostrar o **risco cumulativo**, sendo o **risco** o **índice instantâneo de ocorrência de eventos** (ver referências).

```{r fit_struct}

str(linelistsurv_fit)

```

<!-- ======================================================= -->

### Traçando curvas Kaplan-Meir {.unnumbered}

Uma vez encaixadas as estimativas KM, podemos visualizar a probabilidade de estarmos vivos durante um determinado tempo utilizando a função básica `plot()` que desenha a "curva Kaplan-Meier". Em outras palavras, a curva abaixo é uma ilustração convencional da experiência de sobrevivência em todo o grupo de pacientes.

Podemos verificar rapidamente o tempo de seguimento mínimo e máximo na curva.

Uma maneira fácil de interpretar é dizer que no tempo zero, todos os participantes ainda estão vivos e a probabilidade de sobrevivência é então de 100%. Esta probabilidade diminui com o tempo, à medida que os pacientes morrem. A proporção de participantes que sobrevivem nos últimos 60 dias de seguimento é de cerca de 40%.

```{r }

plot(linelistsurv_fit, 
     xlab = "Days of follow-up",    # nome eixo X
     ylab="Survival Probability",   # nome eixo Y
     main= "Overall survival curve" # título da figura
     )

```

O intervalo de confiança das estimativas de sobrevivência do KM também são traçados por padrão e podem ser descartados adicionando a opção `conf.int = FALSE` ao comando `plot()`.

Uma vez que o evento de interesse é "óbito", desenhar uma curva descrevendo os complementos das proporções de sobrevivência levará a desenhar as proporções de mortalidade acumulada. Isto pode ser feito com `lines()`, o que acrescenta informação a uma parcela existente.

```{r}

# gráfico original
plot(
  linelistsurv_fit,
  xlab = "Dias de seguimento",       
  ylab = "Probabilidade de Sobrevivência",       
  mark.time = TRUE,               # marcar eventos na curva: um "+" é impresso em cada evento
  conf.int = FALSE,              # não traçar o intervalo de confiança
  main = "Curva geral de sobrevivência e mortalidade acumulada"
  )

# desenhar uma curva adicional ao gráfico anterior
lines(
  linelistsurv_fit,
  lty = 3,             # usar tipo de linha diferente para maior clareza
  fun = "event",       # desenhar os eventos cumulativos em vez da sobrevivência
  mark.time = FALSE,
  conf.int = FALSE
  )

# adiciona legenda ao gráfico
legend(
  "topright",                                       # posição da legenda
  legend = c("Sobrevivência", "Mortalidade Acum."), # texto da legenda
  lty = c(1, 3),                                    # tipos de linha a serem usados na legenda
  cex = .85,                                        # parâmetros que definem o tamanho do texto da legenda
  bty = "n"                                         # nenhum tipo de caixa a ser desenhada para a legenda
  )

```

<!-- ======================================================= -->

## Comparação de curvas de sobrevivência

Para comparar a sobrevivência dentro de diferentes grupos dos nossos participantes ou pacientes observados, podemos ter de olhar primeiro para as suas respectivas curvas de sobrevivência e depois fazer testes para avaliar a diferença entre grupos independentes. Esta comparação pode dizer respeito a grupos baseados no sexo, idade, tratamento, comorbidade...

### Teste de classificação de registo {.unnumbered}

O teste de log-rank é um teste popular que compara toda a experiência de sobrevivência entre dois ou mais grupos *independentes* e pode ser pensado como um teste para verificar se as curvas de sobrevivência são idênticas (sobreposição) ou não (hipótese nula de não haver diferença na sobrevivência entre os grupos). A função `survdiff()` do pacote **survival** permite executar o teste de log-rank quando especificamos `rho = 0` (que é o padrão). Os resultados do teste dão uma estatística de qui-quadrado juntamente com um p-valor, uma vez que a estatística de classificação logarítmica é distribuída aproximadamente como uma estatística de teste de qui-quadrado.

Tentamos primeiro comparar as curvas de sobrevivência por grupo de gênero. Para tal, tentamos primeiro visualizá-la (verificar se as duas curvas de sobrevivência estão sobrepostas). Um novo objeto *survfit* será criado com uma fórmula ligeiramente diferente. Depois será criado o objeto *survdiff*.

Ao fornecer `~ gender` como o lado direito da fórmula, deixamos de traçar a sobrevivência global e passamos a fazê-lo por gênero.

```{r comp_surv, warning=FALSE}

# criar um novo objeto do tipo survfit baseado no gênero
linelistsurv_fit_sex <-  survfit(Surv(futime, event) ~ gender, data = linelist_surv)
```

Agora podemos traçar as curvas de sobrevivência por gênero. Veja a *ordem* dos níveis de estratos na coluna do gênero antes de definir as suas cores e legendas.

```{r}
# padrão de cor
col_sex <- c("lightgreen", "darkgreen")

# cria a impressão
plot(
  linelistsurv_fit_sex,
  col = col_sex,
  xlab = "Days of follow-up",
  ylab = "Survival Probability")

# adiciona legenda
legend(
  "topright",
  legend = c("Feminino","Masculino"),
  col = col_sex,
  lty = 1,
  cex = .9,
  bty = "n")
```

E agora podemos calcular o teste da diferença entre as curvas de sobrevivência usando `survdiff ()`

```{r}
# calcula o teste da diferença entre as curvas de sobrevivência
survival::survdiff(
  Surv(futime, event) ~ gender, 
  data = linelist_surv
  )

```

Vemos que a curva de sobrevivência das mulheres e a dos homens se sobrepõem e o teste do log-rank não dá provas de uma diferença de sobrevivência entre mulheres e homens.

Alguns outros pacotes de R permitem ilustrar curvas de sobrevivência para diferentes grupos e testar a diferença de uma só vez. Utilizando a função `ggsurvplot()` do pacote **survminer**, podemos também incluir na nossa curva as tabelas de risco impressas para cada grupo, bem como o valor p do teste de log-rank.

[**CUIDADO:** funções **survminer** requerem que se especifique o objeto de sobrevivência *e* novamente os dados utilizados para encaixar o objeto de sobrevivência. Lembre-se de fazer isto para evitar mensagens de erro não específicas].{style="color: orange;"}

```{r, warning=F, message=F}

survminer::ggsurvplot(
    linelistsurv_fit_sex, 
    data = linelist_surv,          # novamente especificar o dado usado para encaixar linelistsurv_fit_sex 
    conf.int = FALSE,              # não mostrar o intervalo de confiança da estimativa KM
    surv.scale = "percent",        # apresentar probabilidades no eixo Y em %
    break.time.by = 10,            # apresentar o eixo de tempo com um incremento de 10 dias
    xlab = "Follow-up days",
    ylab = "Survival Probability",
    pval = T,                      # adicionar o p-valor do teste Log-rank 
    pval.coord = c(40,.91),        # adicionar o p-valor às coordenadas especificadas
    risk.table = T,                # imprimir a tabela de risco no fundo  
    legend.title = "Gender",       # características da legenda
    legend.labs = c("Female","Male"),
    font.legend = 10, 
    palette = "Dark2",             # especificar paleta de cores 
    surv.median.line = "hv",       # desenhar linhas horizontais e verticais para a mediana de sobrevivência
    ggtheme = theme_light()        # simplificar o plano de fundo da impressão
)

```

Também podemos querer testar diferenças na sobrevivência pela fonte de infecção (fonte de contaminação).

Neste caso, o teste de Log rank dá provas suficientes de uma diferença nas probabilidades de sobrevivência em `alpha= 0,005`. As probabilidades de sobrevivência de pacientes que foram infectados em funerais são superiores às probabilidades de sobrevivência de pacientes que foram infectados em outros locais, sugerindo um benefício de sobrevivência.

```{r}

linelistsurv_fit_source <-  survfit(
  Surv(futime, event) ~ source,
  data = linelist_surv
  )

# impressão
ggsurvplot( 
  linelistsurv_fit_source,
  data = linelist_surv,
  size = 1, linetype = "strata",   # tipos de linhas
  conf.int = T,
  surv.scale = "percent",  
  break.time.by = 10, 
  xlab = "Follow-up days",
  ylab= "Survival Probability",
  pval = T,
  pval.coord = c(40,.91),
  risk.table = T,
  legend.title = "Source of \ninfection",
  legend.labs = c("Funeral", "Other"),
  font.legend = 10,
  palette = c("#E7B800","#3E606F"),
  surv.median.line = "hv", 
  ggtheme = theme_light()
)

```

<!-- ======================================================= -->

## Análise de regressão de Cox

O modelo de riscos proporcionais de Cox é uma das técnicas de regressão mais populares para a análise de sobrevivência. Outros modelos também podem ser utilizados, uma vez que o modelo Cox requer *importantes pressupostos* que precisam ser verificados para uma utilização adequada, tal como o pressuposto dos riscos proporcionais: ver referências.

Num modelo de riscos proporcionais de Cox, a medida do efeito é a **taxa de risco ou razão de riscos**(HR na sigla *Hazard Ratio* em inglês), que é o risco de fracasso (ou o risco de morte no nosso exemplo), dado que o participante sobreviveu até um tempo específico. Normalmente, estamos interessados em comparar *grupos independentes* com respeito aos seus perigos, e utilizamos uma taxa de risco, que é análoga a uma taxa de probabilidade no estabelecimento de uma análise de regressão logística múltipla. A função `cox.ph()` do pacote **survival** é utilizada para se adequar ao modelo. A função `cox.zph()` do pacote **survival** pode ser utilizada para testar a hipótese de riscos proporcionais para um ajuste do modelo de regressão Cox.

<span style="color: black;">**NOTA:** A probabilidade deve estar no intervalo de 0 a 1. No entanto, o perigo representa o número esperado de eventos por uma unidade de tempo.

-   Se a razão de perigo para um preditor for próxima de 1, então esse preditor não afeta a sobrevivência,
-   se o HR for inferior a 1, então o preditor é protetor (ou seja, associado a uma melhor sobrevivência),
-   e se a FC for superior a 1, então o preditor está associado ao aumento do risco (ou diminuição da sobrevivência).</span>

### Ajuste de um modelo Cox {.unnumbered}

Podemos primeiro ajustar um modelo para avaliar o efeito da idade e do gênero na sobrevivência. Ao imprimir apenas o modelo, temos a informação sobre:

-   os coeficientes de regressão estimados "coef" que quantificam a associação entre os preditores e o resultado,
-   a sua exponencial (para interpretabilidade, `exp(coef)`) que produz a *razão de riscos HR*,
-   o seu erro padrão `se(coef)`,
-   o z-score: quantos erros padrão é o coeficiente estimado a partir de 0,
-   e o p-valor: a probabilidade de o coeficiente estimado poder ser 0.

A função `summary()` aplicada ao objeto modelo Cox dá mais informações, tais como o intervalo de confiança do HR estimado e os diferentes resultados do teste.

O efeito da primeira covariável "gênero" é apresentado na primeira linha. O `genderm` (masculino) é mostrado indicando que o primeiro nível de estratos ("f"), ou seja, o grupo feminino, é o grupo de referência para as comparações dentro do gênero. Assim, a interpretação do parâmetro de teste é a dos homens em comparação com a das mulheres. O p-valor indica que não havia evidências suficientes de um efeito do gênero sobre o risco esperado ou de uma associação entre o gênero e a mortalidade por todas as causas.

A mesma falta de evidências é notada no que diz respeito ao grupo etário.

```{r coxmodel_agesex}

# ajustando o modelo cox
linelistsurv_cox_sexage <-  survival::coxph(
              Surv(futime, event) ~ gender + age_cat_small, 
              data = linelist_surv
              )


#imprimindo o modelo ajustado
linelistsurv_cox_sexage


#resumo do modelo
summary(linelistsurv_cox_sexage)

```

Foi interessante executar o modelo e olhar para os resultados, mas um primeiro olhar para verificar se os pressupostos de riscos proporcionais são respeitados poderia ajudar a poupar tempo.

```{r test_assumption}

test_ph_sexage <- survival::cox.zph(linelistsurv_cox_sexage)
test_ph_sexage

```

[**NOTA:** Um segundo argumento da função chamado *method* pode ser especificado ao calcular o modelo cox, que determina como os empates são tratados. O *padrão* é "efron", e as outras opções são "breslow" e "exact".]{style="color: black;"}

Num outro modelo, adicionamos mais fatores de risco, tais como a fonte da infecção e o número de dias entre a data de início e a admissão. Desta vez, verificamos primeiro a hipótese de riscos proporcionais antes de avançarmos.

Neste modelo, incluímos um preditor contínuo (`days_onset_hosp`). Neste caso, interpretamos as estimativas dos parâmetros como o aumento do registo esperado do risco relativo para cada aumento de uma unidade no preditor, mantendo constantes outros preditores. Primeiro verificamos a suposição de perigos proporcionais.

```{r coxmodel_fit_ph,  message=FALSE}

#cria o modelo
linelistsurv_cox <-  coxph(
                        Surv(futime, event) ~ gender + age_years+ source + days_onset_hosp,
                        data = linelist_surv
                        )


#testa o modelo de risco proporcional
linelistsurv_ph_test <- cox.zph(linelistsurv_cox)
linelistsurv_ph_test
```

A verificação gráfica desta hipótese pode ser realizada com a função `ggcoxzph()` do pacote **survminer**.

```{r}
survminer::ggcoxzph(linelistsurv_ph_test)

```

Os resultados do modelo indicam a existência de uma associação negativa entre o início da duração da admissão e a mortalidade por todas as causas. O risco esperado é 0,9 vezes menor numa pessoa que é admitida um dia mais tarde do que outra, mantendo constante o gênero. Ou, numa explicação mais direta, um aumento de uma unidade na duração do início da admissão está associado a uma diminuição de 10,7% (`coef *100`) no risco de morte.

Os resultados mostram também uma associação positiva entre a fonte da infecção e a mortalidade por todas as causas. Ou seja, há um aumento do risco de morte (1,21x) para os pacientes que têm outra fonte de infecção.

```{r coxmodel_summary,  message=FALSE}

#resumo do modelo
summary(linelistsurv_cox)

```

Podemos verificar essa relação com a tabela:

```{r}
linelist_case_data %>% 
  tabyl(days_onset_hosp, outcome) %>% 
  adorn_percentages() %>%  
  adorn_pct_formatting()

```

Teríamos de considerar e investigar porque é que esta associação existe nos dados. Uma explicação possível poderia ser que os pacientes que vivem o tempo suficiente para serem admitidos mais tarde, tem uma doença menos grave. Outra explicação talvez mais provável é que, uma vez que utilizámos um conjunto de dados falso simulado, este padrão não reflete a realidade!

<!-- ======================================================= -->

### Gráficos em floresta (Forest plots) {.unnumbered}

Podemos visualizar os resultados do modelo Cox usando "forest plots" com a função `ggforest()` do pacote **survminer**.

```{r forestp}

ggforest(linelistsurv_cox, data = linelist_surv)

```

<!-- ======================================================= -->

## Covariáveis dependentes do tempo em modelos de sobrevivência

Algumas das seções seguintes foram adaptadas com permissão de uma excelente [introdução à análise de sobrevivência em R](https://www.emilyzabor.com/tutorials/survival_analysis_in_r_tutorial.html) pela [Dra. Emily Zabor](https://www.emilyzabor.com/)

Na última seção usamos a regressão Cox para examinar associações entre covariáveis de interesse e resultados de sobrevivência. Mas estas análises dependem da covariância ser medida na linha de base, ou seja, antes do tempo de seguimento do evento começar.

O que acontece se estiver interessado em uma covariável que é medida **após** o início do tempo de seguimento? Ou, e se uma dessas covariáveis possa mudar ao longo do tempo?

Por exemplo, talvez esteja trabalhando com dados clínicos onde repetiu medidas de valores laboratoriais hospitalares que podem mudar ao longo do tempo. Este é um exemplo de uma **Covariável Dependente do Tempo**. Para resolver este problema é necessário uma configuração especial, mas felizmente o modelo cox é muito flexível e este tipo de dados também pode ser modelado com ferramentas do pacote **survival**.

### Configuração de covariável dependente do tempo {.unnumbered}

A análise de covariáveis dependentes do tempo em R requer a configuração de um conjunto de dados especial. Se estiver interessado, ver o artigo mais detalhado sobre este assunto do autor do pacote **survival** [Using Time Dependent Covariates and Time Dependent Coefficients in the Cox Model](https://cran.r-project.org/web/packages/survival/vignettes/timedep.pdf).

Para tal, utilizaremos um novo conjunto de dados do pacote `SemiCompRisks' chamado `BMT', que inclui dados sobre 137 pacientes de transplante de medula óssea. As variáveis em que nos vamos concentrar são:

-   `T1` - tempo (em dias) até à morte ou último seguimento\

-   `delta1` - indicador de óbito; 1-Óbito, 0-Vivos\

-   `TA` - tempo (em dias) até à doença aguda de enxerto-versus-hospedeiro\

-   `deltaA` - indicador de doença aguda de enxerto-versus-hospedeiro;

    -   1 - desenvolveu a doença aguda de enxerto-versus-hospedeiro\
    -   0 - Nunca desenvolveu doença aguda de enxerto-versus-hospedeiro

Vamos carregar este conjunto de dados a partir do pacote **survival** utilizando o comando do R **base** `data()`, que pode ser utilizado para carregar dados que já estão incluídos num pacote R que é carregado. A moldura de dados `BMT` irá aparecer no seu ambiente R.

```{r}
data(BMT, package = "SemiCompRisks")
```

#### Adicionar identificador único de doente {.unnumbered}

Não existe uma coluna de ID única nos dados `BMT`, que é necessária para criar o tipo de conjunto de dados que desejamos. Assim, utilizamos a função `rowid_to_column()` do pacote **tidyverse** para criar uma nova coluna de id chamada `my_id` (adiciona coluna no início do Data Frame com ids sequenciais de linha, começando em 1). Nomeamos o data frame como `bmt`.

```{r}
bmt <- rowid_to_column(BMT, "my_id")
```

O conjunto de dados tem agora este aspecto:

```{r message=FALSE, echo=F}
DT::datatable(bmt, rownames = FALSE, options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```

#### Expandir as linhas de pacientes {.unnumbered}

A seguir, utilizaremos a função `tmerge()` com as funções auxiliares `event()` e `tdc()` helper para criar o conjunto de dados reestruturado. Neste caso, cada paciente pode ter no máximo duas linhas, dependendo se desenvolveu doença aguda de enxerto-versus-hospedeiro durante o período de coleta de dados. Vamos chamar o nosso novo indicador para o desenvolvimento da doença aguda de enxerto-versus-hospedeiro `agvhd`.

-   `tmerge()` cria um longo conjunto de dados com múltiplos intervalos de tempo para os diferentes valores covariados para cada paciente
-   `event()` cria o novo indicador de evento para combinar com os intervalos de tempo recém-criados
-   `tdc()` cria a coluna covariada dependente do tempo, `agvhd`, para combinar com os intervalos de tempo recém-criados

```{r}
td_dat <- 
  tmerge(
    data1 = bmt %>% select(my_id, T1, delta1), 
    data2 = bmt %>% select(my_id, T1, delta1, TA, deltaA), 
    id = my_id, 
    death = event(T1, delta1),
    agvhd = tdc(TA)
    )
```

Para ver o que foi feito, vamos olhar os dados dos primeiros 5 pacientes.

As variáveis de interesse do dado original terão essa aparência:

```{r}
bmt %>% 
  select(my_id, T1, delta1, TA, deltaA) %>% 
  filter(my_id %in% seq(1, 5))
```

O novo conjunto de dados para esses pacientes terá essa aparência:

```{r}
td_dat %>% 
  filter(my_id %in% seq(1, 5))
```

Agora alguns dos nossos pacientes têm duas linhas no conjunto de dados correspondentes a intervalos em que têm um valor diferente da nossa nova variável, `agvhd`. Por exemplo, o Paciente 1 tem agora duas linhas com um valor `agvhd` de zero do tempo 0 ao tempo 67, e um valor de 1 do tempo 67 ao tempo 2081.

### Regressão Cox com covariáveis dependentes do tempo {.unnumbered}

Agora que remodelamos os nossos dados e acrescentamos a nova variável dependente do tempo `aghvd` , vamos encaixar um modelo simples de regressão de uma única variável cox. Podemos utilizar a mesma função `coxph()` como antes, só precisamos alterar a nossa função `Surv()` para especificar tanto o tempo de início como o tempo de paragem para cada intervalo utilizando os argumentos `time1 =` e `time2 =`.

```{r}
bmt_td_model = coxph(
  Surv(time = tstart, time2 = tstop, event = death) ~ agvhd, 
  data = td_dat
  )

summary(bmt_td_model)
```

Novamente vamos visualizar o resultado do nosso modelo cox usando a função `ggforest()` do pacote **survminer**.:

```{r}

ggforest(bmt_td_model, data = td_dat)

```

Como se pode ver pela "forest plot", intervalo de confiança e p-valor, não parece haver forte associação entre ocorrência de óbito e a doença aguda do enxerto-versus-hospedeiro no contexto do nosso modelo simples.

<!-- ======================================================= -->

## Referências

[Survival Analysis Part I: Basic concepts and first analyses](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2394262/)

[Análise de sobrevivência no R](https://www.emilyzabor.com/tutorials/survival_analysis_in_r_tutorial.html)

[Survival analysis in infectious disease research: Describing events in time](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2954271/)

[Chapter on advanced survival models Princeton](https://data.princeton.edu/wws509/notes/c7.pdf)

[Using Time Dependent Covariates and Time Dependent Coefficients in the Cox Model](https://cran.r-project.org/web/packages/survival/vignettes/timedep.pdf)

[Cheatsheet (cola) de análise de sobrevivência](https://publicifsv.sund.ku.dk/~ts/survival/survival-cheat.pdf)

[Cheatsheet (cole) do Survminer ](https://paulvanderlaken.files.wordpress.com/2017/08/survminer_cheatsheet.pdf)

[Paper on different survival measures for cancer registry data with Rcode provided as supplementary materials](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6322561/)
```{r include=FALSE, cache=FALSE}

# clear workspace
rm(list = ls(all = TRUE))

# clear all packages except base
#lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))

# to ensure that tidyverse packages prevail
filter <- dplyr::filter
select <- dplyr::select
summarise <- dplyr::summarise
summary <- base::summary
incidence <- incidence2::incidence

#load core packages
pacman::p_load(
     rio,
     here,
     DT,
     stringr,
     lubridate,
     tidyverse
)

# import the cleaned ebola linelist
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

# import the count data - facility level
#count_data <- rio::import(here::here("data", "facility_count_data.rds"))

# Settings

options(scipen=1, digits=7)

# print only text (not code)
# library(knitr)
# opts_chunk$set(list(echo = FALSE, eval = FALSE))
```

<!--chapter:end:new_pages/survival_analysis.Rmd-->

# (PART) Visualização de Dados {.unnumbered}
```{r include=FALSE, cache=FALSE}

# clear workspace
rm(list = ls(all = TRUE))

# clear all packages except base
#lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))

# to ensure that tidyverse packages prevail
filter <- dplyr::filter
select <- dplyr::select
summarise <- dplyr::summarise
summary <- base::summary
incidence <- incidence2::incidence

#load core packages
pacman::p_load(
     rio,
     here,
     DT,
     stringr,
     lubridate,
     tidyverse
)

# import the cleaned ebola linelist
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

# import the count data - facility level
#count_data <- rio::import(here::here("data", "facility_count_data.rds"))

# Settings

options(scipen=1, digits=7)

# print only text (not code)
# library(knitr)
# opts_chunk$set(list(echo = FALSE, eval = FALSE))
```

<!--chapter:end:new_pages/cat_data_viz.Rmd-->


# Tabelas para apresentação {#tables-presentation}  


```{r echo=FALSE, fig.show='hold', message=FALSE, warning=FALSE, out.width=c('50%', '50%')}

linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds")) 

border_style = officer::fp_border(color="black", width=1)

pacman::p_load(
  rio,            # importar/exportar
  here,           # caminho do arquivo
  flextable,      # fazer tabelas HTML 
  officer,        # Funções auxiliares para tabelas
  tidyverse)      # visualização, resumo e gerenciamento dos dados

width <- flextable::width


table <- linelist %>% 
  # filtro
  ########
  #filtro(!is.na(outcome) & hospital != "Missing") %>%  # Remove casos com desfecho ou hospital faltante
  
  # Obter valores resumidos por grupo hospital-resultado
  ###############################################
  group_by(hospital, outcome) %>%                      # Dados por grupo
  summarise(                                           # Criar novas colunas resumidas de indicadores de interesse
    N = n(),                                            # Numero de linhas por grupo hospital-resultado     
    ct_value = median(ct_blood, na.rm=T)) %>%           # mediana limiares de ciclo (CT) por grupo
  
  # Adicionando Totais
  ############
  bind_rows(                                           # Vincular as tabelas prévias com esta mini-tabela de totais
    linelist %>% 
      filter(!is.na(outcome) & hospital != "Missing") %>%
      group_by(outcome) %>%                            # Agrupar somente pelo resultado, não pelo hospital    
      summarise(
        N = n(),                                       # Número de linhas para conjunto de dados total     
        ct_value = median(ct_blood, na.rm=T))) %>%     # Mediana de CT para conjunto de dados total  
  
  # Dados dinâmicos 
  ########################
  mutate(hospital = replace_na(hospital, "Total")) %>% 
  pivot_wider(                                         # Colunas longas e amplas
    values_from = c(ct_value, N),                       # novos valores de CT e colunas de contagem
    names_from = outcome) %>%                           # novos nomes da colunas são de resultados
  mutate(                                              # Adicionar novas colunas
    N_Known = N_Death + N_Recover,                               # número com resultados conhecidos
    Pct_Death = scales::percent(N_Death / N_Known, 0.1),         # porcentagem de casos de óbito (com 1 casa decimal)
    Pct_Recover = scales::percent(N_Recover / N_Known, 0.1)) %>% # porcentagem dos reuperados (com 1 casa decimal)
  select(                                              # Reordenar as colunas
    hospital, N_Known,                                   # Colunas introdutórias
    N_Recover, Pct_Recover, ct_value_Recover,            # Coluna dos recuperados
    N_Death, Pct_Death, ct_value_Death)  %>%             # Coluna de óbitos
  arrange(N_Known) %>%                                 # Organizar linhas da mais alta para mais baixa (linha superior a linha Total)

  # formatação
  ############
  flextable() %>% 
  add_header_row(
    top = TRUE,                # Novo cabeçalho colocado acima da linha do cabeçalho existente
    values = c("Hospital",     # Valores dos cabeçalhos para cada coluna abaixo
               "Total de casos com desfecho conhecido", 
               "Recuperados",    # Este será o nome que ocupará esta coluna e as duas seguintes
               "",
               "",
               "Óbito",         # Este será o nome que ocupará esta coluna e as duas seguintes
               "",             # Deixar em branco, essa coluna sera mesclada com a coluna Óbito"
               "")) %>% 
    set_header_labels(         # Renomear as colunas na linha original do cabeçalho
      hospital = "", 
      N_Known = "",                  
      N_Recover = "Total",
      Pct_Recover = "% de casos",
      ct_value_Recover = "Mediana de valores CT",
      N_Death = "Total",
      Pct_Death = "% de casos",
      ct_value_Death = "Mediana de valores CT")  %>% 
  merge_at(i = 1, j = 3:5, part = "header") %>% # Mesclar horizontalmente colunas 3 a 5 in nova linha do cabeçalho
  merge_at(i = 1, j = 6:8, part = "header") %>%  
  border_remove() %>%  
  theme_booktabs() %>% 
  vline(part = "all", j = 2, border = border_style) %>%   # na coluna 2 
  vline(part = "all", j = 5, border = border_style) %>%   # na coluna 5
  merge_at(i = 1:2, j = 1, part = "header") %>% 
  merge_at(i = 1:2, j = 2, part = "header") %>% 
  width(j=1, width = 2.7) %>% 
  width(j=2, width = 1.5) %>% 
  width(j=c(4,5,7,8), width = 1) %>% 
  flextable::align(., align = "center", j = c(2:8), part = "all") %>% 
  bg(., part = "body", bg = "gray95")  %>% 
  #bg(., j=c(1:8), i= ~ hospital == "Military Hospital", part = "body", bg = "#91c293") %>% 
  bg(j = 7, i = ~ Pct_Death >= 55, part = "body", bg = "red") %>% 
  colformat_num(., j = c(4,7), digits = 1) %>%
  bold(i = 1, bold = TRUE, part = "header") %>% 
  bold(i = 7, bold = TRUE, part = "body")

table
```


Esta seção demonstra como converter *data frames* resumo dos seus dados em tabelas prontas para apresentação com o uso do pacote **flextable**. Estas tabelas podem ser inseridas em slides do programa powerpoint, em páginas HTML ou documentos em formatos PDF ou Word, entre outros.

É preciso compreender que, *antes* de usar o pacote **flextable**, você deve criar a tabela resumida como um data frame. Você pode utilizar os métodos das [Tabelas Descritivas](#tables-descriptive) ou [Pivoteando dados](#pivoting), tais como: tabulações, tabulações cruzadas, pivotamento e calcular estatísticas descritivas. O data frame resultantes pode então ser utilizado na função **flextable** para formatar a visualização. 

Há muitos outros pacotes R que podem ser usados para elaborar tabelas para apresentação – aqui, nós escolhemos destacar o pacote “flextable” nesta seção. Um exemplo usando o pacote **knitr** e sua função `kable()` pode ser encontrado na página de [Rastreamento de Contatos](#contact-tracing). Da mesma maneira, o pacote **DT** é evidenciado na seção de [Paineis com Shiny](#shiny-basics). Outros programas, tais como o **GT** e o **huxtable** são mencionados na página de pacotes sugeridos [Pacotes sugeridos](#packages-suggested).


<!-- ======================================================= -->
## Preparação {  }

### Carregando pacotes {.unnumbered} 

Instalar e carregar o pacote **flextable**. Neste manual, nós destacamos o `p_load()` do **pacman**, o qual instala o pacote, se necessário, *e* o carrega para ser utilizado. Você também pode carregar os pacotes com `library()` presente no R **base**. Veja a seção sobre [Introdução ao R](#basics) para obter mais informações sobre os pacotes “R”.


```{r}
pacman::p_load(
  rio,            # importar/exportar
  here,           # caminho do arquivo
  flextable,      # fazer tabelas HTML 
  officer,        # Funções auxiliares para tabelas
  tidyverse)      # visualização, resumo e gerenciamento dos dados 

```

### Importando dados {.unnumbered}  

Para começar, nós importamos a *linelist* dos casos que simulam uma epidemia de Ebola. Se você quiser acompanhar, <a href='https://github.com/epirhandbook/Epi_R_handbook/raw/master/data/case_linelists/linelist_cleaned.rds' class='download-button'> clique para baixar o "clean "linelist </a> (como arquivo .rds). Importe dados com a função `import()` do pacote **rio** (ele trabalho com vários tipos de arquivo, tais como: .xlsx, .csv, .rds - você pode visualizar a seção [Importar e exportar](#importing) para outros detalhes).


```{r, echo=F}
#importar a lista - linelist dentro R
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))
```

```{r, eval=F}
# importar a linelist
linelist <- import("linelist_cleaned.rds")
```

As primeiras 50 linhas da linelist estão exibidas abaixo:

```{r, message=FALSE, echo=F}
# exibir os dados da lista lista - linelist como tabela
DT::datatable(head(linelist, 50), rownames = FALSE, filter="top", options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```

### Preparar a tabela {.unnumbered}  

*Antes* de começar a utilizar o pacote **flextable** você precisará *criar* a sua tabela como um data frame. Veja a seção em [Tabelas descritivas](#tables-descriptive) e [Pivotando dados](#pivoting) para aprender a criar um quadro de dados utilizando pacotes como **janitor*** e **dplyr***. 
Você deverá organizar o conteúdo em linhas e colunas conforme você queira que seja exibido. Então,  o conjunto de dados será passado para o comando **flextable*** para ser exibido com cores, cabeçalhos, fontes, etc. 
 
Abaixo está um exemplo da página [Tabelas descritivas](#tables-descriptive) de conversão dos casos na `linelist` dentro de um conjunto de dados que resume os resultados dos pacientes e os valores de CT (limiar de detecção, da sigla em inglês "cycle threshold") por hospital, com uma linha de Totais na parte inferior. A saída é salva como o objeto `table`.


```{r message=FALSE, warning=FALSE}
table <- linelist %>% 
  
  # Obter valores resumidos por grupo hospital-resultado
  ###############################################
  group_by(hospital, outcome) %>%                      # Dados por grupo
  summarise(                                           # Criar novas colunas resumidas de indicadores de interessse
    N = n(),                                           # Numero de linhas por grupo hospital-resultado   
    ct_value = median(ct_blood, na.rm=T)) %>%          # mediana do valor de TC por grupo

  
  # add totals
  ############
  bind_rows(                                           # Vincular as tabelas prévias com esta mini-tabela de totais    
  linelist %>% 
      filter(!is.na(outcome) & hospital != "Missing") %>%
      group_by(outcome) %>%                            # Agrupar somente pelo resultado, não pelo hospital    
      summarise(
        N = n(),                                       # Número de linhas para conjunto de dados total     
        ct_value = median(ct_blood, na.rm=T))) %>%     # Mediana de CT para conjunto de dados total
  
   # Pivot wider and format
  ########################
  mutate(hospital = replace_na(hospital, "Total")) %>% 
  pivot_wider(                                         # Colunas longas e amplas
    values_from = c(ct_value, N),                      # novos valores de CT e colunas de contagem
    names_from = outcome) %>%                          # novos nomes da colunas são de resultados
  mutate(                                              # Adicionar novas colunas
    N_Known = N_Death + N_Recover,                               # número com resultados conhecidos
    Pct_Death = scales::percent(N_Death / N_Known, 0.1),         # porcentagem de casos de óbitos (com 1 casa decimal)
    Pct_Recover = scales::percent(N_Recover / N_Known, 0.1)) %>% # porcentagem dos reuperados (com 1 casa decimal)
  select(                                              # Reordenar as colunas
    hospital, N_Known,                                   # Colunas introdutórias
    N_Recover, Pct_Recover, ct_value_Recover,            # Coluna dos recuperados
    N_Death, Pct_Death, ct_value_Death)  %>%             # Coluna de óbitos
  arrange(N_Known)                                    # Organizar linhas da mais alta para mais baixa (linha superior a linha Total)

table  # impressão

```

<!-- ======================================================= -->
## Básico do flextable {  }

### Criar um flextable {.unnumbered}  

Para criar e gerenciar os objetos do comando **flextable**, passamos primeiro o conjunto de dados por meio da função `flextable()`. Nós salvamos os resultados como `my_table`.  

```{r}

my_table <- flextable(table) 
my_table

```

Após ter feito isso, podemos progresssivamente vincular o objeto `my_table` por meio de outras funções de formatação **flextable**.  

Nesta página, por uma questão de clareza, nós devemos salvar a tabela em níveis intermediários como `my_table`, e adicionando as funções **flextable**  uma a uma. Se você quiser ver uma parte de *todos* os comandos escritos do início ao fim, visite a seção logo abaixo [Todos os códigos juntos](#tbl_pres_all).  

A sintaxe geral de cada linha de comando **flextable*** é a seguinte:


* `função(tabela, i = X, j = X, part = "X")`, onde:
  * A 'função' pode ser uma das das muitas funções diferentes, tais como `width()` para determinar a largura de colunas, `bg()` para definir as cores do plano de fundo, `align()` para ajustar o alinhamento do texto centro/direita/esquerda, e assim por diante. 
  *  `tabela = ` é o nome do seu conjunto de dados, embora não precise estar explícita, se a sua data frame estiver escadeada com um pipe (%>%) à função.
  *   `part = `  se refere em qual parte da tabela a função deverá ser aplicada. Por exemplo, "cabeçalho", "corpo" ou "todos", ("header", "body" ou "all"). 
  *    `i = ` especifica  a linha (*row*) para aplicar a função, onde 'X' é o número da linha. Se há linhas múltiplas, por exemplo, da primeira a terceira linha,  pode especificar: `i = c(1:3)`. Observe que se o corpo estiver selecionado ('body'), a primeira linha começa a ser contada abaixo do cabeçalho.
  *     `j = ` especifica a coluna a qual aplicar função, onde 'x' é o número ou nome das colunas. Se houver colunas multiplas, por exemplo, da quinta e à sexta colunas, pode-se especificar: `j = c(5,6)`. 
  
Você pode encontrar a lista completa das funções de formatação do comando **flextable** clique [aqui](https://davidgohel.github.io/flextable/reference/index.html) ou revisar a documentação inserindo `?flextable`.  

### Largura das colunas {.unnumbered}

Nós podemos usar a função `autofit()`, para expandir a tabela para que cada célula tenha somente uma linha de texto. A função `qflextable()` é uma abreviação mais simples para `flextable()` and `autofit()`.

```{r}

my_table %>% autofit()

```

No entanto, nem sempre isto poderá ser apropriado, principalmente se houver valores muito longos dentro das células, o que significa que a tabela pode não ter o tamanho da página.

Por isso, podemos especificar larguras com a função `width ()`. Isto pode ser feito arredondando um pouco para saber qual valor de largura inserir. No exemplo abaixo, especificamos larguras diferentes para cada coluna 1, coluna 2 e colunas 4 a 8.


```{r}

my_table <- my_table %>% 
  width(j=1, width = 2.7) %>% 
  width(j=2, width = 1.5) %>% 
  width(j=c(4,5,7,8), width = 1)

my_table
  
```

### Cabeçalhos/Títulos das colunas {.unnumbered}

Queremos cabeçalhos mais simples para facilitar a interpretação do conteúdo das tabelas.

Para esta tabela, queremos acrescentar uma segunda camada do cabeçalho para que as colunas que cobrem os mesmos subgrupos possam ser agrupadas. Nós fazemos isto usando a função `add_header_row()` com `top = TRUE`. Nós colocamos o novo nome de cada coluna para valores usando o comando `values = `, e para deixar colunas com valores vazios use `""` que sabemos que iremos mesclar mais tarde.

Nós também podemos renomear os nomes do cabeçalho em um segundo nível de cabeçalho usando um comando separado `set_header_labels()`.  

Finalmente, para "combinar" certos cabeçalhos das colunas no cabeçalho superior, utilizamos o comando `merge_at()` para mesclar os cabeçalhos da coluna na linha do cabeçalho superior. 


```{r}
my_table <- my_table %>% 
  
  add_header_row(
    top = TRUE,                # Novo cabeçalho posicionado acima da linha do cabeçalho existente
    values = c("Hospital",     # Valores dos cabeçalhos para cada coluna abaixo
               "Total de casos com desfecho conhecido", 
               "Recuperado",    # este será o nome desta coluna e das duas seguintes 
               "",
               "",
               "Óbitos",         # este será o nome desta coluna e das duas seguintes 
               "",             # Deixar em branco, essa coluna sera mesclada com a coluna óbitos 
               "")) %>% 
    
  set_header_labels(         # Renomear as colunas na linha original do cabeçalho
   
      hospital = "", 
      N_Known = "",                  
      N_Recover = "Total",
      Pct_Recover = "% de casos",
      ct_value_Recover = "Mediana dos valores CT",
      N_Death = "Total",
      Pct_Death = "% de casos",
      ct_value_Death = "Mediana dos valores C")  %>% 
  
  merge_at(i = 1, j = 3:5, part = "header") %>%   # Mesclar horizontalmente colunas 3 a 5 na nova linha do cabeçalho
  merge_at(i = 1, j = 6:8, part = "header")       # Mesclar horizontalmente colunas 6 a 8 na nova linha do cabeçalho

my_table  # visualizar

```

### Bordas e plano de fundo {.unnumbered}  

Você pode ajustar as bordas, linhas internas, entre outros, com várias funções do comando **flextable**.  Freqüentemente, é mais fácil começar removendo todas as bordas existentes com `border_remove()`.  

Depois, você pode aplicar os temas de borda padrão com as funções  `theme_box()`, `theme_booktabs()`, ou `theme_alafoli()`.  

Linhas verticais e horizontais poderão ser adicionadas com uma variedade de funções. Os comandos `hline()` e `vline()` , adicionam linhas a uma linha ou coluna especificada, respectivamente. Dentro de cada uma, você deve especificar a `part = ` como "all" (tudo), "body" (corpo da tabela), ou "header" (cabeçalho). Para linhas verticais, especificar a coluna para `j = `, e para linhas horizontais, a linha para `i = `. Outras funções como `vline_right()`, `vline_left()`, `hline_top()`, e `hline_bottom()` adicionam linhas apenas na parte externa da tabela.  

Em todas estas funções, o estilo atual para linha deve ser especificado para `border = ` e deve ser a saída de um comando separado utilizando a função `fp_border()` do pacote **officer**. Esta função vai ajudá-lo a definir a largura e a cor da linha. Você poderá definir isto acima dos comandos da tabela, conforme apresentado no script abaixo.

```{r}
# definir estilo pa linha da borda
border_style = officer::fp_border(color="black", width=1)

# adicionar linhas de bordas na tabela
my_table <- my_table %>% 

  # Remover todas as bordas existentes
  border_remove() %>%  
  
  # adicionar linhas por meio de configurações de temas pré-determinados
  theme_booktabs() %>% 
  
  # adcionar linhas verticais para separar seção de Recuperados e Óbitos
  vline(part = "all", j = 2, border = border_style) %>%   # na coluna 2 
  vline(part = "all", j = 5, border = border_style)       # na coluna 5

my_table
```

### Fonte e Alinhamento {.unnumbered}

Alinhamos todas as colunas ao centro, em paralelo a coluna mais à esquerda com os nomes dos hospitais, utilizando a função `align()` de **flextable****.

```{r}
my_table <- my_table %>% 
   flextable::align(align = "center", j = c(2:8), part = "all") 
my_table
```

Ademais, podemos aumentar o tamanho da fonte de cabeçalho e alterá-la para negrito. Também podemos alterar a linha total para negrito.  

```{r}

my_table <-  my_table %>%  
  fontsize(i = 1, size = 12, part = "header") %>%   # ajustar o tamanho da fonte do cabeçalho
  bold(i = 1, bold = TRUE, part = "header") %>%     # colocar o cabeçalho em negrito
  bold(i = 7, bold = TRUE, part = "body")           # ajustar a linha de totais para negrito

my_table

```

Podemos assegurar que as colunas de proporção exibam somente uma casa decimal utilizando a função `colformat_num()`. Observe que isto também poderia ter sido feito na fase de gerenciamento de dados com a função `round()`. 

```{r}
my_table <- colformat_num(my_table, j = c(4,7), digits = 1)
my_table
```

### Células Mescladas {.unnumbered}  

Da mesma forma que mesclamos as células horizontalmente na linha de cabeçalho, também podemos mesclar as  células verticalmente utilizando `merge_at()` e especificando as linhas (`i`) e coluna (`j`). Aqui mesclamos os valores "Hospital" e "Total de casos com desfecho conhecido" verticalmente para lhes dar mais espaço. 

```{r}
my_table <- my_table %>% 
  merge_at(i = 1:2, j = 1, part = "header") %>% 
  merge_at(i = 1:2, j = 2, part = "header")

my_table
```

### Cor do plano de fundo {.unnumbered}

Para distinguir o conteúdo dos cabeçalhos da tabela, podemos acrescentar uma formatação adicional. Por exemplo, mudar a cor do plano de fundo. Neste exemplo, alteramos o corpo da tabela para cinza.



```{r}
my_table <- my_table %>% 
    bg(part = "body", bg = "gray95")  

my_table 
```


<!-- ======================================================= -->
## Formatação condicional {  }

Podemos destacar todos os valores em uma coluna que atendam a uma determinada regra, por exemplo, onde mais de 55% dos casos morreram. Simplesmente insira os critérios no argumento `i =` ou `j =`, precedido por um til `~`. Referencie aos nomes da coluna como são no data frame, não aos valores do cabeçalho que criou para exibição.

```{r}

my_table %>% 
  bg(j = 7, i = ~ Pct_Death >= 55, part = "body", bg = "red") 

```

Ou podemos destacar a linha inteira que cumpra a critério determinado, tais como um hospital de interesse. Para fazer isto, removeremos a especificação da coluna (`j`) para que os critérios sejam aplicados a todas as colunas.

```{r}

my_table %>% 
  bg(., i= ~ hospital == "Military Hospital", part = "body", bg = "#91c293") 

```

## Todos os comandos juntos {#tbl_pres_all}  

Abaixo apresentamos todos os comandos abordados nesta seção:


```{r}  

border_style = officer::fp_border(color="black", width=1)

pacman::p_load(
  rio,            # importar/exportar
  here,           # caminho do arquivo
  flextable,      # fazer tabelas HTML 
  officer,        # Funções auxiliares para tabelas
  tidyverse)      # visualização, resumo e gerenciamento dos dados

table <- linelist %>% 
  # filtro
  ########
  #filtro(!is.na(outcome) & hospital != "Missing") %>%  # Remove casos com desfecho ou hospital vazios
  
  # Obter valores resumidos por grupo hospital-resultado
  ###############################################
  group_by(hospital, outcome) %>%                      # Dados por grupo
  summarise(                                           # Criar novas colunas resumidas de indicadores de interesse
    N = n(),                                           # Numero de linhas por grupo hospital-resultado     
    ct_value = median(ct_blood, na.rm=T)) %>%          # mediana do valor de CT por grupo
  
  # Adicionando Totais
  ############
  bind_rows(                                           # Vincular as tabelas prévias com esta mini-tabela de totais
    linelist %>% 
      filter(!is.na(outcome) & hospital != "Missing") %>%
      group_by(outcome) %>%                            # Agrupar somente pelo resultado, não pelo hospital    
      summarise(
        N = n(),                                       # Número de linhas para conjunto de dados total     
        ct_value = median(ct_blood, na.rm=T))) %>%     # Mediana de CT para conjunto de dados total  
  
  # Dados dinâmicos 
  ########################
  mutate(hospital = replace_na(hospital, "Total")) %>% 
  pivot_wider(                                         # Colunas longas e largas
    values_from = c(ct_value, N),                       # novos valores de CT e colunas de contagem
    names_from = outcome) %>%                           # novos nomes da colunas são de resultados
  mutate(                                              # Adicionar novas colunas
    N_Known = N_Death + N_Recover,                               # número com resultados conhecidos
    Pct_Death = scales::percent(N_Death / N_Known, 0.1),         # porcentagem de casos de óbitos (com 1 casa decimal)
    Pct_Recover = scales::percent(N_Recover / N_Known, 0.1)) %>% # porcentagem dos reuperados (com 1 casa decimal)
  select(                                              # Reordenar as colunas
    hospital, N_Known,                                   # Colunas introdutórias
    N_Recover, Pct_Recover, ct_value_Recover,            # Coluna dos recuperados
    N_Death, Pct_Death, ct_value_Death)  %>%             # Coluna de óbitos
  arrange(N_Known) %>%                                 # Organizar linhas da mais alta para mais baixa (linha superior a linha Total)

  # formatação
  ############
  flextable() %>% 
  add_header_row(
    top = TRUE,                # Novo cabeçalho colocado acima da linha do cabeçalho existente
    values = c("Hospital",     # Valores dos cabeçalhos para cada coluna abaixo
               "Total de casos com desfecho conhecido", 
               "Recuperados",    
               "",
               "",
               "Óbito",        
               "",             # Deixar em branco, essa coluna sera mesclada com a coluna de óbito
               "")) %>% 
    set_header_labels(         # Renomear as colunas na linha original do cabeçalho
      hospital = "", 
      N_Known = "",                  
      N_Recover = "Total",
      Pct_Recover = "% de casos",
      ct_value_Recover = "Mediana de valores CT",
      N_Death = "Total",
      Pct_Death = "% of cases",
      ct_value_Death = "Mediana de valores CT")  %>% 
  merge_at(i = 1, j = 3:5, part = "header") %>% # Mesclar horizontalmente colunas 3 a 5 in nova linha do cabeçalho
  merge_at(i = 1, j = 6:8, part = "header") %>%  
  border_remove() %>%  
  theme_booktabs() %>% 
  vline(part = "all", j = 2, border = border_style) %>%   # na coluna 2 
  vline(part = "all", j = 5, border = border_style) %>%   # na coluna 5
  merge_at(i = 1:2, j = 1, part = "header") %>% 
  merge_at(i = 1:2, j = 2, part = "header") %>% 
  width(j=1, width = 2.7) %>% 
  width(j=2, width = 1.5) %>% 
  width(j=c(4,5,7,8), width = 1) %>% 
  flextable::align(., align = "center", j = c(2:8), part = "all") %>% 
  bg(., part = "body", bg = "gray95")  %>% 
  #bg(., j=c(1:8), i= ~ hospital == "Military Hospital", part = "body", bg = "#91c293") %>% 
  bg(j = 7, i = ~ Pct_Death >= 55, part = "body", bg = "red") %>% 
  colformat_num(., j = c(4,7), digits = 1) %>%
  bold(i = 1, bold = TRUE, part = "header") %>% 
  bold(i = 7, bold = TRUE, part = "body")

table
```


<!-- ======================================================= -->
## Como salvar sua tabela {  }

Há diferentes caminhos para que sua tabela seja integrada em uma saída (*output*). 

### Como salvar uma tabela única {.unnumbered}

Você pode exportar as tabelas como arquivos para Word, PowerPoint ou HTML ou como arquivo de imagem (PNG). Para fazer isto, você pode usar uma das seguintes funções:

* `save_as_docx()`  
* `save_as_pptx()`  
* `save_as_image()`  
* `save_as_html()`  

Por exemplo, abaixo salvamos nossa tabela como um documento do word. Observe a sintaxe do primeiro argumento - você pode apenas fornecer o nome do seu objeto flextable, por exemplo `my_table`, ou poderá dar um "nome" como apresentado a seguir (o nome é "my table"). Se for nome, este aparecerá como o título da tabela no Word. Também demonstramos comando para salvar como imagem PNG. 

```{r message=FALSE, warning=FALSE, eval=F}
# Editar a 'my table' como necessário para adicionar o título na tabela
.  
save_as_docx("my table" = my_table, path = "file.docx")

save_as_image(my_table, path = "file.png")
```

Observe que os pacotes `webshot` or `webshot2` são necessários para a "flextable" como uma imagem. As imagens poderá sair com fundo transparente. 

Se quiser ver uma versão 'ao vivo' da saída **flexível** no formato de documento pretendido, utilize `print()` e especifique uma das seguintes opções abaixo para `preview = `. O documento será aberto uma "pop-up" em um programa de software especificado no seu computador, mas não será salvo. Isto pode ser útil para verificar se a tabela cabe numa página/slide ou para que possa copiar rapidamente dentro de outro documento. Você pode, por exemplo, utilizar esse método com o argumento `preview = ` definido para "pptx" ou "docx" como mostrado abaixo.  

```{r, eval=F}
print(my_table, preview = "docx") # Exemplo documento do Word
print(my_table, preview = "pptx") # Exemplo Powerpoint 
```

### Imprimir a tabela no R markdown {.unnumbered}  

Esta tabela poderá ser integrada em um documento automatizado, uma saída R markdown, se o objeto tabela for chamado dentro do *chunk* do R markdown. Isto significa que a tabela poderá ser atualizada como parte de um relatório em que os dados podem ser alterados, e os números podem ser atualizados.

Veja detalhes na seção [Relatórios com R Markdown](#rmarkdown) deste manual.

<!-- ======================================================= -->
## Recursoa {  }

O manual completo **flextable** se encontra [aqui](https://ardata-fr.github.io/flextable-book/)

O site Github pode ser encontrado [aqui](https://davidgohel.github.io/flextable/)  

O manual com todas a funções usadas no pacote **flextable** poderá ser encontrada [aqui](https://davidgohel.github.io/flextable/reference/index.html)

Uma galeria com bons modelos de tabela **flextable** com códigos pode ser acessada [aqui](https://ardata-fr.github.io/flextable-gallery/gallery/)  









 
```{r include=FALSE, cache=FALSE}

# clear workspace
rm(list = ls(all = TRUE))

# clear all packages except base
#lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))

# to ensure that tidyverse packages prevail
filter <- dplyr::filter
select <- dplyr::select
summarise <- dplyr::summarise
summary <- base::summary
incidence <- incidence2::incidence

#load core packages
pacman::p_load(
     rio,
     here,
     DT,
     stringr,
     lubridate,
     tidyverse
)

# import the cleaned ebola linelist
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

# import the count data - facility level
#count_data <- rio::import(here::here("data", "facility_count_data.rds"))

# Settings

options(scipen=1, digits=7)

# print only text (not code)
# library(knitr)
# opts_chunk$set(list(echo = FALSE, eval = FALSE))
```

<!--chapter:end:new_pages/tables_presentation.Rmd-->


# O básico do ggplot {#ggplot-basics}


```{r, out.width=c('100%', '100%'), fig.align = "center", echo=F}
knitr::include_graphics(here::here("images", "ggplot_basics_top.png"))
```


O **ggplot2** é o pacote R mais popular de visualização de dados. Sua função `ggplot()` está no centro deste pacote, e toda esta abordagem é conhecida coloquialmente como *"ggplot "* com as imagens resultantes às vezes carinhosamente chamadas de "ggplots". O "gg" nestes nomes reflete a "**g**ramática de **g**ráficos" utilizados para construir as figuras. O **ggplot2** beneficia-se de uma grande variedade de pacotes R suplementares que melhoram ainda mais sua funcionalidade.

A sintaxe é significativamente diferente dos gráficos gerados pelo R **base***, e tem uma curva de aprendizado associada a ela. A utilização do **ggplot2** geralmente exige que o usuário formate seus dados de uma forma altamente **compatível com o "tidyverse"**, o que em última análise torna a utilização conjunta destes pacotes muito eficaz.


Nesta página cobriremos os fundamentos da criação de gráficos com o pacote **ggplot2**. Veja a página [Dicas para o ggplot](#ggplot-tips) para sugestões e técnicas avançadas para tornar seus gráficos realmente bonitos.  


Há vários tutoriais completos de **ggplot2**  disponíveis na seção de recursos. Você também pode baixar esta [ *cheat sheet* (colinha) de visualização de dados ](https://github.com/rstudio/cheatsheets/raw/master/data-visualization-2.1.pdf) do site do RStudio. Se você quiser inspiração para formas de visualizar criativamente seus dados, sugerimos que você revise sites como o [galeria de gráficos R](https://www.r-graph-gallery.com/) e [Data-to-viz](https://www.data-to-viz.com/caveats.html). 




<!-- ======================================================= -->
## Preparação {}

### Carregar pacotes {.unnumbered}

Este trecho de código mostra o carregamento dos pacotes necessários para as análises. Neste manual, enfatizamos `p_load()` de **pacman**, que instala o pacote se necessário *e* o carrega para utilização. Você também pode carregar os pacotes instalados com `library()` do R **base***. Veja a página em [Introdução ao R](#basics) para mais informações sobre os pacotes R.  

```{r}
pacman::p_load(
  tidyverse,      # inclui ggplot2 e outras ferramentas de manipular dados
  ggforce,        # extensão ggplot
  rio,            # importar/exportar
  here,           # localizador de arquivos
  stringr         # trabalhando com caracteres
)
```

### Importar datos {.unnumbered}  

Importamos o conjunto de dados de casos de uma epidemia simulada de Ebola. Se você quiser acompanhar, <a href='https://github.com/appliedepi/epirhandbook_eng/raw/master/data/case_linelists/linelist_cleaned.rds' class='download-button'> clique para baixar a linelist "limpa" </a> (como arquivo .rds). Importe seus dados com a função `import()` do pacote **rio** (ele aceita muitos tipos de arquivos como .xlsx, .rds, .csv - veja a página [Importar and exportar](#importing) para detalhes). 


```{r,  echo=F}
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

```

```{r, eval=F}
linelist <- rio::import("linelist_cleaned.rds")
```

As primeiras 50 linhas da linelist são exibidas abaixo. Vamos nos concentrar nas variáveis contínuas `age`, `wt_kg` (peso em quilos), `ct_blood` (valores de CT) e `days_onset_hosp` (diferença entre data de início e hospitalização). 

```{r, message=FALSE, echo=F}
# mostra os dados da linelist como uma tabela

DT::datatable(head(linelist, 50), rownames = FALSE, filter="top", options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```



### Limpeza geral {.unnumbered}

Ao preparar os dados para traçar o gráfico, é melhor fazer com que os dados adiram aos padrões de dados ["arrumados"](https://r4ds.had.co.nz/tidy-data.html) (do inglês *tidy*) na medida do possível. Como conseguir isto é explicado com mais detalhes nas páginas de gerenciamento de dados deste manual, tais como [Dados de limpeza e principais funções](#cleaning). 

Algumas maneiras simples de prepararmos nossos dados para torná-los melhores para a visualização podem incluir tornar o conteúdo dos dados melhor para exibição - o que não necessariamente equivale a melhor para a manipulação de dados. Por exemplo:  

* Substituir os valores `NA` em uma coluna do tipo caracteres pela *string* "Desconhecido".  
* Considerar converter a coluna para classe *fator* para que seus valores tenham níveis em uma ordem específica. 

* Limpar algumas colunas para que os valores adequados à manipulações (_"data friendly"_), tais como valores que possuam sublinhado (_"underline"_), por exemplo, sejam alterados para texto normal ou padrão título (ver [Caracteres e strings](#characters-strings))  



Aqui estão alguns exemplos disso em ação.

```{r, }
#faça uma versão visualizaçãi das colunas com nomes mais amigáveis 

linelist <- linelist %>%
  mutate(
    gender_disp = case_when(gender == "m" ~ "Male",        # m para Male
                            gender == "f" ~ "Female",      # f para Femimino,
                            is.na(gender) ~ "Desconhecido"),    # NA para Desconhecido
    
    outcome_disp = replace_na(outcome, "Desconhecido")          # substituir na por "Desconhecido" 
  )
```

### Pivoteamento para "mais longo" {.unnumbered}

Por uma questão de estrutura de dados, para **ggplot2** muitas vezes também queremos *pivotar* nossos dados para formatos *mais longos*. Leia mais sobre isto na página em [Pivoteando dados](#pivoting).  

```{r out.width = "100%", fig.align = "center", echo=F}
knitr::include_graphics(here::here("images", "pivoting", "pivot_longer_new.png"))
```


Por exemplo, digamos que queremos fazer um gráfico de dados que estão em um formato "largo", como para cada caso na `linelist` e seus sintomas. Abaixo criamos uma mini-linelist chamada `symptoms_data` que contém apenas as colunas `case_id` e sintomas.  

```{r}
symptoms_data <- linelist %>% 
  rename(tosse=cough,
         febre=fever, 
         vômito=vomit,
         dores=aches,
         calafrio=chills) %>%  #traduzindo
  select(c(case_id, febre, calafrio, tosse, dores, vômito)) 
     
```

Veja como são as primeiras 50 linhas desta mini-linelist  - veja como elas são formatadas de forma "larga" com cada sintoma como uma coluna:

```{r, message=FALSE, echo=F}
# mostra os dados da linelist como uma tabela

DT::datatable(head(symptoms_data, 50), rownames = FALSE, filter="top", options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```

Se quisermos traçar um gráfico com o número de casos com sintomas específicos, estamos limitados pelo fato de que cada sintoma é uma coluna específica. Entretanto, podemos *pivotar* as colunas de sintomas para um formato mais longo como este:

```{r, }
symptoms_data_long <- symptoms_data %>%    # comece com a "mini" linelist chamada symptoms_data
  
  pivot_longer(
    cols = -case_id,                       # pivote todas as colunas exceto case_id 
    names_to = "nome_sintoma",             # dê o nome para a nova coluna que contém os sintomas 
    values_to = "sintoma_esta_presente") %>%  # dê o nome para a coluna que diz se o sintoma está presente 

  
  mutate(sintoma_esta_presente = replace_na(sintoma_esta_presente, "desconhecido")) # converte NA para "desconhecido"

```


Aqui estão as primeiras 50 linhas. Observe que o caso tem 5 fileiras - uma para cada sintoma possível. As novas colunas `nome_sintoma` e `sintoma_esta_presente` são o resultado do pivoteamento. Note que este formato pode não ser muito útil para outras operações, mas é útil para a criação do gráfico.


```{r, message=FALSE, echo=F}
DT::datatable(head(symptoms_data_long, 50), rownames = FALSE, filter="top", options = list(pageLength = 10, scrollX=T), class = 'white-space: nowrap' )
```






<!-- ======================================================= -->
## Básico do ggplot {}

**"Gramática dos gráficos" - ggplot2**  


A criação de gráficos com o **ggplot2**  é baseada na "adição" de camadas de gráficos e de design uns sobre os outros, com cada comando adicionado aos anteriores com um símbolo de mais (`+`). O resultado é um objeto do tipo gráfico com várias camadas que pode ser salvo, modificado, impresso, exportado, etc.  

Os objetos de ggplot podem ser altamente complexos, mas a ordem básica das camadas geralmente será assim:  

1. Comece com o comando de base `ggplot()` - isto "abre" o ggplot e permite que funções subseqüentes sejam adicionadas com `+`. Tipicamente, o conjunto de dados também é especificado neste comando  
2. Adicionar camadas "geom" - estas funções visualizam os dados como *geometrias* (*formas*), por exemplo, como um gráfico de barras, gráfico de linhas, gráfico de dispersão, histograma (ou uma combinação!). Todas estas funções começam com `geom_` como um prefixo.  
3. Adicione elementos de desenho ao gráfico, como etiquetas de eixos, título, fontes, tamanhos, esquemas de cores, legendas ou rotação de eixos.  

Um exemplo simples de código esqueleto é o seguinte. Vamos explicar cada componente nas seções abaixo.  

```{r, eval=F}
# plote os dados das colunas do objeto my_data como pontos vermelhos


ggplot(data = my_data)+                   # use a base de dados "my_data"
  geom_point(                             # adicione uma camada de pontos 

    mapping = aes(x = col1, y = col2),    # mapeie as colunas para os eixos
    color = "red")+                       # outras especificações para o geom
  labs()+                                 # aqui você pode adicionar títulos, rótulos dos eixos, etc. 
  theme()                                 # aqui você pode ajustar a cor, fonte, tamanho, de elementos que não são orindos dos dados (eixo, título, etc.) 
```

 


## `ggplot()`  

O comando de abertura de qualquer gráfico ggplot2 é `ggplot()`. Este comando simplesmente cria uma tela em branco sobre a qual se pode adicionar camadas. Ele "abre" o caminho para que outras camadas sejam adicionadas com um símbolo `+`.

Normalmente, o comando `ggplot()` inclui o `dados = ` argumento para o gráfico. Isto define o conjunto de dados padrão a ser utilizado para as camadas subsequentes do gráfico.  

Este comando terminará com um `+` após seus parênteses de fechamento. Isto deixa o comando "aberto". O ggplot só será executado/aparecerá quando o comando completo incluir uma camada final *sem* um `+` no final.  

```{r, eval=F}
# Isso irá criar um gráfco que é um painel em branco 
ggplot(data = linelist)
```


## Geoms  

Uma tela em branco certamente não é suficiente - precisamos criar geometrias (formas) a partir de nossos dados (por exemplo, gráficos de barra, histogramas, gráficos de dispersão, gráficos de caixa).  

Isto é feito adicionando camadas "geoms" ao comando inicial `ggplot()`. Há muitas funções do **ggplot2**  que criam "geoms". Cada uma destas funções começa com "geom_", portanto, vamos nos referir a elas genericamente como `geom_XXXX()`. Há mais de 40 geoms em **ggplot2** e muitos outros criados por fãs e contribuidores. Veja-os na [galeria ggplot2](https://exts.ggplot2.tidyverse.org/gallery/). Alguns geoms comuns estão listados abaixo:  


* Histogramas - `geom_histogram()`  
* Gráficos de barras - `geom_bar()` ou `geom_col()` (veja ["Bar plot" seção](#ggplot_basics_bars))  
* Diagrama de caixas - `geom_boxplot()`  
* Pontos (por exemplo, gráficos de dispersão) - `geom_point()`  
* Gráficos de linhas - `geom_line()` ou `geom_path()`  
* Linhas de tendência - `geom_smooth()`  

Em um gráfico você pode exibir um ou vários geoms. Cada um é adicionado aos comandos anteriores **ggplot2** com um `+`, e eles são plotados sequencialmente de forma que os geoms posteriores sejam plotados sobre os anteriores.  



## Mapeando dados ao gráfico {#ggplot_basics_mapping}  

A maioria das "funções geom" devem ser informadas *do que usar* para criar suas formas - portanto, você deve dizer-lhes como devem *mapear (atribuir) colunas em seus dados* aos componentes do gráfico como os eixos, cores das formas, tamanhos das formas, etc. Para a maioria dos geoms, os componentes *essenciais* que devem ser mapeados para colunas nos dados são o eixo x, e (se necessário) o eixo y.  


Este "mapeamento" ocorre com o argumento `mapping = `. Os mapeamentos que você fornece ao `mapping` devem ser envolvidos na função `aes()`, assim você escreveria algo como `mapping = aes(x = col1, y = col2)`, como mostrado abaixo.


Abaixo, no comando `ggplot()`, os dados são definidos como o caso `linelist`. No argumento `mapping = aes()` a coluna `age` é mapeada para o eixo x, e a coluna `wt_kg` é mapeada para o eixo y.  

Depois de um `+`, os comandos de plotagem continuam. Uma forma é criada com a função "geom" `geom_point()`. Este geom *herda* os mapeamentos do comando `ggplot()` anterior - ele conhece as atribuições eixo-coluna e procede para visualizar essas relações como *pontos* na área do gráfico.  

```{r, warning=F, message=F}
ggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+
  geom_point()

# o nome dos eixos fica automaticamente com o nome da variável na base
# que está em inglês. É possível traduzir na base ou usando a camada
# labs() para escrever o nome dos eixos como se quer
```

Como outro exemplo, os seguintes comandos utilizam os mesmos dados, um mapeamento um pouco diferente e um *geom* diferente. A função `geom_histogram()` requer apenas uma coluna mapeada para o eixo x, pois as contagens do eixo y são geradas automaticamente. 

```{r, warning=F, message=F}
ggplot(data = linelist, mapping = aes(x = age))+
  geom_histogram()
```


### As estéticas do gráfico {.unnumbered}  

Na terminologia ggplot, uma "estética" do gráfico tem um significado específico. Ela se refere a uma propriedade visual de *dados plotados*. Note que "estético" aqui se refere aos *dados que estão sendo plotados em geometrias/formas* - não ao display ao redor, como títulos, etiquetas de eixos, cor de fundo, que você pode associar com a **palavra** "estética". No ggplot, esses detalhes são chamados de "themes" (temas) e são ajustados dentro de um comando `theme()` (veja [esta seção](#ggplot_basics_themes)).  


Portanto, os objetos *aesthetics* podem ser cores, tamanhos, transparências, posição, etc. *dos dados traçados*. Nem todos os geoms terão as mesmas opções de *aesthetics*, mas muitos podem ser usados pela maioria dos geoms. Aqui estão alguns exemplos:  


* `shape =` Mostra um ponto de `geom_point()` como um círculo, estrela, triângulo...  
* `fill = ` A cor de preenchimento (ex. de uma barra ou boxplot)  
* `color =` A linha exterior de uma barra ou boxplot, ou a cor do ponto se usar o `geom_point()`  

* `size = ` tamanho (ex. grossura da linha, tamanho do ponto)  
* `alpha = ` Transparencia (1 = opaco, 0 = invisível)  
* `binwidth = ` Largura das classes do histograma
* `width = ` Largura das barras do gráfico de barras

* `linetype =` Tipo de linha (ex. sólida, tracejada, pontilhada) 

A esses objetos do gráfico podem ser atribuídos valores de duas maneiras:  

1) Atribuindo um valor estático (por exemplo, `color = "blue" `) a ser aplicado em todas as observações plotadas  
2) Atribuído a uma coluna de dados (por exemplo, "color = hospital") de tal forma que a exibição de cada observação depende de seu valor nessa coluna  

<!-- * A estes valores do tipo *aesthetics* podem ser atribuídos valores estáticos (por exemplo `size = 1`) ou eles podem ser mapeados a uma coluna existente no banco (por exemplo `size = age`).* Se você quiser que seja atribuído um valor estático, a atribuição é colocada *fora* do `mapping = aes()`. Se você quiser que esse elemento seja dependente do valor em cada linha de dados, a atribuição é feita *dentro* do `mapping = aes()`.   -->


### Configurar para um valor estático {.unnumbered}  

Se você quiser que a estética do objeto do gráfico seja estática, ou seja - para ser a mesma para cada observação nos dados, você escreve sua atribuição dentro do geom desejado mas *fora* de qualquer `mapping = aes()`. Essas atribuições poderiam ser `size = 1` ou `color = "blue" `. Aqui estão dois exemplos:  

* No primeiro exemplo, o `mapping = aes()` está no comando `ggplot()` e os eixos são mapeados para as colunas de idade e peso nos dados. A estética do gráfico `color = `, `size = `, e `alpha = ` (transparência) são atribuídos a valores estáticos. Para maior clareza, isto é feito na função `geom_point()`, pois você pode adicionar outras geometrias posteriormente que levariam valores diferentes.  

* No segundo exemplo, o histograma requer apenas o eixo x mapeado para uma coluna. O histograma `binwidth = `, `color = `, `fill = ` (cor de preenchimento), e `alpha = ` são novamente definidos dentro do geom para valores estáticos.  


```{r, out.width=c('50%', '50%'), fig.show='hold', warning=F, message=F}
# gráfico de dispersão
ggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+  # configurar mapeamento dos dados e eixos 
  geom_point(color = "darkgreen", size = 0.5, alpha = 0.2)   # configurar a estética estática dos pontos

# histograma
ggplot(data = linelist, mapping = aes(x = age))+       # configurar mapeamento dos dados e eixos 

  geom_histogram(              # mostra o histograma
    binwidth = 7,                # largura das classes
    color = "red",               # cor da linha da classe
    fill = "blue",               # cor de preenchimento da barra
    alpha = 0.1)                 # transparência da barra

```


### Responsivo a valores de uma coluna {.unnumbered}  

A alternativa é mapear os argumentos da estética de um gráfico a uma coluna (variável) do seus dados. Nesta abordagem, a exibição deste *aesthetics* dependerá do valor desta observação naquela coluna dos dados. Se os valores da coluna forem contínuos, a escala de exibição (legenda) para aquele *aesthetics* será contínua. Se os valores da coluna forem discretos, a legenda exibirá cada valor e os dados plotados aparecerão "agrupados" de forma distinta (leia mais na seção [agrupamento](#ggplotgroups) desta página).  


Para conseguir isso, você mapeia esse *aesthetics* do gráfico para um nome de *coluna* (não entre aspas). Isto deve ser feito *em uma função `mapping = aes()` (nota: há vários lugares no código que você pode fazer estas atribuições de mapeamento, como discutido [abaixo](##ggplot_basics_map_loc))).  

Dois exemplos estão abaixo.  

* No primeiro exemplo, a *aesthetics* `color = ` (de cada ponto) é mapeada para a coluna `age` - e uma escala de cores apareceu na legenda! Por enquanto, basta observar que a escala existe - mostraremos como modificá-la em seções posteriores.  
* No segundo exemplo, duas novas *aesthetics* do gráfico também são mapeados para colunas (`color = ` e `size = `), enquanto a *aesthetics* do gráfico `shape = ` e `alpha = ` são mapeados para valores estáticos fora de qualquer função `mapping = aes()`.   


```{r, out.width=c('50%', '50%'), fig.show='hold', warning=F, message=F}
# gráfico de dispersão

ggplot(data = linelist,   # escolha os dados
       mapping = aes(     # mapeie as aesthetics para coluna de valores
         x = age,           # mapeie o eixo x para idade (coluna age)       

         y = wt_kg,         # mapeie o eixo y para peso (wt_kg)      

         color = age) # mapeie a cor segundo a idade

       )+     
  geom_point()         # mostre como pontos

# gráfico de dispersão
ggplot(data = linelist,   # escolha os dados
       mapping = aes(     # mapeie as aesthetics para coluna de valores
         x = age,           # mapeie o eixo x para idade (coluna age)    

         y = wt_kg,         # mapeie o eixo y para peso (wt_kg) 

         color = age,       # mapeie a cor segundo a idade

         size = age))+      # mapeie o tamanho segundo a idade

  geom_point(             # mostre como pontos
    shape = "diamond",      # pontos como losangos (diamantes)
    alpha = 0.3)            # transparência do ponto a 30%



```


Nota: Os argumentos referentes aos eixos são sempre atribuídos a colunas dos dados (não a valores estáticos), e isto é sempre feito dentro de `mapping = aes()`.  


Torna-se importante acompanhar as camadas e a *aesthetics* de seus gráficos à medida que vão ficando mais complexos - por exemplo, gráficos com múltiplos *geoms*. No exemplo abaixo, a aesthetic `size = ` é atribuída duas vezes - uma para `geom_point()` e outra para `geom_smooth()` - ambas as vezes como um valor estático.   


```{r, warning=F, message=F}
ggplot(data = linelist,
       mapping = aes(           # mapeia a aesthetics para as colunas
         x = age,
         y = wt_kg,
         color = age_years)
       ) + 
  geom_point(                   # addiciona pontos para cada linha de dados
    size = 1,
    alpha = 0.5) +  
  geom_smooth(                  # adiciona uma linha de tendência 

    method = "lm",              # com um método linear
    size = 2)                   # tamanho (grossura da linha) de 2

```



### Onde incluir os atributos de mapeamento {#ggplot_basics_map_loc .unnumbered}


O mapeamento das *aesthetics* dentro de `mapping = aes()` pode ser escrito em vários lugares em seus comandos para criar o gráfico, podendo até mesmo ser escrito mais de uma vez. Isto pode ser escrito no comando superior `ggplot()`, e/ou para cada *geom* individual abaixo. As nuances incluem:  


* As atribuições de mapeamento feitas no  primeiro comando `ggplot()` serão herdadas como padrão em qualquer geom abaixo, da mesma forma como `x = ` e `y = ` são herdadas 
* Outros mapeamentos feitos dentro de um geom se aplicam somente a esse geom


Da mesma forma, o parâmetro  `data = ` (do inglês dados) especificado no primeiro comando `ggplot()` será aplicado por padrão a qualquer geom abaixo, mas você também poderia especificar dados novos para cada geom (mas isto é mais complicado).  


Assim, cada um dos seguintes comandos irá criar o mesmo gráfico:  

```{r, eval=F, warning=F, message=F}
# Esses comandos irão criar o mesmo gráfico

ggplot(data = linelist, mapping = aes(x = age))+
  geom_histogram()

ggplot(data = linelist)+
  geom_histogram(mapping = aes(x = age))

ggplot()+
  geom_histogram(data = linelist, mapping = aes(x = age))
```




### Grupos {#ggplotgroups .unnumbered}  

Você pode facilmente agrupar os dados e "plotar por grupo". Na verdade, você já fez isso!  

Atribua a coluna de "agrupamento" à *aesthetic* apropriada do gráfico, dentro de um `mapping = aes()`. Acima, demonstramos isso utilizando valores contínuos quando atribuímos o ponto `size = ` à coluna `age` (idade). Entretanto, isto funciona da mesma forma para colunas discretas/categóricas.  

Por exemplo, se você quiser que os pontos sejam exibidos por gênero, você definiria `mapping = aes(color = gender)`. Uma legenda aparece automaticamente. Esta atribuição pode ser feita dentro do comando `mapping = aes()` no `ggplot()` do topo (e ser herdada pelo geom), ou pode ser definida em um `mapping = aes()` separado dentro do geom. Ambas as abordagens são mostradas abaixo:  


```{r, warning=F, message=F}
ggplot(data = linelist,
       mapping = aes(x = age, y = wt_kg, color = gender))+
  geom_point(alpha = 0.5)
```


```{r, eval=F}
# Este código alternativo produz o mesmo gráfico 
ggplot(data = linelist,
       mapping = aes(x = age, y = wt_kg))+
  geom_point(
    mapping = aes(color = gender),
    alpha = 0.5)

```


Observe que, dependendo do geom, será necessário utilizar argumentos diferentes para agrupar os dados. Para `geom_point()` você provavelmente utilizará `color =`, `shape = ` ou `size = `. Enquanto para `geom_bar()` é mais provável que você utilize `fill = `. Isto depende apenas do geom e do tipo de *aesthetic* do gráfico que você deseja usar para refletir os agrupamentos.  

Para sua informação - a forma mais básica de agrupar os dados é utilizando apenas o argumento `group =` dentro do `mapping = aes()`. Entretanto, isto por si só não mudará as cores, o preenchimento ou as formas. Tampouco criará uma legenda. No entanto, os dados são agrupados, de modo que as exibições estatísticas poderão ser afetadas.  


Para ajustar a ordem dos grupos em um gráfico, veja a página [Dicas para o ggplot](#ggplot-tips) ou a página em [Fatores](#factors). Há muitos exemplos de gráficos agrupados nas seções abaixo sobre a plotagem de dados contínuos e categóricos.    



## Facetas / Pequenos-Múltiplos {#ggplot_basics_facet}  


Facetas, ou "pequenos-múltiplos", são usadas para dividir uma parcela em uma figura de vários painéis, com um painel ("faceta") por grupo de dados. O mesmo tipo de gráfico é criado várias vezes, cada um usando um subgrupo do mesmo conjunto de dados.  

O Facetamento (*Faceting*) é uma funcionalidade que vem com **ggplot2**, portanto as legendas e eixos dos "painéis" de faceta são automaticamente alinhados. Há outros pacotes discutidos na página [Dicas para o ggplot](#ggplot-tips) que são usados para combinar gráficos completamente diferentes (**cowplot** e **patchwork**) em uma única figura.  

O facetamento é feito com uma das seguintes funções **ggplot2**:

   1. `facet_wrap()` Para mostrar um painel diferente para cada nível de uma variável *única*. Um exemplo disso poderia ser mostrar uma curva epidêmica diferente para cada hospital de uma região. As facetas são ordenadas alfabeticamente, a menos que a variável seja um fator com outra ordenação definida.  
  + Você pode invocar certas opções para determinar o layout das facetas, por exemplo `nrow = 1` ou `ncol = 1` para controlar o número de linhas ou colunas dentro das quais as facetas estão dispostas.  

  
  2. `facet_grid()` Isto é utilizado quando se deseja trazer uma segunda variável para a disposição das facetas. Aqui cada painel de uma "grade" (grid) mostra a interseção entre os valores em *duas colunas*. Por exemplo, curvas epidêmicas para cada combinação hospital-idade com hospitais ao longo do topo (colunas) e faixas etárias ao longo dos lados (linhas).  

  + "nrow" e "ncol" não são relevantes, pois os subgrupos são apresentados em um grid  

Cada uma destas funções aceita uma sintaxe de fórmula para especificar a(s) coluna(s) de faceta(s). Ambas aceitam até duas colunas, uma de cada lado de um til `~'.  

* Para `facet_wrap()` na maioria das vezes você escreverá apenas uma coluna precedida por um til `~` como `facet_wrap(~hospital)`. Entretanto, você pode escrever duas colunas `facet_wrap(outcome ~ hospital)` - cada combinação única será exibida em um painel separado, mas não serão dispostas em um grid. Os cabeçalhos mostrarão termos combinados e estes não terão uma lógica específica para as colunas vs. linhas.  Se você estiver fornecendo apenas uma variável facetada, um ponto `.` é utilizado como um espaço reservado no outro lado da fórmula - veja os exemplos de código.  


* Para `facet_grid()` você também pode especificar uma ou duas colunas para a fórmula (grid `linhas ~ colunas`). Se você quiser especificar apenas uma, você pode colocar um ponto `.` no outro lado do til como `facet_grid(. ~ hospital)` ou `facet_grid(hospital ~ .)`.  


As facetas podem rapidamente conter uma quantidade avassaladora de informações - é bom garantir que você não tenha muitos níveis de cada variável que você escolher facetar. Aqui estão alguns exemplos rápidos com o conjunto de dados sobre malária (ver [Baixar manual e dados](#data-used)) que consiste em contagens diárias de casos de malária para estabelecimentos, por faixa etária.  

A seguir, importamos e fazemos algumas modificações rápidas para simplificar: 

```{r, , warning=F, message=F}
# Esses dados correspondem a contagens diárias de malária, por estabelecimento-dia 
malaria_data <- import(here("data", "malaria_facility_count_data.rds")) %>%  # importar
  select(-submitted_date, -Province, -newid)                                 # remove colunas desnecessárias

```

As primeiras 50 filas dos dados sobre a malária estão abaixo. Observe que existe uma coluna `malaria_tot`, mas também colunas para contagens por faixa etária (estas serão utilizadas no segundo exemplo referente ao  `facet_grid()` ).  

```{r, message=FALSE, echo=F}
DT::datatable(head(malaria_data, 50), rownames = FALSE, filter="top", options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```



### `facet_wrap()` {.unnumbered}

No momento, vamos nos concentrar nas colunas `malaria_tot` e `District`. Ignore por enquanto as colunas de contagem por idade. Vamos traçar curvas epidêmicas com `geom_col()`, que produz uma coluna para cada dia com a altura do eixo y sendo especificada com o valor obtido na coluna `malaria_tot` (os dados já são contagens diárias, então utilizamos `geom_col()` - veja [a seção "Bar plot" abaixo](#ggplot_basics_bars)).  

Quando adicionamos o comando `facet_wrap()`, especificamos um til e depois a coluna para facetar sobre (neste caso, `District`). Você pode colocar outra coluna no lado esquerdo do til - isto criará uma faceta para cada combinação - mas recomendamos que você faça isto com `facet_grid()` em seu lugar. Neste caso de uso, uma faceta é criada para cada valor único de `District`.  

```{r, warning=F, message=F}
# Um gráfico com facetas por distrito 

ggplot(malaria_data, aes(x = data_date, y = malaria_tot)) +
  geom_col(width = 1, fill = "darkred") +       # plote a contagem como colunas 
  theme_minimal()+                              # simplifique os paineis de fundo
  labs(                                         # aficione rótulos, títulos, etc. 
    x = "Data dos registros",
    y = "Casos de malária",
    title = "Casos de malária por distrito") +
  facet_wrap(~District)                       # As facetas são criadas
```

### `facet_grid()` {.unnumbered}  

Podemos utilizar uma abordagem `facet_grid()` para cruzar duas variáveis. Digamos que queremos cruzar o `Distrito` (*District*) e a idade (*age*). Bem, precisamos fazer algumas transformações de dados nas colunas de idade para obter esses dados no formato "longo", preferido pelo ggplot. Todos os grupos etários têm suas próprias colunas - queremo-los em uma única coluna chamada `faixa_etaria` e outra chamada `num_casos`. Consulte a página em [Pivoteamento de dados](#pivoting) para obter mais informações sobre este processo.  


```{r, message=F, warning=F}
malaria_age <- malaria_data %>%
  select(-malaria_tot) %>% 
  pivot_longer(
    cols = c(starts_with("malaria_rdt_")),  # escolha as colunas que quer pivotear para o formato longo
    names_to = "faixa_etaria",      # column names become age group
    values_to = "num_casos"      # values to a single column (num_casos)
  ) %>%
  mutate(
    faixa_etaria = str_replace(faixa_etaria, "malaria_rdt_", ""),
    faixa_etaria = forcats::fct_relevel(faixa_etaria, "5-14", after = 1))
```

Agora as primeiras 50 linhas dos dados aparecem assim: 

```{r, message=FALSE, echo=F}
DT::datatable(head(malaria_age, 50), rownames = FALSE, filter="top", options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```

Quando você passa as duas variáveis para `facet_grid()`, o mais fácil é utilizar notação de fórmula (por exemplo `x ~ y`) onde x corresponde às linhas e y às colunas. Aqui está o gráfico, utilizando `facet_grid()` para mostrar os gráficos para cada combinação das colunas `faixa_etaria` e `District`.

```{r, message=F, warning=F}
ggplot(malaria_age, aes(x = data_date, y = num_casos)) +
  geom_col(fill = "darkred", width = 1) +
  theme_minimal()+
  labs(
    x = "Data dos registros",
    y = "Casos de malária",
    title = "Casos de malária por distrito e faixa etária"
  ) +
  facet_grid(District ~ faixa_etaria)
```

### Eixos livres ou fixos {.unnumbered}  


As escalas de eixos exibidas quando realizamos o facetamento é por padrão a mesma (ou seja, fixa) em todas as facetas. Isto é útil para a comparação cruzada, mas nem sempre apropriado.  

Ao utilizar `facet_wrap()` ou `facet_grid()`, podemos adicionar `scales = "free_y"` para "liberar" os eixos y dos painéis para escalar adequadamente seu subconjunto de dados. Isto é particularmente útil se as contagens reais forem pequenas para uma das subcategorias e se as tendências forem difíceis de se observar de outra forma. Em vez de "free_y" também podemos escrever "free_x" para fazer o mesmo para o eixo x (por exemplo, para datas) ou apenas "free" para ambos os eixos. Note que em `facet_grid`, a escala y será a mesma para facetas na mesma linha, e a escala x será a mesma para facetas na mesma coluna.


Ao utilizar somente `facet_grid`, podemos adicionar `space = "free_y"` ou `space = "free_x"` para que a altura ou largura real da faceta seja ponderada para os valores da figura dentro. Isto só funciona se `scales = "free"` (y ou x) já estiver aplicado. 

```{r, message=FALSE, warning=FALSE}

# Eixo y livre


ggplot(malaria_data, aes(x = data_date, y = malaria_tot)) +
  geom_col(width = 1, fill = "darkred") +       # plote os dados de contagem como colunas
  theme_minimal()+                              # simplifique os painel de fundo
  labs(                                         # adicione rótulos, título, etc.

    x = "Data de registro",
    y = "Casos de malária",
    title = "Casos de malária por distrito - Eixos x e y 'livres'") +
  facet_wrap(~District, scales = "free")        # as facetas são criadas
```


<!-- ```{r fig.show='hold', message=FALSE, warning=FALSE, out.width=c('50%', '50%')} -->
<!-- # A) Facet hospitalsation date by hospital, free y axis -->
<!-- ggplot(data = linelist %>% filter(hospital != "Missing"), # filter removes unknown hospital -->
<!--        aes(x = date_hospitalisation ))+ -->
<!--   geom_histogram(binwidth=7) + # Bindwidth = 7 days -->
<!--   labs(title = "A) Histogram with free y axis scales")+ -->
<!--   facet_grid(hospital~., # Facet with hospital as the row  -->
<!--              scales = "free_y") # Free the y scale of each facet -->

<!-- # B) Facet hospitalisation date by hospital, free y axis and vertical spacing -->
<!-- ggplot(data = linelist %>% filter(hospital != "Missing"), # filter removes unknown hospital -->
<!--        aes(x = date_hospitalisation ))+ -->
<!--   geom_histogram(binwidth=7) + # Bindwidth = 7 days -->
<!--   labs(title = "B) Histogram with free y axis scales and spacing")+ -->
<!--   facet_grid(hospital~., # Facet with hospital as the row  -->
<!--              scales = "free_y", # Free the y scale of each facet -->
<!--              space = "free_y") # Free the vertical spacing of each facet to optimise space -->

<!-- ``` -->

### Ordem dos fatores nas facetas {.unnumbered}  

Veja este [post](https://juliasilge.com/blog/reorder-within/) sobre como reordenar os níveis de um fator *dentro* de cada faceta.  



## Armazenando gráficos

### Salvando gráficos {.unnumbered}

Por padrão, quando você executa um comando 'ggplot()`, o gráfico será apresentado no painel Plots do RStudio. Entretanto, você também pode salvar o gráfico como um objeto utilizando o operador de atribuição `<-` e dando-lhe um nome. Então, ele não será exibido a menos que o próprio nome do objeto seja executado. Você também pode imprimi-lo envolvendo o nome do gráfico com `print()`, mas isto só é necessário em certas circunstâncias, como se o gráfico for criado dentro de um *loop* utilizado para imprimir vários gráficos de uma vez (veja a página [Iteração, laços e listas](#iteration)).  


```{r, warning=F, message=F}
# Atribua o gráfico a um objeto


age_by_wt <- ggplot(data = linelist, mapping = aes(x = age_years, y = wt_kg, color = age_years))+
  geom_point(alpha = 0.1)

# exiba
age_by_wt    
```


### Modificando gráficos salvos {.unnumbered}  


Uma coisa legal sobre **ggplot2** é que você pode definir um gráfico (como acima), e depois adicionar camadas a ele começando com seu nome. Você não precisa repetir todos os comandos que criaram o gráfico original! 

Por exemplo, para modificar o gráfico `age_by_wt` que foi definida acima, para incluir uma linha vertical aos 50 anos de idade, basta adicionar um `+` e começar a adicionar camadas adicionais ao gráfico. 

```{r, warning=F, message=F}
age_by_wt+
  geom_vline(xintercept = 50)
```


### Exportando gráficos {.unnumbered}   

A exportação de gráficos feitos no ggplot é facilitada com a função `ggsave()` de **ggplot2**. Ela pode funcionar de duas maneiras:  


* Especifique o nome do objeto do gráfico, depois o caminho do arquivo e o nome com extensão  
  * Por exemplo: `ggsave(my_plot, here("plots", "my_plot.png"))`  
* Execute o comando com apenas o parâmetro do caminho de arquivo, para salvar o último gráfico que foi feito  

  * Por exemplo: `ggsave(here("plots", "my_plot.png"))`  
  
Você pode exportar como png, pdf, jpeg, tiff, bmp, svg, ou vários outros tipos de arquivo, especificando a extensão do arquivo no caminho do arquivo.  

Você também pode especificar os argumentos `width = `, (largura) `height = ` (altura), e `units = ` (ou "in", "cm", ou "mm"). Você também pode especificar `dpi = ` com um número para a resolução da imagem a ser salva (por exemplo, 300). Veja os detalhes da função digitando `?ggsave` ou lendo a [documentação online](https://ggplot2.tidyverse.org/reference/ggsave.html). 


Lembre-se de que você pode utilizar a sintaxe da função `here()` para fornecer o caminho de arquivo desejado. Consulte a página [Importar e exportar](#importing) para obter mais informações.    


## Rótulos

Certamente você vai querer adicionar ou ajustar os rótulos (elementos de texto) do gráfico. Estes ajustes são mais facilmente feitos dentro da função `labs()` que é adicionada ao gráfico com `+` tal como os geoms eram.  


Dentro de `labs()` você pode fornecer *strings*  para estes parâmetros:  

* `x = ` e `y = ` O título do eixo x e do eixo y (etiquetas)  
* `title = `  O título principal do gráfico
* `subtitle = `  O subtítulo do gráfico, em texto menor abaixo do título  
* `caption =` A legenda do gráfico, na parte inferior direita por padrão  

Aqui está um gráfico que fizemos anteriormente, mas com rótulos mais bonitos:  

```{r, warning=F, message=F}
age_by_wt <- ggplot(
  data = linelist,   # especifique o objeto com os dados
  mapping = aes(     # mapeie as aesthetics para colunas desses dados
         x = age,           # mapeie o eixo x para idade (coluna age)            
         y = wt_kg,         # mapeie o eixo x para peso (coluna wt_kg)       
         color = age))+     # mapeie a cor para a idade
  geom_point()+           # mostre os dados como pontos
  labs(
    title = "Distribuição de idade e peso",

    subtitle = "Surto de Ebola fictício, 2014",
    x = "Idade em anos",
    y = "Peso em quilos",
    color = "Idade",
    caption = stringr::str_glue("Dados como em {max(linelist$date_hospitalisation, na.rm=T)}"))

age_by_wt
```

Observe como na atribuição do título utilizamos `str_glue()` do pacote **stringr** para implantar código R dinâmico dentro do texto da string. O legenda mostrará os "Dados a partir de": "data que reflete a data máxima de hospitalização na linelist". Leia mais sobre isto na página em [Caracteres e strings](#characters-strings).  


Uma nota sobre a especificação do título da  *legenda*: Não há nenhum argumento de "título da legenda", pois você poderia ter múltiplas escalas em sua legenda. Dentro de `labs()`, você pode escrever o argumento da  *aesthetic* do gráfico utilizada para criar a legenda, e fornecer o título desta forma. Por exemplo, acima atribuímos `color = age` para criar a legenda. Portanto, fornecemos `color = ` a `labs()` e atribuímos o título da legenda desejada ("Idade" com I maiúsculo). Se você criar a legenda com `aes(fill = COLUMN)`, então em `labs()` você escreveria `fill = ` para ajustar o título dessa legenda. A seção sobre escalas de cores na página [Dicas para o ggplot](#ggplot-tips) fornece mais detalhes sobre edição de legendas, e uma abordagem alternativa utilizando funções `scales_()`. 


## Temas  {#ggplot_basics_themes} 

Uma das melhores partes do **ggplot2** é a quantidade de controle que você tem sobre o gráfico - você pode definir qualquer coisa! Como mencionado acima, o desenho do gráfico que *não* está relacionado às formas/geometrias dos dados são ajustados dentro da função `theme()`. Por exemplo, a cor de fundo do gráfico, presença/ausência de linhas de grade e a fonte/tamanho/cor/alinhamento do texto (títulos, subtítulos, legendas, texto do eixo...). Estes ajustes podem ser feitos de uma de duas maneiras:  

*Adicionar um [*tema completo*](https://ggplot2.tidyverse.org/reference/ggtheme.html) `theme_()`função para fazer ajustes de varredura - estes incluem `theme_classic()`, `theme_minimal()`, `theme_dark()`, `theme_light()`theme_grey()`, `theme_bw()` entre outros  

* Ajuste cada pequeno aspecto do gráfico individualmente dentro de `theme()`  


### Temas completos {.unnumbered}  

Como eles são bastante diretos, demonstraremos as funções temáticas completas abaixo e não as descreveremos mais aqui. Note que quaisquer micro-ajustes com `theme()` devem ser feitos *após* a utilização de um tema completo.  

Escreva-os com parênteses vazios.    

```{r, out.width=c('50%', '50%'), fig.show='hold', warning=F, message=F}

ggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+  
  geom_point(color = "darkgreen", size = 0.5, alpha = 0.2)+
  labs(title = "Tema classic")+
  theme_classic()

ggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+  
  geom_point(color = "darkgreen", size = 0.5, alpha = 0.2)+
  labs(title = "Tema bw")+
  theme_bw()

ggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+  
  geom_point(color = "darkgreen", size = 0.5, alpha = 0.2)+
  labs(title = "Tema minimal")+
  theme_minimal()

ggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+  
  geom_point(color = "darkgreen", size = 0.5, alpha = 0.2)+
  labs(title = "Tema gray")+
  theme_gray()
  


```

### Modifique o tema {.unnumbered}  

A função `theme()` pode levar um grande número de argumentos, cada um dos quais edita um aspecto muito específico do gráfico. Não há como cobrir todos os argumentos, mas vamos descrever o padrão geral para eles e mostrar-lhe como encontrar o nome do argumento que você precisa. A sintaxe básica é esta:

1. Dentro de `theme()` escreva o nome do argumento para o elemento do gráfico que você deseja editar, como `plot.title = `  
3. Fornecer uma função  `element_()` para o argumento  
  + Na maioria das vezes, utilize `element_text()`, mas outros incluem `element_rect()` para cores de fundo de tela, ou `element_blank()` para remover os elementos do gráfico
4. Dentro da função `element_()`, escreva atribuições de argumentos para fazer os ajustes finos que você deseja  

Essa descrição foi bastante abstrata, portanto, aqui estão alguns exemplos.  

O gráfico abaixo parece bastante tolo, mas serve para mostrar uma variedade de maneiras de ajustar seu gráfico.  

* Começamos com o gráfico `age_by_wt` definido logo acima e acrescentamos `theme_classic()`  
* Para ajustes mais finos, adicionamos `theme()` e incluímos um argumento para cada elemento do gráfico a ser ajustado  

Pode ser bom organizar os argumentos em seções lógicas. Para descrever apenas alguns dos utilizados abaixo:  

* `legend.position = ` é único no sentido de aceitar valores simples como "bottom", "top", "left", e "right". Mas geralmente, os argumentos relacionados ao texto exigem que você coloque os detalhes *no* `element_text()`.  
* tamanho do título com `element_text(size = 30)`.  
* O alinhamento horizontal do título com `element_text(hjust = 0)` (da direita para a esquerda)  
* O subtítulo está em itálico com `element_text(face = "italic")`  

```{r, , warning=F, message=F}
age_by_wt + 
  theme_classic()+                                 # ajustes de tema pré-definidos
  theme(
    legend.position = "bottom",                    # move a legenda  para baixo
    
    plot.title = element_text(size = 30),          # ajusta o tamanho do título para 30
    plot.caption = element_text(hjust = 0),        # alinha a Legenda da figura a esquerda
    plot.subtitle = element_text(face = "italic"), # deixa subtítulo em itálico

    
    axis.text.x = element_text(color = "red", size = 15, angle = 90), # ajusta o texto o eixo x 
    axis.text.y = element_text(size = 15),         # ajusta o texto o eixo y
    
    axis.title = element_text(size = 20)           # ajusta o texto de ambos os eixos
    )     
```

Aqui estão alguns argumentos especialmente comuns em `theme()`. Você reconhecerá alguns padrões, tais como acrescentar `.x' ou `.y' para aplicar a mudança somente em um eixo.  


Argumento `theme()`                |O que é ajustado
-----------------------------------|----------------------------------
`plot.title = element_text()`      |O título
`plot.subtitle = element_text()`   |O subtítulo
`plot.caption = element_text()`    |A legenda da figura (parâmetros: family, face, color, size, angle,...) 
`axis.title = element_text()`      |Títulos e ambos eixos (ambos x e y) (parâmetros: size, face, color...)
`axis.title.x = element_text()`    |Título do eixo x (use `.y` para apenas eixo Y)
`axis.text = element_text()`       |Texto do eixo x (ambos x and y)
`axis.text.x = element_text()`     | Texto do eixo x (use `.y` para apenas eixo Y)  

`axis.ticks = element_blank()`     |Remove marcações de escalas do eixo
`axis.line = element_line()`       |Linhas do eixo (parâmetros: colour, linetype: solid dashed dotted etc)
`strip.text = element_text()`      |Texto do rótulo da faceta (parâmetros: colour, face, size, angle...)
`strip.background = element_rect()`|Rótulo da faceta (parâmetros: fill, colour, size...)  

Mas há tantos argumentos para temas! Como eu poderia me lembrar de todos eles? Não se preocupe - é impossível lembrar-se de todos eles. Felizmente, existem algumas ferramentas para ajudá-lo:  

A documentação sobre [modificação do tema](https://ggplot2.tidyverse.org/reference/theme.html), que tem uma lista completa.   

<span style="color: darkgreen;">**_DICA:_** Rode `theme_get()` do **ggplot2** para listar os mais de 90 argumentos da função `theme()` no console .</span>  

<span style="color: darkgreen;">**_DICA:_** Se você em algum momento quiser remover um elemento do gráfico, você também o pode fazer com o `theme()`. Apenas passe o parâmetro `element_blank()` para um argumento para que ele desapareca completamente. Para legendas, configure `legend.position = "none".`</span>  


## Cores 


Por favor veja [a seção sobre escala de cores na página de dicas do ggplot](#ggplot_tips_colors).  



## Usando o pipe (%>%) no **ggplot2**   

Ao utilizar *pipes* (%>%) para limpar e transformar seus dados, é fácil passar os dados transformados em `ggplot()`.  

Os *pipes* que passam o conjunto de dados de função para função passarão a ser um símbolo de mais `+` assim que a função `ggplot()` for chamada. Observe que, neste caso, não há necessidade de especificar o argumento `data = ` (data), pois este é automaticamente definido como o conjunto de dados que vinha sendo usado no *pipe*.  


Esta é a aparência que pode ter:  

```{r, warning=F, message=F}
linelist %>%   # comece com a linelist
 rename(tosse=cough,
         febre=fever, 
         vômito=vomit,
         dores=aches,
         calafrio=chills) %>%  #traduzindo o nome dos sintomas pois a base está em inglês
  select(c(case_id, febre, calafrio, tosse, dores, vômito)) %>%   # selecione as colunas
  
  pivot_longer(                                                  # faça o pivotamento para ficar mais longo
    cols = -case_id,                                  
    names_to = "nome_sintoma",
    values_to = "sintoma_esta_presente") %>%
  mutate(                                                        # substitua valores faltantes
    sintoma_esta_presente = replace_na(sintoma_esta_presente, "desconhecido")) %>% 
  
  ggplot(                                                        # comece o gráfico!
    mapping = aes(x = nome_sintoma, fill = sintoma_esta_presente))+
  geom_bar(position = "fill", col = "black") +                    
  theme_classic() +
  labs(
    x = "Sintoma",
    y = "Status do sintoma (proporção)"
  )
```









## Fazer gráficos de dados contínuos

Ao longo desta página, você já viu muitos exemplos de gráficos de dados contínuos. Aqui nós os consolidamos brevemente e apresentamos algumas variações.  

As visualizações aqui abordadas incluem:

*Gráficos para uma variável contínua:  
  * **Histograma**, um gráfico clássico para apresentar a distribuição de uma variável contínua. 
  * **Diagramas de caixa** (box-plots), para mostrar os percentis 25%, 50% e 75%, pontas de cauda da distribuição e outliers ([limitações importantes](https://www.data-to-viz.com/caveat/boxplot.html)).  
  * **Gráfico Jitter**, para mostrar todos os valores como pontos que estão 'tremidos' para que possam (principalmente) ser todos vistos, mesmo onde dois têm o mesmo valor.  
  * **Gráfico Violino**, mostrar a distribuição de uma variável contínua com base na largura simétrica do 'violino'. 
  * **Gráfico Sina**, são uma combinação de gráficos de jitter e violino, onde são mostrados pontos individuais mas na forma simétrica da distribuição (via **ggforce** pacote). (Nota do Tradutor: Jitter em inglês significa "agitado, nervoso" e se remete ao fato dos pontos, nesse gráfico ficarem mais "espalhados" de forma a não ficarem sobrepostos )
  * **Gráfico de dispersão** Para duas variáveis contínuas.  
  * **Gráficos de calor** para três variáveis contínuas (ligados à página [gráficos de calor](#heatmaps))    



### Histogramas {.unnumbered}

Os histogramas podem parecer gráficos de barras, mas são distintos porque medem a distribuição de uma variável *contínua*. Não há espaços entre as "barras", e apenas uma coluna é fornecida ao `geom_histogram()`.

Abaixo está o código para gerar **histogramas**, que agrupam dados contínuos em intervalos e exibem em barras adjacentes de altura variável. Isto é feito utilizando o `geom_histogram()`. Ver a secção ["Gráfico de barra"](#ggplot_basics_bars) da página básico do ggplot para compreender a diferença entre `geom_histogram()`, `geom_bar()`, e `geom_col()`.  

Mostraremos a distribuição das idades dos casos. Dentro de `mapping = aes()` especifique a coluna de que deseja ver a distribuição. Pode atribuir esta coluna ao eixo x ou ao eixo y. 

As linhas serão atribuídas a "caixas/classes" com base na sua idade numérica, e estas classes serão representadas graficamente por barras. Se especificar um número de classes com a *aesthetic*  `bins = `, os pontos de quebra são uniformemente espaçados entre os valores mínimo e máximo do histograma. Se `bins = ` não estiver especificado, será adivinhado um número apropriado de classes e esta mensagem será exibida após o gráfico:  


```
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
``` 

Se não quiser especificar um número de classes para `bins = `, pode, em alternativa, especificar `binwidth = ` nas unidades do eixo. Apresentamos alguns exemplos que mostram diferentes quantidades e  larguras de classes:   

```{r fig.show='hold', message=FALSE, warning=FALSE, out.width=c('50%', '50%')}
# A) Histograma regular
ggplot(data = linelist, aes(x = age))+  # forneça a variável do eixo x
  geom_histogram()+
  labs(title = "A) Histograma padrão (30 classes)")

# B) Mais classes
ggplot(data = linelist, aes(x = age))+  # forneça a variável do eixo x
  geom_histogram(bins = 50)+
  labs(title = "B) Ajustado para 50 classes")

# C) Menos classes
ggplot(data = linelist, aes(x = age))+  # forneça a variável do eixo x
  geom_histogram(bins = 5)+
  labs(title = "C) Ajustado para 5 classes")


# D) Mais classes
ggplot(data = linelist, aes(x = age))+  # forneça a variável do eixo x
  geom_histogram(binwidth = 1)+
  labs(title = "D) Largura da classe = 1")

```



Para obter proporções suavizadas, pode utilizar `geom_density()`:  

```{r, fig.show='hold', message=FALSE, warning=FALSE, out.width=c('50%', '50%')}
# Frequencia com eixos de proporção, suavizadas. 
ggplot(data = linelist, mapping = aes(x = age)) +
  geom_density(size = 2, alpha = 0.2)+
  labs(title = "Densidade proporcional")

# Frequência empilhada com eixo proporcional, suavizada 

ggplot(data = linelist, mapping = aes(x = age, fill = gender)) +
  geom_density(size = 2, alpha = 0.2, position = "stack")+
  labs(title = " Densidades proporcionais 'empilhada'")
```


Para obter um histograma "empilhado" (de uma coluna contínua de dados), você pode fazer uma das seguintes ações:  

1) Utilize `geom_histogram()` com o `fill = ` argumento dentro de `aes()` e atribuído à coluna de agrupamento, ou  
2) Utilize `geom_freqpoly()`, que provavelmente é mais fácil de ler (você ainda pode definir `binwidth = `)  
3) Para ver as proporções de todos os valores, defina o `y = after_stat(density)` (utilize esta sintaxe exatamente - não alterada para seus dados). Nota: estas proporções mostrarão *por grupo*.  

Cada uma delas é mostrada abaixo (*notar a utilização de `color = ` vs. `fill = ` em cada uma): 


```{r, fig.show='hold', message=FALSE, warning=FALSE, out.width=c('50%', '50%')}
# Histograma *empilhado*

ggplot(data = linelist, mapping = aes(x = age, fill = gender)) +
  geom_histogram(binwidth = 2)+
  labs(title = "histograma 'empilhado'")

# Frequência
ggplot(data = linelist, mapping = aes(x = age, color = gender)) +
  geom_freqpoly(binwidth = 2, size = 2)+
  labs(title = "Polígono de frequência")

# Freqüência com eixo de proporção 
ggplot(data = linelist, mapping = aes(x = age, y = after_stat(density), color = gender)) +
  geom_freqpoly(binwidth = 5, size = 2)+
  labs(title = "Polígono de frequência proporcional")

# Freqüência com eixo de proporção , suavizado
ggplot(data = linelist, mapping = aes(x = age, y = after_stat(density), fill = gender)) +
  geom_density(size = 2, alpha = 0.2)+
  labs(title = "Proportional, suavizado com geom_density()")
```

Se você quiser se divertir, tente 'geom_density_ridges' do pacote **ggridges*** ([vinheta aqui](https://cran.r-project.org/web/packages/ggridges/vignettes/introduction.html).  

Leia mais em detalhes sobre histogramas no **tidyverse** [página em geom_histogram()](https://ggplot2.tidyverse.org/reference/geom_histogram.html).  



### Box plots {.unnumbered}

Os bos-plots são comuns, mas têm limitações importantes. Elas podem obscurecer a distribuição real - por exemplo, uma distribuição bi-modal. Veja este [galeria de gráficos R](https://www.r-graph-gallery.com/boxplot.html) e este [artigo data-to-viz](https://www.data-to-viz.com/caveat/boxplot.html) para mais detalhes. Entretanto, eles exibem bem a faixa inter-quartil e aberturas - de modo que podem ser sobrepostos em cima de outros tipos de gráficos que mostram a distribuição em mais detalhes.  

Abaixo lembramos os vários componentes de um boxplot:  


```{r, out.width = "100%", fig.align = "center", echo=F}
knitr::include_graphics(here::here("images", "boxplot.png"))
```

Ao utilizar `geom_boxplot()` para criar diagrama de caixas (box-plot), você geralmente mapeia apenas um eixo (x ou y) dentro de `aes()`. O eixo especificado determina se as parcelas são horizontais ou verticais. 

Na maioria dos geoms, você cria um gráfico por grupo mapeando uma estética como `color = ` ou `fill = ` para uma coluna dentro de `aes()`. Entretanto, para box-plots, isso é conseguido atribuindo a coluna de agrupamento ao eixo não atribuído (x ou y). Abaixo está o código para um boxplot de *todos* os valores de idade no conjunto de dados, e o segundo é o código para exibir um box plot para cada sexo (não-faltante) no conjunto de dados. Observe que os valores `NA` (ausentes) aparecerão como um gráfico de caixa separado, a menos que seja removido. Neste exemplo, também definimos o `fill` para a coluna `outcome`, para que cada gráfico seja de uma cor diferente - mas isto não é necessário.  

```{r fig.show='hold', message=FALSE, warning=FALSE, out.width=c('50%', '50%')}
# A) Boxplot geral
ggplot(data = linelist)+  
  geom_boxplot(mapping = aes(y = age))+   # apenas o y é mapeado
  labs(title = "A) Boxplot geral")

# B) Box plot por grupo
ggplot(data = linelist, mapping = aes(y = age, x = gender, fill = gender)) + 
  geom_boxplot()+                     
  theme(legend.position = "none")+   # remove a legenda
  labs(title = "B) Box plot por sexo")      
```

Para obter o código para adicionar um boxplot às bordas de um gráfico de dispersão (gráficos "marginais") veja a página [Dicas para o ggplot]. 

### Gráficos: Violino, jitter, sina {.unnumbered}

Below is code for creating **violin plots** (`geom_violin`) and **jitter plots** (`geom_jitter`) to show distributions. You can specify that the fill or color is also determined by the data, by inserting these options within `aes()`. 

```{r fig.show='hold', message=FALSE, warning=FALSE, out.width=c('50%', '50%')}


# A) Gráfico de jitter por grupo

ggplot(data = linelist %>% drop_na(outcome),      # remove valores faltantes
       mapping = aes(y = age,                     # variável contínua escolhida
           x = outcome,                           # variável de agrupamento
           color = outcome))+                     # variável para cor
  geom_jitter()+                                  # criar o gráfico ´Jitter
  labs(title = "A) Um grafico 'jitter' por gênero" )  



# B) Gráfico de violino
ggplot(data = linelist %>% drop_na(outcome),       # remove valores faltantes
       mapping = aes(y = age,                      # Variável contínua
           x = outcome,                            # Variável de agrupamento
           fill = outcome))+                       # variável de cor para preenchimento
  geom_violin()+                                   # criar o gráfico de violino
  labs(title = "B) Gráfico de violino por gênero")    
```

Você pode combinar os dois utilizando a função `geom_sina()` do pacote **ggforce**. Esse gráfico traça os pontos do gráfico *jitter* na forma do gráfico de violino. Quando sobrepostos (ajustando as transparências), isto pode ser mais fácil de interpretar visualmente.  

```{r, warning=F, message=F}

# Um gráfico Sina por grupo
ggplot(
  data = linelist %>% drop_na(outcome), 
  aes(y = age,           # variável numérica
      x = outcome)) +    # variável de agrupamento
  geom_violin(
    aes(fill = outcome), # mapeie o preenchimento (cor do fundo do violino) segundo uma coluna
    color = "white",     # borda exterior branca
    alpha = 0.2)+        # transparencia
  geom_sina(
    size=1,                # Mude o tamanho do "jitter"
    aes(color = outcome))+ # cor dos pontos
  scale_fill_manual(       # defina as cores de preenchimento do violino
    values = c("Death" = "#bf5300", #óbito
              "Recover" = "#11118c")) + # recuperado
  scale_color_manual(      # defina as cores de preenchimento dos pontos
    values = c("Death" = "#bf5300", 
              "Recover" = "#11118c")) + 
  theme_minimal() +                                # Remove o fundo cinza
  theme(legend.position = "none") +                # Remove legendas desnecessárias
  labs(title = "Gráfico Sina e Violino por gênero, com formtações extras")      


```



### Duas variáveis contínuas  {.unnumbered}

Seguindo uma sintaxe semelhante, `geom_point()` permitirá traçar duas variáveis contínuas uma contra a outra em uma **gráfico de dispersão**. Isto é útil para mostrar os valores reais ao invés de suas distribuições. Um gráfico básico de dispersão de idade vs peso é mostrado em (A). Em (B) utilizamos novamente `facet_grid()` para mostrar a relação entre duas variáveis contínuas na linelist. 

```{r fig.show='hold', message=FALSE, warning=FALSE, out.width=c('50%', '50%')}
#Gráfico de dispersão básico para idade e peso
ggplot(data = linelist, 
       mapping = aes(y = wt_kg, x = age))+
  geom_point() +
  labs(title = "A) Gráfico de dispesão para idade e peso")

# Gráfico de dispersão de peso e idade por gênero e desfecho para o Ebola 
ggplot(data = linelist %>% drop_na(gender, outcome), # filtro mantém apenas gênero e desfecho não faltantes
       mapping = aes(y = wt_kg, x = age))+
  geom_point() +
  labs(title = "B) Gráfico de dispersão do peso por idade facetado para gênero e desfecho")+
  facet_grid(gender ~ outcome) 

```


### Três variáveis contínuas {.unnumbered}  

Você pode exibir três variáveis contínuas utilizando o argumento  `fill = `  para criar um *gráfico de calor*. A cor de cada "célula" irá refletir o valor da terceira coluna contínua de dados. Veja a página [Dicas para o ggplot](#ggplot-tips) e a página em [Gráficos de calor](#heatmaps) para mais detalhes e vários exemplos. 

Existem maneiras de fazer gráficos 3D em R, mas para a epidemiologia aplicada, estes são freqüentemente difíceis de interpretar e, portanto, menos úteis para a tomada de decisões.  


## Gráficos de dados categóricos

Dados categóricos podem ser variáveis do tipo caractere ou variáveis lógicas (TRUE/FALSE. VERDADEIRO/FALSO), ou ainda fatores (veja a página [Fatores](#factors)). 

### Preparação {.unnumbered}

#### Estrutura dos dados {.unnumbered}  

A primeira coisa a entender sobre seus dados categóricos é se eles em sua forma bruta existem  observações como uma lista de casos, ou como um quadro resumido ou agregados que contém contagens ou proporções. O estado de seus dados terá impacto na função de gráficos que você utiliza:  

* Se seus dados forem observações em bruto com uma linha por observação, você provavelmente utilizará `geom_bar()`  
* Se seus dados já estiverem agregados em contagens ou proporções, você provavelmente utilizará `geom_col()`    

#### Classe da coluna e ordenamento dos valores {.unnumbered}  
Em seguida, examine a classe das colunas que você deseja traçar. Examinamos `hospital`, primeiro com a função `class()` do R **base**,  e com `tabyl()` dO pacote **janitor**.   

```{r}
# Veja a classe da coluna hospital - podemos ver que é um caracter
class(linelist$hospital)

# Veja os valores e proporções dentro dessa coluna "hospital" 
linelist %>% 
  tabyl(hospital)
```

Podemos ver que os valores dentro são caracteres, pois se tratam de nomes de hospitais, e por padrão são ordenados alfabeticamente. Existem também "outros" e "faltam" valores, que preferimos que sejam as últimas subcategorias ao apresentarmos as subdivisões. Portanto, transformamos esta coluna em um fator e a reordenamos. Isto é tratado com mais detalhes na página [Fatores](#factors).

```{r}
# Converte para fator e define a ordem dos níveis para que "Other" (outros) e "Missing" (faltantes) sejam os últimos a aparecer 
linelist <- linelist %>% 
  mutate(
    hospital = fct_relevel(hospital, 
      "St. Mark's Maternity Hospital (SMMH)",
      "Port Hospital", 
      "Central Hospital",
      "Military Hospital",
      "Other",
      "Missing"))

```


```{r}
levels(linelist$hospital)
```

### `geom_bar()` {#ggplot_basics_bars .unnumbered}  

Utilize `geom_bar()` se você quiser que a altura da barra (ou a altura dos componentes da barra empilhada) reflita *o número de linhas relevantes nos dados*. Essas barras terão espaços entre elas, a menos que a *aesthetic* largura ( `width = ` ) esteja ajustada.  

* Forneça apenas uma atribuição de coluna de um eixo (tipicamente eixo x). Se você fornecer x e y, você receberá `Error: stat_count() só pode ter uma estética x ou y.`  
* Você pode criar barras empilhadas, adicionando uma atribuição de `fill = ` coluna dentro de `mapping = aes()`.  
* O eixo oposto será intitulado "count" por padrão, pois representa o número de linhas

A seguir, designamos o resultado para o eixo y, mas poderia ser igualmente fácil no eixo x. Se você tiver valores de caracteres mais longos, às vezes pode parecer melhor virar as barras para o lado e colocar a legenda embaixo. Isto pode ter impacto na forma como os níveis do seu fator são ordenados - neste caso os revertemos com `fct_rev()` para colocar "Other" e "Missing" na parte inferior.  

```{r, out.width=c('50%', '50%'), fig.show='hold'}
# A) Desfecho em todos os casos
ggplot(linelist %>% drop_na(outcome)) + 
  geom_bar(aes(y = fct_rev(hospital)), width = 0.7) +
  theme_minimal()+
  labs(title = "A) Número de casos por hospital",
       y = "Hospital")


# B) Desfecho em todos os casos por hospital
ggplot(linelist %>% drop_na(outcome)) + 
  geom_bar(aes(y = fct_rev(hospital), fill = outcome), width = 0.7) +
  theme_minimal()+
  theme(legend.position = "bottom") +
  labs(title = "B) Número de casos de Ebola recuperados e de óbitos,   por hospital",
       y = "Hospital")

```





### `geom_col()` {.unnumbered}  

Utilize `geom_col()` se você quiser que a altura da barra (ou altura dos componentes da barra empilhados) reflita os *valores* pré-calculados que existem nos dados. Muitas vezes, estas são contagens sumárias ou "agregadas", ou proporções.  

Forneça atribuições de colunas para *ambos* eixos para `geom_col()`. Normalmente, sua coluna do eixo x é discreta e sua coluna do eixo y é numérica. 

Digamos que temos este conjunto de dados "resultados":  

```{r, echo = F}
outcomes <- linelist %>% 
  drop_na() %>% 
  mutate(outcome=ifelse(outcome=="Death","Óbito", #traduzindo
                        ifelse(outcome=="Recover","Recuperado", outcome))) %>% 
  group_by(outcome) %>% 
  count %>% 
  ungroup() %>% # desagrupar para que proporção esteja fora do total
  mutate(`proporcao` = n/sum(n)*100) # Calcular a porcentagem
  
outcomes #Visualizar a tabela completa
```



Abaixo está o código utilizando `geom_col` para criar gráficos de barras simples para mostrar a distribuição dos resultados dos pacientes com Ebola. Com o geom_col, tanto x como y precisam ser especificados. Aqui x é a variável categórica ao longo do eixo x, e y é a coluna de proporções geradas `proporcao`.  

```{r, fig.height = 3, fig.width=4.5}
# Desfecho em todos os casos
ggplot(outcomes) + 
  geom_col(aes(x=outcome, y = proporcao)) +
  labs(subtitle = "Número de casos recuperados e óbitos de Ebola")

```

Para mostrarmos as detalhamentos por hospital, precisaríamos que nossa tabela contivesse mais informações e que estivesse em formato "longo". Criamos esta tabela com as freqüências das categorias combinadas `outcome` (Desfecho) e  `hospital` (ver página [Agrupando dados](#grouping) para dicas de agrupamento). 

```{r, fig.height = 4, fig.width=6}
outcomes2 <- linelist %>% 
  drop_na(outcome) %>% 
  count(hospital, outcome) %>%  # obtém contagens para hospital e desfecho 

  group_by(hospital) %>%        # Agrupa para que proporção esteja fora do total do hospital 
  mutate(proportion = n/sum(n)*100) # Calcula as proporções


head(outcomes2) # Veja uma prévia dos dados
```

Criamos então o ggplot com alguma formatação adicional:

  * **Rotação do eixo**: Trocamos o eixo com `coord_flip()` para que pudéssemos ler os nomes dos hospitais.
  * **Colunas lado a lado**: Acrescentou o argumento `position = "dodge" `  para que as barras de óbitos e recuperação sejam apresentadas lado a lado em vez de empilhadas. Note que as barras empilhadas são o padrão.
  * **Largura da coluna**: Largura especificada, de modo que as colunas são agora metade da largura normal.
  * **Ordem das colunas**: Inverteu a ordem das categorias no eixo y para que 'Other' (Outros) e 'Missing' (Faltantes) estejam na parte inferior, com `scale_x_discrete(limits=rev)`. Note que utilizamos isso em vez de `scale_y_discrete` porque o hospital é indicado no argumento 'x' de 'aes()`, mesmo que visualmente esteja no eixo y. Fazemos isso porque ggplot parece apresentar categorias ao contrário, a menos que digamos lhe o contrário.  
  * **Outros detalhes**: Etiquetas/títulos e cores adicionadas dentro de `labs` e `scale_fill_color` respectivamente.
  
```{r, fig.height = 4, fig.width=8}

# Desfecho em todos os casos por hospital
ggplot(outcomes2) +  
  geom_col(
    mapping = aes(
      x = proportion,                 # apresenta os dados calculados previamente
      y = fct_rev(hospital),          # reordenas os níveis do fator, colocando na base os desejados 
      fill = outcome),                # empilhados por desfecho
    width = 0.5)+                     # barras mais finas (valores menores que 1)
  theme_minimal() +                   # Tema mínimo
  theme(legend.position = "bottom")+
  labs(subtitle = "Número de casos recuperados e óbitos por Ebola, por hospital",
       fill = "Desfecho",             # título da legenda
       y = "Contagem",                # título do eixo y
       x = "Hospital de admissão")+   # título do eixo x
  scale_fill_manual(                 # escolhendo as cores manualmente
    values = c("Death"= "#3B1c8C",   # para óbito
               "Recover" = "#21908D" )) # para recuperado

```

Note que as proporções são binárias, por isso podemos preferir abandonar a "recuperação" e apenas mostrar a proporção de quem morreu. Isto é apenas para fins ilustrativos.  


Se utilizar `geom_col()` com dados de datas (por exemplo, uma epicurva a partir de dados agregados) - você vai querer ajustar o argumento `width = `  (largura) para remover as linhas de "espaço" entre as barras. Se utilizar o conjunto de dados diário, ajuste `width = 1`. Se for semanal, ajuste `width = 7`. Os meses não são possíveis de serem visualizados dessa forma,  porque cada mês tem um número de dias diferente.  
 


### `geom_histogram()` {.unnumbered}  

Os histogramas podem parecer gráficos de barras, mas são distintos porque medem a distribuição de uma variável *contínua*. Não há espaços entre as "barras", e apenas uma coluna é fornecida para `geom_histogram()`. Há argumentos específicos para histogramas como `bin_width = ` e `breaks = ` para especificar como os dados devem ser cdivididos em classes. A seção acima sobre dados contínuos e a página sobre [Curvas Epidemiológicas](#epicurves) fornecem detalhes adicionais.  



## Recursos 

Há uma enorme quantidade de ajuda online, especialmente com o ggplot. Veja:

* [Cheat sheet (cola) do ggplot2](http://r-statistics.co/ggplot2-cheatsheet.html)
* [Outra cheat sheet](https://biostats.w.uib.no/the-ggplot2-cheat-sheet-by-rstudio/)
* [Página do básico do ggplot do tidyverse](https://ggplot2.tidyverse.org/reference/)  
* [Platando variáveis contínuas](http://www.sthda.com/english/articles/32-r-graphics-essentials/131-plot-two-continuous-variables-scatter-graph-and-alternatives/)  
* R for Data Science pages on [visualização de dados](https://r4ds.had.co.nz/data-visualisation.html)
* [gráficos para comunicação](https://r4ds.had.co.nz/graphics-for-communication.html)  

```{r include=FALSE, cache=FALSE}

# clear workspace
rm(list = ls(all = TRUE))

# clear all packages except base
#lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))

# to ensure that tidyverse packages prevail
filter <- dplyr::filter
select <- dplyr::select
summarise <- dplyr::summarise
summary <- base::summary
incidence <- incidence2::incidence

#load core packages
pacman::p_load(
     rio,
     here,
     DT,
     stringr,
     lubridate,
     tidyverse
)

# import the cleaned ebola linelist
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

# import the count data - facility level
#count_data <- rio::import(here::here("data", "facility_count_data.rds"))

# Settings

options(scipen=1, digits=7)

# print only text (not code)
# library(knitr)
# opts_chunk$set(list(echo = FALSE, eval = FALSE))
```

<!--chapter:end:new_pages/ggplot_basics.Rmd-->


# Dicas do ggplot {#ggplot-tips}

Nesta página, iremos abordar dicas e truques para criar gráficos inteligentes e bonitos com o ggplot. Para aprender os fundamentos do ggplot, veja a página sobre [básico do ggplot](#ggplot-basics).

Existem diversos [tutoriais sobre o **ggplot2**](https://ggplot2.tidyverse.org/) disponíveis na seção de Recursos ao final deste capítulo. Você também pode baixar essa [colinha sobre visualização de dados com o ggplot](https://rstudio.com/resources/cheatsheets/) do site do RStudio. Nós recomendamos fortemente que você busque inspiração de gráficos [na galeria de gráficos do R](https://www.r-graph-gallery.com/) e no [Data-to-viz](https://www.data-to-viz.com/caveats.html). 



<!-- ======================================================= -->
## Preparando o ambiente R {}

### Carregue os pacotes {.unnumbered}

O código abaixo realiza o carregamento dos pacotes necessários para a análise dos dados. Neste manual, enfatizamos o uso da função `p_load()`, do **pacman**, que instala os pacotes, caso não estejam instalados, *e* os carrega no R para utilização. Também é possível carregar os pacotes instalados utilizando a função `library()`, do R **base**. Para mais informações sobre  pacotes do R, veja a página [Introdução ao R](#basics).  

```{r}
pacman::p_load(
  tidyverse,      # inclue ggplot2 e outros pacotes
  rio,            # importar/exportar
  here,           # localizador de arquivos
  stringr,        # trabalhando com caracteres
  scales,         # transforme números
  ggrepel,        # etiquetas colocadas de forma inteligente
  gghighlight,    # destaque uma parte do gráfico
  RColorBrewer    # escalas de cores
)
```

### Importe os dados {.unnumbered}  

Nesta página, nós importamos um conjunto de dados de casos de uma simulação de epidemia de Ebola. Se você quiser acompanhar, <a href='https://github.com/appliedepi/epirhandbook_eng/raw/master/data/case_linelists/linelist_cleaned.rds' class='download-button'>clique para baixar a linelist "limpa"</a> (as .rds file). Importe os dados com a função `import()`, do pacote **rio** (ela trabalha com uma variedade de tipos de arquivos, como .xlsx, .csv, .rds - veja a página [Importar e exportar](#importing) para detalhes).  

```{r,  echo=F}
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

```

```{r, eval=F}
linelist <- rio::import("linelist_cleaned.rds")
```

As primeiras 50 linhas da linelist são mostradas abaixo.

```{r, message=FALSE, echo=F}
# mostre a linelist como uma tabela
DT::datatable(head(linelist, 50), rownames = FALSE, filter="top", options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```




<!-- ======================================================= -->
## Escalas para as cores, preenchimentos, eixos, etc. {#ggplot_tips_colors}

No **ggplot2**, quando a aparência dos dados no gráfico (ex.: tamanho, cor, formato, preenchimento, eixo do gráfico) é mapeada para colunas nos dados, a visualização exata pode ser ajustada com o comando de "escala" correspondente. Nesta seção, nós explicamos alguns ajustes comuns de escalas.



### Esquemas de cores

Uma coisa que pode ser inicialmente difícil de entender com o **ggplot2**, é o controle dos esquemas de cores. Observe que esta seção discute a cor dos *objetos no gráfico* (geometrias/formatos), como pontos, barras, linhas, bases, etc. Para ajustar a cor de textos adicionais, títulos, ou plano de fundo, veja a seção [Temas](#ggplot_basics_themes) da página sobre [Básico do ggplot](#ggplot-basics).

Para controlar a "cor" dos *objetos no gráfico*, você irá ajustar o argumento `color =` (a cor *exterior* do item) ou o `fill =` (a cor *interior* do item). Uma exceção a esse padrão é o `geom_point()`, em que você realmente só consegue ajustar `color =`, que ajusta a cor do ponto inteiro (interior e exterior).

Ao ajustar a cor ou preenchimento (fill), você pode utilizar o nome das cores reconhecidas pelo R, como `"red"` (vermelho) (veja a [lista completa](http://sape.inf.usi.ch/quick-reference/ggplot2/colour) ou digite `?colors`), ou um código hexadecimal específico para uma cor, como `"#ff0505"`.

```{r, warning=F, message=F}
# histograma - 
ggplot(data = linelist, mapping = aes(x = age))+       # ajuste os dados e eixos
  geom_histogram(              # mostre o histograma
    binwidth = 7,                # largura dos containers
    color = "red",               # cor da linha dos containers
    fill = "lightblue")          # cor interior dos containers (preenchimento)
```



Como explicado na seção [mapeando os dados para o gráfico](#ggplot_basics_mapping), da página [Básico do ggplot](#ggplot-basics), aspectos estéticos como `fill =` e `color =` podem ser definidos *fora* do comando `mapping = aes()`, ou *dentro* dele. Se *fora* de `aes()`, o valor atribuído deve ser estático (ex.: `color = "blue"`) e irá ser aplicado para *todos* os dados colocados no gráfico pelo geom. Se *dentro*, a aparência estética deve ser mapeada para uma variável, como `color = hospital`, e a expressão irá variar de acordo com o valor desta linha nos dados. Alguns exemplos:

```{r, out.width=c('50%', '50%'), fig.show='hold', warning=F, message=F}
# Cor estática para pontos e para a linha
ggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+     
  geom_point(color = "purple")+
  geom_vline(xintercept = 50, color = "orange")+
  labs(title = "Cor estática para os pontos e linha")

# Cor mapeada para uma coluna contínua
ggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+     
  geom_point(mapping = aes(color = temp))+         
  labs(title = "Cor mapeada para uma coluna contínua")

# Cor mapeada para uma coluna discreta
ggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+     
  geom_point(mapping = aes(color = gender))+         
  labs(title = "Cor mapeada para uma coluna discreta")

# gráfico de barras, preenchimento com uma coluna discreta, cor para um valor estático
ggplot(data = linelist, mapping = aes(x = hospital))+     
  geom_bar(mapping = aes(fill = gender), color = "yellow")+         
  labs(title = "Preenchimento mapeado para uma coluna discreta, cor estática")

```


### Escalas {#ggplot_tips_scales .unnumbered}  

Quando você mapear uma coluna para uma aparência estética do gráfico (ex.: `x =`, `y =`, `fill =`, `color =`...), seu gráfico irá ganhar uma escala/legenda. Veja acima como a escala pode ter valores contínuos, discretos, datas, etc. dependendo na classe da coluna atribuída. Se você tiver múltiplas estéticas mapeadas para as colunas, seu gráfico terá múltiplas escalas. 

Você pode controlar as escalas com a função `scales_()` apropriada. As funções de escala do **ggplot()** têm 3 partes, que são escritas assim: `scale_AESTHETIC_METHOD()`.  

1) A primeira parte, `scale_()`, é fixa.
2) A segunda parte, o AESTHETIC, deve ser a estética que você quer ajustar a escala para (`_fill_`, `_shape_`, `_color_`, `_size_`, `_alpha_`...) - as opções aqui também incluem `_x_` e `_y_`.  
3) A terceira parte, o METHOD, será ou `_discrete()`, `continuous()`, `_date()`, `_gradient()`, ou `_manual()`, de acordo com a classe da coluna e *como* você quer controlar ela. Existem outras classes, mas estes são frequentemente os mais utilizados.

Certifique-se de utilizar a função correta para a escala! Do contrário, seu comando de escala não mudará nada no gráfico. Se você tiver múltiplas escalas, pode utilizar múltiplas funções de escala para ajusta-las! Por exemplo:

### Argumentos de escala {.unnumbered}  

Cada tipo de escala possui seus próprios argumentos, embora existam alguns em comum. Busque uma função no R, como `?scale_color_discrete`, para ver a documentação dos argumentos dessa função.

Para escalas contínuas, utilize `breaks =` para fornecer uma sequência de valores com `seq()` (use `to =`, `from =`, e `by =` como mostrado no exemplo abaixo). Ajuste `expand = c(0,0)` para eliminar espaços extras ao redor dos eixos (isto pode ser utilizado em qualquer escala `_x_` ou `_y_`).

Para escalas discretas, você pode ajustar a ordem de aparecimento dos fatores com `breaks =` e também ajustar os rótulos desses fatores com o argumento `labels =`. Forneça um vetor de caractere para cada um desses argumentos (veja exemplos abaixo). Você também pode excluir `NA` facilmente ao ajustar `na.translate = FALSE`.  

As nuances de escalas de datas são abordados mais extensivamente na página [Curvas epidêmicas](#epicurves).


### Ajustes manuais {.unnumbered}  

Um dos truques mais úteis é utilizar funções que alteram as escalas de forma "manual", de forma a explicitamente atribuir cores conforme você desejar. Estas são funções com a sintaxe `scale_xxx_manual()` (ex.: `scale_colour_manual()` ou `scale_fill_manual()`). Cada um dos argumentos a seguir são utilizados no exemplo abaixo.

* Atribua cores para os valores dos dados com o argumento `values =`  
* Especifique uma cor para `NA` com `na.value =`  
* Mude como os valores são *escritos* na legenda com o argumento `labels =`  
* Mude o título da legenda com `name =`  


A seguir, nós criamos um gráfico de barras, mostramos como ele é por padrão, e, então, mostramos como fica após ajustarmos três escalas - a escala contínua do eixo y, a escala discreta do eixo x, e o ajuste manual do preenchimento (cor interior das barras).


```{r, warning=F, message=F}
# PADRÃO - sem ajuste de escalas
ggplot(data = linelist)+
  geom_bar(mapping = aes(x = outcome, fill = gender))+
  labs(title = "Padrão - sem ajuste de escalas")

# ESCALAS AJUSTADAS
ggplot(data = linelist)+
  
  geom_bar(mapping = aes(x = outcome, fill = gender), color = "black")+
  
  theme_minimal()+                   # simplifique o fundo do gráfico
  
  scale_y_continuous(                # escala contínua para o eixo y (contagens)
    expand = c(0,0),                 # sem espaços extras
    breaks = seq(from = 0,
                 to = 3000,
                 by = 500))+
  
  scale_x_discrete(                   # escala discreta para o eixo x (gênero)
    expand = c(0,0),                  # sem espaços extras
    drop = FALSE,                     # mostre todos os níveis de factor (mesmo que não estejam nos dados)
    na.translate = FALSE,             # remove desfechos clínicos desconhecidos (NA) do gráfico
    labels = c("Died", "Recovered"))+ # Mude a visualização dos valores
    
  
  scale_fill_manual(                  # Especifique manualmente o preenchimento (cor interior da barra)
    values = c("m" = "violetred",     # valores de referência nos dados para atribuir cores
               "f" = "aquamarine"),
    labels = c("m" = "Homem",          # renomeie a legenda (use "=" para fazer atribuições e evitar erros)
              "f" = "Mulher",
              "Desconhecido"),
    name = "Gênero",                  # título da legenda
    na.value = "grey"                 # atribua uma cor para dados em branco
  )+
  labs(title = "Com as escalas ajustadas") # Ajuste o título da legenda do preenchimento
```

### Escalas contínuas dos eixos {.unnumbered}  

Quando os dados são mapeados para os eixos do gráfico, estes também podem ser ajustados com comandos de escala. Um exemplo simples é ajustar a visualização de um eixo (ex.: eixo y) que é mapeado para uma coluna com dados contínuos.

No caso de querermos ajustar as quebras ou visualização dos valores no gráfico, podemos utilizar o `scale_y_continuous()`, do ggplot. Como observado acima, utilize o argumento `breaks =` para fornecer uma sequência de valores que irão servir como "quebras" na escala. Estes são os intervalos em que os números serão mostrados. Para este argumento, você pode fornecer um vetor `c()` contendo os valores dos intervalos desejados, ou você pode fornecer uma sequência regular de números utilizando a função `seq()` do R **base**. Esta função aceita `to =`, `from =`, e `by =`.

```{r, warning=F, message=F, out.width=c('50%', '50%'), fig.show='hold'}
# PADRÃO - sem ajuste da escala
ggplot(data = linelist)+
  geom_bar(mapping = aes(x = outcome, fill = gender))+
  labs(title = "Padrão - sem ajuste da escala")

# 
ggplot(data = linelist)+
  geom_bar(mapping = aes(x = outcome, fill = gender))+
  scale_y_continuous(
    breaks = seq(
      from = 0,
      to = 3000,
      by = 100)
  )+
  labs(title = "Intervalo do eixo y ajustado")

```



#### Mostre as porcentagens {.unnumbered}  

Caso os seus dados originais sejam proporções, você pode facilmente mostra-los como porcentagens com "%" ao adicionar `labels = scales::percent` nos seus comandos de escala, como mostrado abaixo.

Embora uma alternativa seria converter os valores para caracteres, e, então, adicionar o "%" como caracter no final, esta abordagem irá causar problemas uma vez que seus dados não serão mais variáveis numéricas contínuas.


```{r, warning=F, message=F, out.width=c('50%', '50%'), fig.show='hold'}
# Proporções originais do eixo y
#############################
linelist %>%                                   # inicie com a linelist
  group_by(hospital) %>%                       # agrupe os dados por hospital
  summarise(                                   # crie uma coluna de resumo dos dados
    n = n(),                                     # total de casos (linhas) em um grupo
    deaths = sum(outcome == "Death", na.rm=T),   # número de mortes nos grupos
    prop_death = deaths/n) %>%                   # proporção de mortes por grupo
  ggplot(                                      # inicie o gráfico
    mapping = aes(
      x = hospital,
      y = prop_death))+ 
  geom_col()+
  theme_minimal()+
  labs(title = "Mostre as proporções originais do eixo y")



# Mostre as proporções do eixo y como porcentagens
########################################
linelist %>%         
  group_by(hospital) %>% 
  summarise(
    n = n(),
    deaths = sum(outcome == "Death", na.rm=T),
    prop_death = deaths/n) %>% 
  ggplot(
    mapping = aes(
      x = hospital,
      y = prop_death))+
  geom_col()+
  theme_minimal()+
  labs(title = "Mostre o eixo y como porcentagem (%)")+
  scale_y_continuous(
    labels = scales::percent                    # mostre as proporções como porcentagens
  )

```

#### Escala logarítmica {.unnumbered}  

Para transformar um eixo contínuo em uma escala logarítmica, adicione `trans = "log2"` no comando da escala. Para os propósitos deste exemplo, criamos um quadro de dados de regiões com seus respectivos `preparedness_index` e valores de casos acumulados.

```{r}
plot_data <- data.frame(
  region = c("A", "B", "C", "D", "E", "F", "G", "H", "I"),
  preparedness_index = c(8.8, 7.5, 3.4, 3.6, 2.1, 7.9, 7.0, 5.6, 1.0),
  cases_cumulative = c(15, 45, 80, 20, 21, 7, 51, 30, 1442)
)

plot_data
```

Os casos acumulados para a região "I" são drasticamente maiores do que todas as outras regiões. Em circunstâncias como esta, você pode optar por mostrar o eixo y utilizando uma escala logarítmica, de forma que o leitor possa ver diferenças entre as regiões com menos casos acumulados.

```{r, warning=F, message=F, out.width=c('50%', '50%'), fig.show='hold'}
# Eixo y original
preparedness_plot <- ggplot(data = plot_data,  
       mapping = aes(
         x = preparedness_index,
         y = cases_cumulative))+
  geom_point(size = 2)+            # pontos para cada região
  geom_text(
    mapping = aes(label = region),
    vjust = 1.5)+                  # adicione os rótulos em texto
  theme_minimal()

preparedness_plot                  # visualize o gráfico original


# visualize o eixo y transformado
preparedness_plot+                   # inicie com o gráfico salvo acima
  scale_y_continuous(trans = "log2") # adicione a transformação para o eixo y
```



### Escalas em gradiente {.unnumbered}  

O preenchimento de escadas em gradiente de cores pode envolver detalhes adicionais. Normalmente, os ajustes padrões são bons, mas você pode querer ajustar os valores, limites de corte, etc.

Para demonstrar como ajustar uma escala contínua de cor, nós iremos utilizar um conjunto de dados da página [Rastreamento de contatos](#contact-tracing), que contém as idades dos casos e dos seus casos-fonte.


```{r, warning=F, message=F}
case_source_relationships <- rio::import(here::here("data", "godata", "relationships_clean.rds")) %>% 
  select(source_age, target_age) 
```

Abaixo, produzimos um arquivo "raster" de um gráfico de densidade de calor. Não iremos discorrer sobre como criar o gráfico (veja o link no parágrafo acima), mas sim como ajustar a escala de cor. Veja mais sobre a função `stat_density2d()` do **ggplot2** [aqui](https://ggplot2.tidyverse.org/reference/geom_density_2d.html). Observe como a escala `fill` é *contínua*.  

```{r, warn=F, message=F}
trans_matrix <- ggplot(
    data = case_source_relationships,
    mapping = aes(x = source_age, y = target_age))+
  stat_density2d(
    geom = "raster",
    mapping = aes(fill = after_stat(density)),
    contour = FALSE)+
  theme_minimal()
```

A seguir, mostramos algumas variações na escala de preenchimento:

```{r, out.width=c('50%', '50%'), fig.show='hold', warning=F, message=F}
trans_matrix
trans_matrix + scale_fill_viridis_c(option = "plasma")
```

Agora veremos alguns exemplos de como ajustar os pontos de quebra da escala:

* `scale_fill_gradient()` aceita duas cores (alta/baixa)
* `scale_fill_gradientn()` aceita um vetor com qualquer quantidade de cores para `values =` (valores intermediários serão intercalados)  
* Use [`scales::rescale()`](https://www.rdocumentation.org/packages/scales/versions/0.4.1/topics/rescale) para ajustar como as cores serão posicionadas no decorrer do gradiente; ele reajusta o seu vetor de posições para ser entre 0 e 1.


```{r, out.width=c('50%', '50%'), fig.show='hold', warning=F, message=F}
trans_matrix + 
  scale_fill_gradient(     # escala de gradiente com 2 cores
    low = "aquamarine",    # valor baixo
    high = "purple",       # valor alto
    na.value = "grey",     # valor para NA
    name = "Densidade")+     # Título da legenda
  labs(title = "Especifique manualmente as cores para valores altos/baixos")

# 3+ cores na escala
trans_matrix + 
  scale_fill_gradientn(    # escala de 3-cores (baixo/médio/alto)
    colors = c("blue", "yellow","red") # forneça cores no vetor
  )+
  labs(title = "Escala de 3 cores")

# Uso de rescale() para ajustar a posição de cores na escala
trans_matrix + 
  scale_fill_gradientn(    # forneça qualquer número de cores
    colors = c("blue", "yellow","red", "black"),
    values = scales::rescale(c(0, 0.05, 0.07, 0.10, 0.15, 0.20, 0.3, 0.5)) # a posições para as cores é reescalado entre 0 e 1
    )+
  labs(title = "Cores não são posicionadas igualmente")

# uso de limites para os valores de corte que recebem a cor de preenchimento
trans_matrix + 
  scale_fill_gradientn(    
    colors = c("blue", "yellow","red"),
    limits = c(0, 0.0002))+
  labs(title = "Restrinja os limites dos valores, resultando em um espaço cinza")

```


### Paletas de cores {.unnumbered}  

#### Colorbrewer e Viridis {.unnumbered}
Geralmente, se você quiser paletas pré-definidas, pode usar as funções `scale_xxx_brewer` ou `scale_xxx_viridis_y`.  

As funções 'brewer' colorem a partir das paletas do [colorbrewer.org](colorbrewer.org).  

As funções 'viridis' colorem das paletas viridis (amigável para deficientes visuais!), que "fornece mapas de cores que são uniformes, tanto nas cores quanto no preto-e-branco. Elas também foram desenhadas para serem percebidas por usuários com formas comuns de cegueiras de cor." (leia mais [aqui](https://ggplot2.tidyverse.org/reference/scale_viridis.html) e [aqui](https://bids.github.io/colormap/)). Defina se a paleta é discreta, contínua, ou contida ao especificar isto no final da função (ex.: discreta é `scale_xxx_viridis_d`).

É recomendado que você teste as cores de seu gráfico neste [simulador de daltonismo](https://www.color-blindness.com/coblis-color-blindness-simulator/). Se você tiver um esquema de cores vermelho/verde, tente um esquema "quente-frio" (vermelho-azul) no lugar, como descrito [aqui](https://www.visualisingdata.com/2019/08/five-ways-to-design-for-red-green-colour-blindness/#:~:text=The%20pink%2Dred%20through%20to,green%20hues%20used%20by%20default.)  

Aqui é um exemplo da página [Básico do ggplot](#ggplot-basics), utilizando diferentes esquemas de cores.

```{r, out.width=c('50%'), fig.show='hold', warning=F, message=F} 
symp_plot <- linelist %>%                                         # inicie com a linelist
  select(c(case_id, fever, chills, cough, aches, vomit)) %>%     # selecione as colunas
  pivot_longer(                                                  # faça o pivoteamento longo
    cols = -case_id,                                  
    names_to = "symptom_name",
    values_to = "symptom_is_present") %>%
  mutate(                                                        # substitua os campos em branco
    symptom_is_present = replace_na(symptom_is_present, "unknown")) %>% 
  ggplot(                                                        # inicie o ggplot!
    mapping = aes(x = symptom_name, fill = symptom_is_present))+
  geom_bar(position = "fill", col = "black") +                    
  theme_classic() +
  theme(legend.position = "bottom")+
  labs(
    x = "Sintoma",
    y = "Status do sintoma (proporção)"
  )

symp_plot  # visualize com as cores padrão

#################################
# visualize com cores especificadas manualmente
symp_plot +
  scale_fill_manual(
    values = c("yes" = "black",         # defina as cores de forma explícita
               "no" = "white",
               "unknown" = "grey"),
    breaks = c("yes", "no", "unknown"), # ordene os fatores corretamente
    name = ""                           # configure a legenda para não ter título

  ) 

#################################
# visualize com as cores discretas do pacote viridis
symp_plot +
  scale_fill_viridis_d(
    breaks = c("yes", "no", "unknown"),
    name = ""
  )


```



<!-- ======================================================= -->
## Altere a ordem das variáveis discretas {}  

Geralmente, alterar a ordem em que as variáveis discretas aparecem no gráfico é difícil de entender para novatos no `ggplot2`. Entretanto, ao compreender o mecanismo que o `ggplot2` usa para trabalhar com variáveis discretas, fica mais fácil de entender como alterar. No geral, se uma variável discreta é utilizada, ela é automaticamente convertida para a classe `factor`- que, por padrão, ordena os factors por ordem alfabética. Para trabalhar com isso, você simplesmente precisa reordenar os níveis de factor para refletirem na ordem que você gostaria que eles aparecessem no gráfico. Para informações mais detalhadas sobre como reordenar objetos da classe `factor`, veja a seção sobre factor neste guia.

Nós podemos utilizar um exemplo comum com grupos de idade - por padrão, o grupo de 5-9 anos será colocado no meio dos grupos ordenados (considerando a ordem alfanumérica), mas nós podemos movê-lo para atrás do grupo de 0-4 anos do gráfico ao renivelar os factors.


```{r, , warning=F, message=F}
ggplot(
  data = linelist %>% drop_na(age_cat5),                         # remova as linhas em que age_cat5 está ausente
  mapping = aes(x = fct_relevel(age_cat5, "5-9", after = 1))) +  # renivele os factors

  geom_bar() +
  
  labs(x = "Grupo de idade", y = "Número de hospitalizações",
       title = "Quantidade total de hospitalizações por grupo de idade") +
  
  theme_minimal()


```

#### Pacote **ggthemr** {.unnnumbered}  

Adicionalmente, considere utilizar o pacote **ggthemr**, que pode ser baixado do Github utilizando [essas instruções](https://github.com/Mikata-Project/ggthemr). Ele oferece paletas de cores muito agradáveis estéticamente, mas tenha ciência de que estas geralmente possuem um número máximo de valores, o que é um fator limitante caso você queira mais de 7 ou 8 cores.






## Linhas de contorno  

Gráficos de contorno são úteis quando você tem muitos pontos que podem se sobrepor ("overplotting"). Iremos utilizar os dados sobre as fontes dos casos utilizados acima para fazer um gráfico, mas de forma mais simples utilizando `stat_density2d()` e `stat_density2d_filled()` para produzir níveis discretos de contorno - como um mapa topográfico. Veja mais sobre as estatísticas utilizadas [aqui](https://ggplot2.tidyverse.org/reference/geom_density_2d.html).  


```{r, out.width=c('50%'), fig.show='hold', warning=F, message=F}
case_source_relationships %>% 
  ggplot(aes(x = source_age, y = target_age))+
  stat_density2d()+
  geom_point()+
  theme_minimal()+
  labs(title = "stat_density2d() + geom_point()")


case_source_relationships %>% 
  ggplot(aes(x = source_age, y = target_age))+
  stat_density2d_filled()+
  theme_minimal()+
  labs(title = "stat_density2d_filled()")

```



## Distribuições marginais

Para mostrar as distribuições nas extremidades de um gráfico de dispersão criado com `geom_point()`, você pode utilizar o pacote **ggExtra** e sua função `ggMarginal()`. Salve seu ggplot original como um objeto, e então o utilize com `ggMarginal()`, como mostrado abaixo. Aqui estão os argumentos chave:

* Você precisa especificar `type =` como "histogram", "density" "boxplot", "violin", ou "densigram".  
* Por padrão, gráficos de dispersão marginal irão aparecer para ambos eixos. Você pode ajustar `margins =` para "x" ou "y" se quiser apenas um deles.
* Outros argumentos opcionais incluem `fill =` (cor da barra), `color =` (cor da linha), `size =` (tamanho do gráfico relativo ao tamanho da margem, de forma que números maiores criam um gráfico de dispersão marginal menor).  
* Você pode fornecer outros argumentos específicos para os eixos em `xparams =` e `yparams =`. Por exemplo, para obter diferentes tamanhos dos containers do histograma, como mostrado abaixo.

Os gráficos de dispersão marginal podem refletir os grupos (colunas que foram atribuídas a `color =` no seu mapa estético do `ggplot()`). Se este for o caso, ajuste os argumentos `groupColour =` ou `groupFill =`, do `ggMarginal()`, para `TRUE`, como mostrado abaixo.

Leia mais [neste resumo](https://cran.r-project.org/web/packages/ggExtra/vignettes/ggExtra.html), na [galeria de gráficos em R](https://www.r-graph-gallery.com/277-marginal-histogram-for-ggplot2.html) ou a documentação da função no R, com `?ggMarginal`.  

```{r, message=FALSE, warning=FALSE}
# Instale/carregue o pacote ggExtra
pacman::p_load(ggExtra)

# Gráfico básico de distribuição de peso e idade
scatter_plot <- ggplot(data = linelist)+
  geom_point(mapping = aes(y = wt_kg, x = age)) +
  labs(title = "Gráfico de distribuição de peso e idade")
```

Para adicionar histogramas marginais, utilize `type = "histogram"`. Opcionalmente, você pode ajustar `groupFill = TRUE` para obter histogramas empilhados.

```{r, message=FALSE, warning=FALSE}
# com histogramas
ggMarginal(
  scatter_plot,                     # adicione histogramas marginais
  type = "histogram",               # especifique histogram
  fill = "lightblue",               # preenchimento das barras
  xparams = list(binwidth = 10),    # outros parâmetros para a dispersão marginal do eixo x
  yparams = list(binwidth = 5))     # outros parâmetros para a dispersão marginal do eixo y
```

Gráfico de densidade marginal com valores agrupados/coloridos:

```{r, message=FALSE, warning=FALSE}

# Gráfico de dispersão, colorido de acordo com o desfecho clínico (outcome) do paciente
# Coluna de desfecho é atribuída como cor no ggplot. groupFill no ggMarginal ajustado para TRUE
scatter_plot_color <- ggplot(data = linelist %>% drop_na(gender))+
  geom_point(mapping = aes(y = wt_kg, x = age, color = gender)) +
  labs(title = "Gráfico de dispersão por peso e idade")+
  theme(legend.position = "bottom")

ggMarginal(scatter_plot_color, type = "density", groupFill = TRUE)
```

Coloque o argumento `size =` para ajustar o tamanho relativo do gráfico de dispersão marginal. Números menores criam gráficos de dispersão marginal maiores. Você também ajusta `color =`. A seguir, um diagrama de caixa (boxplot) marginal, com a demonstração do argumento `margins =`, de forma que apareça apenas em um eixo:

```{r, message=FALSE, warning=FALSE}
# com boxplot 
ggMarginal(
  scatter_plot,
  margins = "x",      # mostre apenas o gráfico de dispersão marginal do eixo x
  type = "boxplot")   
```



<!-- ======================================================= -->
## Rotulagem inteligente {}  

No **ggplot2**, também é possível adicionar texto aos gráficos. Entretanto, a limitação disto é a sobreposição dos rótulos de texto com os dados no gráfico, ficando com aparência confusa e difícil de interpretar. Não existe forma ideal de lidar com issso no pacote básico, mas existe um complemento do **ggplot2**, chamado de **ggrepel**, que lida com isso de forma bem simples!

O pacote **ggrepel** fornece duas novas funções, `geom_label_repel()` e `geom_text_repel()`, que substituem `geom_label()` e `geom_text()`. Simplesmente utilize estas funções, em vez das originais do **ggplot2**, para produzir rótulos claros e bonitos. Dentro da função, mapeie a estética  `aes()` como sempre, mas inclua o argumento `label =`, onde você fornece a coluna com os valores que quer mostrar (ex.: id do paciente, ou nome, etc). Você pode criar mais rótulos complexos ao combinar colunas e linhas novas (`\n`) dentro de `str_glue()`, como mostrado abaixo.

Algumas dicas:

* Use `min.segment.length = 0` para sempre desenhar segmentos de linhas, ou `min.segment.length = Inf` para nunca desenhá-los
* Use `size =` fora de `aes()` para ajustar o tamanho do texto
* Use `force =` para mudar o grau de repulsão entre os rótulos e seus respectivos pontos (padrão é 1)
* Inclua `fill =` dentro de `aes()` para ter os rótulos coloridos de acordo com os valores
  * A letra "a" pode aparecer na legenda - adicione `guides(fill = guide_legend(override.aes = aes(color = NA)))+` para removê-la

Veja esse detalhado [tutorial](https://ggrepel.slowkow.com/articles/examples.html) para mais detalhes.

```{r, , warning=F, message=F}
pacman::p_load(ggrepel)

linelist %>%                                               # comece com a linelist
  group_by(hospital) %>%                                   # agrupe por hospital
  summarise(                                               # crie um novo conjunto de dados com o resumo dos valores por hospital
    n_cases = n(),                                           # número de casos por hospital
    delay_mean = round(mean(days_onset_hosp, na.rm=T),1),    # demora média por hospital
  ) %>% 
  ggplot(mapping = aes(x = n_cases, y = delay_mean))+      # envie o quadro de dados para o ggplot
  geom_point(size = 2)+                                    # adicione os pontos
  geom_label_repel(                                        # adicione os rótulos dos pontos
    mapping = aes(
      label = stringr::str_glue(
        "{hospital}\n{n_cases} casos, {delay_mean} dias")  # como o rótulo é mostrado
      ), 
    size = 3,                                              # tamanho do texto nos rótulos
    min.segment.length = 0)+                               # mostre todos os segmentos de linhas
  labs(                                                    # adicione os rótulos dos eixos
    title = "Tempo médio de espera para admissão, por hospital",
    x = "Número de casos",
    y = "Tempo médio de espera (dias)")
```

Você pode rotular apenas um subconjunto dos dados - ao utilizar a sintaxe padrão do `ggplot()` para fornecer diferentes `data =` para cada camada `geom` do gráfico. Abaixo, todos os casos são colocados no gráfico, mas apenas alguns são rotulados.

```{r, warning=F, message=FALSE}

ggplot()+
  # Todos os pontos em cinza
  geom_point(
    data = linelist,                                   # todos os dados fornecidos para essa camada
    mapping = aes(x = ht_cm, y = wt_kg),
    color = "grey",
    alpha = 0.5)+                                              # cinza e semi-transparente
  
  # Poucos pontos em preto
  geom_point(
    data = linelist %>% filter(days_onset_hosp > 15),  # dados filtrados nesta camada
    mapping = aes(x = ht_cm, y = wt_kg),
    alpha = 1)+                                                # padrão preto e não transparente
  
  # rótulos de pontos para alguns pontos
  geom_label_repel(
    data = linelist %>% filter(days_onset_hosp > 15),  # filtre os dados para os rótulos
    mapping = aes(
      x = ht_cm,
      y = wt_kg,
      fill = outcome,                                          # cor dos rótulos por desfecho
      label = stringr::str_glue("Demora: {days_onset_hosp}d")), # rótulo criado com str_glue()
    min.segment.length = 0) +                                  # mostre os segmentos de linha para todos
  
  # remova a letra "a" de dentro das caixas de legenda
  guides(fill = guide_legend(override.aes = aes(color = NA)))+
  
  # rótulos dos eixos
  labs(
    title = "Casos com longa demora até admissão",
    y = "peso (kg)",
    x = "altura (cm)")
```





<!-- ======================================================= -->
## Eixos de tempo {}

Trabalhar com eixos de tempo no ggplot pode ser cansativo, mas é mais fácil com algumas funções chave. Lembre que, ao trabalhar com tempo ou datas, você deve garantir que as variáveis corretas estejam formatadas como das classes date ou datetime - veja a página [Trabalhando com datas](#dates) para mais informações, ou a página [Curvas epidêmicas](#epicurves), na seção sobre o ggplot, para exemplos.

O conjunto de funções mais útil para trabalhar com datas no `ggplot2` são as funções de escala (`scale_x_date()`, `scale_x_datetime()`, e os seus cognatos do eixo y). Estas funções permitem definir a frequência dos rótulos dos eixos, e como formatar esses rótulos. Para descobrir como formatar datas, veja a seção _working with dates_ novamente! Você pode utilizar os argumentos `date_breaks` e `date_labels` para especificar como as datas devem aparecer:

  1. `date_breaks` permite especificar a frequência das quebras dos eixos - você pode utilizar uma string (ex.: `"3 months"`, ou "`2 days"`)
  
  2. `date_labels` permite definir o formato das datas mostradas. Você pode utilizar uma string de formatação de datas (ex.: `"%b-%d-%Y"`):


```{r, , warning=F, message=F}
# crie uma epicurva por data de início dos sintomas, quando disponível
ggplot(linelist, aes(x = date_onset)) +
  geom_histogram(binwidth = 7) +
  scale_x_date(
    # 1 quebra a cada mês
    date_breaks = "1 months",
    # rótulos devem mostrar o mês, então a data
    date_labels = "%b %d"
  ) +
  theme_classic()

```



<!-- ======================================================= -->
## Destacando {}

Destacar elementos específicos em um gráfico é uma forma útil de chamar a atenção para algo nos dados, enquanto também fornece informação na distribuição dos dados no conjunto inteiro. Embora isto não seja feito de forma fácil no **ggplot2** básico, existe um pacote externo que pode ajudar nisso, conhecido como **gghighlight**. Ele é fácil de usar dentro da sintaxe do ggplot.

O pacote **gghighlight** utiliza a função `gghighlight()` para realizar os destaques. Para usar esta função, forneça um argumento lógico - o que pode ter muitos desfechos, mas iremos mostrar um exemplo da distribuição de idade dos casos em nosso linelist, ao destacar pelo desfecho clínico.

```{r, , warning=F, message=F}
# carregue o pacote gghighlight
library(gghighlight)

# substitua os valores NA por "unknown" na variável de desfecho
linelist <- linelist %>%
  mutate(outcome = replace_na(outcome, "Unknown"))

# produza um histograma de todos os casos de acordo com a idade
ggplot(
  data = linelist,
  mapping = aes(x = age_years, fill = outcome)) +
  geom_histogram() + 
  gghighlight::gghighlight(outcome == "Death")     # destaque as situações onde o desfecho do paciente foi óbito.

```

Isto também funciona bem com as funções de facetas - ele permite a produção de gráficos facetados com os dados no fundo em destaque, mas que não se aplica à faceta! Abaixo, nós contamos os casos por semana e criamos uma curva epidêmica por hospital (`color =` e `facet_wrap()` ajustado para a coluna `hospital`).  

```{r, , warning=F, message=F}

# produz um histograma de todos os casos por idade
linelist %>% 
  count(week = lubridate::floor_date(date_hospitalisation, "week"),
        hospital) %>% 
  ggplot()+
  geom_line(aes(x = week, y = n, color = hospital))+
  theme_minimal()+
  gghighlight::gghighlight() +                      # destaque as situações em que o paciente morreu
  facet_wrap(~hospital)                              # crie facetas de acordo com o desfecho

```





## Criando gráficos de múltiplos conjuntos de dados

Observe que alinhar adequadamente os eixos para criar gráficos de conjuntos de dados múltilos no mesmo gráfico pode ser difícil. Considere uma das seguintes estratégias:

* Una os dados antes de criar o gráfico, e então converta para o formato "longo" com uma coluna associando os dados
* Use **cowplot** ou um pacote similar para combinar dois gráficos (veja abaixo)






<!-- ======================================================= -->
## Combine os gráficos {}

Dois pacotes bem úteis para combinar gráficos são o **cowplot** e o **patchwork**. Nesta página, iremos focar no **cowplot**, e, ocasionalmente, usaremos o **patchwork**.  

Aqui está uma [introdução ao cowplot](https://cran.r-project.org/web/packages/cowplot/vignettes/introduction.html). Você pode ler a documentação mais extensa para cada função [aqui](https://www.rdocumentation.org/packages/cowplot/versions/1.1.1). Nós iremos mostrar alguns dos casos de uso e funções mais comuns a seguir.

O pacote **cowplot** funciona em tandem com **ggplot2** - essencialmente, você o utiliza para organizar e combinar ggplots e suas legendas em figuras compostas. Este pacote também aceita gráficos do R **base**.

```{r}
pacman::p_load(
  tidyverse,      # manipulação e visualização de dados
  cowplot,        # combine os gráficos
  patchwork       # combine os gráficos
)
```


Enquanto facetear (descrito na página [Básico do ggplot](#ggplot-basics)) é uma abordagem conveniente para criar gráficos, as vezes não é possível obter os resultados desejados com essa abordagem. Aqui, você pode escolher combinar os gráficos ao uni-los em um gráfico maior. Existem três pacotes bem conhecidos, que são ótimos para isso - **cowplot**, **gridExtra**, e **patchwork**. Entretanto, estes pacotes fazem basicamente a mesma coisa, de forma que iremos focar no **cowplot** nesta seção.

### `plot_grid()` {.unnumbered}

O pacote **cowplot** tem uma grande variedade de funções, mas o uso mais fácil dele é com `plot_grid()`. Isto é, efetivamente, uma forma de organizar gráficos pré-definidos em forma de uma rede. Nós podemos aplicar em outro exemplo com os dados de malária - aqui nós fizemos um gráfico com o total de casos por distrito, e também mostramos a curva epidêmica pelo tempo.


```{r, , warning=F, message=F}
malaria_data <- rio::import(here::here("data", "malaria_facility_count_data.rds")) 

# gráfico do total de casos por distrito
p1 <- ggplot(malaria_data, aes(x = District, y = malaria_tot)) +
  geom_bar(stat = "identity") +
  labs(
    x = "Distrito",
    y = "Número total de casos",
    title = "Quantidade total de casos de malária por distrito"
  ) +
  theme_minimal()

# curva epidêmica pelo tempo
p2 <- ggplot(malaria_data, aes(x = data_date, y = malaria_tot)) +
  geom_col(width = 1) +
  labs(
    x = "Data de envio dos dados",
    y =  "número de casos"
  ) +
  theme_minimal()

cowplot::plot_grid(p1, p2,
                  # 1 coluna e duas linhas - empilhadas uma sobre a outra
                   ncol = 1,
                   nrow = 2,
                   # gráfico de cima é 2/3 da altura do segundo
                   rel_heights = c(2, 3))


```




### Combine as legendas {.unnumbered}  

Caso os seus gráficos tenham a mesma legenda, combina-las é relativamente fácil. Simplesmente use a abordagem acima do **cowplot** para combinar os gráficos, mas remova a legenda de um deles (de-duplique).  

Caso seus gráficos tenham legendas diferentes, você precisa usar uma abordagem alternativa:

1) Crie e salve seus gráficos *sem as legendas* utilizando `theme(legend.position = "none")`  
2) Extraia as legendas de cada gráfico utilizando `get_legend()`, como mostrado abaixo - *mas extraia as legendas dos gráficos modificados para, na verdade, mostrar a legenda*  
3) Combine as legendas em um painel de legendas
4) Combine os gráficos e o painel de legendas


Para fins de demonstração, primeiro mostramos os dois gráficos separados, e, então organizados em uma grade com suas próprias legendas (feio e uso ineficiente de espaço):

```{r, out.width=c('50%'), fig.show='hold', warning=F, message=F}
p1 <- linelist %>% 
  mutate(hospital = recode(hospital, "St. Mark's Maternity Hospital (SMMH)" = "St. Marks")) %>% 
  count(hospital, outcome) %>% 
  ggplot()+
  geom_col(mapping = aes(x = hospital, y = n, fill = outcome))+
  scale_fill_brewer(type = "qual", palette = 4, na.value = "grey")+
  coord_flip()+
  theme_minimal()+
  labs(title = "Casos por desfecho clínico")


p2 <- linelist %>% 
  mutate(hospital = recode(hospital, "St. Mark's Maternity Hospital (SMMH)" = "St. Marks")) %>% 
  count(hospital, age_cat) %>% 
  ggplot()+
  geom_col(mapping = aes(x = hospital, y = n, fill = age_cat))+
  scale_fill_brewer(type = "qual", palette = 1, na.value = "grey")+
  coord_flip()+
  theme_minimal()+
  theme(axis.text.y = element_blank())+
  labs(title = "Casos por idade")

```

Aqui esta como os dois gráficos ficam quando combinados usando `plot_grid()`, mas sem combinar as suas legendas:

```{r, warning=F, message=F}
cowplot::plot_grid(p1, p2, rel_widths = c(0.3))
```

E agora nós mostramos como combinar as legendas. Essencialmente, o que fazemos é criar cada gráfico *sem* sua legenda (`theme(legend.position = "none"`), e então definimos cada legenda dos gráficos *separadamente*, usando a função `get_legend()` do **cowplot**. Quando extraimos a legenda do gráfico salvo, precisamos adicionar `+` a legenda de volta, incluindo o argumento de posição ("right") e ajustes menores para alinhar as legendas e seus títulos. Então, combinamos as legendas verticalmente, e os dois gráficos com a nova legenda combinada. Voilà!  

```{r, warning=F, message=F}

# Crie o gráfico 1 sem a legenda
p1 <- linelist %>% 
  mutate(hospital = recode(hospital, "St. Mark's Maternity Hospital (SMMH)" = "St. Marks")) %>% 
  count(hospital, outcome) %>% 
  ggplot()+
  geom_col(mapping = aes(x = hospital, y = n, fill = outcome))+
  scale_fill_brewer(type = "qual", palette = 4, na.value = "grey")+
  coord_flip()+
  theme_minimal()+
  theme(legend.position = "none")+
  labs(title = "Casos por desfecho clínico")


# Crie o gráfico 2 sem a legenda
p2 <- linelist %>% 
  mutate(hospital = recode(hospital, "St. Mark's Maternity Hospital (SMMH)" = "St. Marks")) %>% 
  count(hospital, age_cat) %>% 
  ggplot()+
  geom_col(mapping = aes(x = hospital, y = n, fill = age_cat))+
  scale_fill_brewer(type = "qual", palette = 1, na.value = "grey")+
  coord_flip()+
  theme_minimal()+
  theme(
    legend.position = "none",
    axis.text.y = element_blank(),
    axis.title.y = element_blank()
  )+
  labs(title = "Casos por idade")


# extraia a legenda do gráfico 1 (de gráfico1 + legenda)
leg_p1 <- cowplot::get_legend(p1 +
                                theme(legend.position = "right",        # extraia a legenda vertical
                                      legend.justification = c(0,0.5))+ # de forma que as legendas alinhem
                                labs(fill = "Desfecho"))                 # título da legenda
# extraia a legenda do gráfico 2 (de gráfico 2 + legend)
leg_p2 <- cowplot::get_legend(p2 + 
                                theme(legend.position = "right",         # extraia a legenda vertical
                                      legend.justification = c(0,0.5))+  # de forma que as legendas alinhem
                                labs(fill = "Categoria de idade"))             # título da legenda

# crie um gráfico em branco para alinhar a legenda
#blank_p <- patchwork::plot_spacer() + theme_void()

# crie um painel de legendas, pode ser um sobre o outro (ou utilize o espaçados comentado acima)
legends <- cowplot::plot_grid(leg_p1, leg_p2, nrow = 2, rel_heights = c(.3, .7))

# combine os dois gráficos e o painel de legendas criado
combined <- cowplot::plot_grid(p1, p2, legends, ncol = 3, rel_widths = c(.4, .4, .2))

combined  # visualize o gráfico


```

Esta solução foi apresentada [neste post](https://stackoverflow.com/questions/52060601/ggplot-multiple-legends-arrangement) com pequenos ajustes para alinhar as legendas [deste post](https://github.com/wilkelab/cowplot/issues/33).  


<span style="color: darkgreen;">**_DICA:_** Nota interessante -  o "cow" no **cowplot** vem do nome do criador do pacote - Claus O. Wilke.</span>  


### Inserção de gráficos {.unnumbered} 

Você pode inserir um gráfico em outros utilizando **cowplot**. Aqui estão pontos para estar ciente:

* Defina o gráfico principal com `theme_half_open()`, do **cowplot**; é recomendado colocar a legenda no topo ou na base do gráfico
* Defina o gráfico a ser inserido. O melhor é usar um gráfico que não precise de legenda. Você pode remover os elementos de tema deste gráfico com `element_blank()`, como mostrado abaixo.
* Os combine ao aplicar a função `ggdraw()` no gráfico principal, e então adicionando `draw_plot()` no gráfico a ser inserido, e especificando as coordenadas (x e y da extremidade baixa a esquerda), altura e comprimento proporcionais ao tamanho do gráfico principal.


```{r, out.width=c('100%'), fig.show='hold', warning=F, message=F}

# Defina o gráfico principal
main_plot <- ggplot(data = linelist)+
  geom_histogram(aes(x = date_onset, fill = hospital))+
  scale_fill_brewer(type = "qual", palette = 1, na.value = "grey")+ 
  theme_half_open()+
  theme(legend.position = "bottom")+
  labs(title = "Curva epidêmica e desfechos clínicos por hospital")


# Crie o gráfico a ser inserido
inset_plot <- linelist %>% 
  mutate(hospital = recode(hospital, "St. Mark's Maternity Hospital (SMMH)" = "St. Marks")) %>% 
  count(hospital, outcome) %>% 
  ggplot()+
    geom_col(mapping = aes(x = hospital, y = n, fill = outcome))+
    scale_fill_brewer(type = "qual", palette = 4, na.value = "grey")+
    coord_flip()+
    theme_minimal()+
    theme(legend.position = "none",
          axis.title.y = element_blank())+
    labs(title = "Casos por desfecho") 


# Combine o gráfico principal com o gráfico a ser inserido
cowplot::ggdraw(main_plot)+
     draw_plot(inset_plot,
               x = .6, y = .55,    #x = .07, y = .65,
               width = .4, height = .4)

```


Esta técnica é melhor explicada nestes dois resumos:

[Wilke lab](https://wilkelab.org/cowplot/articles/drawing_with_on_plots.html)  
[Documentação do draw_plot()](https://www.rdocumentation.org/packages/cowplot/versions/1.1.1/topics/draw_plot)




<!-- ======================================================= -->
## Eixos duplos {}

Um segundo eixo y é, frequentemente, solicitado em um gráfico `ggplot2`. Embora existam fortes debates sobre a validade destes gráficos na comunidade de visualização de dados, em que geralmente não são recomendados, o seu chefe pode requisitá-los. Abaixo, apresentamos um método para obtê-los: utilizando o pacote **cowplot** para combinar dois gráficos separados.

Esta abordagem envolve criar dois gráficos distintos - um com um eixo y na esquerda, e outro com o eixo y na direita. Ambos utilizarão um específico `theme_cowplot()` e terão o mesmo eixo x. Então, em um terceiro comando, os dois gráficos serão alinhados e sobrepostos. As funcionalidades do **cowplot**, das quais esta é apenas uma delas, são descritas em detalhes neste [site](https://wilkelab.org/cowplot/articles/aligning_plots.html).  

Para demonstrar esta técnica, iremos sobrepor uma curva epidêmica com uma linha de porcentagem semanal de pacientes que morreram. Nós usamos este exemplo pois o alinhamento de datas no eixo x é mais complexo do que, digamos, alinhar um gráfico de barras com outro gráfico. Algumas coisas a serem observadas:

* A epicurva e a linha são agregadas em semanas antes de criarmos os gráficos, *e* os `date_breaks` e `date_labels` são idênticos - nós fizemos isto de forma que os eixos x dos dois gráficos é o mesmo quando sobrepostos.
* O eixo y é movido para o lado direito, no gráfico 2, com o argumento `position =` de `scale_y_continuous()`.  
* Ambos gráficos fazem uso do `theme_cowplot()`  

Note que existe outro exemplo dessa técnica na página [Curvas epidêmicas](#epicurves) - a sobreposição da incidência acumulada acima da epicurva.

**Crie o primeiro gráfico**  
Este é, essencialmente, uma epicurva. Nós utilizamos `geom_area()` apenas para demonstrar o seu uso (área abaixo de uma linha, por padrão)

```{r, warning=F, message=F}
pacman::p_load(cowplot)            # carregue/instale o cowplot

p1 <- linelist %>%                 # salve o gráfico como um objeto
     count(
       epiweek = lubridate::floor_date(date_onset, "week")) %>% 
     ggplot()+
          geom_area(aes(x = epiweek, y = n), fill = "grey")+
          scale_x_date(
               date_breaks = "month",
               date_labels = "%b")+
     theme_cowplot()+
     labs(
       y = "Casos semanais"
     )

p1                                      # veja o gráfico 
```

**Crie o segundo gráfico**  
Crie o segundo gráfico mostrando uma linha com a porcentagem semanal de óbitos.

```{r, warning=F, message=F}

p2 <- linelist %>%         # salve seu gráfico como um objeto
     group_by(
       epiweek = lubridate::floor_date(date_onset, "week")) %>% 
     summarise(
       n = n(),
       pct_death = 100*sum(outcome == "Death", na.rm=T) / n) %>% 
     ggplot(aes(x = epiweek, y = pct_death))+
          geom_line()+
          scale_x_date(
               date_breaks = "month",
               date_labels = "%b")+
          scale_y_continuous(
               position = "right")+
          theme_cowplot()+
          labs(
            x = "Semana epidemiológica de aparecimento dos sintomas",
            y = "Percentual semanal de mortes",
            title = "Incidência semanal de casos e percentual de mortes"
          )

p2     # veja o gráfico
```

Agora alinhamos o gráfico usando a função `align_plots()`, especificando os alinhamentos horizontal e vertical ("hv", poderia também ser "h", "v", "none"). Também especificamos o alinhamento de todos os eixos ("top", "bottom", "left", e "right") com "tblr". O resultado é da classe list (2 elementos).    

Então, desenhamos os dois gráficos juntos utilizando `ggdraw()` (do **cowplot**) e referenciando as outras duas partes do objeto `aligned_plots`.  

```{r, warning=F, message=F}
aligned_plots <- cowplot::align_plots(p1, p2, align="hv", axis="tblr")         # alinhe os dois gráficos e os salve como uma lista
aligned_plotted <- ggdraw(aligned_plots[[1]]) + draw_plot(aligned_plots[[2]])  # sobreponha os gráficos e salve o gráfico visualizado
aligned_plotted                                                                # visualize os gráficos sobrepostos

```



<!-- ### Transformação estatística {.unnumbered}   -->
<!-- Outra forma de fazer isto é criar o segundo eixo como uma transformação do segundo eixo.  -->

<!-- Diferenças nos valores dos eixos serão puramente estéticas - se você quiser mostrar duas variáveis diferentes em um gráfico, com diferentes escalas do eixo y para cada variável, não funcionará sem algum trabalho por trás. Para obtêr este efeito, você precisará transformar uma das suas variáveis nos dados, e então aplicar a mesma transformação *de forma reversa* ao especificar os rótulos dos eixos. Baseado nisto, você pode especificar a transformação de forma explícita (ex.: variável a é 10x maior do que a variável b, ou calcular ela no código (ex.: qual a proporção entre os valores máximos e mínimos de cada conjunto de dados). -->


<!-- A sintaxe para dicionar um segundo eixo é bem direta! Quando usar uma função `scale_xxx_xxx()` (ex.: `scale_y_continuous()`), use o argumento `sec.axis` para chamar a função `sec_axis()`. O argumento `trans` nesta função permite especificar a transformação do rótulo para o eixo - forneça este rótulo na sintaxe do tidyverse.  -->

<!-- Por exemplo, se quisermos mostrar o número de testes rápidos positivos para malária nos dados de malária, para a unidade 1, mostrando 0-4 anos de idade e todos os casos em um gráfico: -->


<!-- ```{r, , warning=F, message=F} -->

<!-- # pegue os dados de malária da unidade 1 -->
<!-- malaria_facility_1 <- malaria_data %>% -->
<!--   filter(location_name == "Facility 1") -->

<!-- # calcule a razão entre malaria_rdt_0-4 e malaria_tot  -->

<!-- tf_ratio <- max(malaria_facility_1$malaria_tot, na.rm = T) / max(malaria_facility_1$`malaria_rdt_0-4`, na.rm = T) -->

<!-- # transforme os valores nos dados -->

<!-- malaria_facility_1 <- malaria_facility_1 %>% -->
<!--   mutate(malaria_rdt_0_4_tf =`malaria_rdt_0-4` * tf_ratio) -->


<!-- # crie o gráfico com dois eixos -->

<!-- ggplot(malaria_facility_1, aes(x = data_date)) + -->
<!--   geom_line(aes(y = malaria_tot, col = "Total cases")) + -->
<!--   geom_line(aes(y = malaria_rdt_0_4_tf, col = "Cases: 0-4 years old")) + -->
<!--   scale_y_continuous( -->
<!--     name = "Total cases", -->
<!--     sec.axis = sec_axis(trans = ~ . / tf_ratio, name = "Casos: 0-4 anos de idade") -->
<!--   ) + -->
<!--   labs(x = "data de obtenção dos dados") + -->
<!--   theme_minimal() + -->
<!--   theme(legend.title = element_blank()) -->



<!-- ``` -->






<!-- ## Sparklines   -->

<!-- UNDER CONSTRUCTION   -->
<!-- (perhaps move to Tables for presentation page) -->




## Pacotes para te ajudar  


Existem ótimos pacotes do R desenhados especificamente para ajudar a navegar no **ggplot2**:  


### Aponte-e-clique no **ggplot2** com **equisse**  {.unnumbered}

"Este complemento permite que você explore seus dados de forma interativa, ao visualiza-los com o pacote ggplot2. Ele permite desenhar gráficos de barras, curvas, gráficos de dispersão, hsitogramas, boxplots e objetos sf, e, então, exportar o gráfico e gerar o código de geração do gráfico."

Instale e então o execute o pacote por meio do menu do RStudio ou com `esquisse::esquisser()`.

Veja a página do [Github](https://github.com/dreamRs/esquisse)

[Documentação](https://dreamrs.github.io/esquisse/index.html)









## Dicas diversas


### Exibição dos números {.unnumbered}  

Você pode desabilitar a notação científica ao executar este comando antes de criar o gráfico.

```{r, eval=F}
options(scipen=999)
```

Ou aplicar `number_format()`, do pacote **scales**, para um valor ou coluna específica, como mostrado abaixo.

Use funções do pacote **scales** para facilmente ajustar como os números são mostrados. Isto pode ser aplicado para colunas em seus dados, mas aqui são mostrados em números individuais para fins de exemplo.

```{r}
scales::number(6.2e5)
scales::number(1506800.62,  accuracy = 0.1,)
scales::comma(1506800.62, accuracy = 0.01)
scales::comma(1506800.62, accuracy = 0.01,  big.mark = "." , decimal.mark = ",")
scales::percent(0.1)
scales::dollar(56)
scales::scientific(100000)
```

## Recursos extras

Para inspiração, 
[galeria de gráficos do ggplot](https://www.tidyverse.org/blog/2018/07/ggplot2-3-0-0/)

Recomendação de formas de apresentação de dados
Centro Europeu de Prevenção e Controle de Doenças [Recomendações para apresentação de dados de vigilância](https://ecdc.europa.eu/sites/portal/files/documents/Guidelines%20for%20presentation%20of%20surveillance%20data-final-with-cover-for-we....pdf) 


Facetas e rotuladores
[Utilizando rotuladores para feixes de facetas](http://www.cookbook-r.com/Graphs/Facets_(ggplot2)/#modifying-facet-label-text)
[Rotuladores](https://ggplot2.tidyverse.org/reference/labellers.html)

Ajustando a ordem com factors
[fct_reorder](https://forcats.tidyverse.org/reference/fct_reorder.html)  
[fct_inorder](https://forcats.tidyverse.org/reference/fct_inorder.html)  
[Como reordenar um  boxplot](https://cmdlinetips.com/2019/02/how-to-reorder-a-boxplot-in-r/)  
[Reordene uma variável no ggplot2](https://www.r-graph-gallery.com/267-reorder-a-variable-in-ggplot2.html)  
[R para Ciência dos Dados - Factors](https://r4ds.had.co.nz/factors.html)  

Legendas  
[Ajuste a ordem da legenda](https://stackoverflow.com/questions/38425908/reverse-stacking-order-without-affecting-legend-order-in-ggplot2-bar-charts)  

Títulos
[Alinhamento do título](https://stackoverflow.com/questions/64701500/left-align-ggplot-caption)  

Rótulos  
[ggrepel](https://ggrepel.slowkow.com/articles/examples.html)  

Colinhas
[Lindos gráficos com  ggplot2](http://zevross.com/blog/2014/08/04/beautiful-plotting-in-r-a-ggplot2-cheatsheet-3/)  




<!-- TO DO - Under construction -->


<!-- * Straight horizontal, vertical, or other line -->

<!-- You can also add straight lines to your plot with `geom_hline()` (horizontal), `geom_vline()` (vertical) or `geom_abline()` (with a specified y intercept and slope) -->


<!-- Using option `label_wrap_gen` in facet_wrap to have multiple strip lines -->
<!-- labels and colors of strips -->

<!-- Axis text vertical adjustment -->
<!-- rotation -->
<!-- Labellers -->

<!-- limit range with limit() and coord_cartesian(), ylim(), or scale_x_continuous() -->
<!-- theme_classic() -->

<!-- expand = c(0,0) -->
<!-- coord_flip() -->
<!-- tick marks -->

<!-- ggrepel -->
<!-- animations -->

<!-- remove -->
<!-- remove title -->
<!-- using fill = or color = in labs() -->
<!-- flip order / don't flip order -->
<!-- move location -->
<!-- color?    theme(legend.title = element_text(colour="chocolate", size=16, face="bold"))+ scale_color_discrete(name="This color is\ncalled chocolate!?") -->
<!-- Color of boxes behind points in legend  -->
<!--      theme(legend.key=element_rect(fill='pink'))   or use fill = NA to remove them. http://zevross.com/blog/2014/08/04/beautiful-plotting-in-r-a-ggplot2-cheatsheet-3/  -->
<!-- Change size of symbols in legend only guides(colour = guide_legend(override.aes = list(size=4))) -->


<!-- Turn off a layer in the legend -->
<!-- geom_text(data=nmmaps, aes(date, temp, label=round(temp)), size=4) -->
<!-- geom_text(data=nmmaps, aes(date, temp, label=round(temp), size=4), show_guide=FALSE) -->

<!-- Force a legend even if there is no aes().  -->
<!-- ggplot(nmmaps, aes(x=date, y=o3))+ -->
<!--      geom_line(aes(color="Important line"))+ -->
<!--      geom_point(aes(color="My points")) -->
<!-- Control the shape in the legend with guides - a list with linetype and shape -->
<!-- ggplot(nmmaps, aes(x=date, y=o3))+geom_line(aes(color="Important line"))+ -->
<!--    geom_point(aes(color="Point values"))+ -->
<!--   scale_colour_manual(name='', values=c('Important line'='grey', 'Point values'='red'), guide='legend') + -->
<!--   guides(colour = guide_legend(override.aes = list(linetype=c(1,0) -->
<!--                                                       , shape=c(NA, 16)))) -->
```{r include=FALSE, cache=FALSE}

# clear workspace
rm(list = ls(all = TRUE))

# clear all packages except base
#lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))

# to ensure that tidyverse packages prevail
filter <- dplyr::filter
select <- dplyr::select
summarise <- dplyr::summarise
summary <- base::summary
incidence <- incidence2::incidence

#load core packages
pacman::p_load(
     rio,
     here,
     DT,
     stringr,
     lubridate,
     tidyverse
)

# import the cleaned ebola linelist
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

# import the count data - facility level
#count_data <- rio::import(here::here("data", "facility_count_data.rds"))

# Settings

options(scipen=1, digits=7)

# print only text (not code)
# library(knitr)
# opts_chunk$set(list(echo = FALSE, eval = FALSE))
```

<!--chapter:end:new_pages/ggplot_tips.Rmd-->


# Curvas epidêmicas {#epicurves}  

```{r, out.width=c('75%'), echo=F, message=F}
knitr::include_graphics(here::here("images", "epicurve_top.png"))
```    


Uma curva epidêmica (também conhecida como "epicurva") é uma ferramenta essencial tipicamente utilizada para visualizar padrões temporais do início de doenças entre um conjunto ou epidemia de casos.

A análise da epicurva pode revelar tendências temporais, anomalias/valores discrepantes ("outliers"), a magnitude de um surto, o período mais provável de exposição, intervalos temporais entre picos de casos, e pode até ajudar a identificar o modo de transmissão de uma doença não identificada (ex.: fonte pontual, fonte comum contínua, propagação pessoa-pessoa). Uma aula online sobre a interpretação de epicurvas pode ser encontrada no website do [CDC americano](https://www.cdc.gov/training/quicklearns/epimode/index.html).    

Nesta página, nós demonstraremos duas abordagens para a produção de curvas epidêmicas no R:

* O pacote **incidence2**, que pode produzir uma epicurva com comandos simples
* O pacote **ggplot2**, que permite customizações avançadas através de comandos mais complexos

Também serão abordados casos de uso específico:

* Criar gráficos de contagem agregada  
* Mostrar ou produzir múltiplos-pequenos
* Aplicar médias móveis
* Mostrar quais dados são "preliminares" ou sujeitos a atrasos na notificação
* Sobreposição da incidência acumulada de casos usando um segundo eixo do gráfico

<!-- ======================================================= -->
## Preparação


### Carregue os pacotes necessários {.unnumbered}  

O código abaixo realiza o carregamento dos pacotes necessários para a análise dos dados. Neste manual, enfatizamos o uso da função `p_load()`, do **pacman**, que instala os pacotes, caso não estejam instalados, *e* os carrega no R para utilização. Também é possível carregar pacotes instalados utilizando a função `library()`, do R **base**. Para mais informações sobre os pacotes do R, veja a página [Introdução ao R](#basics).  

```{r message=F, warning=F}
pacman::p_load(
  rio,          # importar/exportar arquivos
  here,         # caminhos de arquivos relativos 
  lubridate,    # trabalhando com datas/semanas epidemiológicas
  aweek,        # pacote alternativo para trabalhar com datas/semanas epidemiológicas
  incidence2,   # epicurvas de dados em uma linelist
  i2extras,     # suplemento para o pacote incidence2
  stringr,      # procure e manipule strings de caracteres
  forcats,      # trabalhando com fators
  RColorBrewer, # paleta de cores do colorbrewer2.org
  tidyverse     # gerenciamento de dados + gráficos no ggplot2
) 
```


### Importe os dados {.unnumbered}

Dois exemplos de conjuntos de dados são utilizados nesta seção:

* Lista de linhas (linelist) com casos individuais de uma simulação de epidemia
* Contagens agregadas por hospital da mesma epidemia simulada

Os conjuntos de dados são importados utilizando a função `import()` do pacote **rio**. Veja a página sobre [Importar e  exportar](#importing)  para conhecer as diferentes formas de importar dados.


```{r, echo=F, message=F}
# importe a lista de linhas no R
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

# importe os dados de contagem no R
count_data <- linelist %>% 
  group_by(hospital, date_hospitalisation) %>% 
  summarize(n_cases = dplyr::n()) %>% 
  filter(date_hospitalisation > as.Date("2013-06-01")) %>% 
  ungroup()
```


**Lista de linhas de casos**

Nós importamos o conjunto de dados de casos de uma simulação de epidemia de Ebola. Se você quiser baixar os dados para acompanhar etapa-por-etapa, veja instruções na página sobre [Download do manual e dados](data-used). Aqui, nós assumimos que o arquivo está no diretório de trabalho. Logo, nenhuma sub-pasta é especificada no endereço do arquivo.

```{r, eval=F}
linelist <- import("linelist_cleaned.xlsx")
```

As primeiras 50 linhas são mostradas abaixo.

```{r, message=FALSE, echo=F}
# mostre os dados da linelist como uma tabela
DT::datatable(head(linelist, 50), rownames = FALSE, options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```



**Casos agregados por hospital**  

Para atingir os propósitos deste manual, o conjunto de dados de contagens semanais de casos agregados por hospital é criado a partir da `linelist`, com o seguinte código.

```{r, eval=F}
# cria os dados de contagem no R
count_data <- linelist %>% 
  group_by(hospital, date_hospitalisation) %>% 
  summarize(n_cases = dplyr::n()) %>% 
  filter(date_hospitalisation > as.Date("2013-06-01")) %>% 
  ungroup()
```

As primeiras 50 linhas são mostradas abaixo:

```{r message=FALSE, echo=F}
# mostre os dados da linelist como uma tabela
DT::datatable(head(count_data, 50), rownames = FALSE, options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```




### Ajuste os parâmetros {.unnumbered}

Para produzir um relatório, você pode querer ajustar parâmetros modificáveis, como a data para a qual os dados são atuais (a "data dos dados"). Você pode, então, referenciar o objeto `data_date` em seu código ao aplicar filtros ou em legendas dinâmicas.

```{r set_parameters}
## ajuste a data do relatório para o relatório
## nota: pode ser ajustada para Sys.Date() para a data atual
data_date <- as.Date("2015-05-15")
```



### Verifique as datas {.unnumbered}

Perceba que cada coluna de datas relevantes é da classe Date e tem um intervalo apropriado de valores. Você pode fazer isso simplesmente utilizando `hist()`, para histograma, ou `range()` com `na.rm=TRUE`, ou com o `ggplot()`, como mostrado abaixo.

```{r, out.width = c('50%', '50%', '50%'), fig.show='hold', warning=F, message=F}
# cheque o intervalo das datas de início dos sintomas
ggplot(data = linelist)+
  geom_histogram(aes(x = date_onset))
```



<!-- ======================================================= -->
## Epicurvas no ggplot2 { }

Utilizar o `ggplot()` para criar sua epicurva permite mais flexibilidade e customização. Entretanto, é necessário mais esforço e entendimento sobre como o `ggplot()` funciona.

Diferente do pacote **incidence2**, no **ggplot** você precisa controlar *manualmente* a agregação dos casos pelo tempo (em semanas, meses, etc) *e* os intervalos dos rótulos no eixo de data. Isto precisa ser cuidadosamente gerenciado.

Os exemplos abaixo utilizam um subconjunto do banco de dados `linelist` - apenas os casos do Hospital Central.


```{r, echo=F}
# importe a linelist para o R
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))
```

```{r}
central_data <- linelist %>% 
  filter(hospital == "Central Hospital")
```

```{r, eval=F, echo=F}
detach("package:tidyverse", unload=TRUE)
library(tidyverse)
```


Para produzir uma epicurva com o `ggplot()`, existem três elementos principais:

* Um histograma, com os casos da linelist agregados em "classes" (Nota do tradutor: tradução livre de ´bins´, que em inglês significa caixa, ou container) separados por pontos "de quebra" específicos
* Escalas para os eixos e seus rótulos
* Temas para a aparência do gráfico, incluindo títulos, rótulos, legendas, etc.


### Especifique as classes de casos {.unnumbered}  

Aqui nós mostramos como especificar a maneira em que os casos serão agregados nas classes do histogramas ("barras"). É importante reconhecer que o agrupamento dos casos nessas classes do histograma **não** será necessariamente nos mesmos intervalos das datas que irão aparecer no eixo x.

A seguir é mostrado, provavelmente, o código mais simples para produzir epicurvas diárias ou semanais.

No comando global `ggplot()`, o conjunto de dados é fornecido em `data = `. A partir disto, a geometria do histrograma é adicionada com um `+`. Dentro de `geom_histogram()`, nós mapeamos a aparência do gráfico de forma que a coluna `date_onset` é mapeada para o eixo x. Também dentro de `geom_histogram()`, mas *não* dentro de `aes()`, nós ajustamos o `binwidth =` dos containers do histobrama, em dias. Se essa sintaxe do **ggplot2** é confusa, revise a página sobre [básico do ggplot](#ggplot-basics).  

<span style="color: orange;">**_CUIDADO:_** Criar um gráfico de casos semanas ao utilizar `binwidth = 7` inicia o primeiro container de 7-dias no primeiro caso, que pode ser em qualquer dia da semana! Para criar semanas específicas, veja a seção abaixo.</span>


``` {r ggplot_simple,  out.width = c('50%', '50%'), fig.show='hold', warning= F, message = F}
# diariamente 
ggplot(data = central_data) +          # escolha os dados
  geom_histogram(                      # adicione o histograma
    mapping = aes(x = date_onset),     # mapeia a coluna de data para o eixo x
    binwidth = 1)+                     # casos unidos por 1 dia
  labs(title = "Hospital Central - Diariamente")                # título

# semanal
ggplot(data = central_data) +          # escolha os dados 
  geom_histogram(                      # adicione o histograma
      mapping = aes(x = date_onset),   # mapeia a coluna de data para o eixo x
      binwidth = 7)+                   # casos unidos a cada 7 dias, iniciando no primeiro caso (!)
  labs(title = "Hospital Central - classes de 7-dias, iniciando no primeiro caso") # título
```

Deixe-nos observar que o primeiro caso neste conjunto de dados do Hospital Central teve o início dos sintomas em:

```{r}
format(min(central_data$date_onset, na.rm=T), "%A %d %b, %Y")
```

**Para especificar manualmente as quebras das classes do histograma, *não* utilize o argumento `binwidth = `, e, em vez disso, forneça um vetor de datas para `breaks = `.**  

Crie o vetor de datas com a função `seq.Date()` do R **base**. Esta função precisa dos argumentos `to = `, `from = `, e `by = `. Por exemplo, o comando abaixo retorna datas mensais começando em 15 de janeiro e terminando em 28 de junho.

```{r}
monthly_breaks <- seq.Date(from = as.Date("2014-02-01"),
                           to = as.Date("2015-07-15"),
                           by = "months")

monthly_breaks   # exporta para o console
```

Este vetor pode ser fornecido para `geom_histogram()` como `breaks = `:  

```{r, warning=F, message=F}
# mensalmente 
ggplot(data = central_data) +  
  geom_histogram(
    mapping = aes(x = date_onset),
    breaks = monthly_breaks)+         # forneça um vetor pré-definido de quebras
  labs(title = "Classe de casos mensais")   # título
```

Uma sequência semanal simples pode ser obtida ao ajustar `by = "week"`. Por exemplo:

```{r}
weekly_breaks <- seq.Date(from = as.Date("2014-02-01"),
                          to = as.Date("2015-07-15"),
                          by = "week")
```

 
Uma alternativa para o fornecimento de datas específicas de início e fim, é escrever um código *dinâmico* de forma que classes semanais iniciem *na segunda antes do primeiro caso*. **Nós iremos utilizar estes vetores de data nos exemplos abaixo.**  
     
```{r}
# Sequência de datas semanais iniciando nas Segundas para o HOSPITAL CENTRAL
weekly_breaks_central <- seq.Date(
  from = floor_date(min(central_data$date_onset, na.rm=T),   "week", week_start = 1), # segunda anterior
  to   = ceiling_date(max(central_data$date_onset, na.rm=T), "week", week_start = 1), # segunda após o último caso
  by   = "week")
```  

Vamos destrinchar o código complicado mostrado acima:

* O valor "from" (data mais antiga da sequência) é criado da seguinte forma: a menor data (`min()` com `na.rm=TRUE`) na coluna `date_onset` é atribuída a `floor_date()`, do pacote **lubridate**. `floor_date()` é ajustada para gerar "semanas" a partir da data de início dos casos da "semana" em questão, considerando que o dia de início de cada semana é segunda (`week_start = 1`).  
* Da mesma forma, o valor "to" (data final da sequência) é criado utilizando a função inversa `ceiling_date()` para retornar a segunda *após* o último caso.
* O argumento "by" de `seq.Date()` pode ser ajustado para qualquer número de dias, semanas, ou meses.
* Utilize `week_start = 7` para semanas que iniciem no Domingo

Como iremos utilizar estes vetores de data nesta página, nós também definimos um vetor para o surto inteiro (o vetor acima é apenas para os casos do Hospital Central).

```{r}
# Sequência para o surto inteiro
weekly_breaks_all <- seq.Date(
  from = floor_date(min(linelist$date_onset, na.rm=T),   "week", week_start = 1), # segunda antes do primeiro caso
  to   = ceiling_date(max(linelist$date_onset, na.rm=T), "week", week_start = 1), # segunda após o último caso
  by   = "week")
```

Estas saídas do `seq.Date()` podem ser usadas para criar quebras de classes do histogramas, assim como as quebras para os rótulos de data, que podem ser independentes das primeiras. Leia mais sobre os rótulos de datas em seções posteriores.

<span style="color: darkgreen;">**_DICA:_** Para um comando `ggplot()` mais simples, salve as quebras das classes e as quebras dos rótulos de datas como vetores nomeados no começo, e simplesmente os forneça em `breaks = `.</span>  







### Exemplo de epicurva semanal {.unnumbered}  

**Abaixo esta detalhado um exemplo de código utilizado para produzir epicurvas semanais para semanas que iniciam nas segundas, com barras alinhadas, rótulos de data, e linhas de grade verticais.** Esta seção é para o usuário que precisa rapidamente de um código. Para entender cada aspecto (temas, rótulos de datas, etc.) profundamente, continue para as seções subsequentes. De nota:

* As *quebras dos containers do histograma* são definidas com `seq.Date()`, como explicado acima, para iniciar na segunda anterior ao primeiro caso, e para terminar na segunda posterior ao último caso
* O intervalo dos *rótulos de data* é especificado por `date_breaks =` dentro de `scale_x_date()`  
* O intervalo de linhas da grade vertical menores entre os rótulos de data é especificado em `date_minor_breaks = `  
* `expand = c(0,0)` nas escalas de x e y remove o excesso de espaço em cada lado dos eixos, o que também garante que os rótulos de data iniciem a partir da primeira barra.

```{r, warning=F, message=F}
# ALINHAMENTO TOTAL A PARTIR DAS SEGUNDAS-FEIRAS
#############################
# Defina a sequência de quebras semanais
weekly_breaks_central <- seq.Date(
      from = floor_date(min(central_data$date_onset, na.rm=T),   "week", week_start = 1), # Segunda antes do primeiro caso
      to   = ceiling_date(max(central_data$date_onset, na.rm=T), "week", week_start = 1), # Segunda após último caso
      by   = "week")    # containers são de 7-dias


ggplot(data = central_data) + 
  
  # crie o histograma: especifique os pontos de quebra do container: inicie na segunda antes do primeiro caso, termine na segunda após o último caso
  geom_histogram(
    
    # mapeando a estética do gráfico
    mapping = aes(x = date_onset),  # coluna de data mapeada para o eixo x
    
    # quebras da classe do histograma
    breaks = weekly_breaks_central, # quebras do container do histograma definidas anteriormente
    
    # barras
    color = "darkblue",     # cor das linhas ao redor das barras
    fill = "lightblue"      # cor do preenchimento das barras
  )+ 
    
  # rótulos do eixo x
  scale_x_date(
    expand            = c(0,0),           # remove o espaço em excesso do eixo x antes e após as barras de casos
    date_breaks       = "4 weeks",        # rótulos de data e principais linhas de grade verticais aparecem a cada 3 semanas iniciando nas segundas
    date_minor_breaks = "week",           # linhas de grade menores aparecem a cada semana iniciando na segunda
    date_labels       = "%a\n%d %b\n%Y")+ # formato dos rótulos de data
  
  # eixo y
  scale_y_continuous(
    expand = c(0,0))+             # remove o excesso de espaço do eixo y abaixo de 0 (alinha o histograma nivelado com o eixo x)
  
  # temas estéticos
  theme_minimal()+                # simplifique o fundo do gráfico
  
  theme(
    plot.caption = element_text(hjust = 0,        # legenda no lado esquerdo
                                face = "italic"), # legenda em itálico
    axis.title = element_text(face = "bold"))+    # título dos eixos em negrito
  
  # rótulos incluindo legendas dinâmicas
  labs(
    title    = "Incidência semanal de casos (Semanas iniciadas na segunda)",
    subtitle = "Observe o alinhamento das barras, linhas de grade verticais, e rótulos dos eixos nas semanas iniciadas na segunda",
    x        = "Semana de aparecimetno dos sintomas",
    y        = "Incidência semanal dos casos notificados",
    caption  = stringr::str_glue("n = {nrow(central_data)} do Hospital Central; Aparecimento dos casos varia de {format(min(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')} a {format(max(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')}\n{nrow(central_data %>% filter(is.na(date_onset)))} casos sem a data de aparecimento dos sintomas e não mostrados neste gráfico"))
```


#### Semanas iniciando no domingo {.unnumbered}  

Para obter o gráfico acima para semanas que iniciam no domingo, algumas poucas modificações são necessárias, uma vez que o `date_breaks = "weeks"` funciona apenas para semanas iniciando às segundas.

* Os pontos de quebra das *classes do histograma* precisam serem ajustados para os domingos (`week_start = 7`)  
* Dentro de `scale_x_date()`, as datas de quebra similares devem ser fornecidas para `breaks =` e `minor_breaks = `, visando garantir que os rótulos de data e linhas de grade verticais alinhem nos domingos.

Por exemplo, o comando `scale_x_date()`, para semanas iniciando nos domingos, pode ser semelhante ao seguinte:

```{r, eval=F}
scale_x_date(
    expand = c(0,0),
    
    # especifique o intervalo do rótulo de datas e das linhas de grade principais
    breaks = seq.Date(
      from = floor_date(min(central_data$date_onset, na.rm=T),   "week", week_start = 7), # Domingo antes do primeiro caso
      to   = ceiling_date(max(central_data$date_onset, na.rm=T), "week", week_start = 7), # Domingo após o último caso
      by   = "4 weeks"),
    
    # especifique o intervalo das linhas de grade vertical secundárias
    minor_breaks = seq.Date(
      from = floor_date(min(central_data$date_onset, na.rm=T),   "week", week_start = 7), # Domingo antes do primeiro caso
      to   = ceiling_date(max(central_data$date_onset, na.rm=T), "week", week_start = 7), # Domingo após o último caso
      by   = "week"),
   
    # formato do rótulo de data
    #date_labels = "%a\n%d %b\n%Y")+         # dia, mês acima abreviado, sobre o ano com 2-dígitos
    label = scales::label_date_short())
```



### Grupo/cor por valor {.unnumbered}

As barras do histograma podem ser coloridas por grupo e podem ser "empilhadas" (o inglês *stacked*). Para designar a coluna de agrupamento, faça as seguintes modificações. Veja a página sobre [básico do ggplot](#ggplot-basics) para mais detalhes.

* Dentro do mapeamento estético do histograma, `aes()`, mapeie o nome da coluna para os argumentos `group = ` e `fill = `  
* Remova qualquer argumento de `fill = ` *fora* de `aes()`, uma vez que irá sobrepor-se ao argumentos que estão dentro
* Argumentos *dentro* de `aes()` serão aplicados *por grupo*, enquanto qualquer argumento *fora* será aplicado para todas as barras (ex.: você pode querer `color = ` fora, de forma que cada barra tenha a mesma borda)

Aqui é mostrado como o comando `aes()` pode ser utilizado para agrupar e colorir as barras de acordo com o gênero:

```{r, eval=F}
aes(x = date_onset, group = gender, fill = gender)
```

A seguir, ele sendo aplicado:

```{r, warning=F, message=F}
ggplot(data = linelist) +     # comece com o linelist (muitos hospitais)
  
  # crie o histograma: especifique os pontos de ruptura dos containers: começe na segunda anterior ao primeiro caso, e finalize na segunda após o último caso
  geom_histogram(
    mapping = aes(
      x = date_onset,
      group = hospital,       # ajuste os dados para serem agrupados por hospital
      fill = hospital),       # preenchimento da barra (cor de dentro) de acordo com o hospital
    
    # quebras dos contentores são nas semanas iniciadas nas segundas
    breaks = weekly_breaks_all,   # sequência de quebras semanais iniciadas nas segundas para o surto inteiro, como definido em código anterior
    
    # Cor ao redor das barras
    color = "black")
```


### Ajuste as cores {.unnumbered}  

* Para *manualmente* ajustar o preenchimento de cada grupo, utilize `scale_fill_manual()` (nota: `scale_color_manual()` é diferente!).
  * Use o argumetno `values = ` para aplicar um vetor de cores.
  * Use o argumetno `na.value = ` para especificar uma cor para os valores `NA`.  
  * Use o argumento `labels = ` para mudar o texto dos itens da legenda. Por segurança, forneça como um vetor nomeado, como `c("old" = "new", "old" = "new")` ou ajuste os valores nos próprios dados.
  * Use `name = ` para dar um título adequado à legenda
* Para mais dicas sobre escalas de cor e paletas, veja a página sobre [básico do ggplot](#ggplot-basics).  

```{r, warning=F, message=F}
ggplot(data = linelist)+           # inicie com a linelist (muitos hospitais)
  
  # crie um histograma
  geom_histogram(
    mapping = aes(x = date_onset,
        group = hospital,          # casos agrupados por hospital
        fill = hospital),          # barras preenchidas por hospital
    
    # quebra dos containers
    breaks = weekly_breaks_all,        # sequência de quebras semanais iniciadas nas segundas, como definido em código anterior
    
    # Cor ao redor das barras
    color = "black")+              # cor da borda para cada barra
  
  # especificação manual das cores
  scale_fill_manual(
    values = c("black", "orange", "grey", "beige", "blue", "brown"),
    labels = c("St. Mark's Maternity Hospital (SMMH)" = "St. Mark's"),
    name = "Hospital") # especifique as cores de preenchimento ("values") - atenção à ordem!
```




### Ajuste a ordem dos níveis {.unnumbered}  

A ordem em que as barras agrupadas estão empilhadas é melhor ajustada ao se classificar a coluna de agrupamento como sendo da classe fator (*Factor*). Você poderá, então, designar a ordem dos níveis desse fator (e os rótulos mostrados). Veja a página sobre [Fatores](#factors) ou [dicas do ggplot](#ggplot-tips) para mais detalhes.

Antes de criar o gráfico, utilize a função `fct_relevel()` do pacote **forcats** para converter a coluna de agrupamento para a classe factor, e manualmente ajustar a ordem dos níveis, como detalhado na página sobre [Fatores](#factors).

```{r}
# carregue o pacote forcats para trabalhar com fators
pacman::p_load(forcats)

# Defina um novo conjunto de dados com o hospital como fator
plot_data <- linelist %>% 
  mutate(hospital = fct_relevel(hospital, c("Missing", "Other"))) # Converta para fator e ajuste "Missing" e "Other" como níveis do topo para aparecerem no topo da epicurva

levels(plot_data$hospital) # gere os níveis em ordem
```

No gráfico abaixo, a única diferença do gráfico anterior é que a coluna `hospital` foi consolidada como mostrado acima, e nós utilizamos `guides()` para reverter a ordem da legenda, de forma que "Missing" está no fim da legenda.

```{r, warning=F, message=F}
ggplot(plot_data) +                     # Utilize um NOVO conjunto de dados com hospital reordenado como fator
  
  # crie o histograma
  geom_histogram(
    mapping = aes(x = date_onset,
        group = hospital,               # casos agrupados por hospital
        fill = hospital),               # preenchimento da barra (cor) por hospital
    
    breaks = weekly_breaks_all,         # sequência de quebras semanais iniciadas nas segundas para o surto inteiro, como definido no topo da seção sobre ggplot
    
    color = "black")+                   # cor da borda ao redor de cada barra
    
  # rótulos do eixo x
  scale_x_date(
    expand            = c(0,0),         # remova o excesso de espaço do eixo x antes e após as barras de casos
    date_breaks       = "3 weeks",      # rótulos aparecem a cada 3 semanas que iniciam nas segundas
    date_minor_breaks = "week",         # linhas verticais aparecem a cada semana iniciada na segunda
    label = scales::label_date_short()) + # efficient date label
  
  # eixo y
  scale_y_continuous(
    expand = c(0,0))+                   # remova o espaço em excesso do eixo y abaixo de 0
  
  # especificação manual das cores, atenção para a ordem!
  scale_fill_manual(
    values = c("grey", "beige", "black", "orange", "blue", "brown"),
    labels = c("St. Mark's Maternity Hospital (SMMH)" = "St. Mark's"),
    name = "Hospital")+ 
  
  # temas estéticos
  theme_minimal()+                      # simplifique o fundo do gráfico
  
  theme(
    plot.caption = element_text(face = "italic", # legenda no lado esquerdo em itálico
                                hjust = 0), 
    axis.title = element_text(face = "bold"))+   # títulos dos eixos em negrito
  
  # rótulos
  labs(
    title    = "Incidência semanal de casos por hospital",
    subtitle = "Hospital como um factor re-ordenado",
    x        = "Semana de aparecimento dos sintomas",
    y        = "Casos semanais")
```

<span style="color: darkgreen;">**_DICA:_** Para reverter apenas a ordem da legenda, adicione o seguinte no comando **ggplot2**: `guides(fill = guide_legend(reverse = TRUE))`.</span>  





### Ajuste a legenda {.unnumbered}

Leia mais sobre legendas e escalas no página sobre [dicas do ggplot](#ggplot-tips). Aqui estão alguns destaques:

* Edite o título da legenda por meio da função de escala ou com `labs(fill = "Legend title")` (se você estiver estilizando com `color = `, utilize `labs(color = "")`)  
* `theme(legend.title = element_blank())` para não ter título de legenda
* `theme(legend.position = "top")` para a legenda acima do gráfico. Pode-se também escolher também "bottom" , "left", "right" ou "none" para as posições embaixo, à esqueda, à direita ou para remover a legenda, respectivamente. 
* `theme(legend.direction = "horizontal")` legenda horizontal 
* `guides(fill = guide_legend(reverse = TRUE))` para reverter a ordem da legenda







### Barras lado-a-lado {.unnumbered}  

A visualização do grupo de barras lado-a-lado (oposto à posição de barras empilhadas) é especificado dentro de `geom_histogram()`, com o argumento `position = "dodge"` fora de `aes()`(Nota do tradutor: *dodge* vem do inglês "esquivar").  

Se existirem mais de dois grupos de valores, estes podem ser difíceis de ler. Em vez disso, considere utilizar um gráfico facetado (pequenos múltiplos). Para melhorar a visualização do gráfico neste exemplo, campos sem a informação do gênero foram removidos.

```{r, warning=F, message=F}
ggplot(central_data %>% drop_na(gender))+   # inicie com casos do Hospital Central, excluindo as linhas sem dados do gênero
    geom_histogram(
        mapping = aes(
          x = date_onset,
          group = gender,         # casos agrupados por gênero
          fill = gender),         # barras preenchidas de acordo com o gênero
        
        # quebras dos containers do histrograma
        breaks = weekly_breaks_central,   # sequência de datas semanais para o surto no Central - definido no topo da seção sobre ggplot
        
        color = "black",          # cor do contorno das barras
        
        position = "dodge")+      # barras LADO-A-LADO
                      
  
  # Os rótulos no eixo x
  scale_x_date(expand            = c(0,0),         # remova os espaços em excesso abaixo do eixo x e após as barras de casos
               date_breaks       = "3 weeks",      # rótulos aparecem a cada 3 semanas iniciadas nas segundas
               date_minor_breaks = "week",         # linhas verticais aparecem a cada semana iniciada nas segundas
               label = scales::label_date_short()) + # efficient label formatting
  
  # eixo y
  scale_y_continuous(expand = c(0,0))+             # remove o espaço extra nos eixos y entre a base das barras e os rótulos
  
  # escala de cores e rótulos de legendas
  scale_fill_manual(values = c("brown", "orange"),  # especifique as cores de preenchimento ("values") - atenção na ordem!
                    na.value = "grey" )+     

  # temas estéticos
  theme_minimal()+                                               # um conjunto de temas para simplificar o gráfico
  theme(plot.caption = element_text(face = "italic", hjust = 0), # título no lado esquerdo em itálico
        axis.title = element_text(face = "bold"))+               # título dos eixos em negrito
  
  # rótulos
  labs(title    = "Incidência semanal de casos, por gênero",
       subtitle = "Legenda",
       fill     = "Gênero",                                      # forneça novos títulos para os eixos
       x        = "Semana de início dos sintomas",
       y        = "Incidência semanal dos casos notificados")
```




### Limite dos eixos {.unnumbered}  

Existem duas formas de limitar a extensão dos valores dos eixos.

Geralmente, o método indicado é utilizar o comando  `coord_cartesian()`, que aceita `xlim = c(min, max)` e `ylim = c(min, max)` (onde você fornece os valores mínimos e máximos). Esta ferramenta age como um "zoom" sem, na realidade, remover qualquer dado, o que é importante para estatísticas e resumos das medidas.

Alternativamente, você pode ajustar os valores mínimos e máximos das datas utilizando `limits = c()` dentro de `scale_x_date()`. Por exemplo:

```{r eval=F}
scale_x_date(limits = c(as.Date("2014-04-01"), NA)) # escolhe uma data mínima mas deixa a data máxima em aberto.
```

Da mesma forma, se você quiser que o eixo x se estenda até uma data específica (ex.: data atual), mesmo que novos casos não sejam notificados, você pode utilizar:

```{r eval=F}
scale_x_date(limits = c(NA, Sys.Date()) # garante que o eixo da data se estenda até a data atual
```

<span style="color: red;">**_PERIGO:_** Tenha cuidado ao ajustar  as quebras ou limites da escala do eixo y (ex.: 0 a 30 por 5: `seq(0, 30, 5)`). Estes números estáticos podem cortar o seu gráfico casos seus dados mudem e ultrapassem os limites!</span>



### Rótulos/linha de grade do eixo de data {.unnumbered} 

<span style="color: darkgreen;">**_DICA:_** Lembre que os **rótulos** do eixo das datas são independentes da agregação das datas em barras, mas visualmente podem ser importantes para alinhar as classes, rótulos de data, e linhas de grade verticais.</span>

Para **modificar os rótulos de data e as linhas de grade**, utilize a função `scale_x_date()` em uma das seguintes formas:

* **Se as suas classes do histograma são dias, semanas iniciadas em segundas, meses, ou anos**:  
  * Utilize `date_breaks = ` para especificar o intervalo de rótulos e linhas de grade principais (ex.: "day" (dia), "week" (semana), "3 weeks" (3 semanas), "month" (mês), ou "year" (ano))
  * Utilize `date_minor_breaks = ` para especificar o intervalo das linhas de grade verticais secundárias (entre os rótulos)
  * Adicione `expand = c(0,0)` para iniciar os rótulos na primeira barra
  * Utilize `date_labels = ` para especificar o formato dos rótulos de data - veja a página sobre Datas para dicas (utilize `\n` para uma nova linha)  
* **Se as suas classes do histograma são semanas iniciadas nos domingos**:  
  * Utilize `breaks = ` e `minor_breaks = ` ao fornecer uma sequência de quebras de datas para cada um
  * Você ainda pode utilizar `date_labels = ` e `expand = ` para formatação, como decrito acima

Algumas notas:

* Veja a seção de abertura do ggplot para instruções sobre como criar uma sequência de datas utilizando `seq.Date()`.  
* Veja [esta página](https://rdrr.io/r/base/strptime.html) ou a página [Trabalhando com datas](#dates) para dicas sobre como criar rótulos de data.




#### Demonstrações {.unnumbered}

Abaixo está uma demonstração de gráficos onde as cásses e os rótulos/linhas de grade do gráfico estão alinhados e desalinhados:

```{r fig.show='hold', class.source = 'fold-hide', warning=F, message=F}
# classes de 7-dias + rótulos de Segunda
#############################
ggplot(central_data) +
  geom_histogram(
    mapping = aes(x = date_onset),
    binwidth = 7,                 # classes de 7-dias com início no primeiro caso
    color = "darkblue",
    fill = "lightblue") +
  
  scale_x_date(
    expand = c(0,0),               # remova o excesso de espaço do eixo x abaixo e após as barras de caso
    date_breaks = "3 weeks",       # Segunda a cada 3 semanas
    date_minor_breaks = "week",    # Semanas iniciadas na segunda
    label = scales::label_date_short())+ # automatic label formatting
  
  scale_y_continuous(
    expand = c(0,0))+              # remova o espaço em excesso abaixo do eixo x, fazendo um nivelamento
  
  labs(
    title = "DESALINHADO",
    subtitle = "! CUIDADO: barras de 7-dias iniciam nas quintas-feiras no primeiro caso\nRótulos de data e linhas de grade nas segundas-feiras\nObserve como os traços não alinham com as barras")



# classes de 7-dias + meses
#####################
ggplot(central_data) +
  geom_histogram(
    mapping = aes(x = date_onset),
    binwidth = 7,
    color = "darkblue",
    fill = "lightblue") +
  
  scale_x_date(
    expand = c(0,0),                  # remova o espaço em excesso abaixo e após as barras de casos
    date_breaks = "months",           # primeiro do mês
    date_minor_breaks = "week",       # semanas iniciadas nas segundas
    label = scales::label_date_short())+ # automatic label formatting
  
  scale_y_continuous(
    expand = c(0,0))+                # remova o espaço em excesso abaixo do eixo x, faça um nivelamento
  
  labs(
    title = "DESALINHADO",
    subtitle = "! CUIDADO: Barras de 7-dias iniciam nas quintas-feiras com o primeiro caso\nLinhas de grade principais e rótulos de data no primeiro de cada mês\nLinhas de grade secundárias semanalmente nas segundas\nObserve o espaçamento diferente de algumas das linhas de grade e traços desalinhados com as barras")


# ALINHAMENTO TOTAL NAS SEGUNDAS: especifique manualmente as quebras das classes para serem nas segundas
#################################################################
ggplot(central_data) + 
  geom_histogram(
    mapping = aes(x = date_onset),
    
    # quebras do histograma ajustadas para 7 dias iniciando na Segunda antes do primeiro caso
    breaks = weekly_breaks_central,    # definido anteriormente nesta página
    
    color = "darkblue",
    
    fill = "lightblue") + 
  
  scale_x_date(
    expand = c(0,0),                   # remova o excesso de espaço do eixo x abaixo e após as barras de caso
    date_breaks = "4 weeks",           # Segunda-feira a cada 4 semanas
    date_minor_breaks = "week",        # Semanas iniciadas na segunda
    label = scales::label_date_short())+ # automatic label formatting
  
  scale_y_continuous(
    expand = c(0,0))+                # remova o excesso de espaço abaixo do eixo x, faça o nivelamento
  
  labs(
    title = "Segunda ALINHADAS",
    subtitle = "Classes de 7-dias manualmente ajustados para iniciarem na segunda antes do primeiro caso (28 de abril)\nRótulos de data e linhas de grade também nas segundas")


# ALINHAMENTO TOTAL NA SEGUNDA COM RÓTULOS DE MESES:
############################################
ggplot(central_data) + 
  geom_histogram(
    mapping = aes(x = date_onset),
    
    # quebras do histograma ajustaddas para 7 dias iniciando na segunda antes do primeiro caso
    breaks = weekly_breaks_central,            # definido anteriormente nesta página
    
    color = "darkblue",
    
    fill = "lightblue") + 
  
  scale_x_date(
    expand = c(0,0),                   # remova o excesso de espaço no eixo x abaixo e após as barras de casos
    date_breaks = "months",            # Segunda a cada 4 semanas
    date_minor_breaks = "week",        # Semanas iniciadas nas segundas
    label = scales::label_date_short())+ # label formatting
  
  scale_y_continuous(
    expand = c(0,0))+                # remova o excesso de espaço abaixo do eixo x, faça um nivelamento
  
  theme(panel.grid.major = element_blank())+  # Remove as linhas de grade principais )caem no primeiro dia do mês)
          
  labs(
    title = "ALINHADO nas segundas com rótulos MENSAIS",
    subtitle = "Classes de 7-dias manualmente ajustado para iniciar na segunda antes do primeiro caso (28 de abril)\nRótulo de datas no primeiro dia do mês\nPrincipais linhas de grade mensais removidas")


# ALINHAMENTO TOTAL NO DOMINGO: especifique manualmente as quebras das classes E rótulos para serem nos domingos
############################################################################
ggplot(central_data) + 
  geom_histogram(
    mapping = aes(x = date_onset),
    
    # quebra do histograma ajustadas para serem de 7 dias, iniciando no Domingo antes do primeiro caso
    breaks = seq.Date(from = floor_date(min(central_data$date_onset, na.rm=T),   "week", week_start = 7),
                      to   = ceiling_date(max(central_data$date_onset, na.rm=T), "week", week_start = 7),
                      by   = "7 days"),
    
    color = "darkblue",
    
    fill = "lightblue") + 
  
  scale_x_date(
    expand = c(0,0),
    # quebras dos rótulos de datas e principais linhas de grade ajustadas para ocorrerem a cada 3 semanas iniciando no domingo antes do primeiro caso
    breaks = seq.Date(from = floor_date(min(central_data$date_onset, na.rm=T),   "week", week_start = 7),
                      to   = ceiling_date(max(central_data$date_onset, na.rm=T), "week", week_start = 7),
                      by   = "3 weeks"),
    
    # linhas de grade secundárias ajustadas para iniciarem semanalmente no domingo antes do primeiro caso
    minor_breaks = seq.Date(from = floor_date(min(central_data$date_onset, na.rm=T),   "week", week_start = 7),
                            to   = ceiling_date(max(central_data$date_onset, na.rm=T), "week", week_start = 7),
                            by   = "7 days"),
    
    label = scales::label_date_short())+ # automatic label formatting
  
  scale_y_continuous(
    expand = c(0,0))+                # remova o espaço em excesso abaixo do eixo x, faça um nivelamento
  
  labs(title = "ALINHAMENTO nos domingos",
       subtitle = "Classes de 7-dias manualmente ajustados para iniciarem no domingo antes do primeiro caso (27 de abril)\nRótulo de datas e linhas de grade manualmente ajustadas também para os domingos")

```





### Dados agregados {.unnumbered} 

Frequentemente, ao invés de uma linelist, você inicia com contagens agregadas de unidades, distritos, etc. Você pode criar uma epicurva com o `ggplot()`, mas o código será levemente diferente. Esta seção irá utilizar o conjunto de dados do `count_data` que foi importado anteriormente, na seção de preparação dos dados. Este conjunto de dados é o `linelist` agregado para contagens diárias por hospital. As primeiras 50 linhas são mostradas abaixo.

```{r message=FALSE, warning=F, echo=F}
# mostre a linelist como uma tabela
DT::datatable(head(count_data, 50), rownames = FALSE, filter="top", options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```


#### Criando um gráfico de contagens diárias {.unnumbered}  

Nós podemos criar um gráfico de uma epicurva diária destas *contagens diárias*. Aqui estão as diferenças no código:

* Dentro do mapeamento estético `aes()`, especifique `y = ` como a coluna de contagem (neste caso, o nome da coluna é `n_cases`)
* Adicione o argumento `stat = "identity"` dentro de `geom_histogram()`, que especifica que a altura da barra deve ser o valor `y = ` , e não o número de linhas, como é o padrão
* Adicione o argumento `width = ` para evitar linhas verticais brancas entre as barras. Para contagens diárias o ajuste é 1. Para contagens semanais o ajuste é 7.  Para contagens mensais, linhas brancas são um problema (cada M~es possui diferente número de dias) - considere transformar seu eixo x para um factor ordenado categoricamente (meses) e utilizando `geom_col()`.


```{r, message=FALSE, warning=F}
ggplot(data = count_data)+
  geom_histogram(
   mapping = aes(x = date_hospitalisation, y = n_cases),
   stat = "identity",
   width = 1)+                # para contagens diárias, ajuste width = 1 para evitar o espaço braco entre as barras
  labs(
    x = "Data de notificação", 
    y = "Número de casos",
    title = "Incidência diária de casos, a partir dos dados de contagem diária")
```

#### Criando um gráfico de contagens semanais {.unnumbered}

Se os seus casos já estão contados por semana, eles podem parecer como o seguinte conjunto de dados (chamado `count_data_weekly`):  

```{r, warning=F, message=F, echo=F}
# Crie um conjunto de dados semanal com uma coluna de semana epidemiológica
count_data_weekly <- count_data %>%
  mutate(epiweek = lubridate::floor_date(date_hospitalisation, "week")) %>% 
  group_by(hospital, epiweek, .drop=F) %>% 
  summarize(n_cases_weekly = sum(n_cases, na.rm=T))   
```

As primeiras 50 linhas de `count_data_weekly` são mostradas abaixo. Você pode ver que as contagens foram agregadas por semanas. Cada semana é mostrada pelo primeiro dia da semana (segunda-feira, por padrão).

```{r message=FALSE, echo=F}
# mostre os dados da linelist como uma tabela
DT::datatable(count_data_weekly, rownames = FALSE, options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```

Agora crie o gráfico de forma que `x = ` a coluna da semana epidemiológica. Lembre de adicionar `y = ` a coluna de contagens para o mapeamento estético, e adicione `stat = "identity"`, como explicado acima.

```{r, warning=F, message=F}
ggplot(data = count_data_weekly)+
  
  geom_histogram(
    mapping = aes(
      x = epiweek,           # eixo x é a semana epidemiológica (variável da classe Data)
      y = n_cases_weekly,    # altura do eixo y nas contagens de casos semanais
      group = hospital,      # nós estamos agrupando as barras e colorindo por hospital
      fill = hospital),
    stat = "identity")+      # isto também é requerido quando criar um gráfico dos dados de contagem
     
  # rótulos para o eixo x
  scale_x_date(
    date_breaks = "2 months",      # rótulos a cada 2 meses
    date_minor_breaks = "1 month", # linhas de grade a cada mês
    label = scales::label_date_short())+ # label formatting
     
  # Escolha a paleta de cor (utiliza o pacote RColorBrewer)
  scale_fill_brewer(palette = "Pastel2")+ 
  
  theme_minimal()+
  
  labs(
    x = "Semana de início", 
    y = "Incidência semanal de casos",
    fill = "Hospital",
    title = "Incidência semanal de casos, a partir dos dados de casos agregados por hospital")
```




### Média móvel {.unnumbered}

Veja a página sobre [médias móveis](#moving-average) para uma descrição detalhada e diferentes opções. Abaixo, uma alternativa para calcular as médias móveis com o pacote **slider** é utilizada. Nesta abordagem, *a média móvel é calculada no conjunto de dados antes de criar os gráficos*:  

1) Agregue os dados em contagens conforme necessário (diárias, semanais, etc.) (veja a página [Agrupando dados](#grouping))  
2) Crie uma nova coluna para salvar a média móvel, criada com `slide_index()` do pacote **slider**  
3) Crie um gráfico da média móvel como uma `geom_line()` acima do (após) o histograma da epicurva

Veja este útil [resumo online do pacote **slider**](https://cran.r-project.org/web/packages/slider/vignettes/slider.html)  


```{r, warning=F, message=F}
# carregue o pacote
pacman::p_load(slider)  # slider utilizado para calcular as médias móveis

# crie um conjunto de dados de contagens diárias e média móvel de 7-dias
#######################################################
ll_counts_7day <- linelist %>%    # inicie com o objeto linelist
  
  ## conte os casos por dia
  count(date_onset, name = "new_cases") %>%   # crie uma nova coluna com as contagens, chamada "new_cases"
  drop_na(date_onset) %>%                     # remova os casos sem a informação do dia de início dos sintomas (date_onset)
  
  ## calcule o número médio de casos em uma janela de 7 dias
  mutate(
    avg_7day = slider::slide_index(    # crie uma nova coluna
      new_cases,                       # calcule baseado nos valores da coluna new_cases
      .i = date_onset,                 # o indexador é a coluna de date_onset, de forma que as contagens sem datas são incluídas na janela de análise
      .f = ~mean(.x, na.rm = TRUE),    # a função utilizada é mean() com os valores em branco removidos
      .before = 6,                     # a janela de análise é o dia e os 6-dias anteriores
      .complete = FALSE),              # precisa ser FALSE para unlist() funcionar na próxima etapa
    avg_7day = unlist(avg_7day))       # converta da classe "list" para a classe "numeric"


# crie o gráfico
######
ggplot(data = ll_counts_7day) +  # inicie com o novo conjunto de dados criado acima
    geom_histogram(              # crie uma epicurva em histograma
      mapping = aes(
        x = date_onset,          # coluna de datas no eixo x
        y = new_cases),          # a altura é o número de novos casos diários
        stat = "identity",       # altura da coluna é o valor de y
        fill="#92a8d1",          # cor legal para as barras
        colour = "#92a8d1",      # mesma cor para a borda das barras
        )+ 
    geom_line(                   # crie uma linha para a média móvel
      mapping = aes(
        x = date_onset,          # coluna de data para o eixo x
        y = avg_7day,            # valor de y ajustado para a coluna de média móvel
        lty = "Média móvel \nde 7-dias"), # nome da linha na legenda
      color="red",               # cor da linha
      size = 1) +                # espessura da linha
    scale_x_date(                # escala da data
      date_breaks = "1 month",
      label = scales::label_date_short(), # label formatting
      expand = c(0,0)) +
    scale_y_continuous(          # escala do eixo y
      expand = c(0,0),
      limits = c(0, NA)) +       
    labs(
      x="",
      y ="Número de casos confirmados",
      fill = "Legenda")+ 
    theme_minimal()+
    theme(legend.title = element_blank())  # remove o título da legenda
```




### Facetas/múltiplos pequenos {.unnumbered}

Como em outros ggplots, você pode criar gráficos facetados ("múltiplos pequenos"). Como explicado na página [dicas do ggplot](#ggplot-tips) deste manual, você pode utilizar tanto `facet_wrap()` quanto `facet_grid()`. Aqui, nós demonstramos com o `facet_wrap()`. Para epicurvas, `facet_wrap()` é tipicamente mais fácil, uma vez que provavelmente você só precisa facetar uma coluna.

A sintaxe geral é `facet_wrap(rows ~ cols)`, em que no lado esquerdo do til (~) é o nome da coluna a ser espalhada através das "linhas" do gráfico facetado, e no lado direito do til é o nome de uma coluna a ser espalhada através das "colunas" do gráfico facetado. De forma mais simples, só utilize um nome de coluna, no lado direito do til: `facet_wrap(~age_cat)`.  


**Eixos livres**  
Você precisará decidir se as escalas dos eixos para cada faceta são "fixas" para as mesmas dimensões (padrão), ou "livres" (significando que irão mudar baseado nos dados dentro da faceta). Faça isso com o argumento `scales = ` dentro de `facet_wrap()` ao especificar "free_x" ou "free_y", ou "free".  


**Número de colunas e linhas das facetas**  
Isto pode ser especificado com `ncol = ` e `nrow = ` dentro de `facet_wrap()`. 


**Ordem dos painéis**  
Para alterar a ordem de aparecimento, altere a ordem dos níveis da coluna de factor utilizada para criar as facetas.


**Estética**  
Tamanho da fonte e face, cor da tira, etc. podem ser modificados através de `theme()` com argumentos como:

* `strip.text = element_text()` (tamanho, cor, face, ângulo...)
* `strip.background = element_rect()` (ex.:  element_rect(fill="grey"))  
* `strip.position = ` (posição da tira "bottom" (embaixo), "top" (em cima), "left" (à esquerda), ou "right" (à direita))  


**Rótulos das tiras**  
Rótulos dos gráficos facetados podem ser modificados por meio de "rótulos" da coluna como um factor, ou pelo uso de um "rotulador".  

Crie um rotulador como este, utilizando a função `as_labeller()` do **ggplot2**. Então, forneça o rotulador para o argumento `labeller = ` de `facet_wrap()`, como mostrado abaixo.

```{r, class.source = 'fold-show'}
my_labels <- as_labeller(c(
     "0-4"   = "Ages 0-4",
     "5-9"   = "Ages 5-9",
     "10-14" = "Ages 10-14",
     "15-19" = "Ages 15-19",
     "20-29" = "Ages 20-29",
     "30-49" = "Ages 30-49",
     "50-69" = "Ages 50-69",
     "70+"   = "Over age 70"))
```

**Um exemplo de gráfico facetado** - facetado pela coluna `age_cat`.


```{r, warning=F, message=F}
# crie o gráfico
###########
ggplot(central_data) + 
  
  geom_histogram(
    mapping = aes(
      x = date_onset,
      group = age_cat,
      fill = age_cat),    # argumentos dentro de aes() aplicam-se ao grupo
      
    color = "black",      # argumentos fora de aes() aplicam-se a todos os dados
        
    # quebras do histograma
    breaks = weekly_breaks_central)+  # vetor pré-definido de datas (veja mais acima nesta página)
                      
  # Os rótulos no eixo x
  scale_x_date(
    expand            = c(0,0),         # remove o espaço em excesso do eixo x abaixo e após as barras de casos
    date_breaks       = "2 months",     # rótulos aparecem a cada 2 meses
    date_minor_breaks = "1 month",      # linhas verticais aparecem a cada mês
    label = scales::label_date_short())+ # label formatting
  
  # eixo y
  scale_y_continuous(expand = c(0,0))+                       # remove o espaço em excesso do eixo y entre os fundos das barras e os rótulos
  
  # temas estéticos
  theme_minimal()+                                           # um conjunto de temas para simplificar a plotagem
  theme(
    plot.caption = element_text(face = "italic", hjust = 0), # título no lado esquerdo em itálico
    axis.title = element_text(face = "bold"),
    legend.position = "bottom",
    strip.text = element_text(face = "bold", size = 10),
    strip.background = element_rect(fill = "grey"))+         # títulos dos eixos em negrito
  
  # crie as facetas
  facet_wrap(
    ~age_cat,
    ncol = 4,
    strip.position = "top",
    labeller = my_labels)+             
  
  # rótulos
  labs(
    title    = "Incidência semanal de casos, por categoria de idade",
    subtitle = "Legenda",
    fill     = "Categoria de idade",                                      # forneça um novo título para a legenda
    x        = "Semana de início dos sintomas",
    y        = "Incidência semanal dos casos notificados",
    caption  = stringr::str_glue("n = {nrow(central_data)} do Hospital Central; Aparecimento dos casos varia entre {format(min(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')} a {format(max(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')}\n{nrow(central_data %>% filter(is.na(date_onset)))} casos sem a data de início dos sintomas e não mostrados no gráfico"))
```

Veja este [link](https://ggplot2.tidyverse.org/reference/labellers.html) para mais informações sobre os rotuladores.




#### Epidemia total no fundo da faceta {.unnumbered}

Para mostrar o total da epidemia no fundo de cada faceta, adicione a função `gghighlight()` com parênteses vazios ao ggplot. Isto é do pacote **gghighlight**. Observe que o máximo do eixo y em todas as facetas é agora baseado no pico da epidemia inteira. Existem mais exemplos deste pacote na página sobre [dicas do ggplot](#ggplot-tips).  

```{r, warning=F, message=F}
ggplot(central_data) + 
  
  # epicurvas por grupo
  geom_histogram(
    mapping = aes(
      x = date_onset,
      group = age_cat,
      fill = age_cat),  # argumentos dentro de aes() são aplicados por grupo
    
    color = "black",    # argumentos fora de aes() são aplicados a todos os dados
    
    # quebras do histograma
    breaks = weekly_breaks_central)+     # vetor de datas pré-definidas (veja o topo da seção sobre ggplot)
  
  # adicione a epidemia total em cinza em cada faceta
  gghighlight::gghighlight()+
  
  # rótulos no eixo x
  scale_x_date(
    expand            = c(0,0),         # remova o espaço em excesso do eixo x abaixo e após as barras de casos
    date_breaks       = "2 months",     # rótulos aparecem a cada 2 meses
    date_minor_breaks = "1 month",      # linhas verticais aparecem a cada 1 mês
    label = scales::label_date_short())+ # label formatting
  
  # eixo y
  scale_y_continuous(expand = c(0,0))+  # remove o excesso de espaço do eixo y abaixo de 0
  
  # temas estéticos
  theme_minimal()+                                           # um conjunto de temas para simplificar o gráfico
  theme(
    plot.caption = element_text(face = "italic", hjust = 0), # título no lado esquerdo em itálico
    axis.title = element_text(face = "bold"),
    legend.position = "bottom",
    strip.text = element_text(face = "bold", size = 10),
    strip.background = element_rect(fill = "white"))+        # títulos dos eixos em negrito
  
  # crie as facetas
  facet_wrap(
    ~age_cat,                          # cada gráfico é um valor de age_cat
    ncol = 4,                          # número de colunas
    strip.position = "top",            # posição do título/tira da faceta
    labeller = my_labels)+             # rotulador definido acima
  
  # rótulos
  labs(
    title    = "Incidência semanal de casos, por categoria de idade",
    subtitle = "Legenda",
    fill     = "Categoria de idade",                                      # forneça um novo título para a legenda
    x        = "Semana de início dos sintomas",
    y        = "Incidência semanal dos casos notificados",
    caption  = stringr::str_glue("n = {nrow(central_data)} do Hospital Central; Surgimento dos casos foi de {format(min(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')} a {format(max(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')}\n{nrow(central_data %>% filter(is.na(date_onset)))} casos sem a data de início dos sintomas e não mostrados no gráfico"))
```


#### Uma faceta com dados {.unnumbered}  

Se você quer ter uma caixa de faceta que contem todos os dados, duplique o conjunto de dados inteiro e trate as duplicatas como um valor de facetas. Uma função "auxiliar", `CreateAllFacet()`, abaixo pode auxiliar nisso (agradecimento a esse [post](https://stackoverflow.com/questions/18933575/easily-add-an-all-facet-to-facet-wrap-in-ggplot2)). Quando é executado, o número de linhas duplica, e então terá uma nova coluna chamada `facet`, em que as linhas duplicadas terão o valor "all", e as linhas originais terão o valor original da coluna de facetas. Agora você só precisa facetear com a coluna `facet`.   

Aqui está a função auxiliar. Execute ela de forma que esteja disponível para você.

```{r}
# Defina uma função auxiliar
CreateAllFacet <- function(df, col){
     df$facet <- df[[col]]
     temp <- df
     temp$facet <- "all"
     merged <-rbind(temp, df)
     
     # garanta que o valor da faceta é um fator
     merged[[col]] <- as.factor(merged[[col]])
     
     return(merged)
}
```

Agora aplique a função auxiliar para o conjunto de dados, na coluna `age_cat`:  

```{r}
# Crie um conjunto de dados que é duplicado e com a nova coluna "facet" para mostrar "all" (todas) as categorias de idade como outro nível da faceta
central_data2 <- CreateAllFacet(central_data, col = "age_cat") %>%
  
  # ajuste os níveis do fator
  mutate(facet = fct_relevel(facet, "all", "0-4", "5-9",
                             "10-14", "15-19", "20-29",
                             "30-49", "50-69", "70+"))

# verifique os níveis
table(central_data2$facet, useNA = "always")
```

Alterações notáveis no comando `ggplot()` são:  

* Os dados utilizados agora são central_data2 (duplique as linhas, com a nova coluna "facet")
* Rotulador precisará ser atualizado, caso usado
* Opcional: para obter facetas empilhadas verticalmente: a coluna facetada é movida para o lado das linhas na equação e no lado esquerdo é substituído por "." (`facet_wrap(facet~.)`), e `ncol = 1`. Você também pode precisar ajustar o comprimento e altura da imagem do gráfico salvo (veja `ggsave()` no [dicas do ggplot](#ggplot-tips)).  

```{r, fig.height=12, fig.width=5, warning=F, message=F}
ggplot(central_data2) + 
  
  # epicurvas atuais por grupo
  geom_histogram(
        mapping = aes(
          x = date_onset,
          group = age_cat,
          fill = age_cat),  # argumentos dentro de aes() são aplicados por grupo
        color = "black",    # argumentos fora de aes() são aplicados a todos os dados
        
        # quebras do histograma
        breaks = weekly_breaks_central)+    # vetor de datas pré-definidos (veja o topo da seção sobre o ggplot)
                     
  # Rótulos no eixo x
  scale_x_date(
    expand            = c(0,0),         # remova o excesso de espaço no eixo x abaixo e após as barras de casos
    date_breaks       = "2 months",     # rótulos aparecem a cada 2 meses
    date_minor_breaks = "1 month",      # linhas verticais aparecem a cada mês
    label = scales::label_date_short())+ # label formatting
  
  # eixo y
  scale_y_continuous(expand = c(0,0))+  # remove o espaço em excesso do eixo y entre a base das barras e os rótulos
  
  # temas estéticos
  theme_minimal()+                                           # um conjunto de temas para simplificar o gráfico
  theme(
    plot.caption = element_text(face = "italic", hjust = 0), # título no lado esquerdo em itálico
    axis.title = element_text(face = "bold"),
    legend.position = "bottom")+               
  
  # crie as facetas
  facet_wrap(facet~. ,                            # cada gráfico é um valor da faceta
             ncol = 1)+            

  # rótulos
  labs(title    = "Incidência semanal de casos, por categoria de idade",
       subtitle = "Legenda",
       fill     = "Categoria de idade",                                      # forneça um novo título para a legenda
       x        = "Semana de início dos sintomas",
       y        = "Incidência semanal dos casos notificados",
       caption  = stringr::str_glue("n = {nrow(central_data)} do Hospital Central; Surgimento dos casos foi de {format(min(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')} a {format(max(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')}\n{nrow(central_data %>% filter(is.na(date_onset)))} casos sem a data de aparecimento dos sintomas e não mostrados no gráfico"))
```








## Dados preliminares


Os dados mais recentes mostrados em epicurvas precisam, frequentemente, serem marcados como preliminares, ou sujeitos à demoras na notificação. Isto pode ser feito ao adicionar uma linha vertical e/ou retângulo sobre um número específico de dias. Aqui estão duas opções:

1) Utilize `annotate()`:  
    + Para utilizar uma linha, use `annotate(geom = "segment")`. Forneça `x`, `xend`, `y`, e `yend`. Ajuste o tamanho, tipo de linha (`lty`), e cor.
    + Para utilizar um retângulo, use `annotate(geom = "rect")`. Forneça xmin/xmax/ymin/ymax. Ajuste a cor e o alfa.
2) Agrupe os dados por status da tentativa e utilize cores diferentes para essas barras

<span style="color: orange;">**_CUIDADO:_** Você pode querer experimentar `geom_rect()` para desenhar um retângulo, mas ajustar a transparência não funciona no contexto de uma linelist. Esta função sobrepõe um retângulo para cada observação/linha!. Utilize ou um alfa muito baixo (ex.: 0.01), ou outra abordagem.</span>

### Utilizando `annotate()` {.unnumbered}

* Dentro de `annotate(geom = "rect")`, os argumentos `xmin` e `xmax` precisam ser dados como valores da classe Date (data).
* Note que, devido ao fato destes dados serem agregados em barras semanais, e a última barra extender para a segunda após o último caso, a região sombreada pode parecer cobrir 4 semanas
* Aqui é um [exemplo online](https://ggplot2.tidyverse.org/reference/annotate.html) de `annotate()`


```{r, warning=F, message=F}
ggplot(central_data) + 
  
  # histograma
  geom_histogram(
    mapping = aes(x = date_onset),
    
    breaks = weekly_breaks_central,   # vetor de data pré-definido - veja o topo da seção sobre o ggplot
    
    color = "darkblue",
    
    fill = "lightblue") +

  # escalas
  scale_y_continuous(expand = c(0,0))+
  scale_x_date(
    expand = c(0,0),                   # remove o excesso de espaço do eixo x abaixo e após as barras de casos
    date_breaks = "1 month",           # Primeiro do mês
    date_minor_breaks = "1 month",     # Primeiro do mês
    label = scales::label_date_short())+ # label formatting
  
  # rótulos e tema
  labs(
    title = "Utilizando annotate()\nRetângulo e linha mostrando que os dados dos últimos 21 dias são preliminares",
    x = "Semana de início de sintomas",
    y = "Incidência semanal de casos")+ 
  theme_minimal()+
  
  # adicione um retângulo vermelho semi-transparente nos dados preliminares
  annotate(
    "rect",
    xmin  = as.Date(max(central_data$date_onset, na.rm = T) - 21), # a nota precisa ser englobada dentro de as.Date()
    xmax  = as.Date(Inf),                                          # a nota precisa ser englobada dentro de as.Date()
    ymin  = 0,
    ymax  = Inf,
    alpha = 0.2,          # alfa fácil e intuitivo para ajustar usando annotate()
    fill  = "red")+
  
  # adicione uma linha preta vertical no topo das outras camadas
  annotate(
    "segment",
    x     = max(central_data$date_onset, na.rm = T) - 21, # 21 dias antes dos últimos dados
    xend  = max(central_data$date_onset, na.rm = T) - 21, 
    y     = 0,         # linha inicia em y = 0
    yend  = Inf,       # linha no topo do gráfico
    size  = 2,         # tamanho da linha
    color = "black",
    lty   = "solid")+   # tipo de linha ex.: "solid", "dashed"

  # adicione texto no retângulo
  annotate(
    "text",
    x = max(central_data$date_onset, na.rm = T) - 15,
    y = 15,
    label = "Sujeito à atrasos nas notificações",
    angle = 90)
```


A mesma linha preta vertical pode ser obtida com o código abaixo, mas, utilizando `geom_vline()`, você perde a capacidade de controlar a altura:

```{r, eval=F}
geom_vline(xintercept = max(central_data$date_onset, na.rm = T) - 21,
           size = 2,
           color = "black")
```



### Cor das barras {.unnumbered}  

Uma abordagem alternativa pode ser ajustar a cor ou exibição das dos dados preliminares. Você pode criar uma nova coluna no estágio de preparação dos dados, e utiliza-la para agrupar os dados, de forma que o `aes(fill = )` dos dados preliminares possa ter uma cor ou alfa diferente das outras barras.

```{r, message=F, warning=F}
# adiciona uma coluna
############
plot_data <- central_data %>% 
  mutate(tentative = case_when(
    date_onset >= max(date_onset, na.rm=T) - 7 ~ "Tentative", # preliminares e estiverem dentro dos últimos 7 dias
    TRUE                                       ~ "Reliable")) # todos os demais são confiáveis

# crie o gráfico
######
ggplot(plot_data, aes(x = date_onset, fill = tentative)) + 
  
  # histograma
  geom_histogram(
    breaks = weekly_breaks_central,   # vetor de datas pré-definido, veja o topo da página sobre o ggplot
    color = "black") +

  # escalas
  scale_y_continuous(expand = c(0,0))+
  scale_fill_manual(values = c("lightblue", "grey"))+
  scale_x_date(
    expand = c(0,0),                   # remove o espaço em excesso do eixo x, abaixo e após as barras de casos
    date_breaks = "3 weeks",           # segundas a cada 3 semanas
    date_minor_breaks = "week",        # semanas iniciadas nas segundas
    label = scales::label_date_short())+ # label formatting
  
  # rótulos e temas
  labs(title = "Mostra os dias que possuem notificações preliminares",
    subtitle = "")+ 
  theme_minimal()+
  theme(legend.title = element_blank())                 # remove o título da legenda
  
```


## Etiquetas multiníveis de data  

Se você quiser etiquetas multiníveis de datas (ex.: mês e ano) *sem duplicar as etiquetas de níveis mais baixos*, utilize uma das abordagens abaixo:

Lembre - você pode utilizar ferramentas como `\n` *dentro* dos argumentos de `date_labels` ou `labels` para colocar partes de cada etiqueta em uma nova linha abaixo da atual. Entretanto, o código abaixo o ajuda a colocar anos ou meses (por exemplo) em uma linha abaixo *e apenas uma vez*. Algumas notas sobre o código abaixo:

* Contagem de casos são agregados em semanas por razões estéticas. Veja a página sobre epicurvas (parte sobre a separação dos dados agregados) para mais detalhes.
* Uma linha `geom_area()` é utilizada no lugar de um histograma, uma vez que a abordagem de faceteamento abaixo não funciona bem com histogramas.


**Agregue para contagens semanais**

```{r out.width = c('50%', '50%'), fig.show='hold', warning=F, message=F}

# Crie o conjunto de dados de contagens de casos por semana
#######################################
central_weekly <- linelist %>%
  filter(hospital == "Central Hospital") %>%   # filtre a linelist
  mutate(week = lubridate::floor_date(date_onset, unit = "weeks")) %>%  
  count(week) %>%                              # faça um resumo das contagens de casos semanais
  drop_na(week) %>%                            # remova os casos sem a informação de onset_date
  complete(                                    # preencha todas as semanas com nenhum caso notificado
    week = seq.Date(
      from = min(week),   
      to   = max(week),
      by   = "week"),
    fill = list(n = 0))                        # converta novos campos NA (faltantes) para contagens de 0
```

**Crie os gráficos**  

```{r, warning=F, message=F}
# crie um gráfico com a borda da caixa no ano
##############################
ggplot(central_weekly) +
  geom_area(aes(x = week, y = n),    # crie uma linha, especificando x e y
            stat = "identity") +             # a altura da linha é o número da contagem
  scale_x_date(date_labels="%b",             # formato do rótulo de data mostra o mês
               date_breaks="month",          # rótulos de data no primeiro dia de cada mês
               expand=c(0,0)) +              # remove o espaço em excesso em cada extremidade
  scale_y_continuous(
    expand  = c(0,0))+                       # remove o espaço em excesso abaixo do eixo x
  facet_grid(~lubridate::year(week), # crie uma faceta com o ano (da coluna da classe Date (Data))
             space="free_x",                
             scales="free_x",                # eixo x se adapta para o intervalo dos dados (não é fixo)
             switch="x") +                   # etiquetas de faceta (ano) na base
  theme_bw() +
  theme(strip.placement = "outside",         # posicionamento das etiquetas das facetas
        strip.background = element_rect(fill = NA, # rótulos das facetas sem preenchimento e com bordas cinzas
                                        colour = "grey50"),
        panel.spacing = unit(0, "cm"))+      # sem espaço entre os painéis das facetas
  labs(title = "Etiquetas de ano aninhadas, com borda cinza")


# crie o gráfico sem a borda de caixa no ano
#################################
ggplot(central_weekly,
       aes(x = week, y = n)) +              # estabeleça o x e y para o gráfico inteiro
  geom_line(stat = "identity",              # crie a linha, em que a altura da linha é o número da contagem
            color = "#69b3a2") +            # cor da linha
  geom_point(size=1, color="#69b3a2") +     # crie pontos nos pontos de data semanais
  geom_area(fill = "#69b3a2",               # preencha a área abaixo da linha
            alpha = 0.4)+                   # preencha a transparência
  scale_x_date(date_labels="%b",            # formato do rótulo de data mostra o mês
               date_breaks="month",         # rótulos de data no primeiro dia de cada mês
               expand=c(0,0)) +             # remova o espaço em excesso
  scale_y_continuous(
    expand  = c(0,0))+                      # remova o espaço em excesso abaixo do eixo x
  facet_grid(~lubridate::year(week),        # faça a faceta no ano (da coluna de classe Date (data))
             space="free_x",                
             scales="free_x",               # eixo x se adapta ao intervalo de dados (não é fixo)
             switch="x") +                  # rótulos da faceta (ano) na base
  theme_bw() +
  theme(strip.placement = "outside",                     # posicionamento do rótulo da faceta
          strip.background = element_blank(),            # rótulo da faceta sem fundo
          panel.grid.minor.x = element_blank(),          
          panel.border = element_rect(colour="grey40"),  # borda cinza para o painel da faceta
          panel.spacing=unit(0,"cm"))+                   # sem espaço entre os painéis da faceta
  labs(title = "Etiquetas de ano aninhadas - pontos, sombreamento, e sem borda no rótulo")
```

As técnicas acima foram adaptadas [desta](https://stackoverflow.com/questions/44616530/axis-labels-on-two-lines-with-nested-x-variables-year-below-months) e [desta](https://stackoverflow.com/questions/20571306/multi-row-x-axis-labels-in-ggplot-line-chart) postagem no stackoverflow.com.  






<!-- ======================================================= -->
## Eixo duplo { }  

Embora existam discussões intensas sobre a validade de eixos duplos na comunidade de visualização de dados, muitos supervisores de epidemiologia ainda querem ver uma epicurva ou gráfico similar com um percentual sobreposto com um segundo eixo. Isto é discutido mais extensivamente na página [dicas do ggplot](#ggplot-tips), mas um exemplo utilizando o método de **cowplot** é mostrado abaixo:

* Dois gráficos distintos são feitos, e então combinados com o pacote **cowplot**.  
* Os gráficos precisam ter exatamente o mesmo eixo x (ajuste os limites). Do contrário, os dados e rótulos não serão alinhados
* Cada um utiliza `theme_cowplot()` e um deles tem o eixo y movido para o lado direito do gráfico

```{r, warning=F, message=F}
# carregue o pacote
pacman::p_load(cowplot)

# Crie o primeiro gráfico de histograma de uma epicurva
#######################################
plot_cases <- linelist %>% 
  
  # crie o gráfico com casos por semana
  ggplot()+
  
  # crie o histograma
  geom_histogram(
    
    mapping = aes(x = date_onset),
    
    # quebras das classes a cada semana, iniciando na segunda antes do primeiro caso, e indo até a segunda após o último caso
    breaks = weekly_breaks_all)+  # vetor pré-definido de datas semanais (veja o topo da seção sobre o ggplot)
        
  # especifique o início e o fim do eixo da data para alinhar com o outro gráfico
  scale_x_date(
    limits = c(min(weekly_breaks_all), max(weekly_breaks_all)))+  # mín/máx das quebras semanais pré-definidas do histograma
  
  # rótulos
  labs(
      y = "Casos diários",
      x = "Data de aparecimento dos sintomas"
    )+
  theme_cowplot()


# crie um segundo gráfico com o percentual de óbitos por semana
###########################################
plot_deaths <- linelist %>%                        # inicie com a linelist
  group_by(week = floor_date(date_onset, "week")) %>%  # crie a coluna week (semana)
  
  # utilize summarise para obter o percentual semanal de casos que morreram
  summarise(n_cases = n(),
            died = sum(outcome == "Death", na.rm=T),
            pct_died = 100*died/n_cases) %>% 
  
  # inicie o gráfico
  ggplot()+
  
  # linha com o percentual semanal de óbitos
  geom_line(                                # crie um linha com o percentual de mortos
    mapping = aes(x = week, y = pct_died),  # especifique o y-altura como sendo da coluna pct_died
    stat = "identity",                      # ajuste a altura da linha para o valor na coluna pct_death, e não a quantidade de linhas (que é o padrão)
    size = 2,
    color = "black")+
  
  # Mesmos limites no eixo de datas como no outro gráfico - alinhamento perfeito
  scale_x_date(
    limits = c(min(weekly_breaks_all), max(weekly_breaks_all)))+  # mín/máx das quebras semanais pré-definidas do histograma
  
  
  # ajustes no eixo y
  scale_y_continuous(                # ajuste o eixo y
    breaks = seq(0,100, 10),         # ajuste os intervalos de quebra do eixo da porcentagem
    limits = c(0, 100),              # ajuste a extensão do eixo de porcentagem
    position = "right")+             # mova o eixo de porcentagem para a direita
  
  # rótulo do eixo y, sem rótulo no eixo x
  labs(x = "",
       y = "Percentual de óbitos")+      # rótulo do eixo de porcentagem
  
  theme_cowplot()                   # adicione isto para unir os dois gráficos
```

Agora, use o **cowplot** para sobrepor os dois gráficos. A atenção precisa ser dada ao alinhamento do eixo x, ao lado do eixo y, e ao uso de `theme_cowplot()`.  

```{r, warning=F, message=F}
aligned_plots <- cowplot::align_plots(plot_cases, plot_deaths, align="hv", axis="tblr")
ggdraw(aligned_plots[[1]]) + draw_plot(aligned_plots[[2]])
```




## Incidência acumulada {}

Nota: Caso esteja utilizando o pacote **incidence2**, veja a seção sobre como você pode produzir incidência acumulada com uma simples função. Esta página irá ensinar como calcular a incidência acumulada e fazer um gráfico dela utilizando `ggplot()`.  

Se estiver iniciando com os casos em uma linelist, crie uma nova coluna contendo o número acumulado de casos por dia em um surto utilizando a função `cumsum()` do R **base**:    

```{r}
cumulative_case_counts <- linelist %>% 
  count(date_onset) %>%                # contagem de linhas por dia (salvo na coluna "n")
  mutate(                         
    cumulative_cases = cumsum(n)       # nova coluna com a quantidade de linhas acumuladas em cada data
    )
```

As primeiras 10 linhas são mostradas abaixo:

```{r message=FALSE, echo=F}
# mostra os dados da linelist como uma tabela
DT::datatable(head(cumulative_case_counts, 10), rownames = FALSE, options = list(pageLength = 10, scrollX=T), class = 'white-space: nowrap' )
```



Esta coluna de casos acumulados pode então ser utilizada para fazer um gráfico com a data de início dos sintomas, `date_onset`, utilizando `geom_line()`:

```{r, warning=F, message=F}
plot_cumulative <- ggplot()+
  geom_line(
    data = cumulative_case_counts,
    aes(x = date_onset, y = cumulative_cases),
    size = 2,
    color = "blue")

plot_cumulative
```


Ela também pode ser sobreposta em uma epicurva, com dois eixos, utilizando o método **cowplot** descrito acima e na página [dicas do ggplot](#ggplot-tips):

```{r, warning=F, message=F}
# carregue o pacote
pacman::p_load(cowplot)

# crie primeiro o histograma de uma epicurva
plot_cases <- ggplot()+
  geom_histogram(          
    data = linelist,
    aes(x = date_onset),
    binwidth = 1)+
  labs(
    y = "Casos diários",
    x = "Data de início dos sintomas"
  )+
  theme_cowplot()

# crie um segundo gráfico com uma linha de casos acumulados
plot_cumulative <- ggplot()+
  geom_line(
    data = cumulative_case_counts,
    aes(x = date_onset, y = cumulative_cases),
    size = 2,
    color = "blue")+
  scale_y_continuous(
    position = "right")+
  labs(x = "",
       y = "Casos acumulados")+
  theme_cowplot()+
  theme(
    axis.line.x = element_blank(),
    axis.text.x = element_blank(),
    axis.title.x = element_blank(),
    axis.ticks = element_blank())
```

Agora, use **cowplot** para sobrepor os dois gráficos. Atenção ao alinhamento do eixo x, o lado do eixo y, e o uso de `theme_cowplot()`.  

```{r, warning=F, message=F}
aligned_plots <- cowplot::align_plots(plot_cases, plot_cumulative, align="hv", axis="tblr")
ggdraw(aligned_plots[[1]]) + draw_plot(aligned_plots[[2]])
```


<!-- ======================================================= -->
## Recursos { }








```{r include=FALSE, cache=FALSE}

# clear workspace
rm(list = ls(all = TRUE))

# clear all packages except base
#lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))

# to ensure that tidyverse packages prevail
filter <- dplyr::filter
select <- dplyr::select
summarise <- dplyr::summarise
summary <- base::summary
incidence <- incidence2::incidence

#load core packages
pacman::p_load(
     rio,
     here,
     DT,
     stringr,
     lubridate,
     tidyverse
)

# import the cleaned ebola linelist
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

# import the count data - facility level
#count_data <- rio::import(here::here("data", "facility_count_data.rds"))

# Settings

options(scipen=1, digits=7)

# print only text (not code)
# library(knitr)
# opts_chunk$set(list(echo = FALSE, eval = FALSE))
```

<!--chapter:end:new_pages/epicurves.Rmd-->


# Pirâmides demográficas e escalas Likert {#age-pyramid}  



```{r, out.width = c('50%', '50%'), fig.show='hold', echo=F}
knitr::include_graphics(here::here("images", "pop_pyramid_baseline.png"))

knitr::include_graphics(here::here("images", "likert.png"))
```


As pirâmides demográficas são úteis para mostrar as distribuições de idade e sexo. Um código semelhante pode ser usado para visualizar os resultados de perguntas de pesquisa do tipo Likert (por exemplo "Concordo plenamente", "Concordo", "Neutro", "Discordo",  "Discordo totalmente"). Nesta página, cobrimos o seguinte:  

* Pirâmides rápidas e fáceis usando o pacote **apyramid**  
* Pirâmides mais personalizáveis usando `ggplot()`  
* Exibindo linhas de base demográficas no fundo da pirâmide  
* Usando gráficos em estilo de pirâmide para mostrar outros tipos de dados (por exemplo, respostas a perguntas de pesquisa **estilo Likert**)  





<!-- ======================================================= -->
## Preparação



### Carregar pacotes {.unnumbered}

Este pedaço de código mostra o carregamento de pacotes necessários para as análises. Neste manual, enfatizamos `p_load()` de **pacman**, que instala o pacote se necessário *e* o carrega para uso. Você também pode carregar pacotes instalados com `library()` de R **base**. Veja a página em [Introdução ao R](#basics) para mais informações sobre pacotes R.  

```{r}
pacman::p_load(rio, # para importar dados
               here, # para localizar arquivos
               tidyverse, # para limpar, manipular e plotar os dados (inclui o pacote ggplot2)
               apyramid, # um pacote dedicado à criação de pirâmides de idades
               janitor, # tabelas e dados de limpeza
               stringr) # trabalhando com strings para títulos, legendas, etc.
```




### Importar dados {.unnumbered}  

Para começar, importamos a lista (*linelist*) limpa de casos de uma simulação de epidemia de Ebola. Se você quiser acompanhar, <a href='https://github.com/appliedepi/epirhandbook_eng/raw/master/data/case_linelists/linelist_cleaned.rds' class='download-button'> clique para baixar o linelist "clean" </a> (como um arquivo .rds). Importe dados com a função `import()` do pacote **rio** (ele lida com muitos tipos de arquivo como .xlsx, .csv, .rds - veja a página [Importar e exportar](#importing) para detalhes).  

```{r, echo=F}
# importe a linelist para R
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))
```

```{r, eval=F}
# import case linelist 
linelist <- import("linelist_cleaned.rds")
```

As primeiras 50 linhas da linelist são exibidas abaixo.

```{r, message=FALSE, echo=F}
# exibe os dados da linelist como uma tabela
DT::datatable(head (linelist, 50), rownames = FALSE, filter = "top", options = list (pageLength = 5, scrollX = T), class = 'white-space: nowrap')
```

### Limpeza {.unnumbered}  

Para fazer uma pirâmide demográfica tradicional de idade / sexo, os dados devem primeiro ser limpos das seguintes maneiras:  

* A coluna de gênero deve ser limpa.  
* Dependendo do seu método, a idade deve ser armazenada como um número ou em uma coluna de *categoria de idade*.  

Se estiver usando categorias de idade, os valores da coluna devem ser corrigidos em ordem, seja alfanumérico padrão ou definido intencionalmente pela conversão para o fator de classe.  

Abaixo, usamos `tabyl()` de **janitor** para inspecionar as colunas `gender` e `age_cat5`.  

```{r}
linelist %>% 
  tabyl(age_cat5, gender)
```


Também executamos um histograma rápido na coluna `idade` para garantir que esteja limpo e classificado corretamente:  

```{r}
hist(linelist$age)
```


<!-- ======================================================= -->
## Pacote **apyramid** {}

O pacote **apyramid** é um produto do projeto [R4Epis](https://r4epis.netlify.com/). Você pode ler mais sobre este pacote [aqui](https://cran.r-project.org/web/packages/apyramid/vignettes/intro.html). Ele permite que você crie rapidamente uma pirâmide de idades. Para situações mais sutis, veja a seção abaixo [usando `ggplot()`](# demo_pyr_gg). Você pode ler mais sobre o pacote **apyramid** em sua página de Ajuda inserindo `?Age_pyramid` em seu console R. 

### Dados linelist {.unnumbered}  


Usando o conjunto de dados `linelist` limpo, podemos criar uma pirâmide de idade com um simples comando `age_pyramid() `. Neste comando:  

* O argumento `data =` é definido como o quadro de dados (*data frame*) `linelist`  
* O argumento `age_group =` (para o eixo y) é definido como o nome da coluna categórica de idade (entre aspas)  
* O argumento `split_by =` (para o eixo x) é definido para a coluna de gênero  

```{r, warning=F, message=F, echo=F}
apyramid::age_pyramid(data = linelist,
                      age_group = "age_cat5",
                      split_by = "gender")
```


A pirâmide pode ser exibida com a porcentagem de todos os casos no eixo x, em vez de contagens, incluindo `proporcional = VERDADEIRO`.  

```{r, warning=F, message=F, echo=F}
apyramid::age_pyramid(data = linelist,
                      age_group = "age_cat5",
                      split_by = "gender",
                      proportional = TRUE)
```


Ao usar o pacote **agepyramid**, se a coluna `split_by` for binária (por exemplo, masculino / feminino ou sim / não), o resultado aparecerá como uma pirâmide. No entanto, se houver mais de dois valores na coluna `split_by` (não incluindo `NA`), a pirâmide aparecerá como um gráfico de barra facetada com barras cinza no "fundo" indicando o intervalo dos dados não facetados para aquele grupo de idade. Nesse caso, os valores de `split_by =` aparecerão como rótulos na parte superior de cada painel de faceta. Por exemplo, abaixo está o que ocorre se `split_by =` é atribuído à coluna `hospital`.  

```{r, warning=F, message=F, echo=F}
apyramid::age_pyramid(data = linelist,
                      age_group = "age_cat5",
                      split_by = "hospital")  
```

#### Valores faltantes {.unnumbered}  

As linhas que têm valores faltantes `NA` nas colunas `split_by = ` ou `age_group = `, se codificadas como `NA`, não irão acionar o facetamento mostrado acima. Por padrão, essas linhas não serão mostradas. No entanto, você pode especificar que eles apareçam em um gráfico de barras adjacente e como uma faixa etária separada no topo, especificando `na.rm = FALSE`.  

```{r, warning=F, message=F, echo=F}
apyramid::age_pyramid(data = linelist,
                      age_group = "age_cat5",
                      split_by = "gender",
                      na.rm = FALSE) # mostra pacientes sem idade ou sexo
```

#### Proporções, cores e estética {.unnumbered}  

Por padrão, as barras exibem contagens (não %), uma linha intermediária tracejada para cada grupo é mostrada e as cores são verde / roxo. Cada um desses parâmetros pode ser ajustado, conforme mostrado abaixo:  

Você também pode adicionar comandos `ggplot()` adicionais ao gráfico usando a sintaxe `ggplot()` "+" padrão, como temas estéticos e ajustes de rótulo: 

```{r, warning=F, message=F, echo=F}
apyramid::age_pyramid(
  data = linelist,
  age_group = "age_cat5",
  split_by = "gender",
  proportional = TRUE, # mostra as porcentagens, não contagens
  show_midpoint = FALSE) + # remove linha de ponto médio da barra
  #pal = c("laranja", "roxo") # pode especificar cores alternativas aqui (mas não rótulos)# comandos ggplot adicionais
  theme_minimal() + # fundo simplfy
  scale_fill_manual(# especificar cores E rótulos
    values = c("orange", "purple"),              
    labels = c("m" = "Masculino", "f" = "Feminino")) +
  labs(y = "Porcentagem de todos os casos", # note que x e y labs são trocados
       x = "Categorias de idade",                          
       fill = "Gênero", 
       caption = "Minha fonte de dados e legenda aqui",
       title = "Título do meu gráfico",
       subtitle = "Subtítulo com \ n uma segunda linha ...") +
  theme(
    legend.position = "bottom", # legenda para a parte de baixo
    axis.text = element_text(size = 10, face = "bold"),  # fonts/sizes
    axis.title = element_text(size = 12, face = "bold"))
```



### Dados agregados {.unnumbered}  

Os exemplos acima assumem que seus dados estão em um formato de linelist, com cada linha correspondendo a uma observação. Se seus dados já estão agregados em contagens por categoria de idade, você ainda pode usar o pacote **apyramid**, conforme mostrado abaixo.  

Para demonstração, agregamos os dados da linelist em contagens por categoria de idade e sexo, em um formato "amplo" ou "wide". Isso simulará como se seus dados estivessem em contagens para começar. Saiba mais sobre [agrupamento de dados](#grouping) e [pivoteamento de dados](#pivoting) em suas respectivas páginas.  

```{r, warning=F, message=F, echo=F}
demo_agg <- linelist%>% 
  count(age_cat5, gender, name = "casos")%>% 
  pivot_wider(
    id_cols = age_cat5,
    names_from = gender,
    values_from = casos) %>% 
  rename(`missing_gender` = `NA`)
```

... o que faz com que o conjunto de dados tenha a seguinte aparência: com colunas para categoria de idade e contagens masculinas, contagens femininas e contagens ausentes.  

```{r, echo=F, warning=F, message=F}
# Visualize os dados agregados
DT::datatable(demo_agg, rownames = FALSE, options = list(pageLength = 5, scrollX = T), class = 'white-space: nowrap')
```

Para configurar esses dados para a pirâmide de idade, vamos organizar os dados no formato "longo" com a função `pivot_longer()` de **dplyr**. Isso ocorre porque `ggplot()` geralmente prefere dados "longos", e **apyramid** está usando `ggplot()`.  

```{r, warning=F, message=F, echo=F}
# pivot os dados agregados em formato longo
demo_agg_long <- demo_agg %>% 
  pivot_longer(
    col = c(f, m, missing_gender), # cols para alongar
    names_to = "gender", # nome para a nova coluna de categorias
    values_to = "counts")%>% # name para nova coluna de contagens
  mutate(
    gender = na_if(gender, "missing_gender")) # converte "missing_gender" em NA
``` 

```{r, echo=F, warning=F, message=F}
# Visualize os dados agregados
DT::datatable(head (linelist, 5), rownames = FALSE, filter = "top", options = list (pageLength = 5, scrollX = T), class = 'white-space: nowrap')
```

Em seguida, use os argumentos `split_by =` e `count =` de `age_pyramid()` para especificar as respectivas colunas nos dados:  

```{r, warning=F, message=F, echo=F}
apyramid::age_pyramid(data = demo_agg_long,
                      age_group = "age_cat5",# nome de coluna para a categoria de idade
                      split_by = "gender",   # nome de coluna para gênero
                      count = "counts") # nome da coluna para contagens de casos
```

Observe acima, que a ordem dos fatores de "m" e "f" é diferente (pirâmide invertida). Para ajustar a ordem, você deve redefinir o gênero nos dados agregados como um fator e ordenar os níveis conforme desejado. Veja a página [Fatores](#factors).  




<!-- ======================================================= -->
## `ggplot()` {#demo_pyr_gg}


Usar `ggplot()` para construir sua pirâmide de idade permite mais flexibilidade, mas requer mais esforço e compreensão de como `ggplot()` funciona. Também é mais fácil cometer erros acidentalmente.  

Para usar `ggplot()` para fazer pirâmides demográficas, você cria dois gráficos de barra (um para cada gênero), converte os valores em um gráfico para negativo e, finalmente, vira os eixos x e y para exibir os gráficos de barra verticalmente, suas bases encontro no meio da trama.  


### Preparação {.unnumbered}

Essa abordagem usa a coluna *numérica* idade, não a coluna *categórica* de `age_cat5`. Portanto, vamos verificar se a classe desta coluna é realmente numérica.  

```{r}
class(linelist$age)
```

Você poderia usar a mesma lógica abaixo para construir uma pirâmide de dados categóricos usando `geom_col()` ao invés de `geom_histogram()`.  

<!-- ======================================================= -->
### Construindo o gráfico {.unnumbered} 

Primeiro, entenda que para fazer essa pirâmide usando `ggplot()` a abordagem é a seguinte:

* Dentro de `ggplot()`, crie **dois** histogramas usando a coluna numérica de idade. Crie um para cada um dos dois valores de agrupamento (neste caso, gêneros masculino e feminino). Para fazer isso, os dados de cada histograma são especificados em seus respectivos comandos `geom_histogram()`, com os respectivos filtros aplicados à `linelist`.    

* Um gráfico terá valores de contagem positivos, enquanto o outro terá suas contagens convertidas em valores negativos - isso cria a "pirâmide" com o valor `0` no meio do gráfico. Os valores negativos são criados usando um termo especial do **ggplot2** `..count..` e multiplicando por -1.  

* O comando `coord_flip()` muda os eixos X e Y, resultando na viragem dos gráficos na vertical e na criação da pirâmide.

* Por último, os rótulos de valor do eixo de contagem devem ser alterados para que apareçam como contagens "positivas" em ambos os lados da pirâmide (apesar dos valores subjacentes em um lado serem negativos). 

Uma versão **simples** disso, usando `geom_histogram()`, está abaixo:

```{r, warning=F, message=F, echo=F}
  # começar ggplot
  ggplot(mapping = aes(x = age, fill = gender))+
  
  # histograma feminino
  geom_histogram(data = linelist %>% filter(gender == "f"),
                 breaks = seq(0,85,5),
                 colour = "white") +
  
  # histograma masculino (valores convertidos em negativos)
  geom_histogram(data = linelist %>% filter(gender == "m"),
                 breaks = seq(0,85,5),
                 mapping = aes(y=..count..*(-1)),
                 colour = "white") +
  
  # inverta os eixos X e Y
  coord_flip() +
  
  # ajustar a escala do eixo de contagem
  scale_y_continuous(limits = c(-600, 900),
                     breaks = seq(-600,900,100),
                     labels = abs(seq(-600, 900, 100)))
```

<span style = "color: red;"> **_ PERIGO: _** Se os **limites** do seu eixo de contagem forem definidos muito baixos e uma barra de contagem ultrapassá-los, a barra desaparecerá totalmente ou será reduzida artificialmente ! Observe isso ao analisar dados que são atualizados rotineiramente. Evite que os limites do eixo de contagem se ajustem automaticamente aos seus dados, conforme abaixo. </span>  

Há muitas coisas que você pode alterar / adicionar a esta versão simples, incluindo:  

* Ajuste automático da escala do eixo de contagem aos seus dados (evite os erros discutidos no aviso abaixo)  
* Especifique manualmente as cores e rótulos de legenda  

**Converta contagens em porcentagens**  

Para converter contagens em porcentagens (do total), faça isso em seus dados antes de plotar. Abaixo, temos as contagens de idade e gênero, então `ungroup()`, e então `mutate()` para criar novas colunas de porcentagem. Se você quiser porcentagens por gênero, pule a etapa de desagrupamento.  


```{r, warning=F, message=F, echo=F}
# cria conjunto de dados com proporção do total
pyramid_data <- linelist%>%
  count(age_cat5,
        gender,
        name = "counts")%>% 
  ungroup()%>% # desagrupar para que as porcentagens não sejam por grupo
  mutate(percent = round(100*(counts / sum(counts, na.rm=T)), digits = 1), 
         percent = case_when(
            gender == "f" ~ percent,
            gender == "m" ~ -percent, # converter masculino em negativo
            TRUE ~ NA_real_)) # NA val deve ser numérico também
```

É importante ressaltar que salvamos os valores máximos e mínimos para que saibamos quais devem ser os limites da escala. Eles serão usados no comando `ggplot()` abaixo.    

```{r}
max_per <- max(pyramid_data$percent, na.rm = T)
min_per <- min(pyramid_data$percent, na.rm = T)

max_per
min_per
```

Finalmente, fazemos o `ggplot()` nos dados de porcentagem. Especificamos `scale_y_continuous()` para estender os comprimentos predefinidos em cada direção (positivo e "negativo"). Usamos `floor()` e `ceiling()` para arredondar decimais na direção apropriada (para baixo ou para cima) para o lado do eixo.  

```{r, warning=F, message=F, echo=F}
# começar ggplot
  ggplot() + # eixo x padrão é a idade em anos;

  # gráfico de dados de caso
  geom_col(data = pyramid_data,
           mapping = aes(
             x = age_cat5,
             y = percent,
             fill = gender),         
           color = "white") + # branco em torno de cada barra
  
  # vire os eixos X e Y para tornar a pirâmide vertical
  coord_flip()+
  

  # ajusta as escalas dos eixos
  # scale_x_continuous(breaks = seq(0,100,5), labels = seq(0,100,5)) +
  scale_y_continuous(
    limits = c(min_per, max_per),
    breaks = seq(from = floor (min_per), # sequência de valores, por 2s
                 to = ceiling(max_per),
                 by = 2),
    labels = paste0(abs(seq(from = floor(min_per), # sequência de valores absolutos, por 2s, com "%"
                            to = ceiling(max_per),
                            by = 2)),
                    "%"))+  

  # designar cores e rótulos de legenda manualmente
  scale_fill_manual(
    values = c("f" = "orange",
               "m" = "darkgreen"),
    labels = c("Female", "Male")) +
  
  # valores de rótulo (lembre-se de X e Y invertidos agora)
  labs(
    title = "Idade e gênero dos casos",
    x = "Faixa etária",
    y = "Porcentagem do total",
    fill = NULL,
    caption = stringr::str_glue("Os dados são da linelist \nn = {nrow(linelist)} (idade ou sexo ausente para {sum(is.na(linelist$gender) | is.na (linelist$age_years))} casos) \nDados a partir de: {format(Sys.Date(), '%d %b %Y')}")) +
  
  # temas de exibição
  theme(
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.background = element_blank(),
    axis.line = element_line(color = "black"),
    plot.title = element_text(hjust = 0.5), 
    plot.caption = element_text(hjust=0, size=11, face = "italic")
    )

```



<!-- ======================================================= -->
### Compare com a linha de base {.unnumbered} 

Com a flexibilidade de `ggplot()`, você pode ter uma segunda camada de barras no fundo que representam a pirâmide populacional "verdadeira" ou "linha de base". Isso pode fornecer uma boa visualização para comparar o observado com a linha de base.  

Importe e visualize os dados populacionais (consulte a página [Baixar manual e dados](#data-used)):

```{r, echo=F}
# importar os dados demográficos da população
pop <- rio::import(here::here("data", "standardization", "country_demographics.csv"))

```

```{r, eval=F}
# importar os dados demográficos da população
pop <- rio::import("country_demographics.csv")
```

```{r, echo=F, warning=F, message=F}
# exibe os dados da linelist como uma tabela
DT::datatable(pop, rownames = FALSE, options = list(pageLength = 10, scrollX = T), class = 'white-space: nowrap')
```


Primeiro, algumas etapas de gerenciamento de dados:  

Aqui gravamos a ordem das categorias de idade que queremos que apareçam. Devido a algumas peculiaridades na forma como o `ggplot()` é implementado, neste cenário específico é mais fácil armazená-los como um vetor de caracteres e usá-los posteriormente na função de gráfico.  

```{r}
# registrar níveis corretos de gatos com idade
age_levels <- c("0-4","5-9", "10-14", "15-19", "20-24",
                "25-29","30-34", "35-39", "40-44", "45-49",
                "50-54", "55-59", "60-64", "65-69", "70-74",
                "75-79", "80-84", "85+")
```

Combine a população e os dados do caso por meio da função **dplyr** `bind_rows()`:  

* Primeiro, certifique-se de que eles tenham os *mesmos* nomes de coluna, valores de categorias de idade e valores de gênero  
* Faça com que tenham a mesma estrutura de dados: colunas de categoria de idade, sexo, contagens e porcentagem do total  
* Una-os, um em cima do outro (`bind_rows()`)  



```{r, warning=F, message=F, echo=F}
# criar / transformar dados populacionais, com porcentagem do total
########################################################
pop_data <- pop%>% 
  pivot_longer(        # colunas de gênero pivot mais longas
    cols = c(m, f),
    names_to = "gender",
    values_to = "counts")%>% 
  
  mutate(
    percent  = round(100*(counts / sum(counts, na.rm=T)),1),  # % do total
    percent = case_when(                                                        
     gender == "f" ~ percent,
     gender == "m" ~ -percent, # se masculino, converter% para negativo
     TRUE          ~ NA_real_))
```

Revise o conjunto de dados de população alterado

```{r, echo=F, warning=F, message=F}
# exibe os dados da linelist como uma tabela
DT::datatable(pop_data, rownames = FALSE, options = list(pageLength = 5, scrollX = T), class = 'white-space: nowrap')
```

Agora implemente o mesmo para a linelist do caso.  Um pouco diferente porque começa com linhas de caso, não conta.  

```{r, warning=F, message=F, echo=F}
# criar dados de caso por idade / sexo, com porcentagem do total
#######################################################
case_data <- linelist%>%
  count(age_cat5, gender, name = "counts")%>% # contagens por grupos de idade-gênero
  ungroup() %>% 
  mutate(
    percent = round(100*(counts / sum(counts, na.rm=T)),1), # calcular % do total para grupos de idade e gênero
    percent = case_when(       # convert % to negative se masculino
      gender == "f" ~ percent,
      gender == "m" ~ -percent,
      TRUE          ~ NA_real_))
```

Revise o conjunto de dados de caso alterado  

```{r, message=FALSE, echo=F}
# exibe os dados da linelist como uma tabela
DT::datatable(case_data, rownames = FALSE, options = list(pageLength = 5, scrollX = T), class = 'white-space: nowrap')
```

Agora os dois data frames estão combinados, um em cima do outro (eles têm os mesmos nomes de coluna). Podemos "nomear" cada frame de dados e usar o argumento `.id =` para criar uma nova coluna "data_source" que indicará de qual frame de dados cada linha se originou. Podemos usar esta coluna para filtrar no `ggplot()`.  



```{r, warning=F, message=F, echo=F}
# combinar dados de caso e população (mesmos nomes de coluna, valores age_cat e valores de gênero)
pyramid_data <- bind_rows("cases" = case_data, "population" = pop_data, .id = "data_source")
```

Armazene os valores percentuais máximos e mínimos, usados na função de plotagem para definir a extensão da plotagem (e não encurte nenhuma barra!)  

```{r}
# Defina a extensão do eixo percentual, usado para os limites do gráfico
max_per <- max(pyramid_data$percent, na.rm = T)
min_per <- min(pyramid_data$percent, na.rm = T)
```

Agora o gráfico é feito com `ggplot()`: 

* Um gráfico de barras de dados populacionais (barras mais largas e transparentes)
* Um gráfico de barras de dados do caso (barras pequenas e mais sólidas)  


```{r, warning=F, message=F, echo=F}

# começar ggplot
##############
ggplot() + # eixo x padrão é a idade em anos;

  # gráfico de dados populacionais
  geom_col(
    data = pyramid_data %>% filter(data_source == "population"),
    mapping = aes(
      x = age_cat5,
      y = percent,
      fill = gender),
    color = "black", # cor preta ao redor das barras
    alpha = 0.2, # mais transparente
    width = 1) + # largura total
  
  # gráfico de dados de caso
  geom_col(
    data = pyramid_data %>% filter(data_source == "cases"), 
    mapping = aes(
      x = age_cat5, # categorias de idade como eixo X original
      y = percent, #% como eixo Y original
      fill = gender), # preencher de barras por gênero
    color = "black", # cor preta ao redor das barras
    alpha = 1, # não transparente 
    width = 0.3) + # meia largura
  
  # vire os eixos X e Y para tornar a pirâmide vertical
  coord_flip()+
  
  # garantir de forma manual que o eixo da idade está ordenado corretamente
  scale_x_discrete(limits = age_levels) + # definido no bloco acima
  
  # definir eixo percentual 
  scale_y_continuous(
    limits = c(min_per, max_per), # min e max definidos acima
    breaks = seq(floor(min_per), ceiling(max_per), by = 2), # de min% a max% por 2 
    labels = paste0(# para os rótulos, cole ... 
              abs(seq(floor(min_per), ceiling(max_per), by = 2)), "%"))+                                                  

  # designar cores e rótulos de legenda manualmente
  scale_fill_manual(
    values = c("f" = "orange", # atribuir cores aos valores nos dados
               "m" = "darkgreen"),
    labels = c("f" = "Feminino",
               "m" = "Masculino"), # alterar rótulos que aparecem na legenda, ordem das notas
  ) +

  # rótulos de plotagem, títulos, legenda    
  labs(
    title = "Idade do caso e distribuição de gênero, \nas em comparação com a população de base",
    subtitle = "",
    x = "Categoria de idade",
    y = "Porcentagem do total",
    fill = NULL,
    caption = stringr::str_glue("Casos mostrados no topo da linha de base demográfica do país \nOs dados do caso são da linelist, n = {nrow(linelist)} \nIdade ou gênero ausente para {sum(is.na(linelist$gênero) | is.na(linelist$age_years))} casos \nDados de caso a partir de: {format(max(linelist$date_onset, na.rm = T), '% d% b% Y')} ")) +
  
  # temas estéticos opcionais
  theme(
    legend.position = "bottom", # mover legenda para baixo
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.background = element_blank(),
    axis.line = element_line(color = "black"),
    plot.title = element_text(hjust = 0), 
    plot.caption = element_text(hjust=0, size=11, face = "italic"))

```


<!-- ======================================================= -->
## Escala de Likert {}

As técnicas usadas para fazer uma pirâmide populacional com `ggplot()` também podem ser usadas para fazer gráficos de dados de pesquisa em escala Likert.  

```{r, eval=F, echo=F}
data_raw <- import("P:/Shared/equateur_mve_2020/lições aprendidas/Pesquisa pós-ação do Ebola - equipe epi HQ (respostas do formulário).csv")


likert_data <- data_raw %>% 
  select(2, 4:11)%>% 
  rename(status = 1,
         Q1 = 2,
         Q2 = 3,
            Q3 = 4,
            Q4 = 5,
            Q5 = 6,
            Q6 = 7,
            Q7 = 8,
            Q8 = 9) %>%
  mutate(status = case_when(
           stringr::str_detect(status, "Mar") ~ "Senior",
           stringr::str_detect(status, "Jan") ~ "Intermediate",
           stringr::str_detect(status, "Feb") ~ "Junior",
           TRUE ~ "Sênior"))%>%
  mutate(Q4 = recode(Q4, "Não aplicável" = "Muito Insuficiente"))

table(likert_data$status)

rio::export(likert_data, here::here("data", "likert_data.csv"))
```

Importe os dados (consulte a página [Baixar manual e dados](#data-used) se desejar).  

```{r, echo=F}
# importar os dados de resposta da pesquisa likert
likert_data <- rio::import(here::here("data", "likert_data.csv"))
```

```{r, eval=F}
# importar os dados de resposta da pesquisa likert
likert_data <- rio::import("likert_data.csv")
```

Comece com dados parecidos com estes, com uma classificação categórica de cada entrevistado (`status`) e suas respostas a 8 perguntas em uma escala do tipo Likert de 4 pontos ("Muito ruim", "Ruim", "Bom", "Muito bom").  

```{r, echo=F, message=FALSE}
# exibe os dados da linelist como uma tabela
DT::datatable(head (linelist, 10), rownames = FALSE, filter = "top", options = list(pageLength = 5, scrollX = T), class = 'white-space: nowrap')
```

Primeiro, algumas etapas de gerenciamento de dados:  

* Dinamizar os dados por mais tempo  
* Crie uma nova coluna `direção` dependendo se a resposta foi geralmente "positiva" ou "negativa"  
* Defina a ordem do nível de fator para a coluna `status` e a coluna `Resposta`  
* Armazene o valor de contagem máxima para que os limites do gráfico sejam apropriados  


```{r, warning=F, message=F, echo=F}
melted <- likert_data%>% 
  pivot_longer(
    cols = Q1: Q8,
    names_to = "Question",
    values_to = "Response")%>% 
  mutate(
    
    direction = case_when(
      Response %in% c("Poor","Very Poor")  ~ "Negative",
      Response %in% c("Good", "Very Good") ~ "Positive",
      TRUE                                 ~ "Unknown"),
    
    status = fct_relevel(status, "Junior", "Intermediate", "Senior"),
    
    # deve reverter 'Muito ruim' e 'Ruim' para que o pedido funcione
    Response = fct_relevel(Response, "Very Good", "Good", "Very Poor", "Poor")) 

# obter o maior valor para os limites de escala
melted_max <- melted %>% 
  count(status, Question) %>% # get counts
  pull(n) %>%                 # column 'n'
  max(na.rm=T)                # get max
```


Agora faça o gráfico. Como nas pirâmides de idades acima, estamos criando dois gráficos de barra e invertendo os valores de um deles para negativo. 

Usamos `geom_bar()` porque nossos dados são uma linha por observação, não contagens agregadas. Usamos o termo especial **ggplot2** `..count..` em um dos gráficos de barra para inverter os valores negativos (* -1) e definimos `position = "stack"` para que os valores sejam empilhados no topo de cada um.  

```{r, warning=F, message=F, echo=F}
# make plot
ggplot()+
     
  # gráfico de barras das respostas "negativas" 
     geom_bar(
       data = melted %>% filter(direction == "Negative"),
       mapping = aes(
         x = status,
         y = ..count..*(-1), # contagens invertidas para negativas
         fill = Response),
       color = "black",
       closed = "left",
       position = "stack")+
     
     # gráfico de barras das "respostas positivas
     geom_bar(
       data = melted %>% filter(direction == "Positive"),
       mapping = aes(
         x = status,
         fill = Response),
       colour = "black",
       closed = "left",
       position = "stack")+
     
     # inverta os eixos X e Y
     coord_flip()+
  
     # Linha vertical preta em 0
     geom_hline(yintercept = 0, color = "black", size=1)+
     
    # converter rótulos em todos os números positivos
    scale_y_continuous(
      
      # limites da escala do eixo x
      limits = c(-ceiling(melted_max/10)*11, # seq de neg para pos por 10, arestas arredondadas para fora para o próximo 5
                 ceiling(melted_max/10)*10),   
      
      # valores da escala do eixo x
      breaks = seq(from = -ceiling (melted_max / 10) * 10,
                   to = ceiling(melted_max / 10) * 10,
                   by = 10),
      
      # rótulos da escala do eixo x
      labels = abs(unique(c(seq(-ceiling(melted_max/10)*10, 0, 10),
                            seq(0, ceiling(melted_max/ 10) * 10, 10))))) +
     
    # escalas de cores atribuídas manualmente 
    scale_fill_manual(
      values = c("Muito bom" = "green4", # atribui cores
                "Bom"      = "green3",
                "Fraco" = "yellow",
                "Muito ruim" = "red3"),
      breaks = c("Muito bom", "Bom", "Ruim", "Muito ruim")) + # ordena a legenda
     
    
     
    # faceta todo o gráfico para que cada questão seja um sub-gráfico
    facet_wrap( ~ Question, ncol = 3)+
     
    # rótulos, títulos, legenda
    labs(
      title = str_glue("Respostas estilo Likert\nn = {nrow (likert_data)}"),
      x = "Status do entrevistado",
      y = "Número de respostas",
      fill = "")+

     # ajustes de exibição 
     theme_minimal() +
     theme(axis.text = element_text(size = 12),
           axis.title = element_text(size = 14, face = "bold"),
           strip.text = element_text(size = 14, face = "bold"),  # facet sub-titles
           plot.title = element_text(size = 20, face = "bold"),
           panel.background = element_rect(fill = NA, color = "black")) # caixa preta ao redor de cada faceta
```


<!-- ======================================================= -->
## Recursos {}

[Documentação do pacote apyramid](https://cran.r-project.org/web/packages/apyramid/vignettes/intro.html)

```{r include=FALSE, cache=FALSE}

# clear workspace
rm(list = ls(all = TRUE))

# clear all packages except base
#lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))

# to ensure that tidyverse packages prevail
filter <- dplyr::filter
select <- dplyr::select
summarise <- dplyr::summarise
summary <- base::summary
incidence <- incidence2::incidence

#load core packages
pacman::p_load(
     rio,
     here,
     DT,
     stringr,
     lubridate,
     tidyverse
)

# import the cleaned ebola linelist
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

# import the count data - facility level
#count_data <- rio::import(here::here("data", "facility_count_data.rds"))

# Settings

options(scipen=1, digits=7)

# print only text (not code)
# library(knitr)
# opts_chunk$set(list(echo = FALSE, eval = FALSE))
```

<!--chapter:end:new_pages/age_pyramid.Rmd-->


# Gráficos de calor {#heatmaps}  


Os gráficos de calor, também conhecidos como "mapas de calor" ou "blocos/ladrilhos de calor" (do inglês heat tiles) , podem ser visualizações úteis ao tentar exibir 3 variáveis (eixo x, eixo y e preenchimento). Abaixo, demonstramos dois exemplos:  

* Uma matriz visual de eventos de transmissão por idade ("quem infectou quem")  
* Acompanhamento de métricas de relatórios em muitas instalações / jurisdições ao longo do tempo  


```{r, out.width = c('50%', '50%'), fig.show='hold', warning=F, message=F, echo=F}
knitr::include_graphics(here::here("images", "transmission_matrix.png"))

knitr::include_graphics(here::here("images", "heat_tile.png"))

```





<!-- ======================================================= -->
## Preparação

### Carregar pacotes {.unnumbered}  

Este pedaço de código mostra o carregamento de pacotes necessários para as análises. Neste manual, enfatizamos `p_load()` do **pacman**, que instala o pacote se necessário *e* o carrega para uso. Você também pode carregar pacotes instalados com `library()` do R **base**. Veja a página em [Introdução ao R](#heatmaps) para mais informações sobre pacotes R.  

```{r}
pacman :: p_load(
  tidyverse, # manipulação e visualização de dados
  rio, # importando dados 
  lubridate # trabalhando com datas
  )
```

**Conjuntos de dados**  

Esta página utiliza a lista de casos de um surto simulado para a seção de matriz de transmissão e um conjunto de dados separado de contagens diárias de casos de malária por instalação para a seção de rastreamento de métricas. Eles são carregados e limpos em suas seções individuais.  







## Matriz de transmissão  

Os quadrados de um mapa de calor podem ser úteis para visualizar matrizes. Um exemplo é exibir "quem infectou quem" em um surto. Isso pressupõe que você tenha informações sobre os eventos de transmissão.  

Observe que a página [Rastreamento de contato](#contact-tracing) contém outro exemplo de criação de uma matriz de contato de do tipo blocos/quadrados térmicos, usando um conjunto de dados diferente (talvez até mais simples) onde as idades dos casos e suas fontes estão perfeitamente alinhadas na mesma linha de observação do quadro de dados (*data frame*). Esses mesmos dados são usados para fazer um mapa de *densidade* na página [dicas do ggplot](#ggplot-tips). O exemplo abaixo começa com uma linelist de caso e, portanto, envolve uma manipulação  considerável de dados antes de obter um data frame que possa ser utilizado em um gráfico. Portanto, existem muitos cenários para escolher...  


Começamos com a lista de casos de uma simulação de epidemia de Ebola. Se você quiser acompanhar, <a href='https://github.com/appliedepi/epirhandbook_eng/raw/master/data/case_linelists/linelist_cleaned.rds' class='download-button'> clique para baixar o "clean" linelist </a> (as .rds file). Importe dados com a função `import()` do pacote **rio** (ele lida com muitos tipos de arquivo como .xlsx, .csv, .rds - veja a página [Importar e exportar](#importing) para detalhes).  


As primeiras 50 linhas da linelist são mostradas abaixo para demonstração:  


```{r, echo=F}
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))
```


```{r, eval=F}
linelist <- import("linelist_cleaned.rds")
```


Nesta linelist:  

* Existe uma linha por caso, conforme identificado por `case_id`  
* Existe uma coluna posterior `infector` que contém o` case_id` do *infectador*, que também é um caso na linelist  


```{r, message=FALSE, echo=F}
# exibe a população como uma tabela
DT::datatable(head(linelist, 50), rownames = FALSE, filter = "top", options = list(pageLength = 5, scrollX = T), class = 'white-space: nowrap')
```



### Preparação {.unnumbered}  

**Objetivo**: Precisamos alcançar um data frame de estilo "longo" que contenha uma linha por rota de transmissão de idade a idade possível, com uma coluna com valores numéricos contendo a proporção dessa linha de todos os eventos de transmissão observados na linelist.  

Isso exigirá várias etapas de manipulação de dados para alcançar:  


#### Criar um data frame dos casos {.unnumbered} 

Para começar, criamos um data frame dos casos, suas idades e seus infectantes - chamamos o data frame de `idades_de_caso`. As primeiras 50 linhas são exibidas abaixo.  

```{r}
case_ages <- linelist%>% 
  select(case_id, infector, age_cat)%>% 
  rename("case_age_cat" = "age_cat")
```

```{r, message=FALSE, echo=F}
# exibir o shapefile como uma tabela
DT::datatable(case_ages, rownames = FALSE, options = list(pageLength = 50, scrollX = T), class = 'white-space: nowrap')
```

#### Criar um data frame de infectantes {.unnumbered}  

A seguir, criamos um data frame dos infectantes - no momento, ele consiste em uma única coluna. Estas são as IDs de infecção da linelist. Nem todos os casos têm um infectante conhecido, por isso removemos os valores ausentes. As primeiras 50 linhas são exibidas abaixo.  


```{r}
infectors <- linelist %>% 
  select(infector) %>% 
  drop_na(infector)
```

```{r, message=FALSE, echo=F}
# exibir o shapefile como uma tabela
DT::datatable(case_ages, rownames = FALSE, options = list(pageLength = 50, scrollX = T), class = 'white-space: nowrap')
```

Em seguida, usamos junções para obter as idades dos infectantes. Isso não é simples, pois na `linelist`, as idades do infectador não são listadas como tal. Alcançamos esse resultado juntando a 'linelist' dos casos a dos infectantes. Começamos com os infectantes e fazemos um `left_join()` ( ou seja, o adicionamos) com o `linelist`, de forma que o data frame de infectates seja a "linha de base" e a coluna `infector id` do lado esquerdo se junte à coluna `case_id` na `linelist` a direita.  

Assim, os dados do registro do caso do infectante na linelist (incluindo a idade) são adicionados à linha do infectante. As 50 primeiras linhas são exibidas abaixo.  

```{r}
infector_ages <- infectors%>% # começam com infectores
  left_join(# adiciona os dados da linelist para cada infectador  
    linelist,
    by = c("infector" = "case_id"))%>% # corresponde ao infector às suas informações como um caso
  select(infector, age_cat)%>% # mantém apenas as colunas de interesse
  rename("infector_age_cat" = "age_cat")   # rename for clarity
```

```{r, message=FALSE, echo=F}
# exibir o shapefile como uma tabela
DT::datatable(case_ages, rownames = FALSE, options = list(pageLength = 50, scrollX = T), class = 'white-space: nowrap')
```

Em seguida, combinamos os casos e suas idades com os infectantes e suas idades. Cada um desses data frame tem a coluna `infector`, então ela é usada para a junção. As primeiras linhas são exibidas abaixo:    

```{r}
ages_complete <- case_ages%>%  
  left_join(
    infector_ages,
    by = "infector")%>% # utilizando a coluna `infector`coomo chave para a junção
  drop_na() # excluir linhas com qualquer dado faltante
```


```{r, message=FALSE, echo=F}
# exibir o shapefile como uma tabela
DT::datatable(case_ages, rownames = FALSE, options = list(pageLength = 50, scrollX = T), class = 'white-space: nowrap')
```

Abaixo, uma tabulação cruzada simples de contagens entre os casos e os grupos de idade dos infectantes. Rótulos foram adicionadas para maior clareza.  

```{r}
table(cases = ages_complete$case_age_cat,
      infectors = ages_complete$infector_age_cat)
```


Podemos converter esta tabela em um dataframe com `data.frame()` do R **base**, que também converte automaticamente para o formato "longo", que é desejado para o `ggplot()`. As primeiras linhas são mostradas abaixo.  

```{r}
long_counts <- data.frame(table(
    cases = ages_complete$case_age_cat,
    infectors = ages_complete$infector_age_cat))
```

```{r, message=FALSE, echo=F}
# exibir o shapefile como uma tabela
DT::datatable(case_ages, rownames = FALSE, options = list(pageLength = 50, scrollX = T), class = 'white-space: nowrap')
```


Agora fazemos o mesmo, mas aplicamos `prop.table()` do R **base** para a tabela de forma que, em vez de contagens, obtenhamos proporções do total. As primeiras 50 linhas são mostradas abaixo.    

```{r}
long_prop <- data.frame(prop.table(table(
    cases = ages_complete$case_age_cat,
    infectors = ages_complete$infector_age_cat)))
```

```{r, message=FALSE, echo=F}
# exibir o shapefile como uma tabela
DT::datatable(case_ages, rownames = FALSE, options = list(pageLength = 50, scrollX = T), class = 'white-space: nowrap')
```




### Criar gráfico de calor {.unnumbered}  

Agora, finalmente, podemos criar o gráfico de calor com o pacote **ggplot2**, usando a função `geom_tile()`. Veja a página de [dicas do ggplot](#ggplot-tips) para aprender mais extensivamente sobre as escalas de cor / preenchimento, especialmente a função `scale_fill_gradient()`.  

* Na estética `aes()` de `geom_tile()` defina x e y como a idade do caso e idade infectante  
* Também em `aes()` defina o argumento `fill =` para a coluna `Freq` - este é o valor que será convertido para uma cor de bloco  
* Defina uma cor de escala com `scale_fill_gradient()` - você pode especificar as cores altas / baixas  
  * Observe que `scale_color_gradient()` é diferente! Neste caso, você quer o preenchimento  
* Como a cor é feita por meio de "preenchimento", você pode usar o argumento `fill =` em `labs()` para alterar o título da legenda  

```{r}
ggplot(data = long_prop) + # usa um dataframe no formato longo, com proporções como Freq
  geom_tile(# visualizar em quadrados
    aes(
      x = cases, # eixo x é a idade do caso
      y = infectors, # eixo y é a idade do infectador
      fill = Freq)) + # cor de cada quadrado é a coluna Freq nos dados
  scale_fill_gradient(# ajusta a cor de preenchimento dos quadrados
    low = "blue",
    high = "orange")+
  labs(# rótulos
    x = "Idade do caso",
    y = "Idade do infectador",
    title = "Quem infectou quem",
    subtitle = "Matriz de frequência de eventos de transmissão",
    fill = "Proporção de todos os eventos de \ ntranmsission" # título da legenda
  )
  
```



<!-- ======================================================= -->
## Métricas de relatório ao longo do tempo {}

Frequentemente, na saúde pública, um objetivo é avaliar as tendências ao longo do tempo para muitas entidades (instalações, jurisdições, etc.). Uma maneira de visualizar essas tendências ao longo do tempo é um gráfico de calor em que o eixo x é o tempo e no eixo y estão as várias entidades.  



### Preparação {.unnumbered}

Começamos importando um conjunto de dados de relatórios diários da malária de muitos estabelecimentos. Os relatórios contêm uma data, província, distrito e contagens de malária. Consulte a página em [Baixar manual e dados](#data-used) para obter informações sobre como baixar esses dados. Abaixo estão as primeiras 30 linhas:  

```{r, echo=F}
facility_count_data <- rio::import(here::here("data", "malaria_facility_count_data.rds")) %>% 
  select(location_name, data_date, District, malaria_tot)
```

```{r, eval=F}
facility_count_data <- import("malaria_facility_count_data.rds")
```


```{r, echo=F}
DT::datatable(head(linelist, 30), rownames = FALSE, filter = "top", options = list (pageLength = 5, scrollX = T), class = 'white-space: nowrap')
```


#### Agregar e resumir {.unnumbered}

**O objetivo neste exemplo** é transformar as contagens diárias de casos de malária *total* dos estabelecimentos (visto na guia anterior) em *estatísticas resumidas semanais* de desempenho de relatórios das instalações - neste caso *a proporção de dias por semana que a instalação/estabelecimento relatou quaisquer dados*. Para este exemplo, mostraremos dados apenas para **Spring District**.  

Para conseguir isso, faremos as seguintes etapas de gerenciamento de dados:  

1) Filtre os dados conforme apropriado (por local, data)  
2) Crie uma coluna de semana usando `floor_date()` do pacote **lubridate**  
    + Esta função retorna a data de início da semana de uma determinada data, usando uma data de início especificada de cada semana (por exemplo, "Segundas")  
3) Os dados são agrupados pelas colunas "local" e "semana" para criar unidades de análise de "semana-estabelecimento"   
4) A função `resumir()` cria novas colunas para refletir as estatísticas de resumo por grupo de semana-estabelecimento:   
    + Número de dias por semana (7 - um valor estático)  
    + Número de relatórios recebidos da semana-estabelecimento (pode ser mais de 7!)   
    + Soma dos casos de malária relatados pela semana-estabelecimento (apenas por interesse)   
    + Número de dias *únicos* na semana-estabelecimento para os quais há dados relatados   
    + **Porcentagem dos 7 dias por semana-estabelecimento para os quais os dados foram relatados**  
5) Odata frame é unido com `right_join()` a uma lista abrangente de todas as combinações possíveis de semana-estabelecimento, para tornar o conjunto de dados completo.  A matriz de todas as combinações possíveis é criada aplicando `expand()` a essas duas colunas dodata frame, como está naquele momento na cadeia de *pipes* (representado por `.`). Como um `right_join()` é usado, todas as linhas no data frame `expand()` são mantidas e adicionadas a `agg_weeks` se necessário. Essas novas linhas aparecem com valores resumidos `NA` (ausentes).  


Abaixo, demonstramos passo a passo:  

```{r, mensagem = FALSE, aviso = FALSE}
# Crie um conjunto de dados de resumo semanal
agg_weeks <- facility_count_data%>% 
  
  # filtrar os dados conforme apropriado
  filter(
    District == "Spring",
    data_date < as.Date("2020-08-01")) 
```

Agora o conjunto de dados tem `nrow(agg_weeks)` linhas, quando anteriormente tinha `nrow(facility_count_data)`.  

Em seguida, criamos uma coluna `semana` refletindo a data de início da semana para cada registro. Isso é obtido com o pacote **lubridate** e a função `floor_date()`, que é definida como "semana" e para as semanas com início às segundas-feiras (dia 1 da semana - domingos seria 7). As linhas superiores são mostradas abaixo.  

```{r}
agg_weeks <- agg_weeks %>% 
  # Crie a coluna da semana a partir de data_date
  mutate(
    week = lubridate::floor_date(# criar uma nova coluna de semanas
      data_date,  # date
      unit = "week", # dá o início da semana
      week_start = 1)) # semanas para começar às segundas-feiras 
```

A nova coluna da semana pode ser vista na extremidade direita do quadro de dados  

```{r, echo=F}
DT::datatable(head(agg_weeks,30), rownames = FALSE, options = list(pageLength = 5, scrollX = T), class = 'white-space: nowrap')
```

Agora agrupamos os dados em semana-instalação e os resumimos para produzir estatísticas por semana-instalação.  Consulte a página em [Tabelas descritivas](#tables-descriptive) para dicas. O próprio agrupamento não altera o quadro de dados, mas impacta como as estatísticas de resumo subsequentes são calculadas.  

As linhas superiores são mostradas abaixo. Observe como as colunas mudaram completamente para refletir as estatísticas de resumo desejadas. Cada linha reflete uma semana-instalação.  

```{r, warning=F, message=F}
agg_weeks <- agg_weeks %>%   

  # Grupo em semana-estabelecimento
  group_by(location_name, week) %>%
  
  # Crie colunas de estatísticas de resumo nos dados agrupados
  summarise(
    n_days = 7, # 7 dias por semana           
    n_reports = dplyr::n(), # número de relatórios recebidos por semana (pode ser> 7)
    malaria_tot = sum (malaria_tot, na.rm = T), # total de casos de malária relatados
    n_days_reported = length(unique (data_date)), # número de dias únicos de relatórios por semana
    p_days_reported = round(100*(n_days_reported / n_days))) # por cento de relatórios de dias
```

```{r, echo=F}
DT::datatable(head(agg_weeks,30), rownames = FALSE, options = list(pageLength = 5, scrollX = T), class = 'white-space: nowrap')
```

Por fim, executamos o comando abaixo para garantir que TODAS as semanas-estabelecimento possíveis estejam presentes nos dados, mesmo que não existissem antes.  

Estamos usando um `right_join()` em si mesmo (o conjunto de dados é representado por "."), Mas foi expandido para incluir todas as combinações possíveis das colunas `semana` e `localização_nome`. Veja a documentação sobre a função `expand()` na página [Pivoteando Dados](#pivoting). Antes de executar este código, o conjunto de dados contém linhas `nrow(agg_weeks)`.   

```{r, warning=F, message=F}
# Crie um dataframe com todas as possibilidades de combinação semana-estabelecimento
expanded_weeks <- agg_weeks%>% 
  tidyr::expand(week) # expanda data frame para incluir todas as combinações possíveis de semana-estabelecimento
```

Aqui está `expanded_weeks`:  

```{r, echo=F}
DT::datatable(expanded_weeks, rownames = FALSE, options = list(pageLength = 5, scrollX = T), class = 'white-space: nowrap')
```

Antes de executar este código, `agg_weeks` contém linhas `nrow(agg_weeks)`.   

```{r}
# Use uma junção à direita com a lista expandida semana-estabelecimento para preencher as lacunas que faltam nos dados
agg_weeks <- agg_weeks %>%      
  right_join(expanded_weeks)%>% # Certifique-se de que todas as combinações possíveis de estabelecimento-semana apareçam nos dados
  mutate(p_days_reported = replace_na(p_days_reported, 0)) # converter valores ausentes para 0                           
```

Depois de executar este código, `agg_weeks` contém linhas `nrow(agg_weeks)`.   


<!-- ======================================================= -->
### Criar gráfico de calor {.unnumbered}


O `ggplot()` é feito usando `geom_tile()` do pacote **ggplot2**:  

* Semanas no eixo x são transformadas em datas, permitindo o uso de `scale_x_date()`  
* `location_name` no eixo y mostrará todos os nomes de estabelecimentos
* O `fill` é `p_days_reported`, o desempenho para aquela semana-estabelecimento(numérico)  
* `scale_fill_gradient()` é usado no preenchimento numérico, especificando cores para alto, baixo e `NA`  
* `scale_x_date()` é usado no eixo x especificando rótulos a cada 2 semanas e seu formato  
* Temas de exibição e rótulos podem ser ajustados conforme necessário




<!-- ======================================================= -->
### Básico {.unnumbered}  

Um gráfico de calor básico é produzido abaixo, usando as cores e escalas padrão. Como explicado acima, dentro de `aes()` para `geom_tile()` você deve fornecer uma coluna do eixo x, coluna do eixo y **e** uma coluna para o `fill =`. O preenchimento é o valor numérico apresentado como cor do bloco.  

```{r}
ggplot(data = agg_weeks)+
  geom_tile(
    aes(x = week,
        y = location_name,
        fill = p_days_reported))
```

### Gráfico limpo {.unnumbered}

Podemos fazer esse gráfico parecer melhor adicionando funções **ggplot2** adicionais, conforme mostrado abaixo. Veja a página em [dicas do ggplot](#ggplot-tips) para detalhes.  

```{r, message=FALSE, warning=FALSE}
ggplot(data = agg_weeks)+ 
  
  # mostrar dados como quadrados
  geom_tile(
    aes(x = week,
        y = location_name,
        fill = p_days_reported),      
    color = "white") + # linhas de grade brancas
  
  scale_fill_gradient(
    low = "orange",
    high = "darkgreen",
    na.value = "grey80")+
  
  # eixo de data
  scale_x_date(
    expand = c(0,0), # remove espaço extra nas laterais
    date_breaks = "2 weeks", # rótulos a cada 2 semanas
    date_labels = "%d\n%b") + # formato é dia após mês (\n em nova linha)
  
  # temas estéticos
  theme_minimal() + # fundo simplificado
  
  theme(
    legend.title = element_text(size=12, face="bold"),
    legend.text  = element_text(size=10, face="bold"),
    legend.key.height = grid::unit(1, "cm"), # altura da chave da legenda
    legend.key.width = grid::unit(0.6, "cm"), # largura da chave da legenda
    
    axis.text.x = element_text(size=12),              # axis text size
    axis.text.y = element_text(vjust = 0.2), # alinhamento do texto do eixo
    axis.ticks = element_line(size=0.4),               
    axis.title = element_text(size = 12, face = "bold"), # tamanho do título do eixo e negrito
    
    plot.title = element_text(hjust=0,size=14,face="bold"),  # title right-aligned, large, bold
    plot.caption = element_text(hjust = 0, face = "italic") # legenda alinhado à direita e itálico
    )+
  
  # rótulos de gráfico
  labs(x = "Semana",
       y = "Nome da instalação",
       fill = "Relatório de \ndesempenho(%)", # título da legenda, porque a legenda mostra preenchimento
       title = "Porcentagem de dias por semana em que a instalação relatou dados",
       subtitle = "Estabelecimentos de saúde distritais, maio-julho de 2020",
       caption = "semanas de 7 dias começando às segundas-feiras.")
```





<!-- ======================================================= -->
### Eixo y ordenado {.unnumbered}  

Atualmente, as instalações são ordenadas "alfanumericamente" de baixo para cima. Se você quiser ajustar a ordem das facilidades do eixo y, converta-as em fator de classe e forneça a ordem. Veja a página em [Fatores](#factors) para dicas.  

Uma vez que existem muitos recursos e não queremos escrevê-los todos, tentaremos outra abordagem - ordenar os recursos em um data frame e usar a coluna de nomes resultante como a ordem dos níveis do fator. Abaixo, a coluna `location_name` é convertida em um fator, e a ordem de seus níveis é definida com base no número total de dias de relatório arquivados pela instalação/estabelecimento ao longo de todo o período de tempo.  

Para fazer isso, criamos um data frame que representa o número total de relatórios por instalação, organizados em ordem crescente. Podemos usar este vetor para ordenar os níveis dos fatores no gráfico.   

```{r}
facility_order <- agg_weeks %>% 
  group_by(location_name)%>% 
  summarize(tot_reports = sum(n_days_reported, na.rm=T)) %>% 
  arrange(tot_reports) # ordem crescente
```

Veja o data frame abaixo:  

```{r, echo=F}
DT::datatable(case_ages, rownames = FALSE, options = list(pageLength = 5, scrollX = T), class = 'white-space: nowrap')
```




Agora use uma coluna do data frame acima (`facility_order$location_name`) para ser a ordem dos níveis de fator de `location_name` no quadro de dados `agg_weeks`:  

```{r, warning=F, message=F, echo=F}
# Carregar pacote 
pacman::p_load(forcats)
# criar fator e definir níveis manualmente
agg_weeks <- agg_weeks %>% 
  mutate(location_name = fct_relevel(
    location_name, facility_order$location_name)
    )
```

E agora os dados são adicionados a um gráfico novamente, com location_name sendo um fator ordenado:  

```{r, message=FALSE, warning=FALSE}
ggplot(data = agg_weeks)+ 
  # mostrar dados como quadrados
  geom_tile(
    aes(x = week,
        y = location_name,
        fill = p_days_reported),      
    color = "white") + # linhas de grade brancas
  
  scale_fill_gradient(
    low = "orange",
    high = "darkgreen",
    na.value = "grey80")+
  
  # eixo de data
  scale_x_date(
    expand = c(0,0), # remove espaço extra nas laterais
    date_breaks = "2 weeks", # rótulos a cada 2 semanas
    date_labels = "%d\n%b") + # formato é dia após mês (\n em nova linha)
  
  # temas estéticos
  theme_minimal() + # fundo simplificado
  
  theme(
    legend.title = element_text(size=12, face="bold"),
    legend.text  = element_text(size=10, face="bold"),
    legend.key.height = grid::unit(1, "cm"), # altura da chave da legenda
    legend.key.width = grid::unit(0.6, "cm"), # largura da chave da legenda
    
    axis.text.x = element_text(size=12),              # axis text size
    axis.text.y = element_text(vjust = 0.2), # alinhamento do texto do eixo
    axis.ticks = element_line(size=0.4),               
    axis.title = element_text(size = 12, face = "bold"), # tamanho do título do eixo e negrito
    
    plot.title = element_text(hjust=0,size=14,face="bold"),  # title right-aligned, large, bold
    plot.caption = element_text(hjust = 0, face = "italic") # legenda alinhado à direita e itálico
    )+
  
  # rótulos de gráfico
  labs(x = "Semana",
       y = "Nome da instalação",
       fill = "Relatório de \ndesempenho(%)", # título da legenda, porque a legenda mostra preenchimento
       title = "Porcentagem de dias por semana em que a instalação relatou dados",
       subtitle = "Estabelecimentos de saúde distritais, maio-julho de 2020",
       caption = "semanas de 7 dias começando às segundas-feiras.")
```





<!-- ======================================================= -->
#### Valores expostos {.unnumbered}  


Você pode adicionar uma camada `geom_text()` no topo dos quadrados, para exibir os números reais de cada quadrado. Esteja ciente de que isso pode não parecer muito elegante se você tiver muitos quadradinhos pequenos!  

O seguinte código foi adicionado: `geom_text(aes(label = p_days_reported))`. Isso adiciona texto a cada bloco. O texto exibido é o valor atribuído ao argumento `label =`, que neste caso foi definido para a mesma coluna numérica `p_days_reported` que também é usada para criar o gradiente de cor.  



  
```{r, message=FALSE, warning=FALSE}
ggplot(data = agg_weeks)+ 
  # mostrar dados como quadrados
  geom_tile(
    aes(x = week,
        y = location_name,
        fill = p_days_reported),      
    color = "white") + # linhas de grade brancas
  
  # texto
  geom_text(
    aes(
      x = week,
      y = location_name,
      label = p_days_reported)) + # adicionar texto no topo do quadrado
  
  # escala de preenchimento
  scale_fill_gradient(
    low = "orange",
    high = "darkgreen",
    na.value = "grey80")+
  
  # eixo de data
  scale_x_date(
    expand = c(0,0), # remove espaço extra nas laterais
    date_breaks = "2 weeks", # rótulos a cada 2 semanas
    date_labels = "%d\n%b") + # formato é dia após mês (\n em nova linha)
  
  # temas estéticos
  theme_minimal() + # fundo simplificado
  
  theme(
    legend.title = element_text(size=12, face="bold"),
    legend.text  = element_text(size=10, face="bold"),
    legend.key.height = grid::unit(1, "cm"), # altura da chave da legenda
    legend.key.width = grid::unit(0.6, "cm"), # largura da chave da legenda
    
    axis.text.x = element_text(size=12),              # axis text size
    axis.text.y = element_text(vjust = 0.2), # alinhamento do texto do eixo
    axis.ticks = element_line(size=0.4),               
    axis.title = element_text(size = 12, face = "bold"), # tamanho do título do eixo e negrito
    
    plot.title = element_text(hjust=0,size=14,face="bold"),  # title right-aligned, large, bold
    plot.caption = element_text(hjust = 0, face = "italic") # legenda alinhado à direita e itálico
    )+
  
  # rótulos de gráfico
  labs(x = "Semana",
       y = "Nome da instalação",
       fill = "Relatório de \ndesempenho(%)", # título da legenda, porque a legenda mostra preenchimento
       title = "Porcentagem de dias por semana em que a instalação relatou dados",
       subtitle = "Estabelecimentos de saúde distritais, maio-julho de 2020",
       caption = "semanas de 7 dias começando às segundas-feiras.")
```




<!-- ======================================================= -->
## Recursos {}

[scale_fill_gradient()](https://ggplot2.tidyverse.org/reference/scale_gradient.html)  

[Galeria de gráfico R - mapa de calor](https://ggplot2.tidyverse.org/reference/scale_gradient.html)  



```{r include=FALSE, cache=FALSE}

# clear workspace
rm(list = ls(all = TRUE))

# clear all packages except base
#lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))

# to ensure that tidyverse packages prevail
filter <- dplyr::filter
select <- dplyr::select
summarise <- dplyr::summarise
summary <- base::summary
incidence <- incidence2::incidence

#load core packages
pacman::p_load(
     rio,
     here,
     DT,
     stringr,
     lubridate,
     tidyverse
)

# import the cleaned ebola linelist
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

# import the count data - facility level
#count_data <- rio::import(here::here("data", "facility_count_data.rds"))

# Settings

options(scipen=1, digits=7)

# print only text (not code)
# library(knitr)
# opts_chunk$set(list(echo = FALSE, eval = FALSE))
```

<!--chapter:end:new_pages/heatmaps.Rmd-->


# Diagramas e gráficos {#diagrams}



```{r out.width = c('50%'), fig.show='hold', echo=F}
knitr::include_graphics(here::here("images", "flow_chart.png"))
knitr::include_graphics(here::here("images", "sankey_diagram.png"))
```


Esta página abrange o código para produzir:

* Diagramas de fluxo usando **DiagrammeR** e a linguagem DOT\
* Diagramas aluviais/Sankey\
* Cronogramas de eventos

    <!-- * DAGs (Directed Acyclic Graphs)   -->
    <!-- * GANTT charts   -->


    <!-- ======================================================= -->
## Preparação

### Carregar pacotes {.unnumbered}

Este chunk mostra o carregamento dos pacotes necessárias para as análises. Neste manual damos ênfase à função `p_load()` do pacote **pacman**, que instala o pacote se necessário *e* carrega-o para utilização. Outra opção é carregar os pacotes instalados utilizando `library()` a partir de **R base**. Ver a página em [Introdução ao R](#basics) para mais informações sobre pacotes R.

```{r}
pacman::p_load(
  DiagrammeR,     # para diagrama de fluxo
  networkD3,      # para diagrama aluvial/Sankey 
  tidyverse)      # exploração (gestão) e visualização de dados
```

### Importar dados {.unnumbered}

A maior parte do conteúdo desta página não requer um conjunto de dados. No entanto, na seção do diagrama de Sankey, usaremos a lista de casos de uma simulação de epidemia de Ebola. Se você deseja acompanhar esta parte, clique no link \<ahref='<https://github.com/appliedepi/epirhandbook_eng/raw/master/data/case_linelists/linelist_cleaned.rdsclass='download-button>'\> para baixar (como arquivo.rds). Importe os dados com `import()` função do pacote **rio** (ele lida com muitos tipos de arquivo como .xlsx, .csv, .rds - veja a página [Importar e exportar](#importing) para detalhes

```{r, echo=F}
# importar lista para o R
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))
```

```{r, eval=F}
# importar a lista de casos
linelist <- import("linelist_cleaned.rds")
```

Para ver as primeiras 50 linhas do banco utilize o codigo a seguir

```{r, message=FALSE, echo=F}
# exibir os dados em formato de tabela
DT::datatable(head(linelist, 50), rownames = FALSE, filter="top", options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```



<!-- ======================================================= -->
## Diagramas de fluxos

Pode-se usar o pacote R **DiagrammeR** para criar gráficos ou gráficos de fluxo. Esses podem ser estáticos, ou podem ser ajustados de forma dinâmica, a partir das mudanças ou alterações do conjunto de dados utilizado.

**Ferramentas**

A função `grViz()` é utilizada para criar um diagrama "Graphviz". Esta função aceita uma *entrada de cadeia de caracteres contendo instruções* para produção do diagrama. Dentro dessa cadeia, as instruções são escritas numa linguagem diferente, chamada [DOT](https://graphviz.org/doc/info/lang.html) - mas muito fácil de aprender a estrutura básica necessária.

**Estrutura básica**

1)  Abra as instruções `grViz("`
2)  Especifique a direcionalidade e o nome do gráfico, e abra colchetes, por exemplo `digraph my_flow_chart {`
3)  Declaração do gráfico (layout, direção de classificação)
4)  Declarações de nós (criar os nós)
5)  Declarações Bordas (fornece links entre os nós)
6)  Feche as instruções `}")`

### Exemplos simples {.unnumbered}

A seguir será usado dois exemplos simples

Um exemplo mínimo:

```{r out.width='50%'}
# plotar o mínimo
DiagrammeR::grViz("digraph {
  
graph[layout = dot, rankdir = LR]

a
b
c

a -> b -> c
}")
```

Um exemplo mais aplicado ao contexto de saúde pública:

```{r out.width='50%'}
grViz("                           # Todas as instruções estão dentro de uma grande cadeia de caracteres
digraph surveillance_diagram {    # 'digraph' significa 'grafico direcional', depois o nome do gráfico
  
  # declaração gráfica
  #################
  graph [layout = dot,
         rankdir = TB,
         overlap = true,
         fontsize = 10]
  
  # nos(nodea)
  #######
  node [shape = circle,           # forma (shape) = circulo
       fixedsize = true
       width = 1.3]               # Largura dos círculos
  
  Primary                         # nome dos nós
  Secondary
  Tertiary

  # edges
  #######
  Primary   -> Secondary [label = ' case transfer']
  Secondary -> Tertiary [label = ' case transfer']
}
")
```

### Sintaxe {.unnumbered}

**Sintaxe básica**

Os nomes de nós, ou declarações de borda, podem ser separados por espaços, ponto e vírgula ou novas linhas.

**Direção da classificação**

Um gráfico pode ser reorientado para se mover da esquerda para a direita, ajustando o `rankdir` argumento dentro da instrução do gráfico. O padrão é TB (da cigla em inglês *top-to-bottom* - de cima para baixo), mas pode ser LR (da cigla em inglês *left-to-right* - da esquerda para a direita), RL (da cigla em inglês *right-to-left* - da direita para esquerda) ou BT (da cigla em inglês *bottom-to-top* - baixo para cima).

**Nomes dos nós**

Os nomes dos nós podem ser palavras únicas, como no exemplo simples acima. Para usar nomes com várias palavras ou caracteres especiais (por exemplo, parênteses, travessões), coloque o nome do nó entre aspas simples (' '). Pode ser mais fácil ter um nome de nó curto e atribuir um rótulo *label*, como mostrado abaixo entre colchetes [ ]. Se você quiser ter uma nova linha no nome do nó, deve fazê-lo por meio de um rótulo - use `\n` rótulo do nó entre aspas simples, conforme mostrado abaixo.

**Subgrupos**\
Dentro das declarações de borda, podem ser criados subgrupos em ambos os lados da borda com chaves ({ }). A borda aplica-se então a todos os nós do parêntese - é uma abreviação.


**Layouts**\

* dot (set `rankdir` to either TB, LR, RL, BT, )
* neato\
* twopi\
* circo


**Nós - atributos editáveis**

* `label` (Rótulo - texto, entre aspas simples, se houver várias palavras)
* `fillcolor` (Cor do preenchimento - muitas cores possíveis)
* `fontcolor` (Cor da fonte - muitas cores possíveis)
* `alpha` (Alfa - transparência 0-1)
* `shape` (Formato - ellipse, oval, diamond, egg, plaintext, point, square, triangle)
* `style` (Estilo)
* `sides` (Tamanhos)
* `peripheries` (Margens)
* `fixedsize` (Tamanho fixo - h x w)
* `height` (Altura)
* `width` (Largura)
* `distortion` (Distorção)
* `penwidth` (Largura/espessura da linha - largura da borda da forma)
* `x` (deslocamento para a esquerda e direita - left/right
* `y` (ddeslocamento para cima e para baixo - up/down
* `fontname` (Nome da fonte)
* `fontsize` (Tamanho da fonte)
* `icon` (Ícone)


**Bordas - atributos editáveis**

* `arrowsize` (Tamanho da seta)
* `arrowhead` (Ponta da seta - normal, box, crow, curve, diamond, dot, inv, none, tee, vee)
* `arrowtail` (Base da seta)
* `dir` (Direção)
* `style` (Estilo "dashed", para tracejadas ...)
* `color` (Cor)
* `alpha` (Alfa)
* `headport` (texto na ponta da seta)
* `tailport` (texto na da base da seta)
* `fontname` (Nome da fonte)
* `fontsize` (Tamanho da fonte)
* `fontcolor`(Cor da fonte)
* `penwidth` (Largura da linha)
* `minlen` (Comprimento minímo)

**Nomes das cores**: usa-se valores hexadecimais ou os nomes de cores 'X11', consulte [detalhes X11](http://rich-iannone.github.io/DiagrammeR/graphviz_and_mermaid.html)


### Exemplos complexos {.unnumbered}

O exemplo abaixo, expande o diagrama de vigilância, adicionando nomes de nós complexos, de bordas agrupadas, com cores e estilo


```
    DiagrammeR::grViz("               # Todas as instruções estão dentro de uma grande cadeia de caracteres
    digraph surveillance_diagram {    # 'digraph' significa 'gráfico direcional', depois vem o nome do gráfico
      
      # Declaração gráfica
      #################
      graph [layout = dot,
             rankdir = TB,            # layout top-to-bottom (de cima para baixo)
             fontsize = 10]
      

      # nós (em círculos)
      #################
      node [shape = circle,           # shape = circulos
           fixedsize = true
           width = 1.3]                      
      
      Primary   [label = 'Primary\nFacility'] 
      Secondary [label = 'Secondary\nFacility'] 
      Tertiary  [label = 'Tertiary\nFacility'] 
      SC        [label = 'Surveillance\nCoordination',
                 fontcolor = darkgreen] 
      
      # Bordas/margens
      #######
      Primary   -> Secondary [label = ' case transfer',
                              fontcolor = red,
                              color = red]
      Secondary -> Tertiary [label = ' case transfer',
                              fontcolor = red,
                              color = red]
      
      # Bordas agrugapas
      {Primary Secondary Tertiary} -> SC [label = 'case reporting',
                                          fontcolor = darkgreen,
                                          color = darkgreen,
                                          style = dashed]
}
")
```


```{r out.width='50%', echo=F}
DiagrammeR::grViz("               # Todas as instruções estão dentro de uma grande cadeia de caracteres
digraph surveillance_diagram {    # 'digraph' significa 'gráfico direcional', depois vem o nome do gráfico
  
  # Demonstração gráfica
  #################
  graph [layout = dot,
         rankdir = TB,            # layout top-to-bottom (de cima para baixo)
         fontsize = 10]
  

  # nós (circles)
  #################
  node [shape = circle,           # shape = círculo
       fixedsize = true
       width = 1.3]                      
  
  Primary   [label = 'Primary\nFacility'] 
  Secondary [label = 'Secondary\nFacility'] 
  Tertiary  [label = 'Tertiary\nFacility'] 
  SC        [label = 'Surveillance\nCoordination',
             fontcolor = darkgreen] 
  
  # Bordas
  #######
  Primary   -> Secondary [label = 'case transfer',
                          fontcolor = red,
                          color = red]
  Secondary -> Tertiary [label = 'case transfer',
                          fontcolor = red,
                          color = red]
  
  # Borda agrupada
  {Primary Secondary Tertiary} -> SC [label = 'case reporting',
                                      fontcolor = darkgreen,
                                      color = darkgreen,
                                      style = dashed]
}
")
```

**Clusters de sub-graficos**

Para agrupar nós em caixas de clusters, coloque-os dentro do mesmo subgráfico nomeado (`subgraph name {}`). Para ter cada subgráfico identificado dentro de uma caixa delimitadora, comece o nome do subgráfico com "cluster", como exemplificado com as 4 caixas abaixo

```    
DiagrammeR::grViz("             # Todas as instruções estão dentro de uma grande cadeia de caracteres
digraph surveillance_diagram {  # 'digraph' significa 'gráfico direcional', depois vem o nome do gráfico
      
      # Demonstração gráfica
      #################
      graph [layout = dot,
             rankdir = TB,            
             overlap = true,
             fontsize = 10]
      

      # nós (círculos)
      #################
      node [shape = circle,                  # shape = círculos
           fixedsize = true
           width = 1.3]                      # largura dos círculos
      
      subgraph cluster_passive {
        Primary   [label = 'Primary\nFacility'] 
        Secondary [label = 'Secondary\nFacility'] 
        Tertiary  [label = 'Tertiary\nFacility'] 
        SC        [label = 'Surveillance\nCoordination',
                   fontcolor = darkgreen] 
      }
      
      # nós (boxes)
      ###############
      node [shape = box,                     # formas dos nós (Box - Caixa)
            fontname = Helvetica]            # fonte do texto no nó
      
      subgraph cluster_active {
        Active [label = 'Active\nSurveillance'] 
        HCF_active [label = 'HCF\nActive Search']
      }
      
      subgraph cluster_EBD {
        EBS [label = 'Event-Based\nSurveillance (EBS)'] 
        'Social Media'
        Radio
      }
      
      subgraph cluster_CBS {
        CBS [label = 'Community-Based\nSurveillance (CBS)']
        RECOs
      }

      
      # Bordas
      #######
      {Primary Secondary Tertiary} -> SC [label = 'case reporting']

      Primary   -> Secondary [label = 'case transfer',
                              fontcolor = red]
      Secondary -> Tertiary [label = 'case transfer',
                              fontcolor = red]
      
      HCF_active -> Active
      
      {'Social Media' Radio} -> EBS
      
      RECOs -> CBS
    }
    ")

```


```{r out.width='120%', echo=F}
DiagrammeR::grViz("             # Todas as instruções estão dentro de uma grande cadeia de caracteres
digraph surveillance_diagram {  # 'digraph' significa 'gráfico direcional', depois vem o nome do gráfico
  
  # Demonstração gráfica
  #################
  graph [layout = dot,
         rankdir = TB,            
         overlap = true,
         fontsize = 10]
  

  # nós (circulos)
  #################
  node [shape = circle,                  # shape = círculos
       fixedsize = true
       width = 1.3]                      # largura dos círculos
  
  subgraph cluster_passive {
    Primary   [label = 'Primary\nFacility'] 
    Secondary [label = 'Secondary\nFacility'] 
    Tertiary  [label = 'Tertiary\nFacility'] 
    SC        [label = 'Surveillance\nCoordination',
               fontcolor = darkgreen] 
  }
  
  # nós (boxes)
  ###############
  node [shape = box,                     # formas dos nós (Box - Caixa)
        fontname = Helvetica]            # fonte do texto no nó
  
  subgraph cluster_active {
    Active [label = 'Active\nSurveillance'] 
    HCF_active [label = 'HCF\nActive Search']
  }
  
  subgraph cluster_EBD {
    EBS [label = 'Event-Based\nSurveillance (EBS)'] 
    'Social Media'
    Radio
  }
  
  subgraph cluster_CBS {
    CBS [label = 'Community-Based\nSurveillance (CBS)']
    RECOs
  }

  
  # Bordas
  #######
  {Primary Secondary Tertiary} -> SC [label = 'case reporting']

  Primary   -> Secondary [label = 'case transfer',
                          fontcolor = red]
  Secondary -> Tertiary [label = 'case transfer',
                          fontcolor = red]
  
  HCF_active -> Active
  
  {'Social Media' Radio} -> EBS
  
  RECOs -> CBS
}
")

```


**Formas dos nós**

O exemplo abaixo, emprestado [deste tutoriall](http://rich-iannone.github.io/DiagrammeR/), mostra exemplos de formas de nós (nodes) aplicadas e uma abreviatura para conexões seriais de borda

```{r out.width='75%'}
DiagrammeR::grViz("digraph {

graph [layout = dot, rankdir = LR]

# definir os estilos globais dos nós. Podemos anulá-los em caixa, se essa for a opção escolhida.
node [shape = rectangle, style = filled, fillcolor = Linen]

data1 [label = 'Dataset 1', shape = folder, fillcolor = Beige]
data2 [label = 'Dataset 2', shape = folder, fillcolor = Beige]
process [label =  'Process \n Data']
statistical [label = 'Statistical \n Analysis']
results [label= 'Results']

# Definições de bordas com as identificações dos nós
{data1 data2}  -> process -> statistical -> results
}")
```


### Saídas {.unnumbered}

Como lidar e salvar resultados

* As saídas aparecerão no painel Viewer do RStudio, por padrão no canto inferior direito ao lado de Files, Plots, Packages e Help.
* Para exportar, você pode "Salvar como imagem" ou "Copiar para a área de transferência" do Visualizador. O gráfico se ajustará ao tamanho especificado.




### Figuras parametrizadas {.unnumbered}

Aqui temos uma citação do tutorial: <https://mikeyharper.uk/flowcharts-in-r-using-diagrammer/>

"Figuras parametrizadas: um grande benefício de projetar figuras dentro de R é que somos capazes de conectar as figuras diretamente com nossa análise, lendo os valores de R diretamente em nossos fluxogramas. Por exemplo, suponha que você tenha criado um processo de filtragem que remove valores após cada estágio de um processo, você pode ter uma figura mostrando o número de valores restantes no conjunto de dados após cada estágio de seu processo. Para fazer isso, você pode usar o símbolo *@@X* diretamente na figura e, em seguida, referir-se a ele no rodapé do gráfico usando [X]:, onde X é um índice numérico único."

Recomenda-se rever este  este tutorial se a parametrização é algo que você esteja interessado


<!-- Abaixo um exemplo deste tutorial. -->

<!-- ```{r, eval=F} -->
<!-- # Definir alguns dados de amostra -->
<!-- data <- list(a=1000, b=800, c=600, d=400) -->


<!-- DiagrammeR::grViz(" -->
<!-- digraph graph2 { -->

<!-- graph [layout = dot] -->

<!-- # definições dos nós com texto de etiqueta substituído -->
<!-- node [shape = rectangle, width = 4, fillcolor = Biege] -->
<!-- a [label = '@@1'] -->
<!-- b [label = '@@2'] -->
<!-- c [label = '@@3'] -->
<!-- d [label = '@@4'] -->

<!-- a -> b -> c -> d -->

<!-- } -->

<!-- [1]:  paste0('Raw Data (n = ', data$a, ')') -->
<!-- [2]: paste0('Remove Errors (n = ', data$b, ')') -->
<!-- [3]: paste0('Identify Potential Customers (n = ', data$c, ')') -->
<!-- [4]: paste0('Select Top Priorities (n = ', data$d, ')') -->
<!-- ") -->

<!-- ``` -->



<!-- ### CONSORT diagram  {.unnumbered} -->

<!-- ESTA SECÇÃO ESTÁ EM CONSTRUÇÃO -->

<!-- https://scriptsandstatistics.wordpress.com/2017/12/22/how-to-draw-a-consort-flow-diagram-using-r-and-graphviz/ -->

<!-- Nota acima está desactualizada via DiagrammeR -->




<!-- ======================================================= -->
## Diagramas Aluviais/Sankey

### Carregar pacotes {.unnumbered}

Esta parte de código mostra o carregamento de pacotes necessários para as análises. Neste manual enfatiza-se o `p_load()` do **pacman**, que instala o pacote se necessário e carrega-o para uso. Você também pode carregar pacotes instalados usando a biblioteca `library()` a partir da **base** R. Consulte a página sobre o [Introdução ao] (#basics) para obter mais informações sobre os pacotes R.

Carregou-se o pacote **networkD3** para a construção do diagrama, e o pacote **tidyverse** para as etapas de preparação dos dados.

```{r}
pacman::p_load(
  networkD3,
  tidyverse)
```

### Mapeamento do conjunto de dados {.unnumbered}

Mapeamento das ligações de um conjunto de dados. Abaixo é apresentado a utilização deste pacote sobre o caso `linelist`. O tutorial está disponível online para consulta. [Tutorial](https://www.r-graph-gallery.com/321-introduction-to-interactive-sankey-diagram-2.html).

Inicia-se obtendo a contagem de casos para cada categoria etária e a combinação por hospital. Os valores sem categoria de idade são removidos para maior clareza. Também foi realizado uma nova rotulagem (renomeadas), o `hospital` como fonte (source) e categorias de idades `age_cat` como alvo (target). Estes serão os dois lados do diagrama aluvial.

```{r}
# Contar por hospital e categoria de idade
links <- linelist %>% 
  drop_na(age_cat) %>% 
  select(hospital, age_cat) %>%
  count(hospital, age_cat) %>% 
  rename(source = hospital,
         target = age_cat)
```

O conjunto de dados tem agora este aspecto:

```{r message=FALSE, echo=F}
DT::datatable(links, rownames = FALSE, options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap')
```


Agora cria-se um Data Frame, de todos os nós do diagrama, sob a coluna `name`. Isso consiste em todos os valores para `hospital` e `age_cat`. Observe que garantiu-se que todos eles pertecem a *classe Character* antes de combiná-los. E ajustou-se as colunas de ID para que fossem números em vez de rótulos:

```{r}
# O nome único para os nós
nodes <- data.frame(
  name=c(as.character(links$source), as.character(links$target)) %>% 
    unique()
  )

nodes  # Exibir
```

Na sequência editou-se o Data Frame `links`, criado anteriormente com o `count()`. Duas novas colunas númericas então foram adicionadas `IDsource` e `IDtarget` que irão refletir/criar os linques entre os nós. Essas colunas manterão os números das linhas (posição) dos nós tanto de origem como o do destino. O 1 é subtraído, para que estes números de posição comecem em 0 (não em 1).

```{r}
# corresponder a números e  não a nomes
links$IDsource <- match(links$source, nodes$name)-1 
links$IDtarget <- match(links$target, nodes$name)-1
```

O conjunto de dados Links agora tem este aspecto:

```{r message=FALSE, echo=F}
DT::datatable(links, rownames = FALSE, options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap')
```

Agora, hora de traçar o diagrama Sankey com `sankeyNetwork()`. Você pode ler mais sobre cada argumento correndo `?sankeyNetwork` no console. Note que, a menos que defina `iterations = 0` a ordem dos seus nós pode não ser a esperada.

```{r}

# traçar o diagrama
######
p <- sankeyNetwork(
  Links = links,
  Nodes = nodes,
  Source = "IDsource",
  Target = "IDtarget",
  Value = "n",
  NodeID = "name",
  units = "TWh",
  fontSize = 12,
  nodeWidth = 30,
  iterations = 0)        # assegurar que a ordem dos nós é como nos dados
p
```



Aqui está um exemplo em que o resultado do paciente também é incluído. Na etapa de preparação dos dados, é necessário calcular as contagens de casos entre a idade e o hospital, e separadamente entre o hospital e o resultado, e depois ligar todas estas contagens juntamente com `bind_rows()`.

```{r}
# conta por hospital e categoria de idade
age_hosp_links <- linelist %>% 
  drop_na(age_cat) %>% 
  select(hospital, age_cat) %>%
  count(hospital, age_cat) %>% 
  rename(source = age_cat,          # renomear
         target = hospital)

hosp_out_links <- linelist %>% 
    drop_na(age_cat) %>% 
    select(hospital, outcome) %>% 
    count(hospital, outcome) %>% 
    rename(source = hospital,       # renomear
           target = outcome)

# combinar links
links <- bind_rows(age_hosp_links, hosp_out_links)

# Nome único para os nós
nodes <- data.frame(
  name=c(as.character(links$source), as.character(links$target)) %>% 
    unique()
  )

# Criar números de identificação
links$IDsource <- match(links$source, nodes$name)-1 
links$IDtarget <- match(links$target, nodes$name)-1

# exibir
######
p <- sankeyNetwork(Links = links,
                   Nodes = nodes,
                   Source = "IDsource",
                   Target = "IDtarget",
                   Value = "n",
                   NodeID = "name",
                   units = "TWh",
                   fontSize = 12,
                   nodeWidth = 30,
                   iterations = 0)
p

```


Consulte: <https://www.displayr.com/sankey-diagrams-r/>



<!-- ======================================================= -->
## Cronograma de eventos

Para fazer uma linha do tempo mostrando eventos específicos, você pode usar o pacote `vistime`.

Veja [vignette](https://cran.r-project.org/web/packages/vistime/vignettes/vistime-vignette.html#ex.-2-project-planning)

```{r}
# Carregando  o pacote
pacman::p_load(vistime,  # criando a linha do tempo
               plotly    # para visualização interativa
               )
```

```{r, echo=F}
# referencia: https://cran.r-project.org/web/packages/vistime/vignettes/vistime-vignette.html#ex.-2-project-planning

data <- read.csv(text="event, group, start, end, color
                       Event 1, Group A,2020-01-22,2020-01-22, #90caf9
                       Event 1, Group B,2020-01-23,2020-01-23, #90caf9
                       Event 1, Group C,2020-01-23,2020-01-23, #1565c0
                       Event 1, Group D,2020-01-25,2020-01-25, #f44336
                       Event 1, Group E,2020-01-25,2020-01-25, #90caf9
                       Event 1, Group F,2020-01-26,2020-01-26, #8d6e63
                       Event 1, Group G,2020-01-27,2020-01-27, #1565c0
                       Event 1, Group H,2020-01-27,2020-01-27, #90caf9
                       Event 1, Group I,2020-01-27,2020-01-27,#90a4ae
                       Event 2, Group A,2020-01-28,2020-01-28,#fc8d62
                       Event 2, Group C,2020-01-28,2020-01-28, #6a3d9a
                       Event 2, Group J,2020-01-28,2020-01-28, #90caf9
                       Event 2, Group J,2020-01-28,2020-01-28, #fc8d62
                       Event 2, Group J,2020-01-28,2020-01-28, #1565c0
")
```

Aqui está um conjunto de dados de eventos para começar

```{r message=FALSE, echo=F}
DT::datatable(data, rownames = FALSE, filter="top", options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap')
```



```{r}
p <- vistime(data)    # aplicar  o vistime

library(plotly)

# passo 1: transformar em lista
pp <- plotly_build(p)

# passo 2: Tamanho do marcador
for(i in 1:length(pp$x$data)){
  if(pp$x$data[[i]]$mode == "markers") pp$x$data[[i]]$marker$size <- 10
}

# passo 3: tamanho do texto
for(i in 1:length(pp$x$data)){
  if(pp$x$data[[i]]$mode == "text") pp$x$data[[i]]$textfont$size <- 10
}


# passo 4: posição do texto
for(i in 1:length(pp$x$data)){
  if(pp$x$data[[i]]$mode == "text") pp$x$data[[i]]$textposition <- "right"
}

#exibir
pp

```



<!-- ======================================================= -->
## Gráficos cíclicos direcionados - DAGs

Você pode construir um DAG manualmente usando o pacote **DiagammeR** e a linguagem DOT conforme descrito acima. 

Uma outra alternativa é usar os pacotes como **ggdag** e **daggity**

[Introdução DAGs ggdag vignette](https://cran.r-project.org/web/packages/ggdag/vignettes/intro-to-dags.html)

[Causal Inferência com dags no R](https://www.r-bloggers.com/2019/08/causal-inference-with-dags-in-r/#:~:text=In%20a%20DAG%20all%20the,for%20drawing%20and%20analyzing%20DAGs.)





<!-- ======================================================= -->
## Recursos



Muito do que foi dito acima em relação à linguagem DOT é adaptado do tutorial [nesta página](https://mikeyharper.uk/flowcharts-in-r-using-diagrammer/)

Outro tutorial mais aprofundado [tutorial on DiagammeR](http://rich-iannone.github.io/DiagrammeR/)

Consulte esta página [Sankey diagrams](https://www.displayr.com/sankey-diagrams-r/)




```{r include=FALSE, cache=FALSE}

# clear workspace
rm(list = ls(all = TRUE))

# clear all packages except base
#lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))

# to ensure that tidyverse packages prevail
filter <- dplyr::filter
select <- dplyr::select
summarise <- dplyr::summarise
summary <- base::summary
incidence <- incidence2::incidence

#load core packages
pacman::p_load(
     rio,
     here,
     DT,
     stringr,
     lubridate,
     tidyverse
)

# import the cleaned ebola linelist
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

# import the count data - facility level
#count_data <- rio::import(here::here("data", "facility_count_data.rds"))

# Settings

options(scipen=1, digits=7)

# print only text (not code)
# library(knitr)
# opts_chunk$set(list(echo = FALSE, eval = FALSE))
```

<!--chapter:end:new_pages/diagrams.Rmd-->


# Análise de Combinações {#combination-analysis}  

```{r echo=F, out.width= "75%", warning=F, message=F}
pacman::p_load(tidyverse,
               UpSetR,
               ggupset)

# Adiciona variável de novos sintomas à linelist, com valores "yes" (sim) e "no" (não)  aleatórios

linelist_sym <- linelist %>% 
  mutate(febre  = sample(c("yes", "no"), nrow(linelist), replace = T, prob = c(0.80, 0.20)),
         calafrio = sample(c("yes", "no"), nrow(linelist), replace = T, prob = c(0.20, 0.80)),
         tosse  = sample(c("yes", "no"), nrow(linelist), replace = T, prob = c(0.9, 0.15)),
         dores  = sample(c("yes", "no"), nrow(linelist), replace = T, prob = c(0.10, 0.90)),
         vômito = sample(c("yes", "no"), nrow(linelist), replace = T))

linelist_sym_2 <- linelist_sym %>% 
  
  # converte os valores  "yes" (sim) e "no" (não) para o nome do sintoma
  mutate(febre = case_when(febre == "yes" ~ 1,  # se era "yes", o novo valor é  febre
                           TRUE           ~ 0),   # se o valor for qualquer coisa diferente de "sim", o novo valor é  NA
         
         calafrio = case_when(calafrio == "yes" ~ 1, 
                           TRUE           ~ 0),
         
         tosse = case_when(tosse == "yes" ~ 1,
                           TRUE           ~ 0),
         
         dores = case_when(dores == "yes" ~ 1,
                           TRUE           ~ 0),
         
         vômito = case_when(vômito == "yes" ~ 1,
                           TRUE           ~ 0))

# Make the plot
UpSetR::upset(
  select(linelist_sym_2, febre, calafrio, tosse, dores, vômito),
  sets = c("febre", "calafrio", "tosse", "dores", "vômito"),
  order.by = "freq",
  sets.bar.color = c("blue", "red", "yellow", "darkgreen", "orange"), # cores opcionais
  empty.intersections = "on",
  # nsets = 3,
  number.angles = 0,
  point.size = 3.5,
  line.size = 2, 
  mainbar.y.label = "Combinação de Sintomas",
  sets.x.label = "Pacientes com Sintomas")

```



Essa análise gera um gráfico de frequência de diferentes **combinações** de valores e respostas. Nesse exemplo, geramos o gráfico da frequência casos exibiram várias combinações de sintomas.

Esse tipo de análise também é chamada de:

* **"Análise de respostas múltiplas"** (*"Multiple response analysis"*)
* **"Análise de Conjuntos"** (*"Sets analysis"*)  
* **"Análise de Combinações"** (*"Combinations analysis"*)  

No gráfico de exemplo acima são mostrados cinco sintomas. Abaixo de cada barra vertical há uma linha e pontos indicando a combinação de sintomas refletidos pela barra de cima. À esquerda, as barras horizontais refletem a frequência de cada sintoma individualmente.  

O primeiro método que mostraremos utiliza o pacote **ggupset**, e o segundo utiliza o pacote **UpSetR**. 




  



<!-- ======================================================= -->
## Preparação {  }

### Carregue os pacotes R {.unnumbered}  

O código abaixo realiza o carregamento dos pacotes necessários para a análise dos dados. Neste manual, enfatizamos o uso da função `p_load()`, do **pacman**, que instala os pacotes, caso não estejam instalados, *e* os carrega no R para utilização. Também é possível carregar pacotes instalados utilizando a função `library()`, do R **base**. Para mais informações sobre os pacotes do R, veja a página [Introdução ao R](#basics).   

```{r, warning=F, message=F}
pacman::p_load(
  tidyverse,     # manupulação de dados e visualização
  UpSetR,        # pacote especial para gráficos de combinção 
  ggupset)       # pacote especial para gráficos de combinção 
```

<!-- ======================================================= -->
### Importe os dados {.unnumbered}  


Para iniciar, importaremos a linelist dos casos de uma epidemia simulada do Ebola. Se você quiser acompanhar, <a href='https://github.com/appliedepi/epirhandbook_eng/raw/master/data/case_linelists/linelist_cleaned.rds' class='download-button'>clique para baixar a linelist "limpa"</a> (como um arquivo .rds). Importe os dados com a função `import()` do pacote **rio**  (a função suporta vários tipos de arquivo como .xlsx, .csv, .rds - cheque a página [Importar e exportar](#importing) para mais detalhes).  



```{r, echo=F}
# importe a lisnelist para o R
linelist_sym <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))
```

```{r, eval=F}
# importe a linelit de casos 
linelist_sym <- import("linelist_cleaned.rds")
```


Essa linelist inclui cinco variáveis do tipo "sim/não" ("sim/no") a respeito dos sintomas relatados. Nós vamos precisar transformar essas variáveis um pouco para poder utilizar o pacote **ggupset** para fazer nosso gráfico. Confira os dados (role para a direita para ver as variáveis dos sintomas).

```{r, message=FALSE, echo=F}
# mostre a linelist como uma tabela do tipo"data table"
DT::datatable(head(linelist_sym, 50), rownames = FALSE, filter="top", options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```



<!-- ======================================================= -->
### Reformate os valores {.unnumbered}  

Para estarmos alinhados com o formato esperado pelo pacote **ggupset** vamos converter os "sim" e "não" para o real nome do sintoma utilizando a função `case_when()` do pacote **dplyr**. Caso seja "não", definiremos o valor como vazio, então os valores serão `NA` ou o nome do sintoma.  
 

```{r, warning=F, message=F}
# criar uma coluna com todos os sintomas separados por ponto-vírgula 
linelist_sym_1 <- linelist_sym %>% 
  rename(febre=fever, # só traduzindo
         calafrio=chills,
         tosse=cough,
         dores=aches,
         vômito = vomit) %>% 
  # converte os valores de "yes" e "no" no nome do sintoma
  mutate(
    febre = case_when(
      febre == "yes" ~ "febre",          #se o valor era "sim", o novo valor é "febre"
      TRUE           ~ NA_character_),   # se o valor era diferente de "sim", o novo valor é NA
         
    calafrio = case_when(
       calafrio == "yes" ~ "calafrio",
       TRUE           ~ NA_character_),
    
    tosse = case_when(
      tosse == "yes" ~ "tosse",
      TRUE           ~ NA_character_),
         
    dores = case_when(
      dores == "yes" ~ "dores",
      TRUE           ~ NA_character_),
         
    vômito = case_when(
      vômito == "yes" ~ "vômito",
      TRUE           ~ NA_character_)
    )
```

Agora nós geramos duas colunas finais:  

1. Concatenando (unindo) todos os sintomas do paciente (uma coluna de caracteres)  
2. Convertendo a coluna acima para a classe *list*, para que ela possa ser passada ao pacote **ggupset** para fazer o gráfico.  

Veja a página de [Caracteres e strings](#characters-strings) para aprender mais sobre a função `unite()` do pacote **stringr**

```{r, warning=F, message=F}
linelist_sym_1 <- linelist_sym_1 %>% 
  unite(col = "all_symptoms",
        c(febre, calafrio, tosse, dores, vômito), 
        sep = "; ",
        remove = TRUE,
        na.rm = TRUE) %>% 
  mutate(
    # faz uma cópia de da coluna all_symptoms, mas na classe lista (que é requisito do ggupset() no próximo passo)
    all_symptoms_list = as.list(strsplit(all_symptoms, "; "))
    )
```

Veja a nova tabela. Note as duas colunas na extremidade da direta - os valores combinados, e a lista

```{r, echo=F, , warning=F, message=F}
DT::datatable(head(linelist_sym_1,50), rownames = FALSE, options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap')
```


<!-- ======================================================= -->
## **ggupset** {  }

Carregue o pacote

```{r}
pacman::p_load(ggupset)
```


Crie o gráfico. Vamos começar com um `ggplot()` e a função `geom_bar()`, mas depois vamos adicionar a função `scale_x_upset()` do pacote **ggupset**.  

```{r, warning=F, message=F}
ggplot(
  data = linelist_sym_1,
  mapping = aes(x = all_symptoms_list)) +
geom_bar() +
scale_x_upset(
  reverse = FALSE,
  n_intersections = 10,
  sets = c("febre", "calafrio", "tosse", "dores", "vômito"))+
labs(
  title = "Sinais e Sintomas",
  subtitle = "10 combinações mais frequentes de sinais e sintomas",
  caption = "Rodapé aqui",
  x = "Combinação de Sintomas",
  y = "Frequência na base de dados")

```
  
Mais informações sobre **ggupset** podem ser vistas [online](https://rdrr.io/cran/ggupset/man/scale_x_upset.html) ou offline na documentação do pacote na aba de Ajuda do seu  RStudio após digitar `?ggupset` no console.  


<!-- ======================================================= -->
## `UpSetR` {  }

O pacote **UpSetR** permite mais personalizações do gráfico, mas pode ser mais difícil de executar.


**Carregue o pacote**  

```{r}
pacman::p_load(UpSetR)
```

**Limpando os dados**  

Precisamos converter os valores dos sintomas da `linelist` para 1 / 0. 

```{r}
# Make using upSetR

linelist_sym_2 <- linelist_sym %>% 
  rename(febre=fever, # só traduzindo
         calafrio=chills,
         tosse=cough,
         dores=aches,
         vômito = vomit) %>% # só traduzindo
  # converte os valores de "sim" e "não" nos nomes dos sintomas
  mutate(
    febre = case_when(
      febre == "yes" ~ 1,    # se o valor antigo era "yes", então o novo valor é 1
      TRUE           ~ 0),   # se o valor era qualquer coisa diferente de "yes", o novo valor é 0
         
    calafrio = case_when(
      calafrio == "yes" ~ 1,
      TRUE           ~ 0),
         
    tosse = case_when(
      tosse == "yes" ~ 1,
      TRUE           ~ 0),
         
    dores = case_when(
      dores == "yes" ~ 1,
      TRUE           ~ 0),
         
    vômito = case_when(
      vômito == "yes" ~ 1,
      TRUE           ~ 0)
    )
```

Agora vamos fazer o gráfico utilizando a função `upset()` - utilizando apenas as colunas de sintomas. Você deve definir quais "conjuntos" serão comparados (passe os nomes das colunas de sintomas). Ou então, utilize `nsets = ` e `order.by = "freq"` para mostrar apenas as maiores X combinações.  

```{r, warning=F, message=F}

# Make the plot
UpSetR::upset(
  select(linelist_sym_2, febre, calafrio, tosse, dores, vômito),
  sets = c("febre", "calafrio", "tosse", "dores", "vômito"),
  order.by = "freq",
  sets.bar.color = c("blue", "red", "yellow", "darkgreen", "orange"), # cores opcionais
  empty.intersections = "on",
  # nsets = 3,
  number.angles = 0,
  point.size = 3.5,
  line.size = 2, 
  mainbar.y.label = "Combinação de sintomas",
  sets.x.label = "Pacientes com Sintomas")

```


<!-- ======================================================= -->
## Recursos {  }

[Página do github do UpSetR](https://github.com/hms-dbmi/UpSetR)  

[Uma versão em Shiny App - você pode fazer upload de seus próprios dados](https://gehlenborglab.shinyapps.io/upsetr/)  

[*documentação - difícil de interpretar](https://cran.r-project.org/web/packages/UpSetR/UpSetR.pdf)  


```{r include=FALSE, cache=FALSE}

# clear workspace
rm(list = ls(all = TRUE))

# clear all packages except base
#lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))

# to ensure that tidyverse packages prevail
filter <- dplyr::filter
select <- dplyr::select
summarise <- dplyr::summarise
summary <- base::summary
incidence <- incidence2::incidence

#load core packages
pacman::p_load(
     rio,
     here,
     DT,
     stringr,
     lubridate,
     tidyverse
)

# import the cleaned ebola linelist
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

# import the count data - facility level
#count_data <- rio::import(here::here("data", "facility_count_data.rds"))

# Settings

options(scipen=1, digits=7)

# print only text (not code)
# library(knitr)
# opts_chunk$set(list(echo = FALSE, eval = FALSE))
```

<!--chapter:end:new_pages/combination_analysis.Rmd-->


# Cadeias de Transmissão {#transmission-chains}


<!-- ======================================================= -->
## Visão Geral {  }

A ferramenta primária para manipular, analisar e visualizar dados de cadeias de transmissão e rastreamento de contatos é o pacote **epicontacts**, desenvolvido por membros do RECON. Experimente o gráfico interativo abaixo passando o mouse sobre os nós para ver mais informações,
arrastando para movê-los e clicando para destacar os casos subjacentes.

```{r out.width=c('25%', '25%'), fig.show='hold', echo=F}

## instala a versão de desenvolvimento do epicontacts
if (
  !"epicontacts" %in% rownames(installed.packages()) |
    packageVersion("epicontacts") != "1.2.0"
) {
  remotes::install_github("reconhub/epicontacts@timeline")
}

## instala e carrega os pacontes
pacman::p_load(tidyverse, epicontacts, magrittr, here, webshot, visNetwork)

## carrega a linelist
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds")) %>%
  filter(!duplicated(case_id))

## gera os contatos
contacts <- linelist %>%
  transmute(
    from = infector,
    to = case_id,
    location = sample(c("Community", "Nosocomial"), n(), TRUE),
    duration = sample.int(10, n(), TRUE)
  ) %>%
  drop_na(from)

## gera os epicontatos
epic <- epicontacts::make_epicontacts(
  linelist = linelist,
  contacts = contacts,
  directed = TRUE
)

## subset object
epic %<>% subset(
  node_attribute = list(date_onset = c(as.Date(c("2014-06-01", "2014-07-01"))))
) %>%
  thin("contacts")

## gera gráfico com as datas de início (onset) no eixo x
plot(
  epic,
  x_axis = "date_onset",
  label = FALSE,
  node_color = "outcome",
  col_pal = c(Death = "firebrick", Recover = "green"),
  node_shape = "gender",
  shapes = c(f = "female", m = "male"),
  unlinked_pos = "bottom",
  date_labels = "%b %d %Y",
  node_size = 35,
  font_size = 20,
  arrow_size = 0.5,
  height = 800,
  width = 700,
  edge_linetype = "location",
  legend_width = 0.15,
  highlight_downstream = TRUE,
  selector = FALSE
)
```

<!-- ======================================================= -->
## Preparação {  }

### Carregue os pacotes R {.unnumbered}

Primeiro carregue os pacotes padrão necessários para importar e manipular os dados. Neste manual, enfatizamos o uso da função `p_load()`, do *pacman**, que instala os pacotes, caso não estejam instalados, *e* os carrega no R para utilização. Também é possível carregar pacotes instalados utilizando a função `library()`, do R **base**. Para mais informações sobre os pacotes do R, veja a página [Introdução ao R](#basics).  
 
	
```{r transmission_chains_packages, eval = FALSE}
pacman::p_load(
  rio, # Importação de arquivos
  here, # Localizador de arquivos
  tidyverse, # Gerenciamento de dados + gráficos do ggplot2
  remotes # Instalação de pacotes do ggplot2
)
```
	
Você vai instalar a versão de desenvolvimento do **epicontacts**, que pode ser instalado diretamente do github utilizando a função `p_install_github()` do pacote **pacman**. Você precisa rodar esse comando abaixo apenas uma vez, e não todas as vezes que usar o pacote (daí em diante, você pode utilizar `p_load()` como de costume).

```{r transmission_chains_epicontacts_install, eval = FALSE}
pacman::p_install_gh("reconhub/epicontacts@timeline")
```


### Importando os dados {.unnumbered}

Vamos importar a base de dados de casos da epidemia simulada de Ebola. Se você quiser fazer download dos dados para seguir o passo a passo, veja as instruções na página [Baixando dados do manual](#data-used). A base será importada utilizando a função `import()` do pacote **rio**. Veja a página sobre [Importação e exportação](#importing) para aprender várias formas de importar dados.

```{r, echo=F}
# importa a linelist para o R
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))
```

```{r, eval=F}
# import the linelist
linelist <- import("linelist_cleaned.xlsx")
```

As primeiras 50 linhas da linelist são mostradas abaixo. As colunas de especial interesse são  `case_id`, `generation`, `infector`, e `source`.  

```{r, message=FALSE, echo=F}
# mostra os dados da linelist como uma tabela
DT::datatable(head(linelist, 50), rownames = FALSE, filter = "top", options = list(pageLength = 5, scrollX = T), class = "white-space: nowrap")
```


### Criando um objeto do tipo epicontacts {.unnumbered}

Depois, precisamos criar um objeto **epicontacts**, que requer dois tipos de dados:

* uma linelist documentando casos onde colunas são variáveis e colunas correspondem a casos únicos 
* uma lista de arestas definindo as ligações entre os casos com base em seus IDs únicos (esses podem ser contatos, eventos de transmissão, etc.) 

Como já temos uma linelist, precisamos apenas criar a lista de arestas entre os casos, mais especificamente entre seus IDs. Podemos extrair relações de transmição da linelist ao relacionar a coluna `infector` com a coluna `case_id`. Nesse ponto podemos também adicionar "propriedades das arestas",  que seriam quaisquer variáveis que descrevem a relação entre os dois casos, e não os casos em si. Para ilustrar, vamos adicionar uma variável `location` que descreve o local do evento de transmissão, e uma variável de duração, que descreve a duração do contato em dias.

No código abaixo, a função `transmute` do **dplyr** atua de forma semelhante à `mutate`, com a diferença que ela mantém apenas as colunas que especificamos na chamada. A função  `drop_na` vai filtrar quaisquer linhas cujas colunas especificadas tenham o valor `NA`; nesse caso, queremos manter apenas as linhas cujo transmissor _(infector)_ é conhecido.

```{r transmission_chains_create_contacts,}
## gera os contatos
contacts <- linelist %>%
  transmute(
    infector = infector,
    case_id = case_id,
    location = sample(c("Community", "Nosocomial"), n(), TRUE),
    duration = sample.int(10, n(), TRUE)
  ) %>%
  drop_na(infector)
```

Agora podemos criar o objeto **epicontacts** utilizando a função `make_epicontacts`. Precisamos especificar qual coluna da linelist aponta para o identificador único dos casos, bem como quais colunas dos contatos apontam para os identificadores únicos dos casos envolvidos em cada relação. Essas relações são direcionadas pois a transmissão vai **do** (_from_) transmissor **para** (_to_) o caso, então precisamos especificar os argumentos `from` e `to` de acordo. Nós também definimos o argumento `directed` _(direcionado)_ para `TRUE`, o que vai afetar as operações no futuro.

```{r transmission_chains_create_epicontacts,}
## gera o objeto epicontacts
epic <- make_epicontacts(
  linelist = linelist,
  contacts = contacts,
  id = "case_id",
  from = "infector",
  to = "case_id",
  directed = TRUE
)
```
Ao examinarmos objetos do tipo **epicontacts**, podemos ver que a coluna `case_id` na linelist foi renomeada para `id` e as colunas `case_id` e `infector` nos contatos foram renomeadas para `from` e `to`. Isso garante a consistência nas operações de manipulação, visualização e análise subsequentes.

```{r transmission_chains_view_epicontacts,}
## visualiza o objeto epicontacts
epic
```

<!-- ======================================================= -->
## Manipulando {  }

### Subsetting (subconjuntos) {.unnumbered}

O método `subset()` dos objetos `epicontacts` permitem, entre outras coisas, filtrar as redes baseadas nas propriedades da linelist ("node attributes") e da base de contatos ("edge attributes"). Esses valores devem ser passados como listas nomeadas ao argumento respectivo. Por exemplo, no código abaixo estamos mantendo apenas os casos masculinos da linelist que possuem data da infecção entre abril e julho de 2014 (datas são especificadas como intervalos), e relações de transmissão que ocorreram no hospital.

```{r transmission_chains_subset_nodes,}
sub_attributes <- subset(
  epic,
  node_attribute = list(
    gender = "m",
    date_infection = as.Date(c("2014-04-01", "2014-07-01"))
  ),
  edge_attribute = list(location = "Nosocomial")
)
sub_attributes
```

Podemos utilizar a função `thin` para filtrar a linelist para incluir casos encontrados nos contatos definindo o argumento `what = "linelist"`, ou filtrar os contatos para incluir casos enontrados na linelist definindo o argumento `what = "contacts"`. No código abaixo, vamos continuar filtrando o objeto epicontacts para manter apenas as relações de transmissão que envolvam os casos masculinos infectados entre abril e julho que já filtramos acima. Podemos ver que apenas duas relações de transmissão se encaixam nessa especificação.

```{r transmission_chains_thin,}
sub_attributes <- thin(sub_attributes, what = "contacts")
nrow(sub_attributes$contacts)
```

Além de gerar os subconjuntos a partir dos atributos dos nós _(node)_ e arestas _(edges)_, as redes podem ser aparadas para incluir apenas componentes que estejam conectados com certos nós. O argumento `cluster_id` recebe um vetor dos IDs dos casos e retorna uma linelist dos indivíduos que estão relacionados, direta ou indiretamente, a esses a IDs. No código abaixo, podemos ver que um total de 13 casos da linelist estão envolvididos nos agrupamentos _(clusters)_ contendo `2ae019` e `71577a`.

```{r}
sub_id <- subset(epic, cluster_id = c("2ae019", "71577a"))
nrow(sub_id$linelist)
```

O método `subset()` para os objetos `epicontacts` também permite filtrar pelo tamanho do agrupamento utilizando os argumentos `cs`, `cs_min` e `cs_max`. No código abaixo, estamos mantendo apenas os casos relacionados aos agrupamentos com 10 casos ou mais, e podemos ver que 271 casos da linelist estão envolvidos nesses agrupamentos.
    
```{r}   
sub_cs <- subset(epic, cs_min = 10)
nrow(sub_cs$linelist)
```

### Acessando os IDs {.unnumbered}

A função `get_id()` recupera informações dos IDs dos casos na base de dados, e pode ser parametrizada como: 

- **linelist**: IDs nos dados da linelist 
- **contacts**: IDs na base de contatos ("from" e "to" combinados)
- **from**: IDs na coluna "from" da base de contatos 
- **to** IDs na coluna "to" da base de contatos 
- **all**: IDs que aparecem em qualquer coluna e em qualquer base 
- **common**: IDs que aparecem tanto na linelist quanto nos contatos 
    
Por exemplo, quais são os primeiros dez IDs na base de contatos?
```{r transmission_chains_get_ids,}
contacts_ids <- get_id(epic, "contacts")
head(contacts_ids, n = 10)
```

Quantos IDs são encontratos tanto na linelist quanto nos contatos?
```{r transmission_chains_get_both,}
length(get_id(epic, "common"))
```

<!-- ======================================================= -->
## Visualização {  }

### Geração de gráficos básicos {.unnumbered}

Todas as visualizações dos objetos **epicontacts** são tratadas pela função `plot`. Primeiro vamos filtrar o objeto **epicontacts** para incluir apenas os casos com as datas de início em junho de 2014 utilizando a função `subset`, e então, incluir apenas os contatos relacionados a esses casos com a função `thin`.

```{r transmission_chains_basic_plot_sub,}
## subconjunto (subset) do objeto epicontacts
sub <- epic %>%
  subset(
    node_attribute = list(date_onset = c(as.Date(c("2014-06-30", "2014-06-01"))))
  ) %>%
  thin("contacts")
```

Podemos criar o gráfico básico e interativo de forma muito simples, como mostrado a seguir:

```{r transmission_chains_basic_plot,}
## cria o gráfico do objeto epicontacts
plot(
  sub,
  width = 700,
  height = 700
)
```

Você pode mover os nós arrastando-os, passar o mouse sobre eles para mais informações ou clicar neles para destacar os casos conectados.

Existem inúmeros argumentos para fazer modificações a esse gráfico. Iremos cobrir os principais aqui, mas confira a documentação via `?vis_epicontacts` (a função chamada ao utilizar `plot` em um objeto **epicontacts**) para ver uma descrição completa dos argumentos da função.

#### Visualizando atributos dos nós {.unnumbered}

Cor, forma e tamanho dos nós podem ser mapeados a uma dada coluna na linelist utilizando respectivamente os argumentos `node_color`, `node_shape` e `node_size`. Isso é parecido com a sintaxe da função `aes`, que você deve reconhecer, do pacote **ggplot2**. 

As cores, formas e tamanhos dos nós podem ser especificados da seguinte forma:

* **Cores:** via argumento `col_pal`, seja pelo fornecimento de uma lista nomeda, para especificação manual da cada cor, como fizemos abaixo, ou pelo fornecimento de uma função de paleta de cor tal como `colorRampPalette(c("black", "red", "orange"))`, que irá fornecer um degradê de cores entre as especificadas.

* **Formas:** passando uma lista nomeada ao argumento `shapes`, especificando uma forma para cada elemento único da coluna da linelist especificado pelo argumento `node_shape`. Veja `codeawesome` para as formas disponíveis.

* **Tamanho:** passando um intervalo de tamanhos dos nós para o argumento `size_range`.

Aqui vemos um exemplo, onde a cor representa o desfecho, forma representa o gênero e tamanho a idade:

```{r transmission_chains_node_attribute,}
plot(
  sub,
  node_color = "outcome",
  node_shape = "gender",
  node_size = "age",
  col_pal = c(Death = "firebrick", Recover = "green"),
  shapes = c(f = "female", m = "male"),
  size_range = c(40, 60),
  height = 700,
  width = 700
)
```

#### Visualizando atributos das arestas {.unnumbered}

Edge color, width and linetype can be mapped to a given column in the contacts dataframe using the `edge_color`, `edge_width` and `edge_linetype` arguments. The specific colors and widths of the edges can be specified as follows:
Cor, espessura e tipo de linha das arestas podem ser mepeados a uma dada coluna do dataframe de contatos utilizando, respectivamente, os argumentos `edge_color`, `edge_width` e `edge_linetype`. As cores e espessuras, em específico, podem ser passadas como abaixo:

* **Cores:** via argumento `edge_col_pal`, da mesma maneira utilizada para `col_pal`.

* **Espessuras** passando um intervalo de espessura para o argumento `width_range`.

Aqui temos um exemplo:

```{r transmission_chains_edge_attribute,}

plot(
  sub,
  node_color = "outcome",
  node_shape = "gender",
  node_size = "age",
  col_pal = c(Death = "firebrick", Recover = "green"),
  shapes = c(f = "female", m = "male"),
  size_range = c(40, 60),
  edge_color = "location",
  edge_linetype = "location",
  edge_width = "duration",
  edge_col_pal = c(Community = "orange", Nosocomial = "purple"),
  width_range = c(1, 3),
  height = 700,
  width = 700
)
```

### Eixo Temporal {.unnumbered}

Também podemos visualizar a rede ao longo do eixo temporal ao mapear o argumento `x_axis` a alguma coluna na linelist. No exemplo abaixo, o eixo x representa a data de início dos sintomas. Também especificamos o argumento `arrow_size` para nos certificar que as setas não serão muito grandes, e definimos `label = FALSE` para deixar a figura menos congestionada.

```{r transmission_chains_x_axis,}
plot(
  sub,
  x_axis = "date_onset",
  node_color = "outcome",
  col_pal = c(Death = "firebrick", Recover = "green"),
  arrow_size = 0.5,
  node_size = 13,
  label = FALSE,
  height = 700,
  width = 700
)
```

Existem inúmeros outros argumentos para especificar como essa rede pode ser visualizada ao longo de um eixo temporal, você pode conferi-los via `?vis_temporal_interactive` (a função que é chamada ao utilizar `plot` em um objeto **epicontacts** com o argumento `x_axis` especificado). Vamos ver algumas formas abaixo.

#### Especificando a forma de uma árvore de transmissão {.unnumbered}

As árvores de transmissão podem assumir duas formas principais, especificadas utilizando o argumento `network_shape`. A primeira é a forma `branching` como mostrada acima, em que uma aresta reta conecta dois nós. Essa é a representação mais intuitiva, no entanto pode resultar em arestas sobrepostas em uma rede densamente conectada. A segunda forma é um `rectangle`, que produz uma árvore que se parece com uma filogenia. Por exemplo:

```{r transmission_chains_rectangle,}
plot(
  sub,
  x_axis = "date_onset",
  network_shape = "rectangle",
  node_color = "outcome",
  col_pal = c(Death = "firebrick", Recover = "green"),
  arrow_size = 0.5,
  node_size = 13,
  label = FALSE,
  height = 700,
  width = 700
)
```

Cada caso pode ser associado a uma posição vertical única ao se modificar o argumento `position_dodge`. A posição dos casos não-conectados (ex: sem nenhum contato reportado) é especificada utilizando o argumento `unlinked_pos`.

```{r transmission_chains_dodge,}
plot(
  sub,
  x_axis = "date_onset",
  network_shape = "rectangle",
  node_color = "outcome",
  col_pal = c(Death = "firebrick", Recover = "green"),
  position_dodge = TRUE,
  unlinked_pos = "bottom",
  arrow_size = 0.5,
  node_size = 13,
  label = FALSE,
  height = 700,
  width = 700
)
```

A posição dos nós pais em relação aos nós filhos pode ser especificada utilizando o argumento `parent_pos`. A opção padrão é posicionar o nó pai no meio, porém ele pode ser posicionado na parte de baixo (`parent_pos = 'bottom'`) ou na parte de cima (`parent_pos = 'top'`).

```{r transmission_chains_parent_pos,}
plot(
  sub,
  x_axis = "date_onset",
  network_shape = "rectangle",
  node_color = "outcome",
  col_pal = c(Death = "firebrick", Recover = "green"),
  parent_pos = "top",
  arrow_size = 0.5,
  node_size = 13,
  label = FALSE,
  height = 700,
  width = 700
)
```

#### Salvando os gráficos e figuras {.unnumbered}

Você pode salvar um mapa como um arquivo html interativo e auto-contido com a função `visSave` do pacote **VisNetwork**:

```{r transmission_chains_save, eval=F}

plot(
  sub,
  x_axis = "date_onset",
  network_shape = "rectangle",
  node_color = "outcome",
  col_pal = c(Death = "firebrick", Recover = "green"),
  parent_pos = "top",
  arrow_size = 0.5,
  node_size = 13,
  label = FALSE,
  height = 700,
  width = 700
) %>%
  visNetwork::visSave("network.html")

```

Salvar essas saídas de redes como imagens, infelizmente não é tão simples e requer que você salve o arquivo como html e depois tire um screenshot do arquivo utilizando o pacote `webshot`. No código abaixo, estamos convertendo o arquivo html salvo acima em um PNG:

```{r transmission_chains_webshot, eval=F}
webshot(url = "network.html", file = "network.png")
```

### Linhas do Tempo {.unnumbered}

Você também pode incluir linhas do tempo à rede, que são representadas no eixo x de cada caso. Elas pode ser utilizadas para visualizar locais dos casos, por exemplo, ou o tempo até o desfecho. Para gerar uma linha do tempo, precisamos criar um data frame de pelo menos 3 colunas, indicadno o ID do caso, a data de início do "evento" e a data de fim do "evento". Você também pode adicionar inúmeras outras colunas que depois podem ser mapeadas para as propriedades de nós ou arestas da linha do tempo. No código abaixo,nós geramos uma linha do tempo que vai da data de início dos sintomas até a data do desfecho, e mantemos as variáveis do desfecho e hospital que utilizamos para definir a forma e cor do nó. Note que você pode ter, por caso, mais do que uma linha do dataframe ou evento na linha do tempo, por exemplo, se um caso for transferido entre multiplos hospitais.

```{r transmission_chains_create_timeline,}

## cria a linha do tempo
timeline <- linelist %>%
  transmute(
    id = case_id,
    start = date_onset,
    end = date_outcome,
    outcome = outcome,
    hospital = hospital
  )
```

Depois, passamos o elemento da linha do tempo para o argumento `timeline`. Podemos mapear os atributos da linha do tempo a cores, formas e tamanhos da mesma forma que definimos nas seções anteriores, exceto que temos _dois_ nós: os nós de início de fim de cada timeline, que possuem argumentos separados. Por exemplo, `tl_start_node_color` define qual a coluna da linha do tempo está mapeada à cor do nó de início, enquanto `tl_end_node_shape` define qual a coluna da linha do tempo está mapeada à forma do nó final. Também podemos mapear cor, tamanho, tipo de linha e rótulos à _aresta_ da linha do tempo via argumentos do tipo `tl_edge_*`. 

Confira `?vis_temporal_interactive` (a função chamada ao criar um gráfico de um objeto epicontacts) para documentação detalhada dos argumentos. Cada argumento está anotado no código abaixo:

```{r transmission_chains_vis_timeline,}

## define as formas
shapes <- c(
  f = "female",
  m = "male",
  Death = "user-times",
  Recover = "heartbeat",
  "NA" = "question-circle"
)

## define cores
colours <- c(
  Death = "firebrick",
  Recover = "green",
  "NA" = "grey"
)

## gera o gráfico
plot(
  sub,
  ## mapeia a coordenada x à data de início
  x_axis = "date_onset",
  ## rede na forma retangular
  network_shape = "rectangle",
  ## mapeia a forma dos nós à coluna de gênero
  node_shape = "gender",
  ## não queremos mapear o cor do nó a nenhuma coluna - esse argumento é importante
  ## pois o padrão é mapear ao id do nó, o que vai bagunçar o esquema de cores
  node_color = NULL,
  ## define o tamanho do nó dos casos como 30 (como não é uma característica dos dados, node_size não
  ## é mapeado para nenhum coluna, mas interpretado como o real tamanho do nó)
  node_size = 30,
  ## define a espessura da relação como 4 (como não é uma característica dos dados, edge_width não
  ## é mapeado para nenhum coluna, mas interpretado como a real espessura da aresta)
  edge_width = 4,
  ## passa o objeto da linha do tempo
  timeline = timeline,
  ## mapeia a forma do nó final à coluna de desfecho do objeto da linha do tempo
  tl_end_node_shape = "outcome",
  ## define o tamanho do nó final como 15 (como não é uma característica dos dados, esse
  ## argumento não é mapeado para nenhum coluna, mas interpretado como o real
  ## tamanho do nó)
  tl_end_node_size = 15,
  ## mapeia a cor da aresta da linha do tempo à coluna hospital
  tl_edge_color = "hospital",
  ## define a espessura da aresta da linha do tempo como 2 (como não é uma característica dos dados, esse
  ## argumento não é mapeado para nenhum coluna, mas interpretado como a real
  ## espessura da aresta)
  tl_edge_width = 2,
  ## mapeia os rótulos das arestas à variável hospital
  tl_edge_label = "hospital",
  ## especifica a forma para cada atributo dos nós (definido acima)
  shapes = shapes,
  ## especifica a paleta de cor (definido acima)
  col_pal = colours,
  ## define o tamanho da seta para 0.5
  arrow_size = 0.5,
  ## utiliza as duas colunas na legenda
  legend_ncol = 2,
  ## define o tamanho da fonte
  font_size = 15,
  ## define a o formato da data
  date_labels = c("%d %b %Y"),
  ## não exibe os rótulos de ID abaixo dos nós
  label = FALSE,
  ## especifica a altura
  height = 1000,
  ## especifica a espessura
  width = 1200,
  ## garante que cada nó dos casos tenha um coordenada y única - isso é muito importante
  ## para linhas do tempo, caso contrário você terá linhas do tempo sobrepostas para
  ## casos diferentes
  position_dodge = TRUE
)
```

<!-- ======================================================= -->
## Análise {  }

### Resumindo {.unnumbered}

Podemos ter uma visão gerão de algumas propriedades da rede utilizando a função `summary`.

```{r transmission_chains_summarise_epicontacts,}
## resume o objeto epicontacts
summary(epic)
```

Por exemplo, podemos ver que apenas 57% dos contatos possuem ambos os casos na linelist; isso significa que nós não temos dados da linelist sobre um número significativo de casos envolvidos nessas cadeias de transmissão.

### Características por pares {.unnumbered}

A função `get_pairwise()` permite o processamento de variáveis na linelist de acordo com cada par na base de dados de contatos. Para o seguinte exemplo, a data de início da doença é extraída da linelist para calcular a diferença entre  a data de início para cada par. O valor produzido a partir dessa comparação representa o **intervalo serial (si)**

```{r transmission_chains_pairwise,}
si <- get_pairwise(epic, "date_onset")
summary(si)
tibble(si = si) %>%
  ggplot(aes(si)) +
  geom_histogram() +
  labs(
    x = "Serial interval",
    y = "Frequency"
  )
```

A `get_pairwise()` vai interpretar a classe da coluna sendo utilizada para comparação e vai ajustar o seu método de comparar os valores de acordo. Para números e datas (como **si** do exemplo acima), a função vai subtrair os valores. Quando aplicado a colunas de caracteres ou categóricas, `get_pairwise()` vai colar _(paste)_ os valores. Pelo fato da função também permitir processamentos arbitrários (veja o argumento "f"), essas combinações discretas podem ser facilmente tabuladas e analisadas.
    
```{r transmission_chains_pairwise_2,}
head(get_pairwise(epic, "gender"), n = 10)
get_pairwise(epic, "gender", f = table)
fisher.test(get_pairwise(epic, "gender", f = table))
```

Aqui observamos uma associação significativa entra as relações de transmissão e gênero.

### Identificando agrupamentoss {.unnumbered}

A função `get_clusters()` pode ser utilizada para identificar componentes conectados em um objeto `epicontacts`. Primeiro, utilizamos para recuperar um `data.frame` contendo a informação dos agrupamentos:

```{r transmission_chains_cluster,}
clust <- get_clusters(epic, output = "data.frame")
table(clust$cluster_size)
ggplot(clust, aes(cluster_size)) +
  geom_bar() +
  labs(
    x = "Cluster size",
    y = "Frequency"
  )
```

Let us look at the largest clusters. For this, we add cluster information to the `epicontacts` object and then subset it to keep only the largest clusters:
Vamos dar uma olhada nos maiores agrupamentos. Para isso, vamos adicionar informações de agrupamentos ao objeto `epicontacts` e depois fazer um subconjunto para manter apenas os maiores agrupamentos:

```{r transmission_chains_cluster_2,}
epic <- get_clusters(epic)
max_size <- max(epic$linelist$cluster_size)
plot(subset(epic, cs = max_size))
```

### Calculando graus {.unnumbered}

O grau de um nó corresponde ao seu número de arestas ou conexões com outros nós. `get_degree()` disponibiliza um método fácil para calcular esse valor para redes de `epicontacts`. Um grau alto nesse contexo indica um indivíduo que esteve em contato com vários outros. O argumento `type` indica que nós queremos contar tanto o grau de entrada (in-degree) quanto o de saída (out-degree) e o argumento `only_linelist` indica que queremos calcular apenas o grau para os casos que estejam na linelist.

```{r transmission_chains_degree,}
deg_both <- get_degree(epic, type = "both", only_linelist = TRUE)
```

Quais os primeiros 10 indivíduos com a maior quantidade de contatos?

```{r}
head(sort(deg_both, decreasing = TRUE), 10)
```

Qual o número médio de contatos?

```{r}
mean(deg_both)
```

<!-- ======================================================= -->
## Recursos {  }

A 
[página epicontacts](https://www.repidemicsconsortium.org/epicontacts/index.html)
disponibiliza uma visão geral das funções do pacote e inclui algumas outras vignettes mais aprofundadas.

A [páginad do github](http://github.com/reconhub/epicontacts) pode ser utilizada para registrar 
problemas (issues) e solicitar funcionalidades.
```{r include=FALSE, cache=FALSE}

# clear workspace
rm(list = ls(all = TRUE))

# clear all packages except base
#lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))

# to ensure that tidyverse packages prevail
filter <- dplyr::filter
select <- dplyr::select
summarise <- dplyr::summarise
summary <- base::summary
incidence <- incidence2::incidence

#load core packages
pacman::p_load(
     rio,
     here,
     DT,
     stringr,
     lubridate,
     tidyverse
)

# import the cleaned ebola linelist
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

# import the count data - facility level
#count_data <- rio::import(here::here("data", "facility_count_data.rds"))

# Settings

options(scipen=1, digits=7)

# print only text (not code)
# library(knitr)
# opts_chunk$set(list(echo = FALSE, eval = FALSE))
```

<!--chapter:end:new_pages/transmission_chains.Rmd-->


# Árvores filogenéticas {#phylogenetic-trees}  


<!-- ======================================================= -->

## Visão Geral {}


**Árvores filogenéticas** são utilizados para visualizar e descrever a relação e evolução dos organismos com base no sequenciamento de seu código genético.   

Elas podem ser construídos a partir de seqüências genéticas usando métodos baseados na distância (como o método de união de vizinhos) ou métodos baseados em caracteres (como o método de máxima verossimilhança e o método Baysiano de Monte Carlo via Cadeias de Markov ). O sequenciamento de próxima geração (NGS) tornou-se mais acessível e está se tornando mais amplamente utilizado na saúde pública para descrever patógenos causadores de doenças infecciosas. Os dispositivos portáteis de seqüenciamento diminuem o tempo de retorno e mantêm promessas de disponibilizar dados para o apoio à investigação de surtos em tempo real. Os dados da NGS podem ser usados para identificar a origem ou fonte de uma variante de surto e sua propagação, bem como determinar a presença de genes de resistência antimicrobiana. Para visualizar a relação genética entre as amostras, é construída uma árvore filogenética.  

Nesta página aprenderemos como utilizar o pacote **ggtree**, que permite a visualização combinada de árvores filogenéticas com dados adicionais de amostras sob a forma de um *data frame*. Isto nos permitirá observar padrões e melhorar a compreensão da dinâmica do surto.

```{r, phylogenetic_trees_overview_graph, out.width=c('80%'), fig.align='center', fig.show='hold', echo = FALSE}

pacman::p_load(here, ggplot2, dplyr, ape, ggtree, treeio, ggnewscale)

tree <- ape::read.tree(here::here("data", "phylo", "Shigella_tree.txt"))

sample_data <- read.csv(here::here("data","phylo", "sample_data_Shigella_tree.csv"),sep=",", na.strings=c("NA"), head = TRUE, stringsAsFactors=F)


ggtree(tree, layout="circular", branch.length='none') %<+% sample_data + # o operador %<+% é usado para unir o seu dataframe com os dados amostrados para a árvore
  aes(color=I(Belgium))+ # colore os ramos de acordo com a variável no seu data frame       
  scale_color_manual(name = "Sample Origin", # nome do seu esquema de cores (como aparecerá na leganda)          
                    breaks = c("Yes", "No"), # as diferentes opções na sua variável
                   labels = c("NRCSS Belgium", "Other"), # como você quer que as diferentes opções sejam nomeadas na sua leganda, permite formatação
                 values= c("blue", "black"), # a cor que você quer que cada variável tenha          
                 na.value = "black") + # coloque os valores faltantes (NA) como preto também
  new_scale_color()+ # permite que se adicione um outro esquema de cores para um outra variável
     geom_tippoint(aes(color=Continent), size=1.5)+ # coloque a ponta de acordo com o continente, você pode mudar a forma adicionando "shape"
scale_color_brewer(name = "Continent",  #nome do sei esquema de cores (assim aparecerá na legenada) 
                       palette="Set1", #nós escolhemos uma paleta de cores de acordo com o pacote brewer
                   na.value="grey")+ # para valores NA escolhemos a cor cinza 
  theme(legend.position= "bottom")

```

<!-- ======================================================= -->

## Preparação {}

### Carregar pacotes {.unnumbered}  

Este trecho de código mostra o carregamento dos pacotes necessárias. Neste manual, enfatizamos `p_load()` de **pacman**, que instala o pacote se necessário *e* o carrega para utilização. Você também pode carregar os pacotes instalados com `library()` do R **base**. Veja a página em [Introdução ao R](#basics) para mais informações sobre os pacotes R.

```{r, phylogenetic_trees_loading_packages}
pacman::p_load(
  rio,             # importar/exportar
  here,            # caminhos relativos dos arquivos
  tidyverse,       # manipulações e visualizações gerais de dados
  ape,             # para importar e exportar dados de árvores filogenéticas
  ggtree,          # para visualizar dados de árvores filogenéticas 
  treeio,          # para visualizar dados de árvores filogenéticas 
  ggnewscale)      # adicionar camadas de esquema de cores 

```

### Importar dados {.unnumbered}  

Os dados para esta página podem ser baixados com as instruções na página [Baixar manual e dados](#data-used).  

Há vários formatos diferentes nos quais uma árvore filogenética pode ser armazenada (por exemplo, Newick, NEXUS, Phylip). Um muito comum é o formato de arquivo Newick (.nwk), que é o padrão para representar árvores em formato legível por computador. Isto significa que uma árvore inteira pode ser expressa em formato de string como "((t2:0.04,t1:0.34):0.89,(t5:0.37,(t4:0.03,t3:0.67):0.9):0.59); ", listando todos os nós e ápices e a relação (comprimento do ramo) entre si. 

Nota: É importante entender que o arquivo de árvore filogenética em si não contém dados de sequenciamento, mas é meramente o resultado das distâncias genéticas entre as seqüências. Portanto, não podemos extrair dados de seqüenciamento de um arquivo de árvore.

Primeiro, utilizamos a função `read.tree()` do pacote **ape** para importar um arquivo de árvore filogenética Newick em formato .txt, e armazená-lo em uma lista de objetos da classe "phylo". Se necessário, utilize a função `here()` do pacote **here** para especificar o caminho relativo do arquivo.

Nota: Neste caso, a árvore newick é salva como um arquivo .txt para facilitar o manuseio e o download do Github.


```{r, echo=F}
tree <- ape::read.tree(here::here("data", "phylo", "Shigella_tree.txt"))
```


```{r, echo=T, eval=F}
tree <- ape::read.tree("Shigella_tree.txt")
```

Inspecionamos nosso objeto árvore e vemos que ele contém 299 ápices/pontas (ou amostras) e 236 nós.  

```{r}
tree
```

Segundo, importamos uma tabela armazenada como um arquivo .csv com informações adicionais para cada amostra sequenciada, como sexo, país de origem e atributos de resistência antimicrobiana, utilizando a função `import()` do pacote **rio**:

```{r, echo=F}
sample_data <- import(here("data", "phylo", "sample_data_Shigella_tree.csv"))
```

```{r, echo=T, eval=F}
sample_data <- import("sample_data_Shigella_tree.csv")
```

Abaixo estão as primeiras 50 linhas de observação dos dados:  

```{r message=FALSE, echo=F}
DT::datatable(head(sample_data,50), rownames = FALSE, options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```

### Limpar e inspecionar {.unnumbered}  

Nós limpamos e inspecionamos nossos dados: A fim de atribuir os dados da amostra correta à árvore filogenética, os valores na coluna `Sample_ID` no data frame `sample_data` precisam corresponder aos valores `tip.labels` do arquivo `tree`: 

Verificamos a formatação das `tip.labels` no arquivo `tree` observando as primeiras 6 entradas utilizando com `head()` do R **base**.

```{r, phylogenetic_trees_inspect_sampledata}
head(tree$tip.label) 
```

Também nos certificamos de que a primeira coluna em nosso data frame "Sample_data" seja "Sample_ID". Olhamos os nomes das colunas de nosso data frame utilizando `colnames()` dm R **base**.

```{r}
colnames(sample_data)   
```

Olhamos para os `Sample_IDs` no data frame para ter certeza de que a formatação é a mesma do que na `tip.label` (por exemplo, todas as letras são maiúsculas, sem sublinhados extras `_' entre letras e números, etc.)

```{r}
head(sample_data$Sample_ID) # novamente inspecionamos os primeiros 6 usando head()
```

Também podemos comparar se todas as amostras estão presentes no arquivo "tree" e vice-versa, gerando um vetor lógico de VERDADEIRO ou FALSO onde elas coincidem ou não. Estas não são impressas aqui, por simplicidade.  

```{r, eval=F}
sample_data$Sample_ID %in% tree$tip.label

tree$tip.label %in% sample_data$Sample_ID
```

Podemos usar estes vetores para mostrar qualquer identificação de amostra que não esteja na árvore (não há nenhuma).

```{r}
sample_data$Sample_ID[!tree$tip.label %in% sample_data$Sample_ID]
```

Após a inspeção, podemos ver que o formato do `Sample_ID` no data frame corresponde ao formato dos nomes das amostras nas `tip.labels`. Estas não precisam ser classificadas na mesma ordem para serem combinadas.

Estamos prontos para ir!



<!-- ======================================================= -->

## Visualização simples da árvore {}


### Diferente layouts para a árvore {.unnumbered}  

**ggtree*** oferece muitos formatos de layout diferentes e alguns podem ser mais adequados para seu propósito específico do que outros. Abaixo estão algumas demonstrações. Para outras opções, veja este [livro online](http://yulab-smu.top/treedata-book/chapter4.html).  

Aqui estão alguns exemplos de layouts de árvores:

```{r, phylogenetic_trees_example_formats, out.width=c('50%'), fig.show='hold'}

ggtree(tree)                                            # árvore linear simples
ggtree(tree,  branch.length = "none")                   # árvore linear simples com todas as pontas alinhadas
ggtree(tree, layout="circular")                         # árvore circular simples
ggtree(tree, layout="circular", branch.length = "none") # árvore circular simples com todas as pontas alinhadas

```

### Árvore simples com dados de amostras {.unnumbered}  

O operador **%<+%*** é utilizado para conectar o data frame `sample_data` ao arquivo `tree`.
A anotação mais fácil de sua árvore é a adição dos nomes das amostras nas pontas, assim como a coloração dos pontos da ponta e, se desejado, dos ramos:

Aqui está um exemplo de uma árvore circular: 

```{r, phylogenetic_trees_adding_sampledata, fig.align='center', warning=F, message=F}

ggtree(tree, layout = "circular", branch.length = 'none') %<+% sample_data + # %<+% unifica o datarframe com os dados de amostras à arvore
  aes(color = (Belgium))+                       # colore os ramos de acordo com a variável no seu dataframe c
  scale_color_manual(
    name = "Sample Origin",                      # nome do seu esquema de cotes (irá aparecer assim na legenda) 
    breaks = c("Yes", "No"),                     # as diferentes opções na sua variável
    labels = c("NRCSS Belgium", "Other"),        # como você quer que as diferentes opções sejam nomeadas na sua legenda, permite formatação 
    values = c("blue", "black"),                  # a cor que você atribuir à variável
    na.value = "black")+                        # colore valores NA como preto também
  new_scale_color()+                             # permite adicionar um novo esquema de cores para uma nova variável
    geom_tippoint(
      mapping = aes(color = Continent),          # cor das pontas por continente. Você pode mudar o formato adicionando "shape = "
      size = 1.5)+                               # define o tamanho do ponto na ponta 
  scale_color_brewer(
    name = "Continent",                    # nome do seu esquema de cotes (irá aparecer assim na legenda) 
    palette = "Set1",                      #  escolhemos uma paleta de cores do pacote Brewer 
    na.value = "grey")+                    # para valores NA escolhemos o cinza 
  geom_tiplab(                             # adiciona o nome da amostra para a ponta do ramo 
    color = 'black',                       # (adiciona quantas linhas de texto desejar, mas talvez precise ajustar o valor de partida para coloca-los proximos uns aos outros. 
    offset = 1,
    size = 1,
    geom = "text",
    #align = TRUE
    )+
  ggtitle("Árvore filogenética de Shigella sonnei")+       # título do seu gráfico
  theme(
    axis.title.x = element_blank(), # remove título de eixo x
    axis.title.y = element_blank(), # remove título de eixo y
    legend.title = element_text(    # define o tamanho da fonte e formata a o título da legenda
      face = "bold",
      size = 12),   
    legend.text=element_text(       # define o tamanho da fonte e formata o texto da legenda
      face = "bold",
      size = 10),  
    plot.title = element_text(      # define o tamanho da fonte e formata o título do gráfico
      size = 12,
      face = "bold"),  
    legend.position = "bottom",     # define a posição da legenda
    legend.box = "vertical",        # define o posicionamento da legenda
    legend.margin = margin())   
```

Você pode exportar seu gráfico de árvore com `ggsave()` como qualquer outro objeto ggplot'. Escrito desta forma, `ggsave()` salva a última imagem produzida para o caminho do arquivo que você especificar. Lembre-se de que você pode utilizar `here()` e caminhos de arquivo relativos para salvar facilmente em subpastas, etc.  

```{r, eval=F}
ggsave("example_tree_circular_1.png", width = 12, height = 14)

```


<!-- ======================================================= -->

## Manipulação da árvore {}

Às vezes você pode ter uma árvore filogenética muito grande e só está interessado em uma parte da árvore. Por exemplo, se você produziu uma árvore incluindo amostras históricas ou internacionais para obter uma grande visão geral de onde seu conjunto de dados pode se encaixar no quadro geral. Mas então, para olhar mais de perto seus dados, você quer inspecionar apenas aquela parte da árvore maior.

Como o arquivo filogenético da árvore é apenas a saída da análise sequencial de dados, não podemos manipular a ordem dos nós e ramos no próprio arquivo. Estes já foram determinados em análises anteriores a partir dos dados brutos do NGS. No entanto, somos capazes de fazer zoom em partes, esconder partes e até mesmo subdividir parte da árvore. 

### Aumentar o zoom {.unnumbered}  

Se você não quiser "cortar" sua árvore, mas apenas inspecionar parte dela mais de perto, você pode ampliar para ver uma parte específica.

Primeiro, plotamos a árvore inteira em formato linear e adicionamos etiquetas numéricas a cada nó da árvore.

```{r, phylogenetic_trees_zoom_in, out.width=c('50%'), fig.show='hold', fig.align='center'}

p <- ggtree(tree,) %<+% sample_data +
  geom_tiplab(size = 1.5) + # adicionamos rótulos às pontas de todos os ramos como nome da amostra no arquivo 
  geom_text2(
    mapping = aes(subset = !isTip,
                  label = node),
    size = 5,
    color = "darkred",
    hjust = 1,
    vjust = 1)                            # adiciona rótulos em todos os nós

p  # printa

```

Para aumentar o zoom para um ramo em particular (à direita), utilize `viewClade()` no objeto ggtree `p` e forneça o número do nó para obter uma visão mais detalhada:

```{r phylogenetic_trees_zoom_in_452, out.width=c('50%'), fig.show='hold', fig.align='center'}

viewClade(p, node = 452)

```

### Colapsando ramos {.unnumbered} 

No entanto, podemos querer ignorar este ramo e podemos colapsa-lo naquele mesmo nó (nó nº 452) utilizando `collapse()`. Esta árvore é definida como `p_collapsed`.

```{r phylogenetic_trees_collapse_452, out.width=c('50%'), fig.show='hold', fig.align='center'}

p_collapsed <- collapse(p, node = 452)
p_collapsed
```

Para maior clareza, quando imprimimos `p_collapsed', adicionamos um `geom_point2()` (um diamante azul) no nó do ramo colapsado.  

```{r}
p_collapsed + 
geom_point2(aes(subset = (node == 452)),  # adicionamos um símbolo ao nó colapsado 
            size = 5,                     # define o tamanho do símbolo  
            shape = 23,                   # define a forma do símbolo  
            fill = "steelblue")           # define a cor do símbolo 
```

### Subdividindo uma árvore {.unnumbered} 

Se quisermos fazer uma mudança mais permanente e criar uma árvore nova e reduzida para trabalhar com ela, podemos separar parte dela com `tree_subset()`. Então você pode salvá-la como novo arquivo newick tree ou arquivo .txt. 

Primeiro, inspecionamos os nós de árvore e os rótulos das pontas a fim de decidir como subdividi-la.

```{r, phylogenetic_trees_subsetting, out.width=c('50%'), fig.show='hold', fig.align='center'}
ggtree(
  tree,
  branch.length = 'none',
  layout = 'circular') %<+% sample_data +               # adicionamos os dados das amostras usando o operdor  %<+% 
  geom_tiplab(size = 1)+                                # rotula as pontas dos ramos com o nome da amostra 
  geom_text2(
    mapping = aes(subset = !isTip, label = node),
    size = 3,
    color = "darkred") +                                # rotula todos os nós na árvore 
 theme(
   legend.position = "none",                            # remove a legenda completamente
   axis.title.x = element_blank(),
   axis.title.y = element_blank(),
   plot.title = element_text(size = 12, face="bold"))
```

Agora, digamos que decidimos dividir a árvore no nó 528 (manter apenas as pontas dentro deste ramo após o nó 528) e a salvamos como um novo objeto `sub_tree1`:

```{r}
sub_tree1 <- tree_subset(
  tree,
  node = 528)                                            # subdividimos a árvore no nó 528 
```

Vamos dar uma olhada na árvore do subconjunto 1 (subset tree 1):

```{r}
ggtree(sub_tree1) +
  geom_tiplab(size = 3) +
  ggtitle("Subset tree 1")
```

Você também pode dividir com base em uma amostra específica, especificando quantos nós "para trás" você deseja incluir. Vamos subdividir a mesma parte da árvore com base em uma amostra, neste caso S17BD07692, retrocedendo 9 nós e a salvamos como um novo objeto `sub_tree2`:

```{r}
sub_tree2 <- tree_subset(
  tree,
  "S17BD07692",
  levels_back = 9) #  levels_back define quantos nós você quer retroceder da ponta da amostra  
```

Vamos dar uma olhada na árvore do subconjunto 2:

```{r}
ggtree(sub_tree2) +
  geom_tiplab(size =3)  +
  ggtitle("Subset tree 2")

```

Você também pode salvar sua nova árvore como um tipo Newick ou mesmo um arquivo de texto utilizando a função `write.tree()` do pacote **ape**:

```{r, eval=F, phylogenetic_trees_write_tree}
# salvar no formato .nwk 
ape::write.tree(sub_tree2, file='data/phylo/Shigella_subtree_2.nwk')

# salvar no formato .txt 
ape::write.tree(sub_tree2, file='data/phylo/Shigella_subtree_2.txt')

```

### Rotacionando nós em uma árvore  {.unnumbered} 


Como mencionado anteriormente, não podemos mudar a ordem das pontas ou nós na árvore, pois isto se baseia em sua relação genética e não está sujeito a manipulação visual. Mas podemos girar ramos em torno dos nós se isso facilitar nossa visualização.

Primeiro, traçamos nossa nova árvore "sub_tree2" com etiquetas de nós para escolher o nó que queremos manipular e armazená-lo como um objeto do tipo gráfico ggtree `p`.

```{r, phylogenetic_trees_rotating_1, out.width=c('50%'), fig.show='hold', fig.align='center'}

p <- ggtree(sub_tree2) +  
  geom_tiplab(size = 4) +
  geom_text2(aes(subset=!isTip, label=node), # rotula todos os nós em uma árvore
             size = 5,
             color = "darkred", 
             hjust = 1, 
             vjust = 1) 
p
```

Podemos então manipular os nós aplicando **ggtree::rotate()** ou **ggtree::flip()**: 
Nota: para ilustrar quais nós estamos manipulando, aplicamos primeiro a função **geom_hilight()** de **ggtree** para destacar as amostras nos nós em que estamos interessados e armazenar esse objeto ggtree em um novo objeto `p1`.

```{r, phylogenetic_trees_rotating_2, out.width=c('50%'), fig.show='hold', fig.align='center'}

p1 <- p + geom_hilight(  # destaca o nó 39 em azul, "extend =" nos permite definir a cor do bloco 
  node = 39,
  fill = "steelblue",
  extend = 0.0017) +  
geom_hilight(            # destaca o nó 37 em amarelo 
  node = 37,
  fill = "yellow",
  extend = 0.0017) +               
ggtitle("Árvore Original")


p1 # printa
```

Agora podemos girar o nó 37 no objeto `p1` para que as amostras no nó 38 se movam para o topo. Armazenamos a árvore rotacionada em um novo objeto `p2`.

```{r}
p2 <- ggtree::rotate(p1, 37) + 
      ggtitle("Nó 37 rotacionado")


p2   # printa
```

Ou podemos usar a função `flip()` para rotacuonar o nó 36 do objeto `p1` e mudar o nó 37 para o topo e o nó 39 para o fundo. Armazenamos a árvore invertida em um novo objeto `p3`.

```{r}

p3 <- ggtree::flip(p1, 39, 37) +
      ggtitle("Nó 36 rotacionado")


p3   # printa
```

### Examplo de sub-árvore com informações das amostras {.unnumbered} 

Digamos que estamos investigando o conjunto de casos com expansão clonal que ocorreram em 2017 e 2018 no nó 39 de nossa sub-árvore. Acrescentamos o ano de isolamento da linhagem, bem como o histórico de viagem e a cor por país para ver a origem de outras linhagens intimamente relacionadas:

```{r, phylogenetic_trees_inspect_subset_example, out.width=c('80%'), fig.show='hold', fig.align='center', warning=F, message=F}

ggtree(sub_tree2) %<+% sample_data +     # Usamos o operador %<+% para juntar com sample_data
  geom_tiplab(                          # rotula as pontas dos ramos com  os nomes das amotras 
    size = 2.5,
    offset = 0.001,
    #align = TRUE
    ) + 
  theme_tree2()+
  xlim(0, 0.015)+                       # configura os limite do eixo x 
  geom_tippoint(aes(color=Country),     # colore a ponta de acordo com o continente  
                size = 1.5)+ 
  scale_color_brewer(
    name = "Country", 
    palette = "Set1", 
    na.value = "grey")+
  geom_tiplab(                          #  adiciona o ano de isolamento como um rótulo de texto nas pontas a
    aes(label = Year),
    color = 'blue',
    offset = 0.0045,
    size = 3,
    linetype = "blank" ,
    geom = "text",
    #align = TRUE
    )+ 
  geom_tiplab(                          # adiciona histórico de viagem nas pontas em vermelho 
    aes(label = Travel_history),
    color = 'red',
    offset = 0.006,
    size = 3,
    linetype = "blank",
    geom = "text",
    #align = TRUE
    )+ 
  ggtitle("Árvore filogenética de de estirpes de Belgian S. sonnei com histórico de viagens")+  # adiciona título 
  xlab("distância genética (0.001 = 4 nucleotídeos de diferença)")+   # adiciona legenda do eixo x
  theme(
    axis.title.x = element_text(size = 10),
    axis.title.y = element_blank(),
    legend.title = element_text(face = "bold", size = 12),
    legend.text = element_text(face = "bold", size = 10),
    plot.title = element_text(size = 12, face = "bold"))

```

Nossa observação aponta para um evento de importação de cepas da Ásia, que então circularam na Bélgica ao longo dos anos e parecem ter causado nosso último surto.

<!-- ======================================================= -->

## Árvores mais complexas: adição de heatmaps de dados de amostra {.unnumbered}


Podemos acrescentar informações mais complexas, como a presença categórica de genes de resistência antimicrobiana e valores numéricos para resistência realmente medida a antimicrobianos na forma de um mapa térmico usando a função **ggtree::gheatmap()**.

Primeiro precisamos traçar nossa árvore (esta pode ser linear ou circular) e armazená-la em um novo objeto de traçado ggtree `p`: Utilizaremos a sub-árvore da parte 3).

```{r, phylogenetic_trees_sampledata_heatmap, out.width=c('60%'), fig.align='center', fig.show='hold'}

p <- ggtree(sub_tree2, branch.length='none', layout='circular') %<+% sample_data +
  geom_tiplab(size =3) + 
 theme(
   legend.position = "none",
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    plot.title = element_text(
      size = 12,
      face = "bold",
      hjust = 0.5,
      vjust = -15))
p

```

Em segundo lugar, preparamos nossos dados. Para visualizar as diferentes variáveis com novos esquemas de cores, nós subdividimos nosso dataframe para a variável desejada. É importante adicionar o `Sample_ID` como nomes das linhas, caso contrário, ele não pode fazer a correspondência dos dados com a árvore `tip.labels`:

Em nosso exemplo, queremos analisar o gênero e as mutações que poderiam conferir resistência à Ciprofloxacina, um importante antibiótico de primeira linha utilizado para tratar as infecções por Shigella.

Criamos um dataframe para gênero:

```{r, phylogenetic_trees_sampledata_heatmap_data}
gender <- data.frame("gender" = sample_data[,c("Gender")])
rownames(gender) <- sample_data$Sample_ID
```

Criamos um dataframe para mutações no gene gyrA, que confere resistência à Ciprofloxacina:

```{r}
cipR <- data.frame("cipR" = sample_data[,c("gyrA_mutations")])
rownames(cipR) <- sample_data$Sample_ID

```

Criamos um dataframe para a concentração inibitória mínima medida (MIC) de Ciprofloxacina do laboratório:

```{r}
MIC_Cip <- data.frame("mic_cip" = sample_data[,c("MIC_CIP")])
rownames(MIC_Cip) <- sample_data$Sample_ID
```

Criamos um primeiro gráfico adicionando um heatmap binário para gênero à árvore filogenética e armazenando-o em um novo objeto do tipo gráfico ggtree `h1`:

```{r, phylogenetic_trees_sampledata_heatmap_gender, out.width=c('70%'), fig.show='hold', fig.align='center'}

h1 <-  gheatmap(p, gender,                                 # adicionamos uma camada "heatmap" de gênero ao gráfico
                offset = 10,                               # "offset" muda o heatmap para a direita,
                width = 0.10,                              # "width" define ta largura da coluna do heatmap,
                color = NULL,                              # "color"  define a borda da coluna do  heatmap 
         colnames = FALSE) +                               # esconde a coluna de nomes do heatmap
  scale_fill_manual(name = "Gender",                       # define o esquema de cores e a legenda do gênero 
                    values = c("#00d1b1", "purple"),
                    breaks = c("Male", "Female"),
                    labels = c("Male", "Female")) +
   theme(legend.position = "bottom",
        legend.title = element_text(size = 12),
        legend.text = element_text(size = 10),
        legend.box = "vertical", legend.margin = margin())
h1

```

Depois adicionamos informações sobre mutações no gene gyrA, que conferem resistência ao Ciprofloxacina:

Nota: A presença de mutações cromossômicas pontuais nos dados do WGS foi previamente determinada usando a ferramenta PointFinder desenvolvida por Zankari et al. (ver referência na seção de referências adicionais)

Primeiro, atribuímos um novo esquema de cores ao nosso objeto do tipo gráfico existente em`h1` e o armazenamos em um objeto agora `h2`. Isto nos permite definir e mudar as cores para nossa segunda variável no heatmap.

```{r}
h2 <- h1 + new_scale_fill() 
```

Depois adicionamos a segunda camada do heatmap ao `h2` e armazenamos os gráficos combinados em um novo objeto `h3`:

```{r, phylogenetic_trees_sampledata_heatmap_cip_genes, out.width=c('80%'), fig.show='hold', fig.align='center'}

h3 <- gheatmap(h2, cipR,  # adiciona uma segunda linha de heatmap descrevendo a mutação de resistência da Ciprofloxacina
               offset = 12, 
               width = 0.10, 
               colnames = FALSE) +
  scale_fill_manual(name = "Mutações que conferem \n resistência a Ciprofloxacina",
                    values = c("#fe9698","#ea0c92"),
                    breaks = c( "gyrA D87Y", "gyrA S83L"),
                    labels = c( "gyrA d87y", "gyrA s83l")) +
   theme(legend.position = "bottom",
        legend.title = element_text(size = 12),
        legend.text = element_text(size = 10),
        legend.box = "vertical", legend.margin = margin())+
  guides(fill = guide_legend(nrow = 2,byrow = TRUE))
h3
```

Repetimos o processo acima, primeiro adicionando uma nova camada de escala de cor ao nosso objeto existente `h3`, e depois adicionando os dados contínuos sobre a concentração inibitória mínima (MIC) de Ciprofloxacina para cada estirpe ao objeto resultante `h4` para produzir o objeto final `h5`:

```{r, phylogenetic_trees_sampledata_heatmap_cip_MIC, out.width=c('90%'), fig.show='hold', fig.align='center'}
# Primeiro adicionamos o novo esquema de cores
h4 <- h3 + new_scale_fill()

# e então combinamos os dois em um novo gráfico:
h5 <- gheatmap(h4, MIC_Cip,  
               offset = 14, 
               width = 0.10,
                colnames = FALSE)+
  scale_fill_continuous(name = "MIC para Ciprofloxacina",  # definimos uma cor em gradiente para a variável contínua MIC 
                      low = "yellow", high = "red",
                      breaks = c(0, 0.50, 1.00),
                      na.value = "white") +
   guides(fill = guide_colourbar(barwidth = 5, barheight = 1))+
   theme(legend.position = "bottom",
        legend.title = element_text(size = 12),
        legend.text = element_text(size = 10),
        legend.box = "vertical", legend.margin = margin())
h5

```

Podemos fazer o mesmo exercício para uma árvore linear:

```{r, phylogenetic_trees_sampledata_heatmap_linear_1, out.width=c('80%'), fig.show='hold', fig.align='center'}

p <- ggtree(sub_tree2) %<+% sample_data +
  geom_tiplab(size = 3) + # rotupa as pontas
  theme_tree2()+
  xlab("distância gentética (0.001 = 4 nucleotídeos de diferença)")+
  xlim(0, 0.015)+
 theme(legend.position = "none",
      axis.title.y = element_blank(),
      plot.title = element_text(size = 12, 
                                face = "bold",
                                hjust = 0.5,
                                vjust = -15))
p
```

Primeiro, adicionamos o gênero:

```{r, phylogenetic_trees_sampledata_heatmap_linear_2, out.width=c('80%'), fig.show='hold', fig.align='center'}

h1 <-  gheatmap(p, gender, 
                offset = 0.003,
                width = 0.1, 
                color="black", 
         colnames = FALSE)+
  scale_fill_manual(name = "Gender",
                    values = c("#00d1b1", "purple"),
                    breaks = c("Male", "Female"),
                    labels = c("Male", "Female"))+
   theme(legend.position = "bottom",
        legend.title = element_text(size = 12),
        legend.text = element_text(size = 10),
        legend.box = "vertical", legend.margin = margin())
h1
```


Depois adicionamos as mutações de resistência Ciprofloxacina depois de adicionar outra camada de esquema de cores:

```{r, phylogenetic_trees_sampledata_heatmap_linear_3, out.width=c('80%'), fig.show='hold', fig.align='center'}

h2 <- h1 + new_scale_fill()
h3 <- gheatmap(h2, cipR,   
               offset = 0.004, 
               width = 0.1,
               color = "black",
                colnames = FALSE)+
  scale_fill_manual(name = "Mutações que conferem \n resistência a Ciprofloxacina",
                    values = c("#fe9698","#ea0c92"),
                    breaks = c( "gyrA D87Y", "gyrA S83L"),
                    labels = c( "gyrA d87y", "gyrA s83l"))+
   theme(legend.position = "bottom",
        legend.title = element_text(size = 12),
        legend.text = element_text(size = 10),
        legend.box = "vertical", legend.margin = margin())+
  guides(fill = guide_legend(nrow = 2,byrow = TRUE))
 h3
```

Em seguida, adicionamos a concentração inibitória mínima determinada pelo laboratório (MIC):

```{r, phylogenetic_trees_sampledata_heatmap_linear_4, out.width=c('80%'), fig.show='hold', fig.align='center'}

h4 <- h3 + new_scale_fill()
h5 <- gheatmap(h4, MIC_Cip, 
               offset = 0.005,  
               width = 0.1,
               color = "black", 
                colnames = FALSE)+
  scale_fill_continuous(name = "MIC para Ciprofloxacina",
                      low = "yellow", high = "red",
                      breaks = c(0,0.50,1.00),
                      na.value = "white")+
   guides(fill = guide_colourbar(barwidth = 5, barheight = 1))+
   theme(legend.position = "bottom",
        legend.title = element_text(size = 10),
        legend.text = element_text(size = 8),
        legend.box = "horizontal", legend.margin = margin())+
  guides(shape = guide_legend(override.aes = list(size = 2)))
h5

```


<!-- ======================================================= -->
## Resources {}

http://hydrodictyon.eeb.uconn.edu/eebedia/index.php/Ggtree# Clade_Colors
https://bioconductor.riken.jp/packages/3.2/bioc/vignettes/ggtree/inst/doc/treeManipulation.html
https://guangchuangyu.github.io/ggtree-book/chapter-ggtree.html
https://bioconductor.riken.jp/packages/3.8/bioc/vignettes/ggtree/inst/doc/treeManipulation.html

Ea Zankari, Rosa Allesøe, Katrine G Joensen, Lina M Cavaco, Ole Lund, Frank M Aarestrup, PointFinder: a novel web tool for WGS-based detection of antimicrobial resistance associated with chromosomal point mutations in bacterial pathogens, Journal of Antimicrobial Chemotherapy, Volume 72, Issue 10, October 2017, Pages 2764–2768, https://doi.org/10.1093/jac/dkx217


```{r include=FALSE, cache=FALSE}

# clear workspace
rm(list = ls(all = TRUE))

# clear all packages except base
#lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))

# to ensure that tidyverse packages prevail
filter <- dplyr::filter
select <- dplyr::select
summarise <- dplyr::summarise
summary <- base::summary
incidence <- incidence2::incidence

#load core packages
pacman::p_load(
     rio,
     here,
     DT,
     stringr,
     lubridate,
     tidyverse
)

# import the cleaned ebola linelist
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

# import the count data - facility level
#count_data <- rio::import(here::here("data", "facility_count_data.rds"))

# Settings

options(scipen=1, digits=7)

# print only text (not code)
# library(knitr)
# opts_chunk$set(list(echo = FALSE, eval = FALSE))
```

<!--chapter:end:new_pages/phylogenetic_trees.Rmd-->


# Gráficos interativos {#interactive-plots}  
A visualização de dados é cada vez mais necessária para questionamento do público. Consequentemente, a criação de gráficos interativos torna-se algo comum. Há várias formas de torná-los interativos, sendo as duas mais comuns: **plotly** e **shiny**. 

Nesta página iremos focar na conversão de um gráfico já existente no `ggplot()`  em um gráfico interativo, utilizando o **plotly**. Para saber mais sobre o **shiny**, veja na no capítulo [Paineis com  Shiny](#shiny-basics). Importante lembrar que este formato de gráfico interativo tem limitações, utilizados apenas em documentos do R Markdown em formato HTML*, não sendo possível em documentos com formatos em PDF ou Word.

No exemplo abaixo, tem-se um gráfico de  curva epidêmica, que foi transformado para ser interativo,  usando a integração de **ggplot2** e **plotly**(_Passe o mouse sobre o grafico, amplie ou clique nos itens na legenda_). 

 
```{r plotly_demo, out.width=c('75%'), out.height=c('500px'), echo=F, warning=F, message=F}
pacman::p_load(plotly, rio, here, ggplot2, dplyr, lubridate)
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

## esses botões são supérfluos/distrações
plotly_buttons_remove <- list('zoom2d','pan2d','lasso2d', 'select2d','zoomIn2d',
                              'zoomOut2d','autoScale2d','hoverClosestCartesian',
                              'toggleSpikelines','hoverCompareCartesian')

p <- linelist %>% 
  mutate(outcome = if_else(is.na(outcome), "Unknown", outcome),
         date_earliest = if_else(is.na(date_infection), date_onset, date_infection),
         week_earliest = floor_date(date_earliest, unit = "week",week_start = 1))%>% 
  count(week_earliest, outcome) %>% 
  ggplot()+
  geom_col(aes(week_earliest, n, fill = outcome))+
  xlab("Week of infection/onset") + ylab("Cases per week")+
  theme_minimal()

p %>% 
  ggplotly() %>% 
  partial_bundle() %>% 
  config(displaylogo = FALSE, modeBarButtonsToRemove = plotly_buttons_remove)

```


<!-- ======================================================= -->
## Preparação {  }

### Carregando os pacotes  {.unnumbered} 

Esta parte de código(chunk) mostra o carregamento de pacotes necessários para as análises, com destaque `p_load()` do **pacman**, que instala o pacote se necessário e o carrega para uso. Você também pode carregar utilizando a função `library()` - "R base". Para mais informações sobre pacotes consulte o capítulo [Introdução ao R](#basics). 

```{r}
pacman::p_load(
  rio,       # importar e exportar dados
  here,      # especificar caminho dos dados
  lubridate, # trabalhar dados
  plotly,    # graficos interativos
  scales,    # percents
  tidyverse, # manuseio e visualização
  incidence2,# gráfico epicurva
  magrittr)  # pipe %>%
# Verificar a versão do R, o pacote pacman e o rio  foi construido na versão 4.1.2
```

### Comece com um `ggplot()` {.unnumbered}  

Nessa seção, assumimos que que você está começando com um gráfico `ggplot()` que pretende tornar interativo. Vamos contruir então, vários gráficos usando o `linelist` de casos, exemplo utilizado em outros capítulos deste manual.

### Importar os dados {.unnumbered}

Para começar, importe a lista de casos (limpa/organizada) de uma epidemia simulada de Ebola. Se quiser acompanhar o script, <ahref='https://github.com/appliedepi/epirhandbook_eng/raw/master/data/case_linelists/linelist_cleaned.rds' class='download-button'> clique para baixar a linelist “limpa”</a> (como arquivo .rds). Importe dados com a função  *import()* do pacote rio (ele lida com vários tipos de arquivos como .xlsx, .csv, .rds - veja a página [Importar e exportar](#importing) para mais detalhes).




```{r, echo=F}
# importar o arquivo linelist para o R
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))
```


```{r, eval=F}
# Importar os casos linelist (Ébola)
linelist <- import("linelist_cleaned.rds")
```


As primeiras 50 linhas da lista de linhas são exibidas abaixo.

```{r, message=FALSE, echo=F}
# Visualização dos dados em forma de tabela
DT::datatable(head(linelist, 50), rownames = FALSE, filter="top", options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```

  
<!-- ======================================================= -->
## Gráfico com `ggplotly()` {  }

A função `ggplotly()` do pacote **plotly** facilita a conversão de um `ggplot()` para ser interativo.  Só precisa salvar o seu `ggplot()` e na sequência direciona-lo para a função do `ggplotly()`.  


Abaixo, é traçada uma linha simples no gráfico representando a proporção de casos que morreram em uma determinada semana: 

Para começar, necessário cria um conjunto de dados resumido de cada semana epidemiológica e a porcentagem de casos com desfecho conhecido que morreram. 

```{r}
weekly_deaths <- linelist %>%
  group_by(epiweek = floor_date(date_onset, "week")) %>%  # criar e agrupar dados por coluna *epiweek*
  summarise(                                              # criar um novo da Data Frame resumido
    n_known_outcome = sum(!is.na(outcome), na.rm=T),      # número de casos por grupo(com resultados conhecidos)
    n_death  = sum(outcome == "Death", na.rm=T),          # número de casos que foram a óbitos
    pct_death = 100*(n_death / n_known_outcome)           # percentual de casos que foram a obitos com resultados conhecidos
  )
```
Aqui estão as primeiras 50 linhas do conjunto `weekly_deaths`.  

```{r message=FALSE, echo=F}
DT::datatable(head(weekly_deaths, 50), rownames = FALSE, options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```
Na sequência criamos o gráfico com  **ggplot2**, usando o `geom_line()`.  

```{r, warning=F, message=F}
deaths_plot <- ggplot(data = weekly_deaths)+            # começar com o registro de óbito semanal
  geom_line(mapping = aes(x = epiweek, y = pct_death))  # criar a linha no gráfico

deaths_plot   # visualizar
```

Para torná-lo interativo, basta passar esse gráfico para `ggplotly()`, como abaixo. Passe o mouse sobre a linha para mostrar os valores x e y. Você pode ampliar o gráfico e arrastá-lo. Você também pode ver os ícones no canto superior direito do gráfico. Em ordem, eles permitem que você:  

* Baixar a visualização atual como uma imagem PNG  
* Ampliar com uma caixa de seleção  
* Gire, ou mova-se pelo gráfico clicando e arrastando  
* Ampliar, reduzir ou retornar ao zoom padrão 
* Redefinir os eixos para os padrões 
* Ative/desative as “Spike Lines” que são linhas pontilhadas do ponto interativo que se estendem até os eixos x e y
* Ajustes para mostrar os dados quando você não está navegando na linha


```{r}
deaths_plot %>% plotly::ggplotly()
```

Dados agrupados também funcionam com o `ggplotly()`. Abaixo, é feita uma epicurva semanal, agrupada por resultado. As barras empilhadas são interativas. Tente clicar nos diferentes itens da legenda (eles irão aparecer/desaparecer). 


```{r plot_show, eval=F}
#Produzir a curva com o pacote incidence2 verificar se tem instalado
p <- incidence2::incidence(
  linelist,
  date_index = date_onset,
  interval = "weeks",
  groups = outcome) %>% #não esquecer de chamar o pacote %>% (magrittr)
  plot(fill = outcome)

```

```{r, echo=T, eval=F}
# Gráfico interativo 
p %>% plotly::ggplotly() 
```
  
```{r, warning = F, message = F, , out.width=c('95%'), out.height=c('500px'), echo=FALSE}
p %>% 
  ggplotly() %>% 
  partial_bundle() 
```
  
<!-- ======================================================= -->
## Modificações{  }

### Tamanho do arquivo {.unnumbered}  

Ao exportar em HTML gerado pelo R Markdown (como este livro!), você irá desejar o gráfico com o menor tamanho de dados possível (sem efeitos colaterais negativos na maioria dos casos). Para isso, basta direcionar a plotagem interativa para `partial_bundle()`, também do **plotly**.  

```{r plot_tidyshow, eval=F}
p <- p %>% 
  plotly::ggplotly() %>%
  plotly::partial_bundle()
```

### Botões {.unnumbered}  

Alguns dos botões em uma plotagem padrão são supérfluos e podem ser uma distração, então você pode removê-los. Você pode fazer isso simplesmente direcionando a saída  `config()` do **plotly** e especificando quais botões  devem ser removidos. No exemplo abaixo, os nomes dos botões a serem removidos foram expecificados previamente  e fornecido o argumento `modeBarButtonsToRemove = `. Também definiu-se a remoção do logotipo do plotly com o  `displaylogo = FALSE`.

```{r plot_tidyshow2, eval=F}
##Esses botões são distrações e podem ser removidos
plotly_buttons_remove <- list('zoom2d','pan2d','lasso2d', 'select2d','zoomIn2d',
                              'zoomOut2d','autoScale2d','hoverClosestCartesian',
                              'toggleSpikelines','hoverCompareCartesian')

p <- p %>%          # redefinir o grafico interativo com esses botões
  plotly::config(displaylogo = FALSE, modeBarButtonsToRemove = plotly_buttons_remove)
```



<!-- ======================================================= -->
## Gráfico -Blocos  de calor {  }

Você pode tornar quase qualquer gráfico do `ggplot()` interativo, incluindo o gráfico de calor. No exemplo, a seguir mostra a proporção de dias por semana que certas instalações reportaram dados de malária  à sua província.

Aqui está o código, embora não descrito em profundidade neste tópico. 

```{r  message=F, warning=F}
# Importar os dados de malária
facility_count_data <- rio::import(here::here("data", "malaria_facility_count_data.rds"))

# Dados agregados por semana para o distrito durante a primavera
agg_weeks <- facility_count_data %>% 
  filter(District == "Spring",
         data_date < as.Date("2020-08-01")) %>% 
  mutate(week = aweek::date2week(
    data_date,
    start_date = "Monday",
    floor_day = TRUE,
    factor = TRUE)) %>% 
  group_by(location_name, week, .drop = F) %>%
  summarise(
    n_days          = 7,
    n_reports       = n(),
    malaria_tot     = sum(malaria_tot, na.rm = T),
    n_days_reported = length(unique(data_date)),
    p_days_reported = round(100*(n_days_reported / n_days))) %>% 
  ungroup(location_name, week) %>% 
  right_join(tidyr::expand(., week, location_name)) %>% 
  mutate(week = aweek::week2date(week))

# Criar gráfico
metrics_plot <- ggplot(agg_weeks,
       aes(x = week,
           y = location_name,
           fill = p_days_reported))+
  geom_tile(colour="white")+
  scale_fill_gradient(low = "orange", high = "darkgreen", na.value = "grey80")+
  scale_x_date(expand = c(0,0),
               date_breaks = "2 weeks",
               date_labels = "%d\n%b")+
  theme_minimal()+ 
  theme(
    legend.title = element_text(size=12, face="bold"),
    legend.text  = element_text(size=10, face="bold"),
    legend.key.height = grid::unit(1,"cm"),
    legend.key.width  = grid::unit(0.6,"cm"),
    axis.text.x = element_text(size=12),
    axis.text.y = element_text(vjust=0.2),
    axis.ticks = element_line(size=0.4),
    axis.title = element_text(size=12, face="bold"),
    plot.title = element_text(hjust=0,size=14,face="bold"),
    plot.caption = element_text(hjust = 0, face = "italic")
    )+
  labs(x = "Semana",
       y = "Nome do Estabelecimento",
       fill = "Performance de \n reporte (%)",
       title = "Porcentagem de dia por semana que o estabelecimento \n reportou dados",
       subtitle = "Estabelecimento de saúdes distritais, Abril-Maio 2019",
       caption = "Semanas de 7 diad começando às segundas")

metrics_plot # mostrar gráfico
```

Abaixo, o gráfico foi transformado no modo interativo e o tamanho do arquivo, assim como os botões modificados para formas mais simples.

```{r,  out.width=c('95%'), out.height=c('500px')}
metrics_plot %>% 
  plotly::ggplotly() %>% 
  plotly::partial_bundle() %>% 
  plotly::config(displaylogo = FALSE, modeBarButtonsToRemove = plotly_buttons_remove)
```

<!-- ## Mapas{.unnumbered}   -->

<!-- Você também pode fazer mapas GIS interativos do `ggplot()`, porém  exige mais trabalho-->

<!-- SEÇÃO EM CONSTRUÇÃO -->

<!-- Embora o **plotly**  funcione bem com o `ggplot2::geom_sf` no RStudio,   quando na tentativa de incluir os resultados no formato HTML pelo R Markdown(como neste livro), não se obteve o resultado esperado.   -->

<!-- Assim, em vez disso, pode usar as próprias ferramentas de mapeamento do{**plotly**} que podem ser complicadas,  mas são fáceis quando se sabe como. Continuar leitura..   -->

<!-- Vamos usar a incidência de Covid-19 em todos os países africanos para este exemplo. Os dados utilizados podem ser encontrados no  [World Health Organisation website](https://covid19.who.int/table).   -->

<!-- Também vai precisar de um novo tipo de arquivo, um GeoJSON, mais ou menos semelhante a um arquivo de shp para quem está familiarizado com o SIG. Para este livro, será utilizado [este](https://geojson-maps.ash.ms).   -->

<!-- GeoJSON são armazenados em R como listas complexas e terá de manipulá-los um pouco -->

<!-- ```{r, echo=T,} -->
<!-- ## Instalar dois novos pacotes: {rjson} and {purrr} -->
<!-- pacman::p_load(plotly, rjson, purrr) -->

<!-- ## Esta é uma versão simplificada dos dados da OMS -->
<!-- df <- rio::import(here::here("data", "gis", "covid_incidence.csv")) -->

<!-- ## Carregar seu arquivo geojson -->
<!-- geoJSON <- rjson::fromJSON(file=here::here("data", "gis", "africa_countries.geo.json")) -->

<!-- ## Aqui estão algumas das propriedades de cada elemento do objeto -->
<!-- head(geoJSON$features[[1]]$properties) -->

<!-- ``` -->

<!-- Esta é a parte complicada. Para{**plotly**} fazer corresponder os seus dados de incidência ao GeoJSON, os países do geoJSON precisam de uma identificação num lugar específico na lista. Para isso, é necessário construir uma função básica: -->
<!-- ```{r} -->
<!-- ## A coluna da propriedade a ser escolhida é a "sovereignt" pois são os nomes de cada país-->
<!-- give_id <- function(x){ -->

<!--   x$id <- x$properties$sovereignt  ## Assumir  "sovereignt" das propriedades e defini-la como o id -->

<!--   return(x) -->
<!-- } -->

<!-- ## Use {purrr} para aplicar esta função a cada elemento da lista de características do objeto geoJSON -->
<!-- geoJSON$features <- purrr::map(.x = geoJSON$features, give_id) -->
<!-- ``` -->

<!-- <!-- ======================================================= --> -->
<!-- ### Mapas - plot {  } -->

<!-- Em construção -->

<!-- ```{r, echo=FALSE, eval=FALSE, out.width=c('95%'), out.height=c('500px'),warning=F} -->
<!-- plotly::plot_ly() %>%  -->
<!--   plotly::add_trace(         ##A função principal de mapeamento -->
<!--     type="choropleth", -->
<!--     geojson=geoJSON, -->
<!--     locations=df$Name,      #A coluna com os nomes (deve corresponder ao id)  -->
<!--     z=df$Cumulative_incidence,  #A coluna com os valores de incidência -->
<!--     zmin=0, -->
<!--     zmax=57008, -->
<!--     colorscale="Viridis", -->
<!--     marker=list(line=list(width=0)) -->
<!--   ) %>% -->
<!--   colorbar(title = "Cases per million") %>% -->
<!--   layout(title = "Covid-19 cumulative incidence", -->
<!--                  geo = list(scope = 'africa')) %>%  -->
<!--   config(displaylogo = FALSE, modeBarButtonsToRemove = plotly_buttons_remove) -->
<!-- ``` -->

<!-- ======================================================= -->
## Recursos {  }

Plotly não é apenas para R, também funciona bem com Python (e qualquer linguagem de ciência de dados, por ser construído em JavaScript). Você pode ler mais sobre o tema no [Website plotly](https://plotly.com/r/)
```{r include=FALSE, cache=FALSE}

# clear workspace
rm(list = ls(all = TRUE))

# clear all packages except base
#lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))

# to ensure that tidyverse packages prevail
filter <- dplyr::filter
select <- dplyr::select
summarise <- dplyr::summarise
summary <- base::summary
incidence <- incidence2::incidence

#load core packages
pacman::p_load(
     rio,
     here,
     DT,
     stringr,
     lubridate,
     tidyverse
)

# import the cleaned ebola linelist
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

# import the count data - facility level
#count_data <- rio::import(here::here("data", "facility_count_data.rds"))

# Settings

options(scipen=1, digits=7)

# print only text (not code)
# library(knitr)
# opts_chunk$set(list(echo = FALSE, eval = FALSE))
```

<!--chapter:end:new_pages/interactive_plots.Rmd-->

# (PART) Relatórios e dashboards {.unnumbered}
```{r include=FALSE, cache=FALSE}

# clear workspace
rm(list = ls(all = TRUE))

# clear all packages except base
#lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))

# to ensure that tidyverse packages prevail
filter <- dplyr::filter
select <- dplyr::select
summarise <- dplyr::summarise
summary <- base::summary
incidence <- incidence2::incidence

#load core packages
pacman::p_load(
     rio,
     here,
     DT,
     stringr,
     lubridate,
     tidyverse
)

# import the cleaned ebola linelist
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

# import the count data - facility level
#count_data <- rio::import(here::here("data", "facility_count_data.rds"))

# Settings

options(scipen=1, digits=7)

# print only text (not code)
# library(knitr)
# opts_chunk$set(list(echo = FALSE, eval = FALSE))
```

<!--chapter:end:new_pages/cat_reports_dashboards.Rmd-->

# Relatórios com R Markdown {#rmarkdown}

```{r out.width = "100%", fig.align = "center", echo=F}
knitr::include_graphics(here::here("images", "markdown/rmarkdown_overview.png"))
```

R Markdown é uma ferramenta amplamente usada para criar produtos automatizados, reproduzíveis e compartilháveis, como relatórios. É possível criar produtos estáticos ou interativos, em MS Word, pdf, html, powerpoint, entre outros formatos.

Um script de R Markdown intercala código em R e texto de modo que o script *se torna o seu output final*. é possível criar um documento completamente formatado, incluindo o texto (que pode ser dinâmico para mudar de acordo com os seus dados), tabelas, figuras, itens enumerados ou não, bibliografia, etc.

Esses documentos podem ser produzidos para serem atualizados com base em uma rotina (por exemplo, relatórios diários de vigilância) ou rodarem com subconjuntos dos seus dados, como relatórios para cada jurisdição de uma agência.

Outras páginas nesse livro expandem esse assunto:

-   A página [Organização de relatórios de rotina](#reportfactory) demonstra como aplicar uma rotina à produção de relatórios com pastas geradas automaticamente com seus metadados de tempo (**timestamps**).
-   A página [Dashboards with R Markdown](#flexdashboard) explica como formatar um relatório R Markdown como um painel (**dashboard**).

Em outra nota, o projeto [R4Epis](https://r4epis.netlify.app/) tem desenvolvido templates de scripts R Markdown para surtos comuns e cenários de pesquisa encontrados em locais do projeto MSF (Médicos Sem Fronteiras).



<!-- ======================================================= -->

## Preparação

**Ideias preliminares ao R Markdown**

Para explicar alguns dos conceitos e pacotes envolvidos:

-   **Markdown** é uma "linguagem" que permite escrever um documento usando texto comum, que pode ser convertido para html e outros formatos. Não é específico de R e arquivos escritos nessa "linguagem" tem extensão '.md'.
-   **R Markdown**: é uma variação de markdown que *é específica de R* - permite escrever um documento usando markdown para produzir código, *mas também incluir código em R e expor seus resultados*.\
-   **rmarkdown - o pacote**: é usado pelo R para renderizar o arquivo .Rmd para a exportação desejada. Seu foco é converter a sintaxe markdown (texto), então também precisamos de...
-   **knitr**: Esse pacote do R lerá os blocos de código, executá-los e costurá-los (do inglês *knit*, tricotar) de volta ao documento.
-   **Pandoc**: Finalmente, pandoc converte o objeto final em um documento word/pdf/powerpoint, etc. É um software separado do R, mas é instalado automaticamente com o RStudio.



```{r out.width = "100%", fig.align = "center", echo=F}
knitr::include_graphics(here::here("images", "markdown/0_rmd.png"))
```

(Fonte: <https://rmarkdown.rstudio.com/authoring_quick_tour.html>):

**Instalação**

Para criar um produto R Markdown, é necessário ter os seguintes instalados:

-   O pacote **rmarkdown** (**knitr** será automaticamente instalado também)\
-   Pandoc, que deve ter vindo instalado com RStudio. Se você não está usando RStudio, é possível baixar o Pandoc aqui: <http://pandoc.org>.
-   Se quiser gerar um arquivo PDF (um pouquinho mais complicado), será necessário instalar o LaTeX. Para usuários de R Markdown que nunca instalaram o LaTeX antes, recomendamos que instale o TinyTeX (<https://yihui.name/tinytex/>). Para isso, use os seguintes comandos:



```{r, eval=F}
pacman::p_load(tinytex)     # instala o pacote tinytex
tinytex::install_tinytex()  # Comando de R para instalar o software TinyTeX
```

<!-- ======================================================= -->

## Começando

### Instalação do pacote rmarkdown para R {.unnumbered}

Instale o pacote **rmarkdown**. Neste livro enfatizamos `p_load()` de **pacman**, que instala o pacote se necessário *e* o carrega para ser usado. É possível também carregar pacotes instalados com `library()` do R **base**. Vera a pagina em [Introdução ao R](#basics) para mais informação sobre os pacotes de R.

<!-- revisar [R basics] -->


```{r, eval=F}
pacman::p_load(rmarkdown)
```

### Começando um novo arquivo Rmd {.unnumbered}

No Rstudio, abra um novo arquivo R markdown, começando em 'Arquivo', depois 'Novo arquivo', depois em 'R markdown...'.


```{r out.width = "50%", fig.align = "center", echo=F}
knitr::include_graphics(here::here("images", "markdown/1_gettingstarted.png"))
```

Rstudio lhe dará opções de output para selecionar. No exemplo abaixo, escolhemos "HTML" porque queremos criar um documento html. O título e o nome do autor não são importantes. Se o tipo do documento de saída desejado não é nenhum desses, não se preocupe - é possível escolher qualquer um e alterar posteriormente.



```{r out.width = "50%", fig.align = "center", echo=F}
knitr::include_graphics(here::here("images", "markdown/1_gettingstartedB.png"))
```

Isso abrirá um novo script .Rmd.

### Importante saber {.unnumbered}

**O diretório de trabalho**

O diretório de trabalho de um arquivo markdown é o local onde o próprio arquivo Rmd é salvo. Por exemplo, se o projeto R estiver dentro de `~/Documents/projectX` e o próprio arquivo Rmd estiver em uma subpasta` ~/Documents/projectX/markdownfiles/markdown.Rmd`, o código `read.csv("data.csv")` Dentro do markdown irá procurar por um arquivo csv na pasta `markdownfiles`, e não na pasta raiz do projeto onde os scripts dentro dos projetos normalmente procurariam automaticamente.

Para se referir a arquivos em outro lugar, você precisará usar o caminho completo do arquivo ou usar o pacote **here**. O pacote **here** define o diretório de trabalho para a pasta raiz do projeto R e é explicado em detalhes nas páginas [Projetos R](#r-projects) e [Importar e exportar])(#importing) deste manual. Por exemplo, para importar um arquivo chamado "data.csv" de dentro da pasta `projectX`, o código seria `import(here(“data.csv”))`.

Observe que o uso de `setwd()` em scripts R Markdown não é recomendado - ele se aplica apenas ao trecho de código em que está escrito.

**Trabalhando em uma unidade vs no seu computador**

Como o R Markdown pode ter problemas de pandoc ao ser executado em uma unidade de rede compartilhada, é recomendado que sua pasta esteja em sua máquina local, por exemplo, em um projeto em 'Meus Documentos'. Se você usa Git (muito recomendado!), Isso será familiar. Para obter mais detalhes, consulte as páginas do manual em [R em unidades de rede](#network-drives) e [Erros](#errors) e [ajuda](#help).


<!-- ======================================================= -->

## Componentes do R Markdown

Um documento R Markdown pode ser editado no RStudio da mesma forma que um script R padrão. Quando você inicia um novo script R Markdown, o RStudio tenta ser útil mostrando um modelo que explica as diferentes seções de um script R Markdown.

A seguir está o que aparece ao iniciar um novo script Rmd destinado a produzir uma saída html (conforme a seção anterior).

```{r out.width = "100%", fig.align = "center", echo=F}
knitr::include_graphics(here::here("images", "markdown/2_defaultRMD.png"))
```


Como você pode ver, existem três componentes básicos em um arquivo Rmd: YAML, texto Markdown e blocos de código R.

Eles irão *criar e se tornar a saída do seu documento*. Veja o diagrama abaixo:

```{r out.width = "100%", out.height="150%", fig.align = "center", echo=F}
knitr::include_graphics(here::here("images", "markdown/rmarkdown_translation.png"))
```

### Metadados YAML {.unnumbered}

Referido como 'metadados YAML' ou apenas 'YAML', isso está no topo do documento R Markdown. Esta seção do script dirá ao seu arquivo Rmd que tipo de saída produzir, preferências de formatação e outros metadados, como título do documento, autor e data. Existem outros usos não mencionados aqui (mas mencionados em 'Produção de uma saída'). Observe que o recuo é importante; tabulações não são aceitas, mas espaços, sim.

Esta seção deve começar com uma linha contendo apenas três traços `---` e deve fechar com uma linha contendo apenas três traços `---`. Os parâmetros YAML vêm em pares `chave: valor`. A colocação dos dois pontos em YAML é importante - os pares `chave: valor` são separados por dois pontos (e não sinais de igual!).

O YAML deve começar com metadados para o documento. A ordem desses parâmetros YAML primários (não recuados) não importa. Por exemplo:

``` {.yaml}
title: "My document"
author: "Me"
date: "`r Sys.Date()`"
```

You can use R code in YAML values by writing it as in-line code (preceded by `r` within back-ticks) but also within quotes (see above example for `date:`).

In the image above, because we clicked that our default output would be an html file, we can see that the YAML says `output: html_document`. However we can also change this to say `powerpoint_presentation` or `word_document` or even `pdf_document`.

Você pode usar o código R em valores YAML escrevendo-o como código in-line (precedido por `r` dentro de crases), mas também entre aspas (veja o exemplo acima para `date:`).

Na imagem acima, como clicamos que nossa saída padrão seria um arquivo html, podemos ver que o YAML diz `output: html_document`. No entanto, também podemos alterar isso para dizer `powerpoint_presentation `ou` word_document` ou mesmo `pdf_document`.

### Texto {.numerado}

Esta é a narrativa do seu documento, incluindo os títulos e cabeçalhos. Ele é escrito na linguagem "markdown", que é usada em muitos softwares diferentes.

Abaixo estão as principais maneiras de escrever este texto. Consulte a documentação mais extensa disponível na "cheatsheet" do R Markdown no [site do RStudio](https://rstudio.com/resources/cheatsheets/).

#### Novas linhas {.unnumbered}

Exclusivamente no R Markdown, para iniciar uma nova linha, insira **dois espaços** no final da linha anterior e pressione Enter / Return.

#### Case {.unnumbered}

Cerque seu texto normal com esses caracteres para alterar como ele aparece na saída.

- Sublinhados (`_text_`) ou asterisco único (`*texto*`) para *itálico*
- Asteriscos duplos (`**texto**`) para **texto em negrito**
- Crases (`text`) para exibir o texto como código

A aparência real da fonte pode ser definida usando modelos específicos (especificados nos metadados YAML; consulte as guias de exemplo).

#### Cor {.numerada}

Não existe um mecanismo simples para alterar a cor do texto no R Markdown. Uma solução alternativa, *SE sua saída for um arquivo HTML*, é adicionar uma linha HTML ao texto markdown. O código HTML abaixo imprimirá uma linha de texto em vermelho negrito.


``` {.md}
<span style="color: red;">**_DANGER:_** This is a warning.</span>  
```

[***PERIGO:*** Este é um aviso.] {style = "color: red;"}

#### Títulos e cabeçalhos {.unnumbered}

Um símbolo hash (#) em uma parte do texto de um script R Markdown cria um título. Isso é diferente de um pedaço de código R no script, no qual um símbolo hash é um mecanismo para comentar / anotar / desativar, como em um script R normal.

Diferentes níveis de título são estabelecidos com diferentes números de símbolos hash no início de uma nova linha. Um símbolo de hash é um título ou cabeçalho principal. Dois símbolos hash são um título de segundo nível. Os cabeçalhos de terceiro e quarto níveis podem ser feitos com mais símbolos hash sucessivamente.


``` {.md}
# First-level heading / title

## Second level heading  

### Third-level heading
```

#### Marcadores e numeração {.unnumbered}

Use asteriscos (`*`) para criar uma lista de marcadores. Conclua a frase anterior, insira dois espaços, Enter/Return *duas vezes* e, em seguida, inicie seus marcadores. Inclua um espaço entre o asterisco e o texto do marcador. Após cada marcador, insira dois espaços e pressione Enter/Return. Os submarcadores funcionam da mesma maneira, mas são recuados. Os números funcionam da mesma maneira, mas em vez de um asterisco, escreva 1), 2), etc. Abaixo está a aparência do texto do script R Markdown.


``` {.md}
Here are my bullets (there are two spaces after this colon):  

* Bullet 1 (followed by two spaces and Enter/Return)  
* Bullet 2 (followed by two spaces and Enter/Return)  
  * Sub-bullet 1 (followed by two spaces and Enter/Return)  
  * Sub-bullet 2 (followed by two spaces and Enter/Return)  
  
```

#### Comente o texto {.unnumbered}

Você pode "comentar" o texto do R Markdown da mesma forma que pode usar o "#" para comentar uma linha do código R em um bloco R. Basta destacar o texto e pressionar Ctrl+Shift+c (Cmd+Shift+c para Mac). O texto será circundado por setas e ficará verde. Ele não aparecerá na sua saída.


```{r out.width = "100%", fig.align = "center", echo=F}
knitr::include_graphics(here::here("images", "markdown/rmarkdown_hide_text.png"))
```

### Blocos de código {.unnumbered}

As seções do script que são dedicadas à execução do código R são chamadas de "blocos". É aqui que você pode carregar pacotes, importar dados e realizar o gerenciamento e visualização de dados reais. Pode haver muitos blocos de código, então eles podem ajudá-lo a organizar seu código R em partes, talvez intercaladas com texto. Note: Esses 'pedaços' parecerão ter uma cor de fundo ligeiramente diferente da parte narrativa do documento.

Cada pedaço é aberto com uma linha que começa com três crases e chaves que contêm parâmetros para o pedaço (`{}`). O pedaço termina com mais três crases.

Você pode criar um novo bloco digitando-o você mesmo, usando o atalho de teclado "Ctrl+Alt+i" (ou Cmd+Shift+r no Mac) ou clicando no ícone verde 'inserir um novo bloco de código' no topo do seu editor de script.

Algumas notas sobre o conteúdo das chaves `{}`:

- Eles começam com 'r' para indicar que o nome do idioma dentro do bloco é R
- Após o r, você pode opcionalmente escrever um "nome" de trecho -- eles não são necessários, mas podem ajudá-lo a organizar seu trabalho. Observe que se você nomear seus blocos, você deve SEMPRE usar nomes exclusivos ou então R reclamará quando você tentar renderizar.\
- As chaves também podem incluir outras opções, escritas como `tag = value`, como:\
- `eval = FALSE` para não executar o código R\
- `echo = FALSE` para não imprimir o código-fonte R do trecho no documento de saída\
- `aviso = FALSO` para não imprimir avisos produzidos pelo código R\
- `mensagem = FALSO` para não imprimir nenhuma mensagem produzida pelo código R\
- `incluir =` VERDADEIRO / FALSO se incluir saídas em partes (por exemplo, gráficos) no documento
- `out.width =` e `out.height =` - fornecer no estilo `out.width ="75%"`\
- `fig.align = "center"` ajustar como uma figura é alinhada na página\
- `fig.show = 'hold'` se o seu pedaço imprimir várias figuras e você quiser que elas sejam impressas lado a lado (par com `out.width = c("33%", "67%")`. Também pode ser definido como `fig.show = 'asis'` para mostrá-los abaixo do código que os gera,`'hide'` para ocultar ou `'animate'` para concatenar múltiplos em uma animação.\
- Um cabeçalho de bloco deve ser escrito em *uma linha*\
- Tente evitar pontos, sublinhados e espaços. Use hifens ( - ) se precisar de um separador.

Leia mais extensivamente sobre as opções do **knitr** [aqui](https://yihui.org/knitr/options/).

Algumas das opções acima podem ser configuradas com apontar e clicar usando os botões de configuração no canto superior direito do bloco. Aqui, você pode especificar quais partes do pedaço você deseja que o documento renderizado inclua, a saber, o código, as saídas e os avisos. Isso sairá como preferências escritas dentro das chaves, por exemplo, `echo = FALSE` se você especificar que deseja 'Mostrar apenas a saída'.


```{r out.width = "80%", fig.align = "center", echo=F}
knitr::include_graphics(here::here("images", "markdown/3_chunk.png"))
```

Também há duas setas no canto superior direito de cada fragmento, que são úteis para executar o código dentro de um fragmento ou todo o código em blocos anteriores. Passe o mouse sobre eles para ver o que fazem.

Para que as opções globais sejam aplicadas a todos os fragmentos do script, você pode configurar isso em seu primeiro bloco de código R no script. Por exemplo, para que apenas as saídas sejam mostradas para cada bloco de código e não o código em si, você pode incluir este comando no fragmento de código R:


```{r, eval=F}
knitr::opts_chunk$set(echo = FALSE) 
```

#### Código R no texto {.unnumbered}

Você também pode incluir código R mínimo dentro de crases. Dentro dos crases, comece o código com "r" e um espaço, para que o RStudio saiba avaliar o código como código R. Veja o exemplo abaixo.

O exemplo abaixo mostra vários níveis de título, marcadores e usa o código R para a data atual (`Sys.Date ()`) para avaliar em uma data impressa.


```{r out.width = "80%", fig.align = "center", echo=F}
knitr::include_graphics(here::here("images", "markdown/2_text.png"))
```

O exemplo acima é simples (mostrando a data atual), mas usando a mesma sintaxe, você pode exibir valores produzidos por códigos R mais complexos (por exemplo, para calcular o mínimo, a mediana, o máximo de uma coluna). Você também pode integrar objetos R ou valores que foram criados em blocos de código R anteriormente no script.

Como exemplo, o script abaixo calcula a proporção de casos com menos de 18 anos, usando as funções **tidyverse**, e cria os objetos `less18`,` total` e `less18prop`. Este valor dinâmico é inserido no texto subsequente. Vemos como fica quando imprimimos um documento do Word.


```{r out.width = "100%", fig.align = "center", echo=F}
knitr::include_graphics(here::here("images", "markdown/3_chunktext.png"))
```

### Imagens {.numeradas}

Você pode incluir imagens em seu R Markdown de duas maneiras:

```{r, eval=F}
![]("path/to/image.png")  
```

Se o acima não funcionar, tente usar `knitr::include_graphics()`

```{r, eval=F}
knitr::include_graphics("path/to/image.png")
```


(lembre-se, o caminho do seu arquivo pode ser escrito usando o pacote **here**)

```{r, eval=F}
knitr::include_graphics(here::here("path", "to", "image.png"))
```

### Tabelas {.numeradas}

Crie uma tabela usando hifens ( - ) e barras ( | ). O número de hifens antes/entre as barras permite o número de espaços na célula antes que o texto comece a quebrar.


``` {.md}
Column 1 |Column  2 |Column 3
---------|----------|--------
Cell A   |Cell B    |Cell C
Cell D   |Cell E    |Cell F
```

O código acima produz a tabela abaixo:

| Column 1 | Column 2 | Column 3 |
|----------|----------|----------|
| Cell A   | Cell B   | Cell C   |
| Cell D   | Cell E   | Cell F   |

### Seções com guias {.numeradas}

Para saídas HTML, você pode organizar as seções em "guias". Basta adicionar `.tabset` nas chaves `{}`que são colocadas * após um título *. Quaisquer subtítulos abaixo desse título (até outro título do mesmo nível) aparecerão como guias nas quais o usuário pode clicar. Leia mais [aqui](https://bookdown.org/yihui/rmarkdown-cookbook/html-tabs.html)


```{r out.width = "100%", fig.align = "center", echo=F}
knitr::include_graphics(here::here("images", "markdown/tabbed_script.png"))
knitr::include_graphics(here::here("images", "markdown/tabbed_view.gif"))

```


Você pode adicionar uma opção adicional `.tabset-pills` após `.tabset` para dar às próprias guias uma aparência de pastilha. Esteja ciente de que, ao visualizar a saída HTML com guias, a funcionalidade de pesquisa Ctrl+f pesquisará apenas guias "ativas", não guias ocultas.


<!-- ======================================================= -->

## Estrutura do arquivo

Existem várias maneiras de estruturar seu R Markdown e quaisquer scripts R associados. Cada um tem vantagens e desvantagens:

- R Markdown independente - tudo o que é necessário para o relatório é importado ou criado dentro do R Markdown
- Fonte de outros arquivos - Você pode executar scripts R externos com o comando `source()` e usar suas saídas no Rmd 
- Scripts filhos - um mecanismo alternativo para `source()` 
- Utilizar um "runfile" - Executar comandos em um script R *antes* de renderizar o R Markdown

### Rmd independente {.não numerado}

Para um relatório relativamente simples, você pode optar por organizar seu script R Markdown de forma que seja "independente" e não envolva nenhum script externo.

Tudo que você precisa para executar o markdown R é importado ou criado dentro do arquivo Rmd, incluindo todos os pedaços de código e carregamento de pacote. Esta abordagem "independente" é apropriada quando você não precisa fazer muito processamento de dados (por exemplo, traz um arquivo de dados limpo ou semilimpeza) e a renderização do R Markdown não demora muito.

Neste cenário, uma organização lógica do script R Markdown pode ser:

1) Defina as opções globais do **knitr**
2) Carregar pacotes
3) Importar dados
4) Dados do processo
5) Produza resultados (tabelas, gráficos, etc.)
6) Salve as saídas, se aplicável (.csv, .png, etc.)

#### Fonte de outros arquivos {.unnumbered}

Uma variação da abordagem "independente" é fazer com que os pedaços de código do R Markdown "originem" (executem) outros scripts R. Isso pode tornar seu script R Markdown menos confuso, mais simples e mais fácil de organizar. Também pode ajudar se você deseja exibir os valores finais no início do relatório. Nesta abordagem, o script final R Markdown simplesmente combina saídas pré-processadas em um documento.

Uma maneira de fazer isso é fornecendo os scripts R (caminho e nome do arquivo com extensão) para o comando R **base** `source()`.


```{r, eval=F}
source("your-script.R", local = knitr::knit_global())
# or sys.source("your-script.R", envir = knitr::knit_global())
```

Observe que ao usar `source()` *dentro* do R Markdown, os arquivos externos ainda serão executados *durante o curso de renderização de seu arquivo Rmd*. Portanto, cada script é executado sempre que você renderiza o relatório. Portanto, ter esses comandos `source()` *dentro* do R Markdown não acelera seu tempo de execução, nem ajuda muito na eliminação de bugs, pois o erro produzido ainda será impresso ao produzir o R Markdown.

Uma alternativa é utilizar a opção `child =` **knitr**. EXPLIQUE MAIS A FAZER

Você deve estar ciente dos vários *ambientes* R. Os objetos criados dentro de um ambiente não estarão necessariamente disponíveis para o ambiente usado pelo R Markdown.

### Runfile {.unnumbered}

Esta abordagem envolve a utilização do script R que contém o (s) comando (s) `render()` para pré-processar objetos que alimentam o markdown R.

Por exemplo, você pode carregar os pacotes, carregar e limpar os dados e até mesmo criar os gráficos de interesse antes de `render()`. Essas etapas podem ocorrer no script R ou em outros scripts originados via source. Contanto que esses comandos ocorram na mesma sessão RStudio e os objetos sejam salvos no ambiente, os objetos podem ser chamados dentro do conteúdo Rmd. Em seguida, o próprio markdown R será usado apenas para a etapa final - para produzir a saída com todos os objetos pré-processados. Isso é muito mais fácil de corrigir se algo der errado.

Essa abordagem é útil pelos seguintes motivos:

- Mensagens de erro mais informativas - essas mensagens serão geradas a partir do script R, não do R Markdown. R Erros de Markdown tendem a dizer qual pedaço teve um problema, mas não revelam qual linha.
- Se aplicável, você pode executar longas etapas de processamento antes do comando `render()` - elas serão executadas apenas uma vez.

No exemplo abaixo, temos um script R separado no qual pré-processamos um objeto `data` no ambiente R e então renderizamos o "create_output.Rmd" usando `render()`.


```{r, eval=F}
data <- import("datafile.csv") %>%       # Load data and save to environment
  select(age, hospital, weight)          # Select limited columns

rmarkdown::render(input = "create_output.Rmd")   # Create Rmd file
```

### Estrutura da pasta {.numerada}

O fluxo de trabalho também diz respeito à estrutura geral da pasta, como ter uma pasta de 'saída' para documentos e figuras criados e pastas de 'dados' ou 'entradas' para dados limpos. Não entramos em maiores detalhes aqui, mas verifique a página [Organizando relatórios de rotina](#reportfactory).

## Produzindo o documento

Você pode produzir o documento das seguintes maneiras:

- Manualmente pressionando o botão "Knit" na parte superior do editor de script RStudio (rápido e fácil) \
- Execute o comando `render()` (executado fora do script R Markdown)

### Opção 1: Botão "Knit" {.numerado}

Quando você tiver o arquivo Rmd aberto, pressione o ícone / botão 'Knit' na parte superior do arquivo.

R Studio mostrará o progresso em uma guia 'R Markdown' perto do console R. O documento será aberto automaticamente quando concluído.

O documento será salvo na mesma pasta que seu script markdown R e com o mesmo nome de arquivo (exceto a extensão). Obviamente, isso não é ideal para o controle de versão (será sobrescrito a cada vez que você exportar, a menos que movido manualmente), pois você pode precisar renomear o arquivo (por exemplo, adicionar uma data).

Este é o botão de atalho do RStudio para a função `render()` de **rmarkdown**. Essa abordagem é compatível apenas com um R markdown autocontido, onde todos os componentes necessários existem ou são originados no arquivo.


```{r out.width = "90%", fig.align = "center", echo=F}
knitr::include_graphics(here::here("images", "markdown/4_progress.png"))
```

### Opção 2: comando `render()` {.unnumbered}

Outra maneira de produzir a saída do R Markdown é rodar a função `render()` (do pacote **rmarkdown**). Você deve executar este comando *fora* do script R Markdown - ou em um script R separado (geralmente chamado de "arquivo de execução") ou como um comando independente no R Console.

```{r, eval=F}
rmarkdown::render(input = "my_report.Rmd")
```

Tal como acontece com "knit", as configurações padrão salvarão a saída Rmd na mesma pasta do script Rmd, com o mesmo nome de arquivo (além da extensão do arquivo). Por exemplo, "my_report.Rmd" quando exportado criará "my_report.docx" se você estiver exportando para um documento do Word. No entanto, usando `render()` você tem a opção de usar configurações diferentes. `render()` pode aceitar argumentos, incluindo:

- `output_format =` Este é o formato de saída para converter (por exemplo, `"html_document"`, `"pdf_document"`, `"word_document"` ou `"all"`). Você também pode especificar isso no YAML dentro do script R Markdown. \
- `output_file =` Este é o nome do arquivo de saída (e caminho do arquivo). Isso pode ser criado por meio de funções R como `here()` ou `str_glue()` conforme demonstrado abaixo. \
- `output_dir =` Este é um diretório de saída (pasta) para salvar o arquivo. Isso permite que você escolha uma alternativa diferente do diretório em que o arquivo Rmd é salvo. \
- `output_options =` Você pode fornecer uma lista de opções que irão sobrescrever aquelas no script YAML (por exemplo)
- `output_yaml =` Você pode fornecer o caminho para um arquivo .yml que contém especificações YAML \
- `params =` Veja a seção sobre parâmetros abaixo \
- Veja a lista completa [aqui](https://pkgs.rstudio.com/rmarkdown/reference/render.html)

Como um exemplo, para melhorar o controle de versão, o comando a seguir salvará o arquivo de saída dentro de uma subpasta 'outputs', com a data atual no nome do arquivo. Para criar o nome do arquivo, a função `str_glue()` do pacote **stringr** é usada para 'colar' strings estáticas (escritas de forma simples) com código R dinâmico (escrito entre colchetes). Por exemplo, se for 10 de abril de 2021, o nome do arquivo abaixo será "Report_2021-04-10.docx". Veja a página em [Caracteres e strings](#characters-strings) para mais detalhes sobre `str_glue()`.


```{r, eval=F}
rmarkdown::render(
  input = "create_output.Rmd",
  output_file = stringr::str_glue("outputs/Report_{Sys.Date()}.docx")) 
```

À medida que o arquivo é renderizado, o console do RStudio mostrará o andamento da renderização em até 100% e uma mensagem final para indicar que a renderização foi concluída.

### Opções 3: pacote **reportfactory** {.unnumbered}

O pacote R **reportfactory** oferece um método alternativo de organização e compilação de relatórios R Markdown *voltados para cenários onde você executa relatórios rotineiramente (por exemplo, diariamente, semanalmente ...).* Facilita a compilação de vários arquivos R Markdown e o organização de seus resultados. Em essência, ele fornece uma "fábrica" a partir da qual você pode executar os relatórios R Markdown, obter pastas com carimbo de data e hora automaticamente para as saídas e ter controle de versão "leve".

Leia mais sobre esse fluxo de trabalho na página [Organização de relatórios de rotina](#reportfactory).

<!-- ======================================================= -->

## Relatórios parametrizados

Você pode usar a parametrização para tornar um relatório dinâmico, de modo que possa ser executado com uma configuração específica (por exemplo, uma data ou local específico ou com certas opções de knit). Abaixo, nos concentramos no básico, mas há mais [detalhes online](https://bookdown.org/yihui/rmarkdown/parameterized-reports.html) sobre relatórios parametrizados.

Usando a lista de linha do Ebola como exemplo, digamos que queremos executar um relatório de vigilância padrão para cada hospital a cada dia. Mostramos como fazer isso usando parâmetros.

*Importante: relatórios dinâmicos também são possíveis sem a estrutura formal de parâmetros (sem `params:`), usando objetos R simples em um script R adjacente. Isso é explicado no final desta seção.*

### Configurando parâmetros {.unnumbered}

Você tem várias opções para especificar valores de parâmetro para sua saída R Markdown.

#### Opção 1: Defina os parâmetros em YAML {.unnumbered}

Edite o YAML para incluir uma opção `params:`, com declarações recuadas para cada parâmetro que você deseja definir. Neste exemplo, criamos os parâmetros `data` e` hospital`, para os quais especificamos valores. Esses valores estão sujeitos a alterações cada vez que o relatório é executado. Se você usar o botão "Knit" para produzir a saída, os parâmetros terão esses valores padrão. Da mesma forma, se você usar `render()` os parâmetros terão esses valores padrão, a menos que seja especificado de outra forma no comando `render()`.


``` {.yaml}
---
title: Surveillance report
output: html_document
params:
 date: 2021-04-10
 hospital: Central Hospital
---

```

Em segundo plano, esses valores de parâmetro estão contidos em uma lista somente leitura chamada `params`. Assim, você pode inserir os valores dos parâmetros no código R da mesma forma que faria com outro objeto / valor R em seu ambiente. Simplesmente digite `params$` seguido do nome do parâmetro. Por exemplo, `params$hospital` para representar o nome do hospital ("Hospital Central" por padrão).

Observe que os parâmetros também podem conter valores `true` ou `false` e, portanto, podem ser incluídos nas opções do **knitr** para um bloco R. Por exemplo, você pode definir `{r, eval = params$run}` em vez de `{r, eval = FALSE}`, e agora se o trecho é executado ou não depende do valor de um parâmetro `run:`.

Observe que para os parâmetros que são datas, eles serão inseridos como uma string. Portanto, para que `params$date` seja interpretado no código R, ele provavelmente precisará ser empacotado com `as.Date()` ou uma função semelhante para converter para a classe Date.

#### Opção 2: Defina os parâmetros em `render()` {.unnumbered}

Como mencionado acima, uma alternativa para pressionar o botão "Knit" para produzir a saída é executar a função `render()` a partir de um script separado. Neste último caso, você pode especificar os parâmetros a serem usados naquela renderização para o argumento `params =` de `render()`.

Observe que quaisquer valores de parâmetro fornecidos aqui irão *sobrescrever* seus valores padrão se escritos dentro do YAML. Escrevemos os valores entre aspas, pois neste caso eles devem ser definidos como valores de caractere / string.

O comando abaixo renderiza "monitoramento_report.Rmd", especifica um nome de arquivo de saída dinâmica e pasta, e fornece uma `list()` de dois parâmetros e seus valores para o argumento `params =`.


```{r, eval=F}
rmarkdown::render(
  input = "surveillance_report.Rmd",  
  output_file = stringr::str_glue("outputs/Report_{Sys.Date()}.docx"),
  params = list(date = "2021-04-10", hospital  = "Central Hospital"))
```

#### Opção 3: Defina os parâmetros usando uma interface gráfica do usuário {.unnumbered}

Para uma sensação mais interativa, você também pode usar a Interface Gráfica do Usuário (GUI) para selecionar manualmente os valores dos parâmetros. Para fazer isso, podemos clicar no menu suspenso ao lado do botão 'Knit' e escolher 'Knit com parâmetros'.

Um pop-up aparecerá permitindo que você digite valores para os parâmetros que são estabelecidos no YAML do documento.


```{r out.width = "50%", fig.align = "center", echo=F}
knitr::include_graphics(here::here("images", "markdown/5_parametersGUI.png"))
```


Você pode conseguir o mesmo por meio de um comando `render()` especificando `params = "ask "`, como demonstrado abaixo.

```{r, eval=F}
rmarkdown::render(
  input = "surveillance_report.Rmd",  
  output_file = stringr::str_glue("outputs/Report_{Sys.Date()}.docx"),
  params = “ask”)
```

No entanto, digitar valores nesta janela pop-up está sujeito a erros e erros ortográficos. Você pode preferir adicionar restrições aos valores que podem ser inseridos nos menus suspensos. Você pode fazer isso adicionando no YAML várias especificações para cada entrada `params:`.

- `label:` é como o título para aquele menu suspenso específico 
- `value:` é o valor padrão (inicial) 
- `input:` definido como `select` para o menu suspenso 
- `choices:` Dê os valores elegíveis no menu suspenso

Abaixo, essas especificações são escritas para o parâmetro `hospital`.

``` {.yaml}
---
title: Surveillance report
output: html_document
params:
 date: 2021-04-10
 hospital: 
  label: “Town:”
  value: Central Hospital
  input: select
  choices: [Central Hospital, Military Hospital, Port Hospital, St. Mark's Maternity Hospital (SMMH)]
---
```

Ao exportar (através do botão 'knit com parâmetros' ou por `render()`), a janela pop-up terá opções suspensas para selecionar.

```{r out.width = "50%", fig.align = "center", echo=F}
knitr::include_graphics(here::here("images", "markdown/5_parametersGUIB.png"))
```

### Exemplo parametrizado {.unnumbered}

O código a seguir cria parâmetros para `data` e` hospital`, que são usados no R Markdown como `params$date` e `params$hospital`, respectivamente.

Na saída do relatório resultante, veja como os dados são filtrados para o hospital específico e o título do gráfico se refere ao hospital e à data corretos. Usamos o arquivo "linelist_cleaned.rds" aqui, mas seria particularmente apropriado se a própria lista de linha também tivesse um carimbo de data para alinhar com a data parametrizada.


```{r out.width = "100%", fig.align = "center", echo=F}
knitr::include_graphics(here::here("images", "markdown/6_Rmdexample.png"))
```

Exportar isso produz a saída final com a fonte e o layout padrão.

```{r out.width = "80%", fig.align = "center", echo=F}
knitr::include_graphics(here::here("images", "markdown/6_RmdexampleB.png"))
```

### Parametrização sem `params` {.unnumbered}

Se você estiver renderizando um arquivo R Markdown com `render()` de um script separado, você pode criar o impacto da parametrização sem usar a funcionalidade `params:`.

Por exemplo, no *script R* que contém o comando `render()`, você pode simplesmente definir `hospital` e `date` como dois objetos R (valores) antes do comando `render()`. No R Markdown, você não precisaria ter uma seção `params:` no YAML, e nos referiríamos ao objeto `date` ao invés de `params$date` e `hospital` ao invés de` params$hospital`.



```{r, eval=F}
# This is a R script that is separate from the R Markdown

# define R objects
hospital <- "Central Hospital"
date <- "2021-04-10"

# Render the R markdown
rmarkdown::render(input = "create_output.Rmd") 
```

Seguir essa abordagem significa que você não pode "tricotar com parâmetros", usar a GUI ou incluir opções de knit dentro dos parâmetros. No entanto, permite um código mais simples, o que pode ser vantajoso.

<!-- ======================================================= -->

## Reiterando relatórios

Podemos querer executar um relatório várias vezes, variando os parâmetros de entrada, para produzir um relatório para cada jurisdição / unidade. Isso pode ser feito usando ferramentas para *iteração*, que são explicadas em detalhes na página [Iteração, loops e listas](#iteration). As opções incluem o pacote **purrr** ou o uso de um *for loop* conforme explicado abaixo.

Abaixo, usamos um simples *for loop* para gerar um relatório de vigilância para todos os hospitais de interesse. Isso é feito com um comando (em vez de alterar manualmente o parâmetro do hospital um por vez). O comando para renderizar os relatórios deve existir em um script separado *fora* do relatório Rmd. Este script também conterá objetos definidos para "fazer um loop" - a data de hoje e um vetor de nomes de hospitais para fazer o loop.


```{r, eval=F}
hospitals <- c("Central Hospital",
                "Military Hospital", 
                "Port Hospital",
                "St. Mark's Maternity Hospital (SMMH)") 
```

Em seguida, alimentamos esses valores um de cada vez no comando `render()` usando um loop, que executa o comando uma vez para cada valor no vetor `hospitais`. A letra `i` representa a posição do índice (1 a 4) do hospital que está sendo usado nessa iteração, de modo que `hospital_list[1]` seria "Hospital Central". Esta informação é fornecida em dois lugares no comando `render()`:

1) Para o nome do arquivo, de forma que o nome do arquivo da primeira iteração, se produzido em 10 de abril de 2021, seria "Report_Central Hospital_2021-04-10.docx", salvo na subpasta 'output' do diretório de trabalho. \
2) Para `params =` tal que o Rmd use o nome do hospital internamente sempre que o valor `params$hospital` é chamado (por exemplo, para filtrar o conjunto de dados para o hospital específico apenas). Neste exemplo, quatro arquivos seriam criados - um para cada hospital.


```{r, eval=F}
for(i in 1:length(hospitals)){
  rmarkdown::render(
    input = "surveillance_report.Rmd",
    output_file = str_glue("output/Report_{hospitals[i]}_{Sys.Date()}.docx"),
    params = list(hospital  = hospitals[i]))
}       
```

 <!-- No cenário em que você não está usando esta forma estrita de parametrização, mas salvando objetos no ambiente, conforme discutido no final da seção de parametrização, a função de renderização ficaria assim:  -->

<!-- ```md -->

<!-- for(i in 1:length(hospital_list)){ -->

<!-- rmarkdown::render("surveillance_report.Rmd", -->

<! - output_file = paste0 ("output / Report_", hospital_list [i], refdate, ".docx") ->

<!-- }        -->

<!-- ``` -->

<! - O texto dentro da marcação precisaria então se referir a `hospital_list [i]` e `refdate`. ->

<!-- ======================================================= -->

## Modelos

Usando um documento de modelo que contém qualquer formatação desejada, você pode ajustar a estética de como a saída Rmd ficará. Você pode criar, por exemplo, um arquivo MS Word ou PowerPoint que contenha páginas / slides com as dimensões, marcas d'água, planos de fundo e fontes desejados.

### Documentos do Word {.numerados}

Para criar um modelo, inicie um novo documento do Word (ou use uma saída existente com a formatação que mais lhe convier) e edite as fontes definindo os Estilos. Em Estilo, os títulos 1, 2 e 3 referem-se aos vários níveis de cabeçalho de redução (`# Cabeçalho 1`, `## Cabeçalho 2` e `### Cabeçalho 3` respectivamente). Clique com o botão direito no estilo e clique em 'modificar' para alterar a formatação da fonte, bem como o parágrafo (por exemplo, você pode introduzir quebras de página antes de certos estilos que podem ajudar com o espaçamento). Outros aspectos do documento do Word, como margens, tamanho da página, cabeçalhos, etc., podem ser alterados como um documento do Word normal no qual você está trabalhando diretamente.


```{r out.width = "100%", fig.align = "center", echo=F}
knitr::include_graphics(here::here("images", "markdown/7_template.png"))
```


### Documentos do PowerPoint {.numerados}

Como acima, crie um novo conjunto de slides ou use um arquivo PowerPoint existente com a formatação desejada. Para outras edições, clique em 'Exibir' e 'Slide Master'. A partir daqui, você pode alterar a aparência do slide 'mestre' editando a formatação do texto nas caixas de texto, bem como as dimensões do plano de fundo / página para a página geral.


```{r out.width = "100%", fig.align = "center", echo=F}
knitr::include_graphics(here::here("images", "markdown/8_ppttemplate.PNG"))
```

Infelizmente, editar arquivos PowerPoint é um pouco menos flexível:

- Um cabeçalho de primeiro nível (`# Cabeçalho 1`) se tornará automaticamente o título de um novo slide,
- Um texto de `## Header 2` não aparecerá como uma legenda, mas como um texto dentro da caixa de texto principal do slide (a menos que você encontre uma maneira de manipular a visualização mestre).
- Plotagens e tabelas geradas irão automaticamente para novos slides. Você precisará combiná-los, por exemplo, a função **patchwork** para combinar ggplots, de modo que apareçam na mesma página. Veja esta [postagem no blog](https://mattherman.info/blog/ppt-patchwork/) sobre como usar o pacote **patchwork** para colocar várias imagens em um slide.

Veja o [pacote **officer**](https://davidgohel.github.io/officer/) para uma ferramenta para trabalhar mais a fundo com apresentações em PowerPoint.

### Integração de modelos no YAML {.unnumbered}

Uma vez que um modelo é preparado, o detalhe disso pode ser adicionado no YAML do Rmd abaixo da linha de 'output' e abaixo de onde o tipo de documento é especificado (que vai para uma linha separada). Nota `reference_doc` pode ser usado para modelos de slides do PowerPoint.

É mais fácil salvar o modelo na mesma pasta onde está o arquivo Rmd (como no exemplo abaixo) ou em uma subpasta.

``` {.yaml}
---
title: Surveillance report
output: 
 word_document:
  reference_docx: "template.docx"
params:
 date: 2021-04-10
 hospital: Central Hospital
template:
 
---
```

### Formatando arquivos HTML {.unnumbered}

Os arquivos HTML não usam modelos, mas podem ter os estilos configurados no YAML. HTMLs são documentos interativos e são particularmente flexíveis. Cobrimos algumas opções básicas aqui.

- Índice: Podemos adicionar um índice com `toc: true` abaixo, e também especificar que ele permanece visível ("floats") conforme você rola, com `toc_float: true`.

- Temas: Podemos nos referir a alguns temas pré-fabricados, que vêm de uma biblioteca de temas Bootswatch. No exemplo abaixo, usamos cerulean. Outras opções incluem: diário, plano, escuro, legível, laboratório espacial, unido, cosmo, lúmen, papel, arenito, simplex e yeti. No original, journal, flatly, darkly, readable, spacelab, united, cosmo, lumen, paper, sandstone, simplex, e yeti

- Realçar: Configurar isso muda a aparência do texto destacado (por exemplo, código dentro dos pedaços que são mostrados). Os estilos suportados incluem default, tango, pygments, kate, monochrome, espresso, zenburn, haddock, breezedark, e textmate.

Aqui está um exemplo de como integrar as opções acima no YAML.

``` {.yaml}
---
title: "HTML example"
output:
  html_document:
    toc: true
    toc_float: true
    theme: cerulean
    highlight: kate
    
---
```

Abaixo estão dois exemplos de saídas HTML, ambas com índices flutuantes, mas diferentes temas e estilos de destaque selecionados:

```{r out.width = "100%", fig.align = "center", echo=F}
knitr::include_graphics(here::here("images", "markdown/9_html.png"))
```

## Conteúdo dinâmico

Em uma saída HTML, o conteúdo do seu relatório pode ser dinâmico. Abaixo estão alguns exemplos:

### Tabelas {.numeradas}

Em um relatório HTML, você pode imprimir quadros / tabelas de dados de forma que o conteúdo seja dinâmico, com filtros e barras de rolagem. Existem vários pacotes que oferecem esse recurso.

Para fazer isso com o pacote **DT**, como é usado em todo este manual, você pode inserir um trecho de código como este:


```{r out.width = "100%", fig.align = "center", echo=F}
knitr::include_graphics(here::here("images", "markdown/10_dynamictable.png"))
```

A função `datatable()` imprimirá o quadro de dados fornecido como uma tabela dinâmica para o leitor. Você pode definir `rownames = FALSE` para simplificar o lado esquerdo da tabela. `filter = "top"` fornece um filtro para cada coluna. No argumento `option()` forneça uma lista de outras especificações. Abaixo, incluímos dois: `pageLength = 5` define o número de linhas que aparecem como 5 (as linhas restantes podem ser visualizadas através das setas), e `scrollX = TRUE` habilita uma barra de rolagem na parte inferior da tabela (para colunas que se estendem muito para a direita).

Se seu conjunto de dados for muito grande, considere mostrar apenas as primeiras X linhas envolvendo o quadro de dados em `head()`.

### Widgets HTML {.unnumbered}

[HTML widgets for R] (http://www.htmlwidgets.org/) são uma classe especial de pacotes R que permitem maior interatividade utilizando bibliotecas JavaScript. Você pode embuti-los nas saídas HTML R Markdown.

Alguns exemplos comuns desses widgets incluem:

- Plotly (usado nesta página do manual e na página [Gráficos interativos](#interactive-plots))
- visNetwork (usado na página [Cadeias de transmissão](#transmission-chains) deste manual) 
- Folheto (usado na página [Noções básicas de GIS](#gis) deste manual) 
- dygraphs (úteis para mostrar dados de séries temporais de forma interativa) 
- DT (`datatable()`) (usado para mostrar tabelas dinâmicas com filtro, classificação, etc.)

A função `ggplotly()` de **plotly** é particularmente fácil de usar. Veja a página [Gráficos interativos](#interactive-plots).

## Recursos

Mais informações podem ser encontradas em:

-   <https://bookdown.org/yihui/rmarkdown/>
-   <https://rmarkdown.rstudio.com/articles_intro.html>

Uma boa explicação de markdown vs knitr vs Rmarkdown está aqui: <https://stackoverflow.com/questions/40563479/relationship-between-r-markdown-knitr-pandoc-and-bookdown>

```{r include=FALSE, cache=FALSE}

# clear workspace
rm(list = ls(all = TRUE))

# clear all packages except base
#lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))

# to ensure that tidyverse packages prevail
filter <- dplyr::filter
select <- dplyr::select
summarise <- dplyr::summarise
summary <- base::summary
incidence <- incidence2::incidence

#load core packages
pacman::p_load(
     rio,
     here,
     DT,
     stringr,
     lubridate,
     tidyverse
)

# import the cleaned ebola linelist
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

# import the count data - facility level
#count_data <- rio::import(here::here("data", "facility_count_data.rds"))

# Settings

options(scipen=1, digits=7)

# print only text (not code)
# library(knitr)
# opts_chunk$set(list(echo = FALSE, eval = FALSE))
```

<!--chapter:end:new_pages/rmarkdown.Rmd-->



# Organização de relatórios de rotina {#reportfactory}  

Esta página cobre o pacote **reportfactory**, que é um *acompanhamento do uso do R Markdown para relatórios*. 

Em cenários onde você executa relatórios rotineiramente (diariamente, semanalmente, etc.), isso facilita a compilação de vários arquivos R Markdown e a organização de seus resultados. Em essência, ele fornece uma "fábrica" a partir da qual você pode executar os relatórios R Markdown, obter pastas com carimbo de data e hora automaticamente para as saídas e ter controle de versão "leve".  

**reportfactory** é um dos pacotes desenvolvidos pelo RECON (R Epidemics Consortium). Aqui está o [site](https://www.repidemicsconsortium.org/) e [Github](https://github.com/reconverse).  


## Preparação

### Carregar pacotes {.unnumbered}  

De dentro do RStudio, instale a versão mais recente do pacote **reportfactory** do Github.  

Você pode fazer isso através do pacote **pacman** com `p_load_current_gh ()` que forçará a instalação da última versão do Github. Forneça a cadeia de caracteres "reconverse/reportfactory", que especifica a organização Github (reconverse) e o repositório (reportfactory). Você também pode usar `install_github ()` do pacote **remotes**, como alternativa.

```{r, eval = FALSE}
# Instale e carregue a última versão do pacote do Github
pacman::p_load_current_gh("reconverse/reportfactory")
#remotes::install_github("reconverse/reportfactory") # alternative
```


## Nova fábrica  

Para criar uma nova fábrica, execute a função `new_factory()`. Isso criará uma nova pasta de projeto R independente. Por padrão:  

* A fábrica será adicionada ao seu diretório de trabalho
* O nome do projeto de fábrica R será denominado "new_factory.Rproj"  
* Sua sessão RStudio irá "mover-se" para este projeto R  

```{r, eval=F}
# Isso criará a fábrica no diretório de trabalho
new_factory()
```

Olhando dentro da fábrica, você pode ver que as subpastas e alguns arquivos foram criados automaticamente.  


```{r, warning=F, message=F, echo=F}
knitr::include_graphics(here::here("images", "factory_new2.png"))
```

* A pasta *report_sources* manterá seus scripts R Markdown, que geram seus relatórios  
* A pasta * outputs * conterá os resultados do relatório (por exemplo, HTML, Word, PDF, etc.)  
* A pasta *scripts* pode ser usada para armazenar outros scripts R (por exemplo, que são fornecidos por seus scripts Rmd)  
* A pasta *data* pode ser usada para armazenar seus dados (subpastas "brutas" e "limpas" estão incluídas)  
* Um arquivo *.here*, para que você possa usar o pacote **here** para chamar arquivos em subpastas por sua relação com esta pasta raiz (consulte a página [Projetos R](#r-projects) para obter detalhes)  
* Um arquivo *gitignore* foi criado no caso de você vincular este projeto R a um repositório Github (consulte [Controle de versão e colaboração com Github](#collaboration))  
* Um arquivo README vazio, se você usar um repositório Github  


<span style = "color: orange;"> **_ CUIDADO: _** dependendo da configuração do seu computador, arquivos como ".here" podem existir, mas são invisíveis. </span>  

Das configurações padrão, abaixo estão várias que você pode querer ajustar dentro do comando `new_factory ()`:  

* `factory =` - Fornece um nome para a pasta de fábrica (o padrão é "new_factory")  
* `path =` - Designa um caminho de arquivo para a nova fábrica (o padrão é o diretório de trabalho)  
* `report_sources =` Fornece um nome alternativo para a subpasta que contém os scripts R Markdown (o padrão é "report_sources")  
* `outputs =` Fornece um nome alternativo para a pasta que contém os resultados do relatório (o padrão é "outputs")  

Veja `?New_factory` para uma lista completa dos argumentos.  


Quando você cria a nova fábrica, sua sessão R é transferida para o novo projeto R, então você deve carregar novamente o pacote **reportfactory**.  

```{r, eval = FALSE}
pacman::p_load(reportfactory)
```

Agora você pode executar o comando `factory_overview()` para ver a estrutura interna (todas as pastas e arquivos) na fábrica.  

```{r, eval=F}
factory_overview() # imprime visão geral da fábrica para o console
```

A seguinte "árvore" das pastas e arquivos da fábrica é impressa no console R. Observe que na pasta "dados" existem subpastas para dados "brutos" e "limpos" e dados CSV de exemplo. Também existe "example_report.Rmd" na pasta "report_sources".    

```{r, warning=F, message=F, echo=F}
knitr::include_graphics(here::here("images", "factory_overview.png"))
```


## Crie um relatório  

De dentro do projeto R de fábrica, crie um relatório R Markdown como faria normalmente e salve-o na pasta "report_sources". Consulte a página [R Markdown](#rmarkdown) para obter instruções. Para fins de exemplo, adicionamos o seguinte à fábrica:  

* Um novo script de markdown R intitulado "daily_sitrep.Rmd", salvo na pasta "report_sources"  
* Dados para o relatório ("linelist_cleaned.rds"), salvos na subpasta "clean" dentro da pasta "data"  

Podemos ver usando `factory_overview()` nosso R Markdown na pasta "report_sources" e o arquivo de dados na pasta de dados "clean" (destacado):

```{r, warning=F, message=F, echo=F}
knitr::include_graphics(here::here("images", "factory_overview2.png"))
```

Abaixo está uma captura de tela do início do R Markdown "daily_sitrep.Rmd". Você pode ver que o formato de saída é definido como HTML, por meio do cabeçalho YAML `output: html_document`. 

```{r, warning=F, message=F, echo=F}
knitr::include_graphics(here::here("images", "factory_new_rmd.png"))
```

Neste script simples, existem comandos para:  

* Carregar os pacotes necessários  
* Importar os dados de lista de linha usando um caminho de arquivo do pacote **here** (leia mais na página em [Importar e exportar](#importing))  

```{r, eval=F}
linelist <- import(here("data", "clean", "linelist_cleaned.rds"))
```

* Imprima uma tabela de resumo de casos e exporte-a com `export()` como um arquivo .csv  
* Imprima uma epicurva e exporte-a com `ggsave()` como um arquivo .png  


Você pode revisar apenas a lista de relatórios R Markdown na pasta "report_sources" com este comando:  

```{r, eval=F}
list_reports()
```



## Compilar  

Em uma fábrica de relatórios, "compilar" um relatório R Markdown significa que o script .Rmd será executado e a saída será produzida (conforme especificado no script YAML, por exemplo, como HTML, Word, PDF, etc).  

*A fábrica criará automaticamente uma pasta com carimbo de data e hora para as saídas na pasta "saídas".*  

O próprio relatório e todos os arquivos exportados produzidos pelo script (por exemplo, csv, png, xlsx) serão salvos nesta pasta. Além disso, o próprio script Rmd será salvo nesta pasta, então você tem um registro dessa versão do script.  

Isso contrasta com o comportamento normal de um R Markdown "knitado" ou "tricotado", que salva as saídas no local do script Rmd. Esse comportamento padrão pode resultar em pastas lotadas e confusas. A fábrica visa melhorar a organização quando é necessário executar relatórios com frequência.  

### Compilar por nome {.unnumbered}  

Você pode compilar um relatório específico executando `compile_reports()` e fornecendo o nome do script Rmd (sem extensão .Rmd) para `reports =`. Para simplificar, você pode pular o `reports =` e apenas escrever o nome R Markdown entre aspas, como abaixo.  

```{r, warning=F, message=F, echo=F}
knitr::include_graphics(here::here("images", "factory_compile1.png"))
```


Este comando compilaria apenas o relatório "daily_sitrep.Rmd", salvando o relatório HTML e as exportações da tabela .csv e epicurva .png para uma subpasta com carimbo de data e hora específica para o relatório, dentro da pasta "outputs".  

Observe que se você optar por fornecer a extensão .Rmd, deverá digitar corretamente a extensão conforme ela é salva no nome do arquivo (.rmd vs. .Rmd).  

Observe também que, ao compilar, você pode ver vários arquivos aparecerem temporariamente na pasta "report_sources" - mas eles irão desaparecer em breve, pois são transferidos para a pasta "outputs" correta. 

### Compilar por número {.unnumbered}

Você também pode especificar o script Rmd para compilar, fornecendo um número ou vetor de números para `relatórios =`. Os números devem estar alinhados com a ordem em que os relatórios aparecem quando você executa `list_reports()`.  

```{r, eval=F}
# Compile o segundo e o quarto Rmds na pasta "report_sources"
compile_reports(reports = c(2, 4))
```



### Compilar todos {.unnumbered}

Você pode compilar *todos* os relatórios R Markdown na pasta "report_sources" definindo o argumento `reports =` para TRUE.  

```{r, warning=F, message=F, echo=F}
knitr::include_graphics(here::here("images", "factory_compile_all.png"))
```


### Compilar da subpasta {.unnumbered}  

Você pode adicionar subpastas à pasta "report_sources". Para executar um relatório R Markdown de uma subpasta, simplesmente forneça o nome da pasta para `subpasta =`. Abaixo está um exemplo de código para compilar um relatório Rmd que reside em uma subpasta de "report_sources".  

```{r, eval=F}
compile_reports(
     reports = "summary_for_partners.Rmd",
     subfolder = "for_partners")
```

Você pode compilar todos os relatórios Rmd dentro de uma subpasta fornecendo o nome da subpasta para `reports =`, com uma barra no final, como abaixo.  

```{r, eval=F}
compile_reports(reports = "for_partners/")
```


### Parametrização {.unnumbered}

Conforme observado na página em [Relatórios com R Markdown](#rmarkdown), você pode executar relatórios com parâmetros especificados. Você pode passar esses parâmetros como uma lista para `compile_reports()` através do argumento `params =`. Por exemplo, neste relatório fictício, há três parâmetros fornecidos para os relatórios R Markdown.  

```{r, eval=F}
compile_reports(
  reports = "daily_sitrep.Rmd",
  params = list(most_recent_data = TRUE,
                region = "NORTHERN",
                rates_denominator = 10000),
  subfolder = "regional"
)
```


### Usando um "arquivo de execução" {.unnumbered}  

Se você tiver vários relatórios para executar, considere a criação de um script R que contenha todos os comandos de `compile_reports ()`. Um usuário pode simplesmente executar todos os comandos neste script R e todos os relatórios serão compilados. Você pode salvar este "arquivo de execução" na pasta "scripts".  



## Saídas  

Depois de termos compilado os relatórios algumas vezes, a pasta "outputs" pode ter a seguinte aparência (destaques adicionados para maior clareza):  


```{r, warning=F, message=F, echo=F}
knitr::include_graphics(here::here("images", "factory_overview_all.png"))
```


* Dentro de "saídas", subpastas foram criadas para cada relatório Rmd  
* Dentro delas, outras subpastas foram criadas para cada compilação única  
  * Estes são marcados com data e hora ("2021-04-23_T11-07-36" significa 23 de abril de 2021 às 11:07:36)  
  * Você pode editar o formato do carimbo de data / hora. Veja `?Compile_reports`
* Dentro de cada pasta compilada de data / hora, a saída do relatório é armazenada (por exemplo, HTML, PDF, Word) junto com o script Rmd (controle de versão!) e quaisquer outros arquivos exportados (por exemplo, table.csv, epidemic_curve.png)  

Aqui está uma visão dentro de uma das pastas com carimbo de data / hora, para o relatório "daily_sitrep". O caminho do arquivo é destacado em amarelo para ênfase.  

```{r, warning=F, message=F, echo=F}
knitr::include_graphics(here::here("images", "factory_compile_folder.png"))
```


Finalmente, abaixo está uma captura de tela da saída do relatório HTML.  


```{r, warning=F, message=F, echo=F}
knitr::include_graphics(here::here("images", "factory_html.png"))
```

Você pode usar `list_outputs()` para revisar uma lista das saídas.  




## Diversos  

### Knit {.numerado} 

Você ainda pode "tricotar" um de seus relatórios R Markdown pressionando o botão "Knit", se desejar. Se você fizer isso, como padrão, as saídas aparecerão na pasta onde o Rmd foi salvo - a pasta "report_sources". Nas versões anteriores do **reportfactory**, ter qualquer arquivo não-Rmd em "report_sources" impedia a compilação, mas não é mais o caso. Você pode executar `compile_reports()` e nenhum erro ocorrerá.  

### Scripts {.unnumbered}  

Incentivamos você a utilizar a pasta "scripts" para armazenar "arquivos de execução" ou scripts .R originados de seus scripts .Rmd. Consulte a página em [R Markdown](#rmarkdown) para dicas sobre como estruturar seu código em vários arquivos.  


### Extras {.unnumbered} 

* Com **reportfactory**, você pode usar a função `list_deps()` para listar todos os pacotes necessários em todos os relatórios em toda a fábrica.  

* Há um pacote de acompanhamento em desenvolvimento chamado **rfextras** que oferece mais funções auxiliares para auxiliá-lo na construção de relatórios, como:  
  * `load_scripts()` - origina / carrega todos os scripts .R em uma determinada pasta (a pasta "scripts" por padrão)  
  * `find_latest()` - encontra a versão mais recente de um arquivo (por exemplo, o conjunto de dados mais recente)




<!-- ======================================================= -->
## Recursos { }

Veja o pacote **reportfactory** [página Github](https://github.com/reconverse/reportfactory)

Veja o pacote **rfextras** [página Github](https://github.com/reconhub/rfextras)  

```{r include=FALSE, cache=FALSE}

# clear workspace
rm(list = ls(all = TRUE))

# clear all packages except base
#lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))

# to ensure that tidyverse packages prevail
filter <- dplyr::filter
select <- dplyr::select
summarise <- dplyr::summarise
summary <- base::summary
incidence <- incidence2::incidence

#load core packages
pacman::p_load(
     rio,
     here,
     DT,
     stringr,
     lubridate,
     tidyverse
)

# import the cleaned ebola linelist
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

# import the count data - facility level
#count_data <- rio::import(here::here("data", "facility_count_data.rds"))

# Settings

options(scipen=1, digits=7)

# print only text (not code)
# library(knitr)
# opts_chunk$set(list(echo = FALSE, eval = FALSE))
```

<!--chapter:end:new_pages/reportfactory.Rmd-->


# Painéis (Dashboards) com R Markdown {#flexdashboard}

```{r out.width = "100%", fig.align = "center", echo=F}
knitr::include_graphics(here::here("images", "flexdashboard_output.png"))
```

Esta página cobrirá o uso básico do pacote **flexdashboard**. Este pacote permite que você formate facilmente a saída do R Markdown como um painel com painéis e páginas. O conteúdo do painel pode ser texto, figuras / tabelas estáticas ou gráficos interativos.  

Vantagens do **flexdashboard**:  

* Requer um mínimo de codificação R fora do padrão - com muito pouca prática, você pode criar rapidamente um painel  
* O painel geralmente pode ser enviado por e-mail para colegas como um arquivo HTML independente - nenhum servidor é necessário  
* Você pode combinar **flexdashboard** com **shiny**, **ggplotly** e outros *"widgets html"* para adicionar interatividade  

Desvantagens do **flexdashboard**:  

* Menos personalização em comparação com o uso de **shiny** sozinho para criar um painel  


Tutoriais muito abrangentes sobre o uso do **flexdashboard** que informaram esta página podem ser encontrados na seção Recursos. Abaixo descrevemos os principais recursos e damos um exemplo de construção de um painel para explorar um surto, usando os dados da `lista de linha` do caso.  


## Preparação

### Carregar pacotes {.unnumbered}  

Neste manual, enfatizamos `p_load()` de **pacman**, que instala o pacote se necessário *e* o carrega para uso. Você também pode carregar pacotes instalados com `library()` de **base** R. Veja a página em [Introdução ao R](#basics) para mais informações sobre pacotes R.  

```{r}
pacman :: p_load(
  rio, # importação / exportação de dados     
  here, # localize arquivos
  tidyverse, # gerenciamento e visualização de dados
  flexdashboard, # versões de painel de relatórios R Markdown
  shiny, # figuras interativas
  plotly # figuras interativas
)
```

### Importar dados {.unnumbered}  

Importamos o conjunto de dados de casos de uma simulação de epidemia de Ebola. Se você quiser acompanhar, <a href='https://github.com/appliedepi/epirhandbook_eng/raw/master/data/case_linelists/linelist_cleaned.rds' class='download-button'> clique para baixar o "clean" linelist </a> (as .rds file). Importe dados com a função `import()` do pacote **rio** (ele lida com muitos tipos de arquivo como .xlsx, .csv, .rds - veja a página [Importar e exportar](#importing) para detalhes). 

```{r, echo=F}
# importe lista de linhas (linelist) para R
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))
```

```{r, eval=F}
# importar a linelist
linelist <- import("linelist_cleaned.rds")
```

As primeiras 50 linhas da *linelist* são exibidas abaixo.

```{r, message=FALSE, echo=F}
# exibe os dados da linelist como uma tabela
DT :: datatable(head (linelist, 50), rownames = FALSE, filter = "top", options = list (pageLength = 5, scrollX = T), class = 'white-space: nowrap')
```


## Criar novo R Markdown  

Depois de instalar o pacote, crie um novo arquivo R Markdown clicando em *Arquivo> Novo arquivo> R Markdown*. 

```{r out.width = "100%", fig.align = "center", echo=F}
knitr::include_graphics(here::here("images", "flexdashboard_new1.png"))
```


Na janela que se abre, selecione "Do modelo" (*From template*) e selecione o modelo "Flex Dashboard". Em seguida, você será solicitado a nomear o documento. No exemplo desta página, nomearemos nosso R Markdown como "outbreak_dashboard.Rmd".  
  

```{r out.width = "100%", out.height="75%", fig.align = "center", echo=F}
knitr::include_graphics(here::here("images", "flexdashboard_new2.png"))
```




## O script  

O script é um script R Markdown e, portanto, tem os mesmos componentes e organização descritos na página [Relatórios com R Markdown](#reportfactory). Nós os revisamos brevemente e destacamos as diferenças de outros formatos de saída do R Markdown.  

### YAML {.unnumbered}  

No topo do script está o cabeçalho "YAML". Isso deve começar com três traços `---` e deve fechar com três traços `---`. Os parâmetros YAML vêm em pares `chave: valor`. **O recuo e a colocação dos dois pontos em YAML são importantes** - os pares `chave: valor` são separados por dois pontos (e não sinais de igual!). 

O YAML deve começar com metadados para o documento. A ordem desses parâmetros YAML primários (não recuados) não importa. Por exemplo:  

```{r, eval=F}
title: "Meu documento"
author: "Eu"
date: "` r Sys.Date() `"
```

Você pode usar o código R em valores YAML escrevendo-o como código in-line (precedido por `r` dentro de crases), mas também entre aspas (veja o exemplo acima para `date:`).  

Um parâmetro YAML necessário é `output:`, que especifica o tipo de arquivo a ser produzido (por exemplo, `html_document`,` pdf_document`, `word_document` ou` powerpoint_presentation`). Para **flexdashboard** este valor de parâmetro é um pouco confuso - ele deve ser definido como `output: flexdashboard :: flex_dashboard`. Observe os dois pontos simples e duplos e o sublinhado. Este parâmetro de saída YAML é frequentemente seguido por *dois pontos adicionais* e subparâmetros indentados (veja os parâmetros `orientação:` e `vertical_layout:` abaixo).  

```{r, eval=F}
title: "Meu painel"
author: "Eu"
date: "` r Sys.Date() `"
output:
  flexdashboard::flex_dashboard:
    orientation: rows
    vertical_layout: scroll
```

Conforme mostrado acima, recuos (2 espaços) são usados para subparâmetros. Neste caso, não se esqueça de colocar dois pontos adicionais após o primário, como `chave: valor:`.  

Se apropriado, os valores lógicos devem ser fornecidos em YAML em letras minúsculas (`true`,` false`, `null`). Se dois pontos fizerem parte do seu valor (por exemplo, no título), coloque o valor entre aspas. Veja os exemplos nas seções abaixo.  



### Blocos de código {.unnumbered}  

Um script R Markdown pode conter vários "pedaços" (*chunks*) de código - essas são áreas do script onde você pode escrever código R de várias linhas e funcionam como mini scripts R.  

Os trechos de código são criados com três marcas invertidas e chaves com um "r" minúsculo dentro. O pedaço é fechado com três crases. Você pode criar um novo bloco digitando-o você mesmo, usando o atalho de teclado "Ctrl+Alt+i" (ou Cmd+Shift+r no Mac) ou clicando no ícone verde 'inserir um novo bloco de código' no topo do seu editor de script. Muitos exemplos são fornecidos a seguir.  


### Texto narrativo {.unnumbered}  

Fora de um "bloco" de código R, você pode escrever um texto narrativo. Conforme descrito na página em [Relatórios com R Markdown](#reportfactory), você pode colocar o texto em itálico circundando-o com um asterisco (*) ou em negrito circundando-o com dois asteriscos (**). Lembre-se de que os marcadores e os esquemas de numeração são sensíveis a novas linhas, recuo e acabamento de uma linha com dois espaços.  

Você também pode inserir o código R nas próprias linhas de texto (*in-line*), conforme descrito na página [Relatórios com R Markdown](#reportfactory), circundando o código com crases e iniciando o comando com "r": `` `1 + 1` ``(veja o exemplo com data acima).  



### Títulos {.unnumbered}  

Diferentes níveis de título são estabelecidos com diferentes números de símbolos hash ou jogo da velha, conforme descrito na página [Relatórios com R Markdown](#reportfactory).  

Em **flexdashboard**, um título principal (#) cria uma "página" do painel. Títulos de segundo nível (##) criam uma coluna ou uma linha dependendo do seu parâmetro `orientação:` (veja os detalhes abaixo). Títulos de terceiro nível (###) criam painéis para plotagens, gráficos, tabelas, texto, etc.   

```md
# Título de primeiro nível (página)

## Título de segundo nível (linha ou coluna)  

### Cabeçalho de terceiro nível (painel para plot, gráfico, etc.)
```





## Atributos da seção  

Como em uma marcação R normal, você pode especificar atributos a serem aplicados a partes do seu painel, incluindo opções `key = value` após um título, entre chaves `{}`. Por exemplo, em um relatório HTML R Markdown típico, você pode organizar subtítulos em guias com `## Meu título {.tabset}`.  

Observe que esses atributos são escritos após um *título* em uma parte do texto do script. Elas são diferentes das opções do **knitr** inseridas no topo dos blocos de código R, como `out.height =`.  

Os atributos de seção específicos para **flexdashboard** incluem:  

* `{data-orientation=}` Defina para `linhas` ou` colunas`. Se o seu painel tiver várias páginas, adicione este atributo a cada página para indicar a orientação (mais explicado em [seção de layout](# layout)).  
* `{data-width =}` e `{data-height =}` definem o tamanho relativo dos gráficos, colunas, linhas dispostas na mesma dimensão (horizontal ou vertical). Tamanhos absolutos são ajustados para melhor preencher o espaço em qualquer dispositivo de exibição graças ao mecanismo [flexbox](https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Flexible_Box_Layout/Using_CSS_flexible_boxes).  
     * A altura dos gráficos também depende de você definir o parâmetro YAML `vertical_layout: fill` ou `vertical_layout: scroll`. Se configurado para rolar, a altura da figura refletirá a opção tradicional `fig.height =` no fragmento do código R.  
     * Consulte a documentação de tamanho completa no [site do flexdashboard](https://rmarkdown.rstudio.com/flexdashboard/using.html#sizing)  
* `{.hidden}` Use isto para excluir uma página específica da barra de navegação  
* `{data-navbar =}` Use isso em um título de nível de página para aninhá-lo dentro de um menu suspenso da barra de navegação. Forneça o nome (entre aspas) do menu suspenso. Veja o exemplo abaixo.  


## Layout {#layout}  

Ajuste o *layout* do seu painel (*dashboard*) das seguintes maneiras:  

* Adicione páginas, colunas / linhas e gráficos com títulos R Markdown (por exemplo, #, ## ou ###)  
* Ajuste o parâmetro YAML `orientation:` para `rows` ou` columns`  
* Especifique se o layout preenche o navegador ou permite rolagem  
* Adicionar guias a um título de seção específico  


### Imagens {.numeradas}  

Os títulos de primeiro nível (#) no R Markdown representarão as "páginas" do painel. Por padrão, as páginas aparecerão em uma barra de navegação na parte superior do painel.  

```{r, out.height = c('100%'), out.width = c('100%'), echo=F}
knitr::include_graphics(here::here("images", "flexdashboard_pages_top_script.png"))
```


```{r, out.width = c ('100%', '100%'), echo = F, fig.show = 'hold', fig.width = 12, fig.height = 9, message = F , warning = F}
knitr::include_graphics(here::here("images", "flexdashboard_pages_top_view.png"))
```



Você pode agrupar páginas em um "menu" na barra de navegação superior adicionando o atributo `{data-navmenu =}` ao título da página. Tenha cuidado - não inclua espaços ao redor do sinal de igual, caso contrário, não funcionará!  

```{r, out.width = c ('100%', '100%'), echo = F, fig.show = 'hold', fig.width = 12, fig.height = 9, message = F , warning = F}
knitr::include_graphics(here::here("images", "flexdashboard_navmenu_script.png"))
```


Aqui está o que o script produz:  


```{r, out.width = c ('100%', '100%'), echo = F, fig.show = 'hold', fig.width = 12, fig.height = 9, message = F , warning = F}
knitr::include_graphics(here::here("images", "flexdashboard_navmenu_view.png"))
```

Você também pode converter uma página ou coluna em uma "barra lateral" no lado esquerdo do painel, adicionando o atributo `{.sidebar}`. Ele pode conter texto (visualizável em qualquer página) ou, se você tiver uma interatividade **shiny** integrada, pode ser útil manter os controles de entrada do usuário, como controles deslizantes ou menus suspensos.  

```{r, out.width = c('100%'), out.height = c('100%'), echo=F}
knitr::include_graphics(here::here("images", "flexdashboard_sidebar_script.png"))
```

Aqui está o que o script produz:  

```{r, out.width = c ('100%', '100%'), echo = F, fig.show = 'hold', fig.width = 12, fig.height = 9, message = F , warning = F}
knitr::include_graphics(here::here("images", "flexdashboard_sidebar_view.png"))
```




### Orientação {.unnumbered}  

Defina o parâmetro `orientation:` yaml para indicar como os cabeçalhos do R Markdown de segundo nível (##) devem ser interpretados - como `orientation: columns` ou `orientação: rows`. 

Títulos de segundo nível (##) serão interpretados como novas colunas ou linhas com base nesta configuração de `orientation`.  

Se você definir `orientation: columns`, os cabeçalhos de segundo nível criarão novas colunas no painel. O painel abaixo possui uma página, contendo duas colunas, com um total de três painéis. Você pode ajustar a largura relativa das colunas com `{data-width =}` conforme mostrado abaixo.  

```{r, out.width = c('100%'), out.height = c('100%'), echo=F}
knitr::include_graphics(here::here("images", "flexdashboard_columns_script.png"))
```

Aqui está o que o script produz:  

```{r, out.width = c ('100%', '100%'), echo = F, fig.show = 'hold', fig.width = 12, fig.height = 9, message = F , warning = F}
knitr::include_graphics(here::here("images", "flexdashboard_columns_view.png"))
```

Se você definir `orientation: rows`, os cabeçalhos de segundo nível criarão novas linhas em vez de colunas. Abaixo está o mesmo script acima, mas com `orientation: rows` para que os títulos de segundo nível produzam linhas em vez de colunas. Você pode ajustar a *altura* relativa das linhas com `{data-height =}` conforme mostrado abaixo.  

```{r, out.width = c('100%'), out.height = c('100%'), echo=F}
knitr::include_graphics(here::here("images", "flexdashboard_rows_script.png"))
```

Aqui está o que o script produz:  

```{r, out.width = c ('100%', '100%'), echo = F, fig.show = 'hold', fig.width = 12, fig.height = 9, message = F , warning = F}
knitr::include_graphics(here::here("images", "flexdashboard_rows_view.png"))
```

Se o seu painel tiver várias páginas, você pode designar a orientação de cada página específica adicionando o atributo `{data -idance =}` ao cabeçalho de cada página (especifique `rows` ou` columns` sem aspas).  

### Tabs {.unnumbered} 

Você pode dividir o conteúdo em guias com o atributo `{.tabset}`, como em outras saídas HTML R Markdown.  

Basta adicionar este atributo após o título desejado. Os subtítulos sob esse título serão exibidos como guias. Por exemplo, no script de exemplo abaixo da coluna 2 à direita (##) é modificado para que a curva epidêmica e os painéis da tabela (###) sejam exibidos em guias.  

Você pode fazer o mesmo com linhas se sua orientação for linhas.  

```{r, out.width = c('100%'), out.height = c('100%'), echo=F}
knitr::include_graphics(here::here("images", "flexdashboard_tabs_script.png"))
```

Aqui está o que o script produz:  

```{r, out.width = c ('100%', '100%'), echo = F, fig.show = 'hold', fig.width = 12, fig.height = 9, message = F , warning = F}
knitr::include_graphics(here::here("images", "flexdashboard_tabs_view.png"))
```


## Adicionando conteúdo  

Vamos começar a construir um painel (*dashboard*). Nosso painel simples terá 1 página, 2 colunas e 4 painéis. Vamos construir os painéis peça por peça para demonstração.  

Você pode incluir facilmente saídas R padrão, como texto, ggplots e tabelas (consulte a página [Tabelas para apresentação](#tables-presentation)). Simplesmente codifique-os dentro de um fragmento de código R, como faria para qualquer outro script R Markdown.  

Observação: você pode baixar o script Rmd finalizado e a saída do painel HTML - consulte a página [Baixar manual e dados](#data-used).  


### Texto {.unnumbered}  

Você pode digitar o texto do Markdown e incluir o código *in-line* como para qualquer outra saída do R Markdown. Consulte a página [Relatórios com R Markdown](#reportfactory) para obter detalhes. 

Neste painel (*dashboard*), incluímos um painel de texto de resumo que inclui um texto dinâmico mostrando a última data de hospitalização e o número de casos relatados no surto. 

### Tabelas {.unnumbered}  

Você pode incluir blocos de código R que imprimem saídas, como tabelas. Mas a saída terá uma aparência melhor e responderá ao tamanho da janela se você usar a função `kable()` do **knitr** para exibir suas tabelas. As funções **flextable** podem produzir tabelas que são reduzidas / cortadas.  

Por exemplo, abaixo, alimentamos `linelist()` por meio de um comando `count()` para produzir uma tabela de resumo de casos por hospital. Por fim, a tabela é direcionada para `knitr :: kable()` e o resultado tem uma barra de rolagem à direita. Você pode ler mais sobre como personalizar sua tabela com `kable()` e **kableExtra** [aqui] (https://cran.r-project.org/web/packages/kableExtra/vignettes/awesome_table_in_html.html).  

```{r, out.width = c('100%'), out.height = c('100%'), echo=F}
knitr::include_graphics(here::here("images", "flexdashboard_tables_script.png"))
```

Aqui está o que o script produz:  

```{r, out.width = c ('100%', '100%'), echo = F, fig.show = 'hold', fig.width = 12, fig.height = 9, message = F , warning = F}
knitr::include_graphics(here::here("images", "flexdashboard_tables_view.png"))
```


Se você deseja mostrar uma tabela dinâmica que permite ao usuário filtrar, classificar e / ou clicar nas "páginas" do quadro de dados, use o pacote **DT** e sua função `datatable()`, como no código abaixo.  

O código de exemplo abaixo, a `linelist` do quadro de dados é impressa. Você pode definir `rownames = FALSE` para conservar espaço horizontal e` filter = "top" `para ter filtros no topo de cada coluna. Uma lista de outras especificações pode ser fornecida para `options =`. Abaixo, definimos `pageLength =` para que 5 linhas apareçam e `scrollX =` para que o usuário possa usar uma barra de rolagem na parte inferior para rolar horizontalmente. O argumento `class = 'white-space: nowrap'` garante que cada linha seja uma linha (não várias linhas). Você pode ler sobre outros argumentos e valores possíveis [aqui](https://rstudio.github.io/DT/?_ga=2.2810736.1321860763.1619286819-369061888.1601594705) ou inserindo `?Datatable`

```{r, eval=F}
DT :: datatable(linelist, 
              rownames = FALSE,
              options = list(pageLength = 5, scrollX = TRUE),
              class = 'white-space: nowrap' )
```

### Gráficos {.unnumbered}  

Você pode imprimir gráficos em um painel de controle como faria em um script R. Em nosso exemplo, usamos o pacote **incidence2** para criar uma "epicurva" por faixa etária com dois comandos simples (consulte a página [Curvas epidêmicas](#epicurves)). No entanto, você pode usar `ggplot()` e imprimir um gráfico da mesma maneira.  

```{r, out.width = c('100%'), out.height = c('100%'), echo=F}
knitr::include_graphics(here::here("images", "flexdashboard_plots_script.png"))
```

Aqui está o que o script produz:  

```{r, out.width = c ('100%', '100%'), echo = F, fig.show = 'hold', fig.width = 12, fig.height = 9, message = F , warning = F}
knitr::include_graphics(here::here("images", "flexdashboard_plots_view.png"))
```


### Gráficos interativos {.unnumbered}  

Você também pode passar um ggplot padrão ou outro objeto de gráfico para `ggplotly()` do pacote **plotly** (consulte a página [Gráficos Interativos](#interactive-plots)). Isso tornará seu gráfico interativo, permitirá que o leitor "amplie" e mostre o valor de cada ponto de dados (neste cenário, o número de casos por semana e a faixa etária na curva).  

```{r, eval=F}
age_outbreak <- incidence(linelist, date_onset, "week", groups = age_cat)
plot(age_outbreak, fill = age_cat, col_pal = muted, title = "") %>% 
  plotly::ggplotly()
```

Aqui está a aparência disso no painel (gif). Essa funcionalidade interativa ainda funcionará mesmo se você enviar por e-mail o painel como um arquivo estático (não online em um servidor).  

```{r, out.width = c('100%'), out.height = c('100%'), echo=F}
knitr::include_graphics(here::here("images", "flexdashboard_ggplotly.gif"))
```

### Ferramentas (*Widgets*) HTML {.unnumbered}

[HTML widgets for R](http://www.htmlwidgets.org/) são uma classe especial de pacotes R que permitem maior interatividade utilizando bibliotecas JavaScript. Você pode incorporá-los nas saídas do R Markdown (como um flexdashboard) e nos painéis do Shiny.  

Alguns exemplos comuns desses widgets incluem:  

- Plotly (usado nesta página do manual e na página [Gráficos interativos](#interactive-plots))
- visNetwork (usado na página [Cadeias de transmissão](#transmission-chains) deste manual) \  
- Leaflet (usado na página [Noções básicas de GIS](#gis) deste manual) \  
- dygraphs (úteis para mostrar dados de séries temporais de forma interativa) \  
- DT (`datatable()`) (usado para mostrar tabelas dinâmicas com filtro, classificação, etc.)  

Abaixo, demonstramos como adicionar uma cadeia de transmissão epidêmica que usa visNetwork ao painel. O script mostra apenas o novo código adicionado à seção "Coluna 2" do script R Markdown. Você pode encontrar o código na página [Cadeias de transmissão](#transmission-chains) deste manual.  

```{r, out.width = c('100%'), out.height = c('100%'), echo=F}
knitr::include_graphics(here::here("images", "flexdashboard_chain_script.png"))
```

Aqui está o que o script produz:  

```{r, out.width = c ('100%', '100%'), echo = F, fig.show = 'hold', fig.width = 12, fig.height = 9, message = F , warning = F}
knitr::include_graphics(here::here("images", "flexdashboard_chain.gif"))
```



## Organização de código

Você pode optar por ter todo o código dentro do script R Markdown **flexdashboard**. Como alternativa, para ter um script de painel mais limpo e conciso, você pode optar por chamar códigos / figuras que são hospedados ou criados em scripts R externos. Isso é descrito com mais detalhes na página [Relatórios com R Markdown](#reportfactory). 


## Shiny  

A integração do pacote R **shiny** pode tornar seus painéis (*dashboards*) ainda mais reativos à entrada do usuário. Por exemplo, você pode fazer com que o usuário selecione uma jurisdição ou um intervalo de datas e os painéis reajam à sua escolha (por exemplo, filtrar os dados exibidos). Para incorporar a reatividade **shiny** ao **flexdashboard**, você só precisa fazer algumas alterações no script R Markdown do **flexdashboard**.  

Você pode usar **shiny** para produzir aplicativos / painéis *sem* flexdashboard também. A página do manual em [Dashboards with Shiny](#shiny-basics) oferece uma visão geral dessa abordagem, incluindo instruções sobre sintaxe **shiny**, estrutura de arquivo de aplicativo e opções para compartilhamento / publicação (incluindo opções de servidor gratuitas). Essa sintaxe e dicas gerais também se traduzem no contexto do **flexdashboard**.  

Incorporar **shiny** em **flexdashboard** é, no entanto, uma mudança fundamental em seu flexdashboard. Ele não produzirá mais uma saída HTML que você pode enviar por e-mail e qualquer pessoa pode abrir e visualizar. Em vez disso, será um "aplicativo". O botão "Knit" na parte superior do script será substituído por um ícone "Executar documento", que abrirá uma instância do painel interativo localmente em seu computador.  

Compartilhar seu painel agora exigirá que você:  

* Envie o script Rmd para o visualizador, ele o abre em R no computador e executa o aplicativo ou  
* O aplicativo / painel é hospedado em um servidor acessível ao visualizador  

Portanto, há benefícios em integrar **shiny**, mas também complicações. Se o compartilhamento fácil por e-mail for uma prioridade e você não precisar de recursos reativos **shiny**, considere a interatividade reduzida oferecida por `ggplotly()` conforme demonstrado acima.    

Abaixo, damos um exemplo muito simples usando o mesmo "outbreak_dashboard.Rmd" acima. A documentação extensa sobre a integração do Shiny no **flexdashboard** está disponível online [aqui](https://rmarkdown.rstudio.com/flexdashboard/shiny.html).  



### Configurações {.unnumbered}  

Habilite **shiny** em um **flexdashboard** adicionando o parâmetro YAML `runtime: shiny` no mesmo nível de indentação que` output: `, como abaixo:  

```md
---
title: "Painel de controle do Outbreak (demonstração Shiny)"
output: 
  flexdashboard::flex_dashboard:
    orientation: columns
    vertical_layout: fill
runtime: shiny
---

```

Também é conveniente habilitar uma "barra lateral" para conter os *widgets* de entrada shiny que coletarão informações do usuário. Como explicado acima, crie uma coluna e indique a opção `{.sidebar}` para criar uma barra lateral no lado esquerdo. Você pode adicionar texto e pedaços R contendo os comandos **shiny** `entrada` dentro desta coluna.  

Se seu aplicativo / painel está hospedado em um servidor e pode ter vários usuários simultâneos, nomeie o primeiro fragmento de código R como `global`. Inclua os comandos para importar / carregar seus dados neste bloco. Esse fragmento com nome especial é tratado de maneira diferente e os dados importados dentro dele são importados apenas uma vez (não continuamente) e estão disponíveis para todos os usuários. Isso melhora a velocidade de inicialização do aplicativo.  

### Exemplo trabalhado {.unnumbered}  

Aqui, adaptamos o script flexdashboard "outbreak_dashboard.Rmd" para incluir **shiny**. Adicionaremos a capacidade de o usuário selecionar um hospital em um menu suspenso e fazer com que a curva de epidemia reflita apenas os casos desse hospital, com um título de gráfico dinâmico. Fazemos o seguinte:  

* Adicione `runtime: shiny` ao YAML  
* Renomeie o trecho de configuração como `global`  
* Crie uma barra lateral contendo:  
  * Código para criar um vetor de nomes de hospitais exclusivos  
  * Um comando `selectInput()` (menu suspenso **shiny**) com a escolha de nomes de hospitais. A seleção é salva como `hospital_choice`, que pode ser referenciada no código posterior como` input$hospital_choice`  
* O código da curva epidêmica (coluna 2) está dentro de `renderPlot({})`, incluindo:  
  * Um filtro no conjunto de dados restringindo a coluna `hospital` ao valor atual de `input$hospital_choice`  
  * Um título de um gráfico dinâmico que incorpora `input$hospital_choice`  
  
Observe que qualquer código que faça referência a um valor `input$` deve estar dentro de uma função `render({})` (para ser reativo).  

Aqui está o topo do script, incluindo YAML, parte global e barra lateral:  

```{r, out.width = c('100%'), out.height = c('100%'), echo=F}
knitr::include_graphics(here::here("images", "flexdashboard_shiny_script1.png"))
```
  
Aqui está a Coluna 2, com o gráfico de epicurva reativa:  

```{r, out.width = c('100%'), out.height = c('100%'), echo=F}
knitr::include_graphics(here::here("images", "flexdashboard_shiny_script2.png"))
```

E aqui está o painel:  

```{r, out.width = c('100%'), out.height = c('100%'), echo=F}
knitr::include_graphics(here::here("images", "flexdashboard_shiny_view.gif"))
```




### Outros exemplos {.unnumbered}  

Para ler um exemplo relacionado à saúde de um Shiny - **flexdashboard** usando a interatividade **shiny** e o widget de mapeamento de **leaflet**, consulte este capítulo do livro online [Dados de saúde geoespaciais: Modelagem e Visualização com R-INLA e Shiny](https://www.paulamoraga.com/book-geospatial/sec-dashboardswithshiny.html).  




## Compartilhamento  

Os painéis que não contêm elementos Shiny produzirão um arquivo HTML (.html), que pode ser enviado por e-mail (se o tamanho permitir). Isso é útil, pois você pode enviar o relatório de "painel" e não precisa configurar um servidor para hospedá-lo como um site.  

Se você tiver incorporado **shiny**, não poderá enviar uma saída por e-mail, mas pode enviar o próprio script para um usuário R ou hospedar o painel em um servidor conforme explicado acima.  


## Recursos  

Excelentes tutoriais que informaram esta página podem ser encontrados abaixo. Se você revisar isso, provavelmente dentro de uma hora poderá ter seu próprio painel.  

https://bookdown.org/yihui/rmarkdown/dashboards.html

https://rmarkdown.rstudio.com/flexdashboard/

https://rmarkdown.rstudio.com/flexdashboard/using.html

https://rmarkdown.rstudio.com/flexdashboard/examples.html
```{r include=FALSE, cache=FALSE}

# clear workspace
rm(list = ls(all = TRUE))

# clear all packages except base
#lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))

# to ensure that tidyverse packages prevail
filter <- dplyr::filter
select <- dplyr::select
summarise <- dplyr::summarise
summary <- base::summary
incidence <- incidence2::incidence

#load core packages
pacman::p_load(
     rio,
     here,
     DT,
     stringr,
     lubridate,
     tidyverse
)

# import the cleaned ebola linelist
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

# import the count data - facility level
#count_data <- rio::import(here::here("data", "facility_count_data.rds"))

# Settings

options(scipen=1, digits=7)

# print only text (not code)
# library(knitr)
# opts_chunk$set(list(echo = FALSE, eval = FALSE))
```

<!--chapter:end:new_pages/flexdashboard.Rmd-->


# Painéis com Shiny {#shiny-basics}  

Os painéis costumam ser uma ótima maneira de compartilhar resultados de análises com outras pessoas. Produzir um painel com **shiny** requer um conhecimento relativamente avançado da linguagem R, mas oferece uma personalização e possibilidades incríveis.  

<! -- Uma das maiores desvantagens do `R` é sua usabilidade para pessoas que são novas ou não têm experiência com linguagens de programação. Embora essas habilidades sejam muito valiosas, a maioria das pessoas descobrirá que isso representa uma barreira para o compartilhamento de análises, especialmente em ambientes multidisciplinares. Requer algum trabalho para manter uma instalação `R`, e nem todos se sentirão confortáveis executando um código compartilhado, mesmo que seja bem documentado e fácil de ler. Isso é *especialmente* verdadeiro quando os usuários precisam alterar os parâmetros do código! -->

<!-- Painéis baseados em R também são vantajosos porque centralizam como o código é executado - quando o mesmo código é executado em máquinas diferentes, muitas vezes as pessoas terão que lidar com caminhos de arquivo diferentes, versões de R diferentes e instalações de pacotes diferentes. Por esse motivo, os painéis são uma ótima maneira de compartilhar código com outras pessoas de uma forma amigável! -->

Recomenda-se que alguém que esteja aprendendo painéis com **shiny** tenha bom conhecimento de transformação e visualização de dados e se sinta confortável para depurar código e escrever funções. Trabalhar com painéis não é intuitivo quando você está começando e às vezes é difícil de entender, mas é uma ótima habilidade de aprender e fica muito mais fácil com a prática!

Esta página fornecerá uma breve visão geral de como fazer painéis com **shiny** e suas extensões. 
Para um método alternativo de tornar os painéis mais rápidos, fáceis, mas talvez menos personalizáveis, consulte a página **flextable** ([Painéis com R Markdown](#flexdashboard)).  



## Preparação  


### Carregar pacotes {.unnumbered}  

Neste manual, enfatizamos `p_load()` de **pacman**, que instala o pacote se necessário *e* o carrega para uso. Você também pode carregar pacotes instalados com `library()` do R **base**. Veja a página em [Introdução ao R](#basics) para mais informações sobre pacotes R.  

Começamos instalando o pacote R **shiny**:  

```{r, eval = FALSE}
pacman::p_load("shiny")
```


### Importar dados {.unnumbered}  

Se você gostaria de acompanhar esta página, consulte esta seção do [Baixar manual e dados](#data-used). Existem links para baixar os scripts R e arquivos de dados que produzem o aplicativo Shiny final.  

Se você tentar reconstruir o aplicativo usando esses arquivos, esteja ciente da estrutura de pastas do projeto R que é criada durante a demonstração (por exemplo, pastas para "dados" e para "funções").  



<!-- ======================================================= -->
## A estrutura de um aplicativo shiny { }

### Estruturas de arquivo básicas {.unnumbered}  

Para entender `shiny`, primeiro precisamos entender como funciona a estrutura de arquivos de um aplicativo! Devemos fazer um novo diretório antes de começar. Na verdade, isso pode ser facilitado escolhendo _Novo projeto_ em _Rstudio_ e escolhendo _Shiny Web Application_. Isso criará a estrutura básica de um aplicativo shiny para você.

Ao abrir este projeto, você notará que já existe um arquivo `.R` chamado _app.R_. É *essencial* que tenhamos uma das duas estruturas básicas de arquivo:

1. Um arquivo chamado _app.R_,  *ou*  
2. Dois arquivos, um denominado _ui.R_ e o outro _server.R_  

Nesta página, usaremos a primeira abordagem de ter um arquivo chamado *app.R*. Aqui está um script de exemplo:  

```{r, eval = FALSE}
# um exemplo de app.R

library(shiny)

ui <- fluidPage(

    # Título do aplicativo
    titlePanel("Meu aplicativo"),

    # Barra lateral com um widget de entrada deslizante
    sidebarLayout(
        sidebarPanel(
            sliderInput("input_1")
        ),

        # Mostrar um gráfico 
        mainPanel(
           plotOutput("my_plot")
        )
    )
)

# Defina a lógica do servidor necessária para desenhar um histograma
server <- function(input, output) {
     
     plot_1 <- reactive({
          plot_func(param = input_1)
     })
     
    output$my_plot <- renderPlot({
       plot_1()
    })
}


# Execute o aplicativo 
shinyApp(ui = ui, server = server)


```


Se você abrir este arquivo, você notará que dois objetos são definidos - um chamado `ui` e outro chamado `servidor`. Esses objetos *devem* ser definidos em *todos* os aplicativos shiny e são centrais para a estrutura do próprio aplicativo! Na verdade, a única diferença entre as duas estruturas de arquivo descritas acima é que na estrutura 1, `ui` e `server` são definidos em um arquivo, enquanto na estrutura 2 eles são definidos em arquivos separados. Nota: nós também podemos (e devemos se tiver um aplicativo maior) ter outros arquivos .R em nossa estrutura que podemos `source()` em nosso aplicativo.



### O servidor e a ui {.unnumbered}

Em seguida, precisamos entender o que os objetos `server` e `ui` realmente _do_. *Simplificando, esses são dois objetos que estão interagindo entre si sempre que o usuário interage com o aplicativo shiny.*

O elemento UI de um aplicativo shiny é, em um nível básico, o código R que cria uma interface HTML. Isso significa tudo o que é *exibido* na IU de um aplicativo. Isso geralmente inclui:

* "Widgets" - menus suspensos, caixas de seleção, controles deslizantes etc. com os quais o usuário pode interagir
* Plots, tabelas, etc - saídas que são geradas com o código R
* Aspectos de navegação de um aplicativo - guias, painéis, etc. 
* Texto genérico, hiperlinks, etc.
* Elementos HTML e CSS (abordado posteriormente)

O mais importante a entender sobre a IU é que ela *recebe entradas* do usuário e *exibe saídas* do servidor. Não há código *ativo* em execução na interface do usuário *a qualquer momento* - todas as alterações vistas na interface do usuário são passadas pelo servidor (mais ou menos). Portanto, temos que fazer nossos gráficos, downloads, etc no servidor

O servidor do aplicativo shiny é onde todo o código está sendo executado assim que o aplicativo é inicializado. A maneira como isso funciona é um pouco confusa. A função de servidor irá efetivamente _reagir_ à interface do usuário com a IU e executar pedaços de código em resposta. Se as coisas mudarem no servidor, elas serão repassadas para a interface do usuário, onde as mudanças podem ser vistas. É importante ressaltar que o código no servidor será executado *não consecutivamente* (ou é melhor pensar dessa forma). Basicamente, sempre que uma entrada da interface do usuário afetar um pedaço de código no servidor, ela será executada automaticamente e essa saída será produzida e exibida.

Isso tudo provavelmente parece muito abstrato por agora, então teremos que mergulhar em alguns exemplos para ter uma ideia clara de como isso realmente funciona. 


### Antes de começar a construir um aplicativo {.unnumbered}

Antes de começar a construir um aplicativo, é extremamente útil saber *o que* você deseja construir. Uma vez que sua IU será escrita em código, você não pode realmente visualizar o que está construindo, a menos que esteja visando algo específico. Por esse motivo, é extremamente útil olhar muitos exemplos de aplicativos shiny para ter uma ideia do que você pode fazer - ainda melhor se você puder olhar o código-fonte por trás desses aplicativos! Alguns ótimos recursos para isso são:

* A [galeria de aplicativos Rstudio](https://shiny.rstudio.com/gallery/)  

Depois de ter uma ideia do que é possível, também é útil mapear como você quer que o seu fique - você pode fazer isso no papel ou em qualquer software de desenho (PowerPoint, MS Paint etc.). É útil começar de forma simples para seu primeiro aplicativo! Também não há vergonha em usar o código que você encontra online de um bom aplicativo como modelo para o seu trabalho - é muito mais fácil do que construir algo do zero!



## Construindo uma IU 

Ao construir nosso aplicativo, é mais fácil trabalhar na IU primeiro, para que possamos ver o que estamos fazendo e não correr o risco de o aplicativo falhar devido a erros do servidor. Como mencionado anteriormente, geralmente é bom usar um modelo ao trabalhar na IU. Existem vários layouts padrão que podem ser usados com o shiny que estão disponíveis no pacote base shiny, mas é importante notar que também há várias extensões de pacote como `shinydashboard`. Usaremos um exemplo da base shiny para começar. 

Uma IU shiny é geralmente definida como uma série de funções aninhadas, na seguinte ordem

1. Uma função que define o layout geral (a mais básica é `fluidPage()`, mas há mais disponíveis)
2. Painéis dentro do layout, como:
     - uma barra lateral (`sidebarPanel()`)
     - um painel "principal" (`mainPanel()`)
     - uma guia (`tabPanel()`)
     - uma "coluna" genérica (`coluna()`)
3. Ferramentas (*Widgets*) e saídas - podem conferir entradas para o servidor (widgets) ou saídas do servidor (saídas)
     - Os widgets geralmente são estilizados como `xxxInput()`, por exemplo `selectInput ()`
     - As saídas são geralmente estilizadas como `xxxOutput()`, por exemplo `plotOutput()`

Vale a pena reafirmar que eles não podem ser visualizados facilmente de forma abstrata, então é melhor dar uma olhada em um exemplo! Vamos considerar a criação de um aplicativo básico que visualiza os dados de contagem de nossas instalações para malária por distrito. Esses dados têm muitos parâmetros diferentes, então seria ótimo se o usuário final pudesse aplicar alguns filtros para ver os dados por faixa etária / distrito como achar melhor! Podemos usar um layout shiny muito simples para começar - o layout da barra lateral. Este é um layout onde os widgets são colocados em uma barra lateral à esquerda e o gráfico é colocado à direita.

Vamos planejar nosso aplicativo - podemos começar com um seletor que nos permite escolher o bairro onde queremos visualizar os dados, e outro para nos permitir visualizar a faixa etária que nos interessa. Nosso objetivo é usar esses filtros para mostrar uma epicurva que reflete esses parâmetros. Então, para isso, precisamos:

1. Dois menus suspensos que nos permitem escolher o distrito que desejamos e a faixa etária em que estamos interessados. 
2. Uma área onde podemos mostrar nossa epicurva resultante.

Isso pode ser parecido com isto:

```{r, eval = FALSE}

library(shiny)

ui <- fluidPage(

  titlePanel ("Aplicativo de visualização de instalação para malária"),

  sidebarLayout(

    sidebarPanel(
         # seletor para distrito
         selectInput(
              inputId = "select_district",
              label = "Selecionar distrito",
              escolhas = c(
                   "Tudo",
                   "Primavera",
                   "Bolo",
                   "Dingo",
                   "Barnard"
              ),
              selecionado = "Tudo",
              múltiplo = TRUE
         ),
         # seletor para faixa etária
         selectInput(
              inputId = "select_agegroup",
              label = "Selecionar faixa etária",
              escolhas = c(
                   "Todas as idades" = "malaria_tot",
                   "0-4 yrs" = "malaria_rdt_0-4",
                   "5-14 yrs" = "malaria_rdt_5-14",
                   "15+ yrs" = "malaria_rdt_15"
              ),
              selecionado = "Tudo",
              múltiplo = FALSE
         )

    ),

    mainPanel(
      # epicurva vai aqui
      plotOutput("malaria_epicurve")
    )
    
  )
)


```


Quando app.R é executado com o código de IU acima (sem nenhum código ativo na parte `server` de app.R), o *layout* aparece assim - observe que não haverá um gráfico se não houver servidor para renderizá-lo, mas nossas entradas estão funcionando!

```{r, out.width = c('100%'), out.height = c('100%'), echo=F}
knitr::include_graphics(here::here("images", "shiny", "simple_UI_view.png"))
```

Esta é uma boa oportunidade para discutir como os widgets funcionam - observe que cada widget está aceitando um `inputId`, um` label` e uma série de outras opções que são específicas para o tipo de widget. Este `inputId` é extremamente importante - esses são os IDs usados para passar informações da IU para o servidor. Por esse motivo, eles *devem ser exclusivos*. Você deve fazer um esforço para nomeá-los de algo sensato e específico para o que estão interagindo em casos de aplicativos maiores.

Você deve ler a documentação cuidadosamente para obter detalhes completos sobre o que cada um desses widgets faz. Os widgets passarão tipos específicos de dados para o servidor, dependendo do tipo de widget, e isso precisa ser totalmente compreendido. Por exemplo, `selectInput()` passará um tipo de caractere para o servidor:

- Se selecionarmos _Spring_ para o primeiro widget aqui, ele passará o objeto de caractere `"Spring"` para o servidor. 
- Se selecionarmos dois itens no menu suspenso, eles aparecerão como um vetor de caracteres (por exemplo, `c(" Spring "," Bolo ")`).

Outros widgets irão passar diferentes tipos de objetos para o servidor! Por exemplo:

- `numericInput()` passará um objeto de tipo numérico para o servidor
- `checkboxInput()` passará um objeto de tipo lógico para o servidor (`TRUE` ou` FALSE`)

Também vale a pena notar o *vetor nomeado* que usamos para os dados de idade aqui. Para muitos widgets, usar um vetor nomeado como as escolhas exibirá os *nomes* do vetor como as opções de exibição, mas passará o *valor* selecionado do vetor para o servidor. Ou seja, aqui, alguém pode selecionar "15+" no menu suspenso e a IU passará `"malaria_rdt_15"` para o servidor - que por acaso é o nome da coluna em que estamos interessados!


Existem muitos widgets que você pode usar para fazer muitas coisas com seu aplicativo. Os widgets também permitem que você carregue arquivos em seu aplicativo e baixe saídas. Existem também algumas extensões shiny excelentes que fornecem acesso a mais widgets do que o básico shiny - o pacote **shinyWidgets** é um ótimo exemplo disso. Para ver alguns exemplos, você pode ver os seguintes links:

- [galeria de widgets shiny de base](https://shiny.rstudio.com/gallery/widget-gallery.html)
- [shinyWidgets gallery](https://github.com/dreamRs/shinyWidgets)



## Carregando dados em nosso aplicativo

A próxima etapa no desenvolvimento de nosso aplicativo é colocar o servidor em funcionamento. Para fazer isso, no entanto, precisamos colocar alguns dados em nosso aplicativo e descobrir todos os cálculos que faremos. Um aplicativo shiny não é simples de depurar, já que geralmente não fica claro de onde vêm os erros, então é ideal para fazer com que todo o nosso processamento de dados e código de visualização funcionem antes de começarmos a fazer o próprio servidor.

Portanto, como queremos fazer um aplicativo que mostra curvas epi que mudam com base na entrada do usuário, devemos pensar sobre o código de que precisaríamos para executá-lo em um script R normal. Precisamos:

1. Carregue nossos pacotes
2. Carregue nossos dados
3. Transforme nossos dados
4. Desenvolva uma _função_ para visualizar nossos dados com base nas entradas do usuário

Esta lista é bastante direta e não deve ser muito difícil de fazer. Agora é importante pensar sobre quais partes desse processo precisam *ser feitas apenas uma vez* e quais partes precisam *ser executadas em resposta às entradas do usuário*. Isso ocorre porque os aplicativos shiny geralmente executam algum código antes de serem executados, o que é executado apenas uma vez. Isso ajudará no desempenho de nosso aplicativo se o máximo de nosso código puder ser movido para esta seção. Para este exemplo, só precisamos carregar nossos dados / pacotes e fazer as transformações básicas uma vez, para que possamos colocar esse código *fora do servidor*. Isso significa que a única coisa de que precisaremos no servidor é o código para visualizar nossos dados. Vamos desenvolver todos esses componentes em um script primeiro. No entanto, como estamos visualizando nossos dados com uma função, também podemos colocar o código _para a função_ fora do servidor para que nossa função esteja no ambiente quando o aplicativo for executado!

Primeiro, vamos carregar nossos dados. Como estamos trabalhando com um novo projeto e queremos torná-lo limpo, podemos criar um novo diretório chamado data e adicionar nossos dados de malária nele. Podemos executar o código abaixo em um script de teste que excluiremos ao limpar a estrutura de nosso aplicativo.

```{r, echo = TRUE}
pacman::p_load("tidyverse", "lubridate")

# dados lidos
malaria_data <- rio::import(here::here("data", "malaria_facility_count_data.rds")) %>% 
  as_tibble()

print(malaria_data)


```


Será mais fácil trabalhar com esses dados se usarmos padrões de dados organizados, então também devemos transformar em um formato de dados mais longo, em que a faixa etária é uma coluna e os casos é outra coluna. Podemos fazer isso facilmente usando o que aprendemos na página [Pivoteando dados](#pivoting).  


```{r, echo = TRUE}

malaria_data <- malaria_data%>%
  select (-newid)%>%
  pivot_longer(cols = starts_with("malaria_"), names_to = "age_group", values_to = "cases_reported")

print(malaria_data)

```

E com isso terminamos de preparar nossos dados! Isso cruza os itens 1, 2 e 3 de nossa lista de coisas a desenvolver para nosso "script de teste R". A última e mais difícil tarefa será construir uma função para produzir uma epicurva baseada em parâmetros definidos pelo usuário. Como mencionado anteriormente, é *altamente recomendado* que qualquer pessoa que esteja aprendendo algo shiny primeiro dê uma olhada na seção sobre programação funcional ([Escrevendo funções](#writing-functions)) para entender como isso funciona!

Ao definir nossa função, pode ser difícil pensar sobre quais parâmetros queremos incluir. Para programação funcional com shiny, cada parâmetro relevante geralmente terá um widget associado a ele, então pensar sobre isso geralmente é bem fácil! Por exemplo, em nosso aplicativo atual, queremos ser capazes de filtrar por distrito e ter um widget para isso, para que possamos adicionar um parâmetro de distrito para refletir isso. Nós *não* temos nenhuma funcionalidade de aplicativo para filtrar por instalação (por enquanto), portanto, não precisamos adicionar isso como um parâmetro. Vamos começar criando uma função com três parâmetros:

1. O conjunto de dados principal
2. O distrito de escolha
3. A faixa etária de escolha

```{r}

plot_epicurve <- function(data, district = "All", agegroup = "malaria_tot") {
  
  if (!("All" %in% district)) {
    data <- data %>%
      filter(District %in% district)
    
    plot_title_district <- stringr::str_glue("{paste0(district, collapse = ', ')} districts")
    
  } else {
    
    plot_title_district <- "all districts"
    
  }
  
  # se não houver dados restantes, retorna NULL
  if (nrow(data) == 0) {
    
    return(NULL)
  }
  
  data <- data %>%
    filter(age_group == agegroup)
  
  
  # se não houver dados restantes, retorna NULL
  if (nrow(data) == 0) {
    
    return(NULL)
  }
  
  if (agegroup == "malaria_tot") {
      agegroup_title <- "All ages"
  } else {
    agegroup_title <- stringr::str_glue("{str_remove(agegroup, 'malaria_rdt')} years")
  }
  
  
  ggplot(data, aes(x = data_date, y = cases_reported)) +
    geom_col(width = 1, fill = "darkred") +
    theme_minimal () +
    labs(
      x = "date",
      y = "number of cases",
      title = stringr::str_glue("Malaria cases - {plot_title_district}"),
      subtitle = agegroup_title
    )
  
  
  
}

```


Não entraremos em muitos detalhes sobre essa função, pois é relativamente simples em como funciona. Uma coisa a se notar, entretanto, é que tratamos os erros retornando `NULL` quando, de outra forma, resultaria em um erro. Isso ocorre porque quando um servidor shiny produz um objeto `NULL` em vez de um objeto de gráfico, nada será mostrado na interface do usuário! Isso é importante, pois, caso contrário, os erros geralmente farão com que seu aplicativo pare de funcionar.  

Outra coisa a se notar é o uso do operador `%in%` ao avaliar a entrada `district`. Como mencionado acima, isso pode chegar como um vetor de caracteres com vários valores, então usar `%in%` é mais flexível do que dizer, `==`.  

Vamos testar nossa função!

```{r, echo = TRUE, warning = FALSE}

plot_epicurve(malaria_data, district = "Bolo", agegroup = "malaria_rdt_0-4")

```

Com nossa função funcionando, agora temos que entender como tudo isso vai se encaixar em nosso aplicativo shiny. Mencionamos o conceito de _código de inicialização_ antes, mas vamos ver como podemos realmente incorporar isso à estrutura de nosso aplicativo. Podemos fazer isso de duas maneiras!

1. Coloque este código em seu arquivo _app.R_ no início do script (acima da IU), ou  
2. Crie um novo arquivo no diretório do seu aplicativo chamado _global.R_ e coloque o código de inicialização neste arquivo.

É importante notar neste ponto que geralmente é mais fácil, especialmente com aplicativos maiores, usar a segunda estrutura de arquivo, pois permite separar sua estrutura de arquivo de uma forma simples. Vamos desenvolver totalmente um script global.R agora. Pode ser assim:


```{r, eval=F}
# global.R script

pacman::p_load("tidyverse", "lubridate", "shiny")

# dados lidos
malaria_data <- rio::import(here::here("data", "malaria_facility_count_data.rds")) %>% 
  as_tibble()

# limpe os dados e gire por mais tempo
malaria_data <- malaria_data%>%
  select (-newid)%>%
  pivot_longer(cols = starts_with("malaria_"), names_to = "age_group", values_to = "cases_reported")


# define a função de criação de um gráfico
plot_epicurve <- function(data, district = "All", agegroup = "malaria_tot") {
  
  # criar título do enredo
  if (!("All" %in% district)) {            
    data <- data %>%
      filter(District %in% district)
    
    plot_title_district <- stringr::str_glue("{paste0(district, collapse = ', ')} districts")
    
  } else {
    
    plot_title_district <- "all districts"
    
  }
  
  # se não houver dados restantes, retorna NULL
  if (nrow(data) == 0) {
    
    return(NULL)
  }
  
  # filtro para faixa etária
  data <- data %>%
    filter(age_group == agegroup)
  
  
  # se não houver dados restantes, retorna NULL
  if (nrow(data) == 0) {
    
    return(NULL)
  }
  
  if (agegroup == "malaria_tot") {
      agegroup_title <- "All ages"
  } else {
    agegroup_title <- stringr::str_glue("{str_remove(agegroup, 'malaria_rdt')} years")
  }
  
  
  ggplot(data, aes(x = data_date, y = cases_reported)) +
    geom_col(width = 1, fill = "darkred") +
    theme_minimal () +
    labs(
      x = "date",
      y = "number of cases",
      title = stringr::str_glue("Malaria cases - {plot_title_district}"),
      subtitle = agegroup_title
    )
  
  
  
}



```


Fácil! Um grande recurso do shiny é que ele entenderá para que servem os arquivos chamados _app.R_, _server.R_, _ui.R_ e _global.R_, portanto, não há necessidade de conectá-los entre si por meio de qualquer código. Portanto, apenas por ter esse código em _global.R_ no diretório, ele será executado antes de iniciarmos nosso aplicativo!  

Devemos também observar que melhoraria a organização de nosso aplicativo se movêssemos a função de plotagem para seu próprio arquivo - isso será especialmente útil à medida que os aplicativos se tornam maiores. Para fazer isso, poderíamos criar outro diretório chamado _funcs_ e colocar essa função em um arquivo chamado _plot_epicurve.R_. Poderíamos então ler essa função por meio do seguinte comando em _global.R_

```{r, eval=F}

source(here("funcs", "plot_epicurve.R"), local = TRUE)

```

Observe que você deve *sempre* especificar `local = TRUE` em aplicativos shiny, uma vez que afetará o fornecimento quando / se o aplicativo for publicado em um servidor. 

## Desenvolvendo um servidor de aplicativos

Agora que temos a maior parte do nosso código, só precisamos desenvolver nosso servidor. Esta é a parte final de nosso aplicativo e provavelmente a mais difícil de entender. O servidor é uma grande função R, mas é útil pensar nele como uma série de funções menores ou tarefas que o aplicativo pode executar. É importante entender que essas funções não são executadas em uma ordem linear. Há uma ordem para eles, mas não é totalmente necessário entender quando se começa com o shiny. Em um nível muito básico, essas tarefas ou funções serão ativadas quando houver uma mudança nas entradas do usuário que as afete, *a menos que o desenvolvedor as tenha configurado para que se comportem de maneira diferente*. Novamente, tudo isso é bastante abstrato, mas vamos primeiro examinar os três tipos básicos de _objetos_ shiny

1. Fontes reativas - este é outro termo para entradas do usuário. O servidor shiny tem acesso às saídas da IU por meio dos widgets que programamos. Cada vez que os valores para estes são alterados, isso é passado para o servidor.

2. Condutores reativos - são objetos que existem *apenas* dentro do servidor shiny. Na verdade, não precisamos deles para aplicativos simples, mas eles produzem objetos que só podem ser vistos dentro do servidor e usados em outras operações. Eles geralmente dependem de fontes reativas.

3. Resultados (*Endpoints*) - são saídas que são passadas do servidor para a IU. Em nosso exemplo, essa seria a curva epi que estamos produzindo. 

Com isso em mente vamos construir nosso servidor passo a passo. Mostraremos nosso código de IU novamente aqui apenas para referência:

```{r, eval = FALSE}

ui <- fluidPage(

  titlePanel ("Aplicativo de visualização de instalação para malária"),

  sidebarLayout(

    sidebarPanel(
         # seletor para distrito
         selectInput(
              inputId = "select_district",
              label = "Selecionar distrito",
              escolhas = c(
                   "Tudo",
                   "Primavera",
                   "Bolo",
                   "Dingo",
                   "Barnard"
              ),
              selecionado = "Tudo",
              múltiplo = TRUE
         ),
         # seletor para faixa etária
         selectInput(
              inputId = "select_agegroup",
              label = "Selecionar faixa etária",
              escolhas = c(
                   "Todas as idades" = "malaria_tot",
                   "0-4 yrs" = "malaria_rdt_0-4",
                   "5-14 yrs" = "malaria_rdt_5-14",
                   "15+ yrs" = "malaria_rdt_15"
              ),
              selecionado = "Tudo",
              múltiplo = FALSE
         )

    ),

    mainPanel(
      # epicurva vai aqui
      plotOutput("malaria_epicurve")
    )
    
  )
)


```

A partir desta IU de código, temos:

- Duas entradas:
  - Seletor de distrito (com um inputId de `select_district`)
  - Seletor de faixa etária (com um inputId de `select_agegroup`)
- Uma saída:
  - A epicurva (com outputId de `malaria_epicurve`)

Conforme declarado anteriormente, esses nomes exclusivos que atribuímos às nossas entradas e saídas são cruciais. Eles *devem ser exclusivos* e são usados para passar informações entre a interface do usuário e o servidor. Em nosso servidor, acessamos nossas entradas através da sintaxe `input $ inputID` e saídas e passadas para a interface do usuário através da sintaxe` output $ output_name` Vamos dar uma olhada em um exemplo, porque novamente é difícil entender de outra forma!

```{r, eval = FALSE}

server <- function(input, output, session) {
  
  output$malaria_epicurve <- renderPlot(
    plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup)
  )
  
}


```


O servidor para um aplicativo simples como esse é bastante direto! Você notará que o servidor é uma função com três parâmetros - `input`, `output` e `session` - isso não é tão importante entender agora, mas é importante seguir esta configuração! Em nosso servidor, temos apenas uma tarefa - isso renderiza um gráfico com base em nossa função que criamos anteriormente e nas entradas do servidor. Observe como os nomes dos objetos de entrada e saída correspondem exatamente aos da interface do usuário.

Para entender os fundamentos de como o servidor reage às entradas do usuário, você deve observar que a saída saberá (por meio do pacote subjacente) quando as entradas mudam e execute novamente esta função para criar um gráfico sempre que mudam. Observe que também usamos a função `renderPlot()` aqui - esta é uma de uma família de funções específicas de classe que passam esses objetos para uma saída da interface do usuário. Existem várias funções que se comportam de maneira semelhante, mas você precisa garantir que a função usada corresponda à classe de objeto que você está passando para a interface do usuário! Por exemplo:

- `renderText()` - envia texto para a interface do usuário
- `renderDataTable` - envia uma tabela interativa para a interface do usuário.

Lembre-se de que eles também precisam corresponder à *função* de saída usada na ui - então `renderPlot()` é pareado com `plotOutput()`, e `renderText()` é pareado com `textOutput()`. 

Então, finalmente criamos um aplicativo funcional! Podemos executá-lo pressionando o botão Executar aplicativo no canto superior direito da janela do script no Rstudio. Você deve observar que pode optar por executar seu aplicativo em seu navegador padrão (em vez de Rstudio), que refletirá com mais precisão a aparência do aplicativo para outros usuários.  


```{r, out.width = c('100%'), out.height = c('100%'), echo=F}
knitr::include_graphics(here::here("images", "shiny", "app_simple_view.gif"))
```


É divertido notar que no console R, o aplicativo está "ouvindo"! É a tal da reatividade!  

```{r, echo=F}
knitr::include_graphics(here::here("images", "shiny", "listening.png"))
```


<! -- A FAZER: *ADICIONE ALGO AO BAIXAR UM ARQUIVO ZIP DO APLICATIVO?* -->



## Adicionando mais funcionalidades

Neste ponto, finalmente temos um aplicativo em execução, mas temos muito poucas funcionalidades. Até agora só vimos a "ponta do iceberg" do que shiny pode fazer, então há muito mais para aprender! Vamos continuar a construir nosso aplicativo existente, adicionando alguns recursos extras. Algumas coisas que podem ser interessantes de adicionar são: 

1. Algum texto explicativo 
2. Um botão de *download* para nosso gráfico - isso forneceria ao usuário uma versão de alta qualidade da imagem que está gerando no aplicativo
3. Um seletor para instalações específicas
4. Outra página do painel - isso pode mostrar uma tabela de nossos dados.

Isso é muito a acrescentar, mas podemos usá-lo para aprender sobre um monte de recursos shiny diferentes no caminho. Há muito o que aprender sobre shiny (ele pode ficar *muito* avançado, mas esperamos que, assim que os usuários tiverem uma ideia melhor de como usá-lo, eles possam se sentir mais confortáveis usando fontes externas de aprendizagem também).



### Adicionando texto estático {.unnumbered}  

Vamos primeiro discutir a adição de texto estático ao nosso aplicativo shiny. Adicionar texto ao nosso aplicativo é extremamente fácil, uma vez que você tenha um domínio básico sobre ele. Visto que o texto estático não muda no aplicativo shiny (se você gostaria que ele mudasse, você pode usar funções de *renderização de texto* no servidor!), todo o texto estático shiny é geralmente adicionado na interface do usuário do aplicativo. Não examinaremos isso em grandes detalhes, mas você pode adicionar vários elementos diferentes à sua interface do usuário (e até mesmo alguns personalizados) fazendo a interface de R com *HTML* e *css*.

HTML e css são linguagens que estão explicitamente envolvidas no design da interface do usuário. Não precisamos entender isso muito bem, mas *HTML* cria objetos na IU (como uma caixa de texto ou uma tabela) e *css* geralmente é usado para alterar o estilo e a estética desses objetos. O Shiny tem acesso a uma grande variedade de _HTML tags_ - presentes para objetos que se comportam de uma maneira específica, como cabeçalhos, parágrafos de texto, quebras de linha, tabelas, etc. Podemos usar alguns desses exemplos como este:

- `h1()` - esta é uma tag de *header*, que tornará o texto fechado automaticamente maior, e mudará os padrões conforme eles pertencem à face da fonte, cor etc. (dependendo do tema geral do seu aplicativo). Você pode acessar_menos e menor_subtítulo com `h2()` até `h6()` também. O uso se parece com:
  * `h1(" meu cabeçalho - seção 1")`

- `p()` - esta é uma tag de *parágrafo*, que tornará o texto fechado semelhante ao texto em um corpo de texto. Este texto será quebrado automaticamente e terá um tamanho relativamente pequeno (os rodapés podem ser menores, por exemplo). Pense nisso como o corpo do texto de um documento do Word. O uso se parece com:  

  * `p(" Este é um corpo de texto maior onde estou explicando a função do meu aplicativo")`
  
- `tags$b()` e `tags$i()` - são usadas para criar tags `$b()` em negrito e `tags$i()` em itálico com qualquer texto que esteja incluído!

- `tags$ul()`, `tags$ol()` e `tags$li()` - são tags usadas na criação de * listas *. Todos eles são usados na sintaxe abaixo e permitem ao usuário criar uma lista ordenada (`tags$ol()`; ou seja, numerada) ou lista não ordenada (`tags$ul()`, ou seja, marcadores). `tags$li()` é usado para denotar itens na lista, independentemente do tipo de lista usado. Por exemplo:

```{r, eval=F}

tags$ol(
  
  tags$li("Item 1"),
  
  tags$li("Item 2"),
  
  tags$li("Item 3")
  
)

```

- `br()` e `hr()` - essas tags criam *quebras de linha* e *linhas horizontais* (com uma quebra de linha) respectivamente. Use-os para separar as seções de seu aplicativo e texto! Não há necessidade de passar nenhum item para essas tags (os parênteses podem permanecer vazios).


- `div()` - esta é uma tag *genérica* que pode *conter qualquer coisa*, e pode ser *nomeada qualquer coisa*. Depois de progredir com o design da interface do usuário, você pode usá-los para compartimentar sua interface do usuário, fornecer estilos específicos a seções específicas e criar interações entre o servidor e os elementos da interface do usuário. Não entraremos em detalhes, mas vale a pena estar ciente deles!

Note que cada um desses objetos pode ser acessado através de `tags$...` ou para alguns, apenas a função. Estes são efetivamente sinônimos, mas pode ajudar usar o estilo `tags$...` se você preferir ser mais explícito e não sobrescrever as funções acidentalmente. Esta também não é, de forma alguma, uma lista exaustiva de tags disponíveis. Há uma lista completa de todas as tags disponíveis em shiny [aqui](https://shiny.rstudio.com/articles/tag-glossary.html) e ainda mais podem ser usadas inserindo HTML diretamente em sua interface do usuário!


Se você se sentir confiante, também pode adicionar quaisquer *elementos de estilo css* às suas tags HTML com o argumento `style` em qualquer um deles. Não entraremos em detalhes sobre como isso funciona, mas uma dica para testar mudanças estéticas em uma IU é usar o modo inspetor HTML em cromo (do seu aplicativo shiny que você está executando no navegador) e editar o estilo dos objetos você mesmo!

Vamos adicionar algum texto ao nosso aplicativo

```{r, eval=F}

ui <- fluidPage(

  titlePanel ("Aplicativo de visualização de instalação para malária"),

  sidebarLayout(

    sidebarPanel(
         h4 ("Opções"),
         # seletor para distrito
         selectInput(
              inputId = "select_district",
              label = "Selecionar distrito",
              escolhas = c(
                   "Tudo",
                   "Primavera",
                   "Bolo",
                   "Dingo",
                   "Barnard"
              ),
              selecionado = "Tudo",
              múltiplo = TRUE
         ),
         # seletor para faixa etária
         selectInput(
              inputId = "select_agegroup",
              label = "Selecionar faixa etária",
              escolhas = c(
                   "Todas as idades" = "malaria_tot",
                   "0-4 yrs" = "malaria_rdt_0-4",
                   "5-14 yrs" = "malaria_rdt_5-14",
                   "15+ yrs" = "malaria_rdt_15"
              ),
              selecionado = "Tudo",
              múltiplo = FALSE
         ),
    ),

    mainPanel(
      # epicurva vai aqui
      plotOutput("malaria_epicurve"),
      br(),
      hr(),
      p("Bem-vindo ao aplicativo de visualização de instalações para malária! Para usar este aplicativo, manipule os widgets ao lado para alterar a curva epidêmica de acordo com suas preferências! Para baixar uma imagem de alta qualidade do plot que você criou, você também pode baixá-la com o botão de download. Para ver os dados brutos, use a guia de dados brutos para uma forma interativa da tabela. O dicionário de dados é o seguinte:"),
    tags$ul(
      tags$li(tags$b("location_name"), "- a instalação onde os dados foram coletados"),
      tags$li(tags$b("data_date"), "- a data em que os dados foram coletados"),
      tags$li(tags$b("submitted_daate"), "- a data em que os dados foram enviados"),
      tags$li(tags$b("Província"), "- a província onde os dados foram coletados (todo 'Norte' para este conjunto de dados)"),
      tags$li(tags$b("Distrito"), "- o distrito onde os dados foram coletados"),
      tags$li(tags$b("age_group"), "- a faixa etária para a qual os dados foram coletados (0-5, 5-14, 15+ e todas as idades)"),
      tags$li(tags$b("cases_reported"), "- o número de casos relatados para o estabelecimento / faixa etária na data fornecida")
    )
    
  )
)
)



```

```{r, echo=F}
knitr::include_graphics(here::here("images", "shiny", "app_text_view.png"))
```


### Adicionando um *link* {.unnumbered}

Para adicionar um *link* para um site, use `tags$a()` com o link e exiba o texto conforme mostrado abaixo. Para ter um parágrafo independente, coloque-o dentro de `p()`. Para ter apenas algumas palavras de uma frase ligada, divida a frase em partes e use `tags$a()` para a parte com hiperlink. Para garantir que o link seja aberto em uma *nova* janela do navegador, adicione `target =" _blank"` como um argumento.  

```{r, eval=F}
tags$a(href = "www.epiRhandbook.com", "Visite nosso site!")
```



### Adicionando um botão de *download* {.unnumbered}

Vamos passar para o segundo dos três recursos. Um botão de *download* é algo bastante comum para adicionar a um aplicativo e é bastante fácil de fazer. Precisamos adicionar outro widget à nossa interface do usuário e precisamos adicionar outra saída ao nosso servidor para anexar a ele. Também podemos introduzir *condutores reativos* neste exemplo!


Vamos atualizar nossa interface do usuário primeiro - isso é fácil, pois o shiny vem com um *widget* chamado `downloadButton()` - vamos dar a ele um inputId e um rótulo.

```{r, eval = FALSE}

ui <- fluidPage(

  titlePanel ("Aplicativo de visualização de instalação para malária"),

  sidebarLayout(

    sidebarPanel(
         # seletor para distrito
         selectInput(
              inputId = "select_district",
              label = "Selecionar distrito",
              escolhas = c(
                   "Tudo",
                   "Primavera",
                   "Bolo",
                   "Dingo",
                   "Barnard"
              ),
              selecionado = "Tudo",
              múltiplo = FALSE
         ),
         # seletor para faixa etária
         selectInput(
              inputId = "select_agegroup",
              label = "Selecionar faixa etária",
              escolhas = c(
                   "Todas as idades" = "malaria_tot",
                   "0-4 yrs" = "malaria_rdt_0-4",
                   "5-14 yrs" = "malaria_rdt_5-14",
                   "15+ yrs" = "malaria_rdt_15"
              ),
              selecionado = "Tudo",
              múltiplo = FALSE
         ),
         # linha horizontal
         hr(),
         downloadButton(
           outputId = "download_epicurve",
           label = "Baixar plot"
         )

    ),

    mainPanel(
      # epicurva vai aqui
      plotOutput("malaria_epicurve"),
      br(),
      hr(),
      p("Bem-vindo ao aplicativo de visualização de instalações para malária! Para usar este aplicativo, manipule os widgets ao lado para alterar a curva epidêmica de acordo com suas preferências! Para baixar uma imagem de alta qualidade do plot que você criou, você também pode baixá-la com o botão de download. Para ver os dados brutos, use a guia de dados brutos para uma forma interativa da tabela. O dicionário de dados é o seguinte:"),
      tags$ul(
        tags$li(tags$b("location_name"), "- a instalação onde os dados foram coletados"),
        tags$li(tags$b("data_date"), "- a data em que os dados foram coletados"),
        tags$li(tags$b("submitted_daate"), "- a data em que os dados foram enviados"),
        tags$li(tags$b("Província"), "- a província onde os dados foram coletados (todo 'Norte' para este conjunto de dados)"),
        tags$li(tags$b("Distrito"), "- o distrito onde os dados foram coletados"),
        tags$li(tags$b("age_group"), "- a faixa etária para a qual os dados foram coletados (0-5, 5-14, 15+ e todas as idades)"),
        tags$li(tags$b("cases_reported"), "- o número de casos relatados para o estabelecimento / faixa etária na data fornecida")
      )
      
    )
    
  )
)


```
 
Observe que também adicionamos uma tag `hr()` - isso adiciona uma linha horizontal separando nossos widgets de controle de nossos widgets de download. Esta é outra das tags HTML que discutimos anteriormente.

Agora que temos nossa interface do usuário pronta, precisamos adicionar o componente do servidor. Os downloads são feitos no servidor com a função `downloadHandler()`. Semelhante ao nosso gráfico, precisamos anexá-lo a uma saída que tenha o mesmo inputId do botão de download. Esta função leva dois argumentos - `nome do arquivo` e `conteúdo` - ambos são funções. Como você pode adivinhar, `filename` é usado para especificar o nome do arquivo baixado, e `content` é usado para especificar o que deve ser baixado. `content` contém uma função que você usaria para salvar dados localmente - então se você estivesse baixando um arquivo csv você poderia usar `rio :: export() `. Já que estamos baixando um gráfico, usaremos `ggplot2 :: ggsave()`. Vamos ver como o programamos (não o adicionaremos ao servidor ainda). 

```{r, eval = FALSE}

server <- function(input, output, session) {
  
  output$malaria_epicurve <- renderPlot(
    plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup)
  )
  
  output $ download_epicurve <- downloadHandler (
    filename = function() {
      stringr::str_glue("malaria_epicurve_{input$select_district}.png")
    },
    
    content = function(file) {
      ggsave(file, 
             plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup),
             width = 8, height = 5, dpi = 300)
    }
    
  )
  
}


```


Observe que a função `content` sempre recebe um argumento `file`, que colocamos onde o nome do arquivo de saída é especificado. Você também pode notar que estamos repetindo código aqui - estamos usando nossa função `plot_epicurve()` duas vezes neste servidor, uma para o download e uma vez para a imagem exibida no aplicativo. Embora isso não afete maciçamente o desempenho, isso significa que o código para gerar este gráfico terá que ser executado quando o usuário alterar os widgets especificando o distrito e a faixa etária, *e* novamente quando você quiser fazer o download do gráfico. Em aplicativos maiores, decisões subótimas como esta irão desacelerar as coisas cada vez mais, então é bom aprender como tornar nosso aplicativo mais eficiente neste sentido. O que faria mais sentido é se tivéssemos uma maneira de executar o código epicurva quando os distritos / grupos de idade são alterados, *e permitir que isso seja usado* pelas funções renderPlot() e downloadHandler(). É aqui que entram os condutores reativos! 

Condutores reativos são objetos que são criados no servidor shiny de uma forma *reativa*, mas não são emitidos - eles podem apenas ser usados por outras partes do servidor. Existem vários tipos diferentes de *condutores reativos*, mas examinaremos os dois básicos.

1.`reactive() `- este é o condutor reativo mais básico - ele reagirá sempre que qualquer entrada usada dentro dele mudar (então nossos widgets de distrito / faixa etária)  
2. `eventReactive()` - este condutor reativo funciona da mesma forma que `reactive()`, exceto que o usuário pode especificar quais entradas fazem com que ele seja executado novamente. Isso é útil se o seu condutor reativo demorar muito para processar, mas isso será explicado mais tarde.  

Vejamos os dois exemplos:

```{r, eval = FALSE}

malaria_plot_r <- reactive({
  
  plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup)
  
})


# só funciona quando o seletor de distrito muda!
malaria_plot_er <- eventReactive(input$select_district, {
  
  plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup)
  
})



```

Quando usamos a configuração `eventReactive()`, podemos especificar quais entradas fazem com que esse pedaço de código seja executado - isso não é muito útil para nós no momento, então podemos deixar por enquanto. Observe que você pode incluir várias entradas com `c()`

Vamos ver como podemos integrar isso em nosso código de servidor:


```{r, eval = FALSE}

server <- function(input, output, session) {
  
  malaria_plot <- reactive({
    plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup)
  })
  
  
  
  output$malaria_epicurve <- renderPlot(
    malaria_plot()
  )
  
  output $ download_epicurve <- downloadHandler (
    
    filename = function() {
      stringr::str_glue("malaria_epicurve_{input$select_district}.png")
    },
    
    content = function(file) {
      ggsave(file, 
             malaria_plot(),
             width = 8, height = 5, dpi = 300)
    }
    
  )
  
}


```

Você pode ver que estamos apenas chamando a saída de nosso reativo, que definimos em ambas as funções de download e de renderização de gráficos. Uma coisa a notar, e que muitas vezes confunde as pessoas, é que você precisa usar os resultados dos reativos como se fossem funções - então você *deve adicionar parênteses vazios no final deles* (ou seja, `malaria_plot()` está correto, e `malaria_plot` não está). Agora que adicionamos essa solução, nosso aplicativo está um pouco mais arrumado, mais rápido e mais fácil de alterar, pois todo o nosso código que executa a função da epicurva está em um só lugar.


```{r, echo=F}
knitr::include_graphics(here::here("images", "shiny", "download_button_view.png"))
```


### Adicionando um seletor de instalação {.unnumbered}  

Vamos passar para o nosso próximo recurso - um seletor para instalações específicas. Implementaremos outro parâmetro em nossa função para que possamos informar isso como um argumento de nosso código. Vamos ver como fazer isso primeiro - ele apenas opera com os mesmos princípios que os outros parâmetros que já configuramos. Vamos atualizar e testar nossa função.


```{r, echo = TRUE}

plot_epicurve <- function(data, district = "All", agegroup = "malaria_tot", facility = "All") {
  
  if (!("All" %in% district)) {
    data <- data %>%
      filter(District %in% district)
    
    plot_title_district <- stringr::str_glue("{paste0(district, collapse = ', ')} districts")
    
  } else {
    
    plot_title_district <- "all districts"
    
  }
  
  # se não houver dados restantes, retorna NULL
  if (nrow(data) == 0) {
    
    return(NULL)
  }
  
  data <- data %>%
    filter(age_group == agegroup)
  
  
  # se não houver dados restantes, retorna NULL
  if (nrow(data) == 0) {
    
    return(NULL)
  }
  
  if (agegroup == "malaria_tot") {
      agegroup_title <- "All ages"
  } else {
    agegroup_title <- stringr::str_glue("{str_remove(agegroup, 'malaria_rdt')} years")
  }
  
    if(! ("All" %in% facility)) {
    data <- data %>%
      filter(location_name == facility)
    
    plot_title_facility <- facility
    
  } else {
    
    plot_title_facility <- "todas as instalações"
    
  }
  
  # se não houver dados restantes, retorna NULL
  if (nrow(data) == 0) {
    
    return(NULL)
  }

  
  
  ggplot(data, aes(x = data_date, y = cases_reported)) +
    geom_col(width = 1, fill = "darkred") +
    theme_minimal () +
    labs(
      x = "date",
      y = "number of cases",
      title = stringr::str_glue("Malaria cases - {plot_title_district}; {plot_title_facility}"),
      subtitle = agegroup_title
    )
  
  
  
}
```

Vamos testar:  

```{r, warning=F, message=F, echo=F}

plot_epicurve(malaria_data, district = "Spring", agegroup = "malaria_rdt_0-4", facility = "Facility 1")

```


Com todas as instalações em nossos dados, não está muito claro quais instalações correspondem a quais distritos - e o usuário final também não saberá. Isso pode tornar o uso do aplicativo pouco intuitivo. Por esse motivo, devemos fazer com que as opções de instalação na IU mudem dinamicamente à medida que o usuário muda o distrito - para que uma filtre a outra! Uma vez que temos tantas variáveis que estamos usando nas opções, também podemos querer gerar algumas de nossas opções para a interface do usuário em nosso arquivo _global.R_ _ a partir dos dados_. Por exemplo, podemos adicionar este fragmento de código a _global.R_ depois de lermos nossos dados em:



```{r, echo = FALSE, mensagem = FALSE}

all_districts <- c("All", unique(malaria_data$District))

# quadro de dados de nomes de locais por distrito
installation_list <- malaria_data%>%
  group_by(location_name, District)%>%
  summarise()%>% 
  ungroup()

```

Vamos dar uma olhada neles:  

```{r}
all_districts
```


```{r}
installation_list
```


Podemos passar essas novas variáveis para a interface do usuário sem nenhum problema, pois elas são visíveis globalmente pelo servidor e pela interface do usuário! Vamos atualizar nossa IU:


```{r, eval = FALSE}


ui <- fluidPage(

  titlePanel ("Aplicativo de visualização de instalação para malária"),

  sidebarLayout(

    sidebarPanel(
         # seletor para distrito
         selectInput(
              inputId = "select_district",
              label = "Selecionar distrito",
              choices = all_districts,
              selecionado = "Tudo",
              múltiplo = FALSE
         ),
         # seletor para faixa etária
         selectInput(
              inputId = "select_agegroup",
              label = "Selecionar faixa etária",
              escolhas = c(
                   "Todas as idades" = "malaria_tot",
                   "0-4 yrs" = "malaria_rdt_0-4",
                   "5-14 yrs" = "malaria_rdt_5-14",
                   "15+ yrs" = "malaria_rdt_15"
              ),
              selecionado = "Tudo",
              múltiplo = FALSE
         ),
         # seletor para instalação
         selectInput(
           inputId = "select_facility",
           label = "Selecionar Instalação",
           choices = c("All", facility_list$location_name),
           selecionado = "All"
         ),
         
         # linha horizontal
         hr(),
         downloadButton(
           outputId = "download_epicurve",
           label = "Baixar plot"
         )

    ),

    mainPanel(
      # epicurva vai aqui
      plotOutput("malaria_epicurve"),
      br(),
      hr(),
      p("Bem-vindo ao aplicativo de visualização de instalações para malária! Para usar este aplicativo, manipule os widgets ao lado para alterar a curva epidêmica de acordo com suas preferências! Para baixar uma imagem de alta qualidade do gráfico que você criou, você também pode baixá-la com o botão de download. Para ver os dados brutos, use a guia de dados brutos para uma forma interativa da tabela. O dicionário de dados é o seguinte:"),
      tags$ul(
        tags$li(tags$b("location_name"), "- a instalação onde os dados foram coletados"),
        tags$li(tags$b("data_date"), "- a data em que os dados foram coletados"),
        tags$li(tags$b("submitted_daate"), "- a data em que os dados foram enviados"),
        tags$li(tags$b("Província"), "- a província onde os dados foram coletados (todo 'Norte' para este conjunto de dados)"),
        tags$li(tags$b("Distrito"), "- o distrito onde os dados foram coletados"),
        tags$li(tags$b("age_group"), "- a faixa etária para a qual os dados foram coletados (0-5, 5-14, 15+ e todas as idades)"),
        tags$li(tags$b("cases_reported"), "- o número de casos relatados para o estabelecimento / faixa etária na data fornecida")
      )
      
    )
    
  )
)


```


Observe como agora estamos informando variáveis para nossas escolhas em vez de codificá-las permanentemente na interface do usuário! Isso pode tornar nosso código mais compacto também! Por último, teremos que atualizar o servidor. Será fácil atualizar nossa função para incorporar nossa nova entrada (só temos que passá-la como um argumento para nosso novo parâmetro), mas devemos lembrar que também queremos que a interface do usuário seja atualizada dinamicamente quando o usuário muda o distrito selecionado. É importante entender aqui que *podemos alterar os parâmetros e o comportamento dos widgets* enquanto o aplicativo está em execução, mas isso precisa ser feito *no servidor*. Precisamos entender uma nova forma de saída para o servidor para aprender como fazer isso.

As funções que precisamos entender como fazer isso são conhecidas como funções de *observador* e são semelhantes às funções *reativas* no modo como se comportam. No entanto, eles têm uma diferença fundamental:

- As funções reativas não afetam diretamente as saídas e produzem objetos que podem ser vistos em outros locais no servidor
- As funções do observador *podem* afetar as saídas do servidor, mas fazem isso por meio de efeitos colaterais de outras funções. (Eles também podem fazer outras coisas, mas esta é sua função principal na prática)

Semelhante às funções reativas, existem dois tipos de funções de observador, e eles são divididos pela mesma lógica que divide as funções reativas:

1. `observe()` - esta função é executada sempre que qualquer entrada usada dentro dela muda
2. `observeEvent()` - esta função é executada quando uma entrada *especificada pelo usuário* muda

Também precisamos entender as funções fornecidas de forma shiny que atualizam widgets. Eles são bastante simples de executar - eles primeiro pegam o objeto `sessão` da função do servidor (isso não precisa ser entendido por enquanto), e então o `inputId` da função a ser alterado. Em seguida, passamos novas versões de todos os parâmetros que já são obtidos por `selectInput()` - eles serão atualizados automaticamente no widget. 

Vejamos um exemplo isolado de como poderíamos usar isso em nosso servidor. Quando o usuário muda o distrito, queremos filtrar nossa tabela de instalações por distrito e atualizar as opções para *refletir apenas aquelas que estão disponíveis naquele distrito* (e uma opção para todas as instalações)

```{r, eval = FALSE}

observe({
  
  if (input$select_district == "All") {
    new_choices <- facility_list$location_name
  } else {
    new_choices <- facility_list%>%
      filter(District == input$select_district) %>%
      pull(location_name)
  }
  
  new_choices <- c("All", new_choices)
  
  updateSelectInput(session, inputId = "select_facility",
                    choices = new_choices)
  
})


```

E é isso! podemos adicioná-lo ao nosso servidor, e esse comportamento agora funcionará. Esta é a aparência de nosso novo servidor:

```{r, eval = FALSE}
server <- function(input, output, session) {
  
  malaria_plot <- reactive({
    plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup, facility = input$select_facility)
  })
  
  
  
  observe({
    
    if (input$select_district == "All") {
      new_choices <- facility_list$location_name
    } else {
      new_choices <- facility_list%>%
        filter(District == input$select_district) %>%
        pull(location_name)
    }
    
    new_choices <- c("All", new_choices)
    
    updateSelectInput(session, inputId = "select_facility",
                      choices = new_choices)
    
  })
  
  
  output$malaria_epicurve <- renderPlot(
    malaria_plot()
  )
  
  output $ download_epicurve <- downloadHandler (
    
    filename = function() {
      stringr::str_glue("malaria_epicurve_{input$select_district}.png")
    },
    
    content = function(file) {
      ggsave(file, 
             malaria_plot(),
             width = 8, height = 5, dpi = 300)
    }
    
  )
  
  
  
}

```


```{r, out.width = c ('100%', '100%'), echo = F, fig.show = 'hold', fig.width = 12, fig.height = 9, message = F , warning = F}
knitr::include_graphics(here::here("images", "shiny", "app_menu_view.gif"))
```







### Adicionando outra guia com uma tabela {.unnumbered}

Agora vamos passar para o último componente que queremos adicionar ao nosso aplicativo. Queremos separar nossa interface do usuário em duas guias, uma das quais terá uma tabela interativa onde o usuário pode ver os dados com os quais está fazendo a curva epidêmica. Para fazer isso, podemos usar os elementos da interface do usuário, que já vêm no pacote shiny, que relevantes para a elaboração de guias. Em um nível básico, podemos incluir a maior parte de nosso painel principal nesta estrutura geral:

```{r, eval = FALSE}


# ... o resto da interface do usuário

mainPanel(
  
  tabsetPanel(
    type = "tabs",
    tabPanel(
      "Curvas epidêmicas",
      ...
    ),
    tabPanel(
      "Dados",
      ...
    )
  )
)


```

Vamos aplicar isso à nossa interface do usuário. Também queremos usar o pacote **DT** aqui - este é um ótimo pacote para fazer tabelas interativas a partir de dados pré-existentes. Podemos ver que está sendo usado para `DT :: datatableOutput()` neste exemplo.

```{r, echo = FALSE}
library(DT)
```

```{r, eval = FALSE}
ui <- fluidPage(
     
     titlePanel ("Aplicativo de visualização de instalação para malária"),
     
     sidebarLayout(
          
          sidebarPanel(
               # seletor para distrito
               selectInput(
                    inputId = "select_district",
                    label = "Selecionar distrito",
                    choices = all_districts,
                    selecionado = "Tudo",
                    múltiplo = FALSE
               ),
               # seletor para faixa etária
               selectInput(
                    inputId = "select_agegroup",
                    label = "Selecionar faixa etária",
                    escolhas = c(
                         "Todas as idades" = "malaria_tot",
                         "0-4 yrs" = "malaria_rdt_0-4",
                         "5-14 yrs" = "malaria_rdt_5-14",
                         "15+ yrs" = "malaria_rdt_15"
                    ),
                    selecionado = "Tudo",
                    múltiplo = FALSE
               ),
               # seletor para instalação
               selectInput(
                    inputId = "select_facility",
                    label = "Selecionar Instalação",
                    choices = c("All", facility_list$location_name),
                    selecionado = "All"
               ),
               
               # linha horizontal
               hr(),
               downloadButton(
                    outputId = "download_epicurve",
                    label = "Baixar plot"
               )
               
          ),
          
          mainPanel(
               tabsetPanel(
                    type = "tabs",
                    tabPanel(
                         "Curvas epidêmicas",
                         plotOutput("malaria_epicurve")
                    ),
                    tabPanel(
                         "Dados",
                         DT::dataTableOutput("raw_data")
                    )
               ),
               br(),
               hr(),
               p("Bem-vindo ao aplicativo de visualização de instalações para malária! Para usar este aplicativo, manipule os widgets ao lado para alterar a curva epidêmica de acordo com suas preferências! Para baixar uma imagem de alta qualidade do gráfico que você criou, você também pode baixá-la com o botão de download. Para ver os dados brutos, use a guia de dados brutos para uma forma interativa da tabela. O dicionário de dados é o seguinte:"),
               tags$ul(
                    tags$li(tags$b("location_name"), "- a instalação onde os dados foram coletados"),
                    tags$li(tags$b("data_date"), "- a data em que os dados foram coletados"),
                    tags$li(tags$b("submitted_daate"), "- a data em que os dados foram enviados"),
                    tags$li(tags$b("Província"), "- a província onde os dados foram coletados (todo 'Norte' para este conjunto de dados)"),
                    tags$li(tags$b("Distrito"), "- o distrito onde os dados foram coletados"),
                    tags$li(tags$b("age_group"), "- a faixa etária para a qual os dados foram coletados (0-5, 5-14, 15+ e todas as idades)"),
                    tags$li(tags$b("cases_reported"), "- o número de casos relatados para o estabelecimento / faixa etária na data fornecida")
               )
               
               
          )
     )
)


```


Agora nosso aplicativo está organizado em guias! Vamos fazer as edições necessárias no servidor também. Como não precisamos manipular nosso conjunto de dados antes de renderizá-lo, isso é na verdade muito simples - apenas renderizamos o conjunto de dados malaria_data via DT :: renderDT() para a interface do usuário!


```{r, eval = FALSE}
server <- function(input, output, session) {
  
  malaria_plot <- reactive({
    plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup, facility = input$select_facility)
  })
  
  
  
  observe({
    
    if (input$select_district == "All") {
      new_choices <- facility_list$location_name
    } else {
      new_choices <- facility_list%>%
        filter(District == input$select_district) %>%
        pull(location_name)
    }
    
    new_choices <- c("All", new_choices)
    
    updateSelectInput(session, inputId = "select_facility",
                      choices = new_choices)
    
  })
  
  
  output$malaria_epicurve <- renderPlot(
    malaria_plot()
  )
  
  output $ download_epicurve <- downloadHandler (
    
    filename = function() {
      stringr::str_glue("malaria_epicurve_{input$select_district}.png")
    },
    
    content = function(file) {
      ggsave(file, 
             malaria_plot(),
             width = 8, height = 5, dpi = 300)
    }
    
  )
  
  # renderiza a tabela de dados para ui
  output$raw_data <- DT::renderDT(
    malaria_data
  )
  
  
}


```


```{r, out.width = c ('100%', '100%'), echo = F, fig.show = 'hold', fig.width = 12, fig.height = 9, message = F , warning = F}
knitr::include_graphics(here::here("images", "shiny", "app_table_view.gif"))
```


## Compartilhando aplicativos shiny

Agora que você desenvolveu seu aplicativo, provavelmente deseja compartilhá-lo com outras pessoas - afinal, essa é a principal vantagem do shiny! Podemos fazer isso compartilhando o código diretamente ou podemos publicá-lo em um servidor. Se compartilharmos o código, outros poderão ver o que você fez e construir sobre ele, mas isso negará uma das principais vantagens do shiny - *pode eliminar a necessidade dos usuários finais de manter uma instalação R* . Por esse motivo, se você estiver compartilhando seu aplicativo com usuários que não se sentem confortáveis com R, é muito mais fácil compartilhar um aplicativo que foi publicado em um servidor. 

Se você preferir compartilhar o código, pode fazer um arquivo .zip do aplicativo, ou melhor ainda, *publicar seu aplicativo no github e adicionar colaboradores.* Você pode consultar a seção no github para obter mais informações aqui.

No entanto, se estamos publicando o aplicativo online, precisamos trabalhar um pouco mais. Em última análise, queremos que seu aplicativo possa ser acessado por meio de um URL da web para que outras pessoas possam ter acesso rápido e fácil a ele. Infelizmente, para publicar seu aplicativo em um servidor, você precisa ter acesso a um servidor para publicá-lo! Existem várias opções de hospedagem quando se trata disso:

- _shinyapps.io_: este é o lugar mais fácil para publicar aplicativos shiny, pois tem a menor quantidade de trabalho de configuração necessária e tem algumas licenças gratuitas, mas limitadas.

- _RStudio Connect_: esta é uma versão muito mais poderosa de um servidor R, que pode realizar muitas operações, incluindo a publicação de aplicativos shiny. No entanto, é mais difícil de usar e menos recomendado para usuários iniciantes.

Para os fins deste documento, usaremos _shinyapps.io_, pois é mais fácil para usuários iniciantes. Você pode criar uma conta gratuita aqui para começar - também existem diferentes planos de preços para licenças de servidor, se necessário. Quanto mais usuários você espera ter, mais caro seu plano de preços terá que ser, portanto, mantenha isso em consideração. Se você está procurando criar algo para um pequeno grupo de indivíduos usar, uma licença gratuita pode ser perfeitamente adequada, mas um aplicativo voltado ao público pode precisar de mais licenças.

Primeiro, devemos nos certificar de que nosso aplicativo é adequado para publicação em um servidor. Em seu aplicativo, você deve reiniciar sua sessão R e garantir que ela seja executada sem executar nenhum código extra. Isso é importante, pois um aplicativo que requer carregamento de pacote ou a leitura de dados não definida no código do aplicativo não será executado em um servidor. Observe também que você não pode ter nenhum caminho de arquivo *explícito* em seu aplicativo - eles serão inválidos na configuração do servidor - usar o pacote `here` resolve este problema muito bem. Finalmente, se você estiver lendo dados de uma fonte que requer autenticação do usuário, como os servidores da sua organização, isso geralmente não funcionará em um servidor. Você precisará entrar em contato com seu departamento de TI para descobrir como colocar o servidor shiny na lista de permissões aqui.

*inscrevendo-se em uma conta*

Depois de ter sua conta, você pode navegar até a página de tokens em _Contas_. Aqui você desejará adicionar um novo token - ele será usado para implantar seu aplicativo. 

A partir daqui, você deve observar que o url da sua conta refletirá o nome do seu aplicativo - portanto, se o seu aplicativo se chamar _my_app_, o url será anexado como _xxx.io/my_app/_. Escolha o nome do seu aplicativo com sabedoria! Agora que você está pronto, clique em implantar - se for bem-sucedido, seu aplicativo será executado no url da web que você escolheu!

*algo sobre como fazer aplicativos em documentos?*

## Leitura adicional

Até agora, cobrimos muitos aspectos do shiny e mal arranhamos a superfície do que é oferecido ele. Embora este guia sirva como uma introdução, há muito mais coisas para aprender para entender completamente o shiny. Você deve começar a fazer aplicativos e adicionar gradualmente mais e mais funcionalidades


## Pacotes de extensão recomendados

O que segue representa uma seleção de extensões shiny de alta qualidade que podem ajudá-lo a obter muito mais brilho (trocadilho com o nome *shiny* que em inglês significa "brilhante"). Em nenhuma ordem particular:

- **BrightWidgets** - este pacote oferece muitos, muitos mais widgets que podem ser usados em seu aplicativo. Execute `shinyWidgets::shinyWidgetsGallery()` para ver uma seleção de widgets disponíveis com este pacote. Veja exemplos [aqui](https://github.com/dreamRs/shinyWidgets)  

- **Brightjs** - este é um excelente pacote que dá ao usuário a habilidade de estender muito a utilidade do shiny por meio de uma série de javascript. Os aplicativos deste pacote variam de muito simples a altamente avançado, mas você pode querer usá-lo primeiro para manipular a interface do usuário de maneiras simples, como ocultar / mostrar elementos ou habilitar / desabilitar botões. Saiba mais [aqui](https://deanattali.com/shinyjs/basic)

- **Brightdashboard** - este pacote expande enormemente a interface do usuário disponível que pode ser usada em shiny, permitindo especificamente que o usuário crie um painel complexo com uma variedade de layouts complexos. Veja mais [aqui](https://rstudio.github.io/shinydashboard/)

- **BrightdashboardPlus** - obtenha ainda mais recursos da estrutura do **Brightdashboard**! Veja mais [aqui](https://rinterface.github.io/shinydashboardPlus/articles/shinydashboardPlus.html)

- **Brightthemes** - mude o tema CSS padrão para seu aplicativo shiny com uma ampla gama de modelos predefinidos! Veja mais [aqui](https://rstudio.github.io/shinythemes/)


Existem também vários pacotes que podem ser usados para criar saídas interativas compatíveis com o shiny. 

- **DT** é semi-incorporado em base shiny, mas fornece um grande conjunto de funções para criar tabelas interativas.

- **plotly** é um pacote para a criação de gráficos interativos que o usuário pode manipular no aplicativo. Você também pode converter seu gráfico para versões interativas via `plotly::ggplotly()`! Como alternativas, **dygraphs** e **highcharter** também são excelentes.


## Recursos recomendados


```{r include=FALSE, cache=FALSE}

# clear workspace
rm(list = ls(all = TRUE))

# clear all packages except base
#lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))

# to ensure that tidyverse packages prevail
filter <- dplyr::filter
select <- dplyr::select
summarise <- dplyr::summarise
summary <- base::summary
incidence <- incidence2::incidence

#load core packages
pacman::p_load(
     rio,
     here,
     DT,
     stringr,
     lubridate,
     tidyverse
)

# import the cleaned ebola linelist
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

# import the count data - facility level
#count_data <- rio::import(here::here("data", "facility_count_data.rds"))

# Settings

options(scipen=1, digits=7)

# print only text (not code)
# library(knitr)
# opts_chunk$set(list(echo = FALSE, eval = FALSE))
```

<!--chapter:end:new_pages/shiny_basics.Rmd-->

# (PART) Miscelânea {.unnumbered}
```{r include=FALSE, cache=FALSE}

# clear workspace
rm(list = ls(all = TRUE))

# clear all packages except base
#lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))

# to ensure that tidyverse packages prevail
filter <- dplyr::filter
select <- dplyr::select
summarise <- dplyr::summarise
summary <- base::summary
incidence <- incidence2::incidence

#load core packages
pacman::p_load(
     rio,
     here,
     DT,
     stringr,
     lubridate,
     tidyverse
)

# import the cleaned ebola linelist
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

# import the count data - facility level
#count_data <- rio::import(here::here("data", "facility_count_data.rds"))

# Settings

options(scipen=1, digits=7)

# print only text (not code)
# library(knitr)
# opts_chunk$set(list(echo = FALSE, eval = FALSE))
```

<!--chapter:end:new_pages/cat_misc.Rmd-->

# Escrevendo funções  {#writing-functions}


<!-- ======================================================= -->
## Preparação {  }


### Carregar pacotes {-}

Este "chuk" (pedaço) de código mostra o carregamento de pacotes necessários para as análises. Neste manual, enfatizamos `p_load()` de **pacman**, que instala o pacote, se necessário, *e* carrega ele para ser utilizado. Você também pode carregar pacotes instalados com  `library()` do R **base**. Veja em [Introdução ao R](#basics) para mais informações sobre pacotes R.  

```{r, echo=F, warning=F, message=F}
pacman::p_load(
  rio,          # Importar arquivos
  here,         # Localizar de arquivos
  skimr,        # Obter uma visão geral dos dados
  tidyverse,    # Gerenciar dados + gráficos ggplot2 
  gtsummary,    # Estatísticas resumo e testes
  janitor,      # Adicionar totais e porcentagens às tabelas
  scales,       # Converter facilmente proporções em porcentagens  
  flextable,    # Converter tabelas para HTML
  purrr,        # Tornar a programação de funções mais fácil
  readr,        # Ler arquivos csv
  highcharter   # Criar objeto highchart e desenhar um gráfico particular

  )
```

### Importar dados {-}

Importamos os dados de casos de uma simulação de epidemia de Ebola. Se desejar fazer o download dos dados para seguir passo a passo, veja as instruções na página [Baixar livro e dados](#data-used). O conjunto de dados é importado usando a função `import ()` do pacote **rio**. Consulte a página [Importar e exportar](#importing) para várias maneiras de importar dados.

Também usaremos na última parte desta página alguns dados sobre a gripe H7N9 de 2013.

```{r, echo=F}
# Importar as listas de casos para o R
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

flu_china <- rio::import(here::here("data", "case_linelists", "fluH7N9_China_2013.csv"))

```


## Funções

As funções são úteis na programação, pois permitem tornar os códigos mais fáceis de entender, de alguma forma mais curtos e menos sujeitos a erros (dado que não haja erros na própria função).

Se você chegou até aqui neste manual, significa que encontrou inúmeras funções, uma vez que no R toda operação é uma chamada de função `+, for, if, [, $, { …`. Por exemplo `x + y` é o mesmo que `'+'(x, y)`

R é uma das linguagens que oferece a maior possibilidade de trabalhar com funções e dar ferramentas suficientes para que o usuário as escreva facilmente. Não devemos pensar nas funções como fixas no topo ou no final da cadeia de programação, o R oferece a possibilidade de usá-las como se fossem vetores e até mesmo dentro de outras funções, listas ...

Existem muitos recursos muito avançados sobre programação de funções e só daremos aqui uma visão para ajudá-lo a começar com breves exemplos práticos. Em seguida, você é incentivado a visitar os links de referências para ler mais sobre o assunto.

## Por que você usaria uma função?

Antes de responder a esta pergunta, é importante observar que você já recebeu dicas para escrever suas primeiras funções R na página [Iteração, loops e listas](#iteration) deste manual. Na verdade, o uso de "if / else" e loops costuma ser uma parte central de muitas de nossas funções, pois ajudam a ampliar a aplicação do nosso código, permitindo várias condições, ou a iterar códigos para tarefas repetidas.

- Estou repetindo várias vezes o mesmo bloco de código para aplicá-lo a uma variável ou dado diferente?

- Livrar-se dele irá encurtar substancialmente meu código e torná-lo executado mais rápido?

- É possível que o código que escrevi seja usado novamente, mas com um valor diferente em muitos lugares do código?

Se a resposta a uma das perguntas anteriores for "SIM", provavelmente você precisará escrever uma função


## Como o R cria funções?

As funções em R têm três componentes principais:

- `formals ()`, que é a lista de argumentos que controla como podemos rodar a função

- `body ()`, que é o código dentro da função, ou seja, entre colchetes ou após o parêntese, dependendo de como o escrevemos

e,

- `environment ()` que ajudará a localizar as variáveis da função e determina como a função encontra o valor.
 
Depois de criar sua função, você pode verificar cada um desses componentes chamando a função associada.
 

## Sintaxe e estrutura básicas


- Uma função precisará ser nomeada corretamente para que sua tarefa seja facilmente compreensível assim que lermos seu nome. Na verdade, este já é o caso com a maioria da arquitetura do R base. Funções como `mean ()`, `print ()`, `summary ()` têm nomes que são muito diretos

- Uma função precisará de argumentos, como os dados nos quais trabalhar e outros objetos que podem ser valores estáticos entre outras opções  

- E, finalmente, uma função fornecerá uma saída com base em sua tarefa principal e nos argumentos fornecidos. Normalmente usaremos funções embutidas como `print ()`, `return ()` ... para produzir a saída. A saída pode ser um valor lógico, um número, um caractere, um quadro de dados ... em suma, qualquer tipo de objeto R.

Basicamente, esta é a composição de uma função:

```{r, eval=FALSE}

nome_da_funcao <- function(argumento_1, argumento_2, argumento_3){
  
           function_task
  
           return(output)
}


```

Podemos criar nossa primeira função que será chamada `conter_covid19 ()`. 

```{r}

conter_covid19 <- function(distanciamento_social, usar_mascara, vacinacao){
  
                            if(distanciamento_social == "sim" & usar_mascara == "sim" & vacinacao == "sim" ) 
       
                            return("successo")
  
  else("Certifique-se de que todos sejam 'sim', esta pandemia tem que acabar!")
}


```

Podemos então verificar os componentes de nossa função recém-criada.

```{r}

formals(conter_covid19)
body(conter_covid19)
environment(conter_covid19)

```

Agora vamos testar nossa função. Para rodar nossa função escrita, você a usa da mesma forma que usa todas as funções R, ou seja, escrevendo o nome da função e adicionando os argumentos necessários.


```{r}

conter_covid19(distanciamento_social = "sim", usar_mascara = "sim", vacinacao = "sim")

```

Podemos escrever novamente o nome de cada argumento por razões de precaução. Mas o código deve funcionar mesmo sem especificá-los, uma vez que o R tem na memória o posicionamento de cada argumento. Portanto, desde que você coloque os valores dos argumentos na ordem correta, você pode pular a escrita dos nomes dos argumentos ao rodar as funções.

```{r}

conter_covid19("sim", "sim", "sim")

```

Então, vamos ver o que acontece se um dos valores for `"não"` ou **diferente de** `"sim"`.

```{r}

conter_covid19(distanciamento_social = "sim", usar_mascara = "sim", vacinacao = "não")
```

Se fornecermos um argumento que não é reconhecido, obteremos um erro:


```{r, eval=F}
conter_covid19(distanciamento_social = "às vezes", usar_mascara = "sim", vacinacao = "não")
```

`Error in conter_covid19(distanciamento_social = "às vezes", usar_mascara = "sim",  : 
  could not find function "conter_covid19"`


<span style="color: black;">**_NOTA:_** Algumas funções (na maioria das vezes muito curtas e diretas) podem não precisar de um nome e podem ser usadas diretamente em uma linha de código, ou dentro de outra função, para fazer tarefa rápida. Elas são chamadas de **funções anônimas**. </span>

Por exemplo, abaixo está uma primeira função anônima que mantém apenas variáveis de caracteres no conjunto de dados.

```{r, eval=F}
linelist %>% 
  dplyr::slice_head(n=10) %>%  # Equivalente à função "head" do R base, que retorna as primeiras n observações do conjunto de dados
    select(function(x) is.character(x)) 
```
  
```{r, echo=F}
linelist %>% 
  dplyr::slice_head(n=10) %>%  # Equivalente à função "head" do R base, que retorna as primeiras n observações do conjunto de dados
  select(function(x) is.character(x)) %>%  
DT::datatable(rownames = FALSE, filter="top", options = list(pageLength = 10, scrollX=T), class = 'white-space: nowrap' )
```


Outra função poderia selecionar o segundo registro realizado no nosso conjunto de dados. Pode ser relevante quando temos dados longitudinais com muitos registros por paciente, por exemplo, após ter solicitado por data ou visita). Nesse caso, a função apropriada para escrever fora do dplyr seria `function (x) (x %% 2 == 0)` para aplicar ao vetor contendo todos os números de linha.


```{r, eval=F}
linelist %>%   
   slice_head(n=20) %>% 
   tibble::rownames_to_column() %>% # Adiciona índices de cada registro como rownames para ver claramente a seleção final
   filter(row_number() %%2 == 0)
```

```{r, echo=F}
linelist %>%   
   slice_head(n=20) %>% 
   tibble::rownames_to_column() %>%    # Adiciona índices de cada registro como rownames para ver claramente a seleção final
   filter(row_number() %%2 == 0) %>% 
DT::datatable(rownames = FALSE, filter="top", options = list(pageLength = 10, scrollX=T), class = 'white-space: nowrap' )

```


Um possível código do R base para a mesma tarefa seria:

```{r, eval = F}

linelist_firstobs <- head(linelist, 20)

linelist_firstobs[base::Filter(function(x) (x%%2 == 0), seq(nrow(linelist_firstobs))),]
```

```{r, echo=F}

linelist_firstobs <- head(linelist, 20)

linelist_firstobs[base::Filter(function(x) (x%%2 == 0), seq(nrow(linelist_firstobs))),] %>% 
DT::datatable(rownames = FALSE, filter="top", options = list(pageLength = 10, scrollX=T), class = 'white-space: nowrap' )

```


<span style="color: orange;">**_CUIDADO:_** Se por um lado é verdade que o uso de funções pode nos ajudar com nosso código, também pode ser demorado escrever ou mesmo consertá-las se não tiver sido pensada completamente, escrita de forma adequada ou estiver retornando erros como resultado. Por esse motivo, geralmente é recomendado escrever primeiro o código R, certificar-se de que ele faz o que pretendemos fazer e, em seguida, transformá-lo em uma função com seus três componentes principais, conforme listado acima. </span>

## Exemplos  

### Retorna tabelas de proporção para várias colunas {.unnumbered}  

Sim, já temos funções interessantes em muitos pacotes, permitindo resumir informações de uma forma muito fácil e agradável. Mas ainda vamos tentar fazer o nosso próprio, em nossos primeiros passos para nos acostumarmos a escrever funções.

Neste exemplo, queremos mostrar como escrever uma função simples evitaria que você copiasse e colasse o mesmo código várias vezes.

```{r}

proptab_multiple <- function(my_data, var_to_tab){
  
  # Grava o nome de cada variável de interesse antes de fazer a tabulação
  print(var_to_tab)

  with(my_data,
       rbind( # Vincula os resultados das duas funções seguintes por linha
        # Tabula a variável de interesse: fornece apenas números
          table(my_data[[var_to_tab]], useNA = "no"),
          # Calcula as proporções para cada variável de interesse e arredonda o resultado para 2 decimais
         round(prop.table(table(my_data[[var_to_tab]]))*100,2)
         )
       )
}


proptab_multiple(linelist, "gender")

proptab_multiple(linelist, "age_cat")

proptab_multiple(linelist, "outcome")


```

<span style="color: darkgreen;">**_DICA:_** Como mostrado acima, é muito importante comentar suas funções como você faria para a programação geral. Lembre-se de que o objetivo de uma função é deixar um código pronto para ser lido, mais curto e mais eficiente. Então, deve-se ser capaz de entender o que a função faz apenas lendo seu nome e encontrar mais detalhes lendo os comentários.</span>


Uma segunda opção é usar a função dentro de outra, por meio de um loop para fazer o processo de uma vez:

```{r}


for(var_to_tab in c("gender","age_cat",  "outcome")){
  
  print(proptab_multiple(linelist, var_to_tab))
  
}

```

Uma maneira mais simples poderia ser usar o "apply" do R base em vez de um "for loop", conforme abaixo:


```{r, include= FALSE, eval=FALSE}

base::lapply(linelist[,c("gender","age_cat", "outcome")], table)

```


<span style="color: darkgreen;">**_DICA:_** R é frequentemente definido como uma linguagem de programação funcional e quase sempre que você executa uma linha de código, está usando algumas funções integradas. Um bom hábito para ficar mais confortável com funções de escrita é frequentemente dar uma olhada interna em como as funções básicas que você usa diariamente são criadas. O atalho para isso é selecionar o nome da função e clicar em`Ctrl+F2` ou `fn+F2` ou `Cmd+F2` (dependendo do seu computador) .</span>

## Usando **purrr**: Escrevendo funções que podem ser aplicadas iterativamente

### Modificar a classe de várias colunas em um conjunto de dados {.unnumbered}  

Digamos que muitas variáveis do tipo caractere nos dados originais da `linelist` precisem ser alteradas para "fator" para fins de análise e plotagem. Em vez de repetir a etapa várias vezes, podemos apenas usar `lapply ()` para fazer a transformação de todas as variáveis envolvidas em uma única linha de código.

<span style="color: orange;">**_CUIDADO:_** `lapply()` retorna uma lista, portanto, seu uso pode exigir uma modificação adicional como última etapa.</span>


```{r, include=FALSE}

linelist_factor1 <- linelist %>%
      lapply(
          function(x) if(is.character(x)) as.factor(x) else x) %>%
      as.data.frame() %>% 
      glimpse()

```


O mesmo passo pode ser feito usando a função `map_if ()` do pacote **purr**

```{r}

linelist_factor2 <- linelist %>%
  purrr::map_if(is.character, as.factor)


linelist_factor2 %>%
        glimpse()

```


### Produzir gráficos iterativamente para diferentes níveis de uma variável {.unnumbered}

Vamos produzir um gráfico de pizza para observar a distribuição dos resultados dos pacientes na China durante o surto de H7N9 para cada província. Em vez de repetir o código para cada um deles, apenas aplicaremos uma função que criaremos.

```{r}

# Opções precisas para o uso do highchart
options(highcharter.theme =   highcharter::hc_theme_smpl(tooltip = list(valueDecimals = 2)))


# Criar uma função chamada "chart_outcome_province" que leva como argumento o conjunto de dados e o nome da província para a qual plotar a distribuição do resultado.

chart_outcome_province <- function(data_used, prov){
  
  tab_prov <- data_used %>% 
    filter(province == prov,
           !is.na(outcome))%>% 
    group_by(outcome) %>% 
    count() %>%
    adorn_totals(where = "row") %>% 
    adorn_percentages(denominator = "col", )%>%
    mutate(
        perc_outcome= round(n*100,2),
        outcome=ifelse(outcome=="Death", "Óbito",  #só traduzindo para ficar com rótulos
                       ifelse(outcome=="Recover","Recuperado", outcome))) # em português
 

  
  
  tab_prov %>%
    filter(outcome != "Total") %>% 
  highcharter::hchart(
    "pie", hcaes(x = outcome, y = perc_outcome),
    name = paste0("Distribuição do desfecho em:", prov)
    )
  
}

chart_outcome_province(flu_china, "Shanghai")
chart_outcome_province(flu_china,"Zhejiang")
chart_outcome_province(flu_china,"Jiangsu")


```


### Produzir tabelas iterativamente para diferentes níveis de uma variável {.unnumbered}

Aqui criaremos três indicadores para resumir em uma tabela e gostaríamos de produzir esta tabela para cada uma das províncias. Nossos indicadores são o atraso entre o início e a internação, o percentual de recuperação e a idade mediana dos casos.

```{r}


indic_1 <- flu_china %>% 
  group_by(province) %>% 
  mutate(
    date_hosp= strptime(date_of_hospitalisation, format = "%m/%d/%Y"),
    date_ons= strptime(date_of_onset, format = "%m/%d/%Y"), 
    delay_onset_hosp= as.numeric(date_hosp - date_ons)/86400,
    mean_delay_onset_hosp = round(mean(delay_onset_hosp, na.rm=TRUE ), 0)) %>%
  select(province, mean_delay_onset_hosp)  %>% 
  distinct()
     

indic_2 <-  flu_china %>% 
            filter(!is.na(outcome)) %>% 
            group_by(province, outcome) %>% 
            count() %>%
            pivot_wider(names_from = outcome, values_from = n) %>% 
    adorn_totals(where = "col") %>% 
    mutate(
        perc_recovery= round((Recover/Total)*100,2))%>% 
  select(province, perc_recovery)
    
    
    
indic_3 <-  flu_china %>% 
            group_by(province) %>% 
            mutate(
                    median_age_cases = median(as.numeric(age), na.rm = TRUE)
            ) %>% 
  select(province, median_age_cases)  %>% 
  distinct()

# Junte os três conjuntos de dados de indicadores

table_indic_all <- indic_1 %>% 
  dplyr::left_join(indic_2, by = "province") %>% 
        left_join(indic_3, by = "province")


# Imprima os indicadores em uma flextable


print_indic_prov <-  function(table_used, prov){
  
  # Primeiro, transforme um pouco o quadro de dados para facilitar a visualização
 indic_prov <- table_used %>%
    filter(province==prov) %>%
    pivot_longer(names_to = "Indicadores", cols = 2:4)%>% 
   mutate( indic_label = factor(Indicadores,
   levels= c("mean_delay_onset_hosp","perc_recovery","median_age_cases"),
   labels=c("Atraso entre início e internação", "Percentual de recuperação", "Idade mediana dos casos"))
   ) %>% 
    ungroup(province) %>% 
    select(indic_label, value)
  

  tab_print <- flextable(indic_prov)  %>%
    theme_vanilla() %>% 
    flextable::fontsize(part = "body", size = 10) 
    
    
     tab_print <- tab_print %>% 
                  autofit()   %>%
                  set_header_labels( 
                indic_label= "Indicadores", value= "Estimativa") %>%
    flextable::bg( bg = "darkblue", part = "header") %>%
    flextable::bold(part = "header") %>%
    flextable::color(color = "white", part = "header") %>% 
    add_header_lines(values = paste0("Indicadores para a província de:", prov)) %>% 
bold(part = "header")
 
 tab_print <- set_formatter_type(tab_print,
   fmt_double = "%.2f",
   na_str = "-")

tab_print 
    
}




print_indic_prov(table_indic_all, "Shanghai")
print_indic_prov(table_indic_all, "Jiangsu")


```


## Dicas e práticas recomendadas para o bom funcionamento das funções

A programação de funções visa facilitar o código e facilitar sua leitura. Deve produzir o contrário. As dicas abaixo irão ajudá-lo a ter um código limpo e fácil de ler.

### Nomenclatura e sintaxe {.unnumbered}

- Evite usar caracteres que poderiam facilmente ter sido contemplados em outras funções já existentes em seu ambiente

- Recomenda-se que o nome da função seja curto e fácil de entender 

- É preferível usar verbos como o nome da função e substantivos para os nomes dos argumentos.


### Nomes de coluna e avaliação organizada {.unnumbered}  

Se você quiser saber como fazer referência a *nomes de coluna* fornecidos em seu código como argumentos, leia  [tidyverse programming guidance](https://dplyr.tidyverse.org/articles/programming.html).Entre os tópicos cobertos estão *avaliação arrumada* (de *tidy evaluation*) e uso de *embrace* `{{ }}` "Colchetes duplos"

Por exemplo, aqui está um esqueleto rápido de código modelo da página do tutorial mencionado acima:

```{r, eval=F}

var_summary <- function(data, var) {
  data %>%
    summarise(n = n(), min = min({{ var }}), max = max({{ var }}))
}
mtcars %>% 
  group_by(cyl) %>% 
  var_summary(mpg)

```


### Teste e tratamento de erros {.unnumbered}

Quanto mais complicada a tarefa de uma função, maior a possibilidade de erros. Portanto, às vezes é necessário adicionar alguma verificação na função para ajudar a entender rapidamente de onde vem o erro e encontrar uma maneira de corrigi-lo.

- Pode ser mais do que recomendado introduzir uma verificação sobre a falta de um argumento usando `missing(argumento)`. Esta verificação simples pode retornar um valor "TRUE" (verdadeiro) ou "FALSE" (falso).

```{r , error=TRUE}

conter_covid19_missing <- function(distanciamento_social, usar_mascara, vacinacao){
  
  if (missing(distanciamento_social)) (print("Por favor, forneça o arg1"))
  if (missing(usar_mascara)) print("Por favor, forneça o arg2")
  if (missing(vacinacao)) print("Por favor, forneça o arg3")


  if (!distanciamento_social == "sim" | usar_mascara =="sim" | vacinacao == "sim" ) 
       
       return ("Você pode fazer melhor")
  
  else("Certifique-se de que todos estejam 'sim', esta pandemia tem que acabar!")
}


conter_covid19_missing(vacinacao = "sim")

```


- Use `stop()` para mais erros detectáveis.

```{r, error=TRUE}

conter_covid19_stop <- function(distanciamento_social, usar_mascara, vacinacao){
  
  if(!is.character(distanciamento_social)) (stop("arg1 deve ser um caractere, digite o valor com` sim`, `não` ou` às vezes"))
  
  if (distanciamento_social == "sim" & usar_mascara =="sim" & vacinacao == "sim" ) 
       
       return ("successo")
  
  else("Certifique-se de que todos estejam 'sim', esta pandemia tem que acabar!")
}


conter_covid19_stop(distanciamento_social=1, usar_mascara="sim", vacinacao = "não")

```

- Como vemos quando executamos a maioria das funções integradas, existem mensagens e avisos que podem aparecer em certas condições. Podemos integrá-los na escrita de nossas funções usando as funções `message()` e `warning()`.

- Também podemos lidar com erros usando `safely()`, que pega uma função como um argumento e a executa de maneira segura. Na verdade, a função será executada sem parar se encontrar um erro. `safely()` retorna como resultado uma **list** com dois objetos, que são os resultados e o erro "pulado".

Podemos verificar executando primeiro a `mean()` como função e, em seguida, executando com `secure ()`.


```{r, warning=FALSE}

map(linelist, mean)
```


```{r, warning=FALSE}
safe_mean <- safely(mean)
linelist %>% 
  map(safe_mean)

```


Como dito anteriormente, comentar bem nossos códigos já é uma boa forma de termos documentação em nosso trabalho.  


<!-- ======================================================= -->
## Recursos


[link para o livro R para Ciência de Dados](https://r4ds.had.co.nz/functions.html)   

[Cheatsheet (cola) em programação avançada em R](https://www.rstudio.com/wp-content/uploads/2016/02/advancedR.pdf)

[Cheatsheet (cola) do Pacote purr](https://purrr.tidyverse.org/)

[Video-ACM palesta por Hadley Wickham: A alegria da programação funcional (como map_dbl funciona)](https://youtube.videoken.com/embed/bzUmK0Y07ck)
```{r include=FALSE, cache=FALSE}

# clear workspace
rm(list = ls(all = TRUE))

# clear all packages except base
#lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))

# to ensure that tidyverse packages prevail
filter <- dplyr::filter
select <- dplyr::select
summarise <- dplyr::summarise
summary <- base::summary
incidence <- incidence2::incidence

#load core packages
pacman::p_load(
     rio,
     here,
     DT,
     stringr,
     lubridate,
     tidyverse
)

# import the cleaned ebola linelist
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

# import the count data - facility level
#count_data <- rio::import(here::here("data", "facility_count_data.rds"))

# Settings

options(scipen=1, digits=7)

# print only text (not code)
# library(knitr)
# opts_chunk$set(list(echo = FALSE, eval = FALSE))
```

<!--chapter:end:new_pages/writing_functions.Rmd-->


# Interações de diretório {#directories}  

Nesta página, cobrimos cenários comuns onde você cria, interage, salva e importa com diretórios (pastas).

## Preparação

### Pacote **fs**  {.unnumbered}  

O **fs**  é um pacote do **tidyverse** que facilita as interações de diretório, melhorando algumas das funções do R **base**. Nas seções a seguir, usaremos frequentemente as funções do **fs**.  

```{r}
pacman::p_load(
  fs,             # Interações de arquivo / diretório
  rio,            # Importar / Exportar
  here,           # Caminhos de arquivo respectivos
  tidyverse)      # Gerenciamento e visualização de dados
```


### Imprimir diretório como uma árvore de dendrograma {.unnumbered}  

Use a função `dir_tree()` do **fs**.  

Forneça o caminho da pasta do arquivo para `path =` e decida se deseja mostrar apenas um nível (`recurse = FALSE`) ou todos os arquivos em todos os subníveis (`recurse = TRUE`). Abaixo, usamos `here()` como uma abreviação para o projeto R e especificamos sua subpasta "data" (dados), que contém todos os dados usados para este manual de R. Nós o configuramos para exibir todos os arquivos na pasta supra citada e suas subpastas (por exemplo, "cache", "epidemic models", "population", "shp", and "weather").


```{r}
fs::dir_tree(path = here("data"), recurse = TRUE)
```


## Listar arquivos em um diretório  

Para listar apenas os nomes dos arquivos em um diretório, você pode usar `dir()` do R **base**. Por exemplo, este comando lista os nomes dos arquivos na subpasta "população" da pasta "dados" em um projeto R. O caminho de arquivo respectivo é fornecido usando `here()` (sobre o qual você pode ler mais na página [Importar e exportar](#importing)).


```{r}
# Nomes de arquivos
dir(here("data", "gis", "population"))
```

Para listar os caminhos completos dos arquivos do diretório, você pode usar `dir_ls()` de **fs**. Uma alternativa é `list.files()` do R **base **.


```{r}
# Caminhos de arquivos
dir_ls(here("data", "gis", "population"))
```

Para obter todas as informações de metadados sobre cada arquivo em um diretório (por exemplo, caminho, data de modificação, etc.), você pode usar `dir_info()` de **fs**.

Isso pode ser particularmente útil se você deseja extrair a hora da última modificação do arquivo, por exemplo, se deseja importar a versão mais recente. Para obter um exemplo disso, consulte a página [Importar e exportar](#importing).

```{r, eval=F}
# Informações do arquivo
dir_info(here("data", "gis", "population"))
```

Aqui está o dataframe que retorna. Role para a direita para ver todas as colunas.  

```{r, echo=F}
DT::datatable(dir_info(here("data", "gis", "population")), rownames = FALSE, options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```

## Informações do arquivo  

Para extrair informações de metadados sobre um arquivo específico, você pode usar `file_info()` de **fs** (ou `file.info()` do R **base**).

```{r, eval=F}
file_info(here("data", "case_linelists", "linelist_cleaned.rds"))
```

```{r, echo=F}
DT::datatable(file_info(here("data", "case_linelists", "linelist_cleaned.rds")), rownames = FALSE, options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```

Aqui usamos o `$` para indexar o resultado e retornar apenas o valor `modify_time`.

```{r}
file_info(here("data", "case_linelists", "linelist_cleaned.rds"))$modification_time
```



## Verifique se existe  

### Objetos R {.unnumbered}  

Você pode usar `exists()` do R **base** para verificar se um objeto existe *dentro do* R (forneça o nome do objeto entre aspas).

```{r}
exists("linelist")
```
Observe que alguns pacotes do R **base** usam nomes de objetos genéricos como "data" (que significa "dados" em inglês) nos bastidores, que aparecerão como TRUE a menos que `inherit = FALSE` seja especificado. Este é um dos motivos para não nomear o conjunto de dados como "data".

```{r}
exists("data")
exists("data", inherit = FALSE)
```

Se você está escrevendo uma função, deve usar `missing()` do R **base** para verificar se um argumento está presente ou não, ao invés de `exists()`.


### Diretórios {.unnumbered}  

Para verificar se existe um diretório, forneça o caminho do arquivo (e nome do arquivo) para `is_dir()` de **fs**. Role para a direita para ver que retorna `TRUE`.

```{r}
is_dir(here("data"))
```

Uma alternativa é `file.exists()` do R **base**.  


### Arquivos {.unnumbered}  

Para verificar se um arquivo específico existe, use `is_file()` de **fs**. Role para a direita para ver que retorna `TRUE`.

```{r}
is_file(here("data", "case_linelists", "linelist_cleaned.rds"))
```
Uma alternativa no R **base** é `file.exists()`.  


## Criar  

### Diretórios {.unnumbered}  

Para criar um novo diretório (pasta), você pode usar `dir_create()` de **fs**. Se o diretório já existir, ele não será criado novamente e não será retornado nenhum erro.

```{r, eval=F}
dir_create(here("data", "test"))
```

Uma alternativa é `dir.create()` do R **base**, que mostrará um erro se o diretório já existir. Em contraste, `dir_create()` neste cenário será silencioso.

### Arquivos {.unnumbered}  

Você pode criar um arquivo (vazio) com `file_create()` de **fs**. Se o arquivo já existir, ele não será criado novamente ou alterado.

```{r, eval=F}
file_create(here("data", "test.rds"))
```

`file.create()` é uma alternativa no R **base**. Mas se o arquivo já existe, esta opção irá truncá-lo. Se você usar `file_create()` o arquivo não será alterado.


### Criar se não existir {.unnumbered}  

EM CONSTRUÇÃO  


## Deletar

### Objetos R {.unnumbered}  

Use `rm()` do R **base** para remover um objeto R.  

### Diretórios {.unnumbered}  

Use `dir_delete()` de **fs**. 


### Arquivos {.unnumbered}  

Você pode excluir arquivos com `file_delete()` de **fs**.  


## Executando outros arquivos  

### `source()` {.unnumbered}  

Para executar um script R a partir de outro script R, você pode usar o comando `source()` (do R **base**).

```{r, eval=F}
source(here("scripts", "cleaning_scripts", "clean_testing_data.R"))
```

Isso é equivalente a visualizar o script R acima e clicar no botão "Source" (Fonte) no canto superior direito do script. Isso executará o script, mas silenciosamente (sem saída para o console do R), a menos que seja especificada esta intenção. Veja a página [Console interativo] para exemplos de uso da `source()` para interagir com um usuário através do console R no modo pergunta e resposta.


```{r, fig.align = "center", out.height = '300%', echo=F}
knitr::include_graphics(here::here("images", "source_button.png"))
```


### `render()` {.unnumbered}  

`render()` é uma variação de `source()` mais frequentemente usada para scripts R markdown. Você fornece o `input =` que é o arquivo Rmarkdown (.Rmd), e também o `output_format =` (normalmente "html_document", "pdf_document", "word_document", "")

Consulte a página [Relatórios com R Markdown](#rmarkdown) para obter mais detalhes. Veja também a documentação para `render()` 
[aqui](https://rmarkdown.rstudio.com/docs/reference/render.html) ou inserindo `?render`.  

### Executar arquivos em um diretório {.unnumbered}

Você pode criar um *for loop* e usá-lo em `source()` para todos os arquivos em um diretório, identificado com `dir()`.
with `dir()`. 

```{r, eval=F}
for(script in dir(here("scripts"), pattern = ".R$")) {   # Para cada nome de script na pasta "scripts" do Projeto R (com extensão .R)
  source(here("scripts", script))                        # Fonte dos arquivos com nomes correspondentes aos encontrados na pasta de scripts
}
```

Se você deseja apenas executar determinados scripts, pode identificá-los pelos nomes da seguinte forma:  

```{r, eval=F}

scripts_to_run <- c(
     "epicurves.R",
     "demographic_tables.R",
     "survival_curves.R"
)

for(script in scripts_to_run) {
  source(here("scripts", script))
}

```



Aqui está uma [comparação](https://cran.r-project.org/web/packages/fs/vignettes/function-comparisons.html) das funções de **fs** e R **base**.  

### Importar arquivos em um diretório  {.unnumbered}

Consulte a página [Importar e exportar](#importing) para importar e exportar arquivos individuais.

Consulte também a página [Importar e exportar](#importing) para métodos que importem automaticamente o arquivo mais recente, com base em uma data no nome do arquivo *ou* nos metadados do arquivo.

Veja na página [Iteração, loops e listas](#iteration) um exemplo com o pacote **purrr** demonstrando:


* Dividir um dataframe e salvá-lo como vários arquivos CSV
* Dividir um dataframe e salvar cada parte em uma planilha separada dentro de uma pasta de trabalho do Excel
* Importar vários arquivos CSV e combiná-los em um dataframe
* Importar uma pasta de trabalho do Excel com várias planilhas e combiná-las em um único dataframe

## R **base** 

Veja abaixo as funções `list.files()` e `dir()`, que realizam a mesma operação de listar arquivos dentro de um diretório especificado. Você pode especificar `ignore.case =` ou um padrão específico para procurar.


```{r, eval=F}
list.files(path = here("data"))

list.files(path = here("data"), pattern = ".csv")
# dir(path = here("data"), pattern = ".csv")

list.files(path = here("data"), pattern = "evd", ignore.case = TRUE)

```

Se um arquivo estiver "aberto" no momento, ele será exibido em sua pasta com um til na frente, como "~$hospital_linelists.xlsx".

<!-- ======================================================= -->
## Recursos {  }

https://cran.r-project.org/web/packages/fs/vignettes/function-comparisons.html
```{r include=FALSE, cache=FALSE}

# clear workspace
rm(list = ls(all = TRUE))

# clear all packages except base
#lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))

# to ensure that tidyverse packages prevail
filter <- dplyr::filter
select <- dplyr::select
summarise <- dplyr::summarise
summary <- base::summary
incidence <- incidence2::incidence

#load core packages
pacman::p_load(
     rio,
     here,
     DT,
     stringr,
     lubridate,
     tidyverse
)

# import the cleaned ebola linelist
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

# import the count data - facility level
#count_data <- rio::import(here::here("data", "facility_count_data.rds"))

# Settings

options(scipen=1, digits=7)

# print only text (not code)
# library(knitr)
# opts_chunk$set(list(echo = FALSE, eval = FALSE))
```

<!--chapter:end:new_pages/directories.Rmd-->

# Controle de versão e colaboração com Git e Github {#collaboration}

Este capítulo apresenta uma visão geral do uso do Git para programar em colaboração com outras pessoas. Tutoriais mais completos podem ser encontrados abaixo na seção Recursos.

## O que é o Git?

Git é um software de **controle de versões** que permite rastrear alterações em uma pasta. Pode ser usado como a opção de "controle de alterações" no Word, LibreOffice ou Google docs, mas para todos os tipos de arquivos. É uma das opções mais poderosas e mais usadas para controle de versões.

**Por que eu nunca ouvi falar disso?**  Enquanto pessoas com formação em programação aprendem rotineiramente a usar softwares de controle de versões (Git, Mercurial, Subversion ou outros), poucos de nós das disciplinas quantitativas aprendem essas habilidades. Consequentemente, a maioria dos epidemiologistas nunca ouviu falar dele durante seus estudos, e tem que aprender repentinamente.

**Espera, já ouvi falar do Github, é a mesma coisa? -** Não exatamente, mas costumamos usá-los juntos. E nós mostraremos como fazer. Resumidamente:

- **Git** é o sistema de controle de versão, um software. Você pode usá-lo localmente em seu computador ou para sincronizar uma pasta com um **site** hospedeiro. Por padrão, usa-se um terminal para fornecer instruções Git na linha de comando.

- Você pode usar **um cliente / uma interface Git** para evitar a linha de comando e executar as mesmas ações (pelo menos para as simples e supercomuns).

- Se você deseja armazenar sua pasta em um **site hospedeiro** para colaborar com outras pessoas, você pode criar uma conta no Github, Gitlab, Bitbucket ou outros.

Portanto, você pode usar o cliente ou a interface **Github Desktop**, que usa **Git** em segundo plano para gerenciar seus arquivos, tanto localmente em seu computador quanto remotamente em um servidor **Github**.

## Por que usar o combo Git e Github?

Usar o **Git** facilita:

1) Arquivar versões documentadas com mudanças adicionais para que você possa recuperar facilmente qualquer versão anterior;

2) Ter *ramos* ( do inglês *branches*) paralelos, ou seja, desenvolver / "trabalhar" diferentes versões com formas estruturadas de integrar as mudanças após a revisão.

Isso pode ser feito localmente em seu computador, mesmo se você não colaborar com outras pessoas. Você já:

- lamentou ter excluído uma seção do código, para perceber apenas dois meses depois que você realmente precisava dela?

- voltou em um projeto que estava parado e tentou lembrar se você fez aquela modificação complicada em um dos modelos?

- teve um arquivo *modelo_1.R *, outro arquivo *modelo_1_teste.R* e ainda um outro arquivo *modelo_1_nao_funciona.R* para testar diferentes soluções?

- teve um arquivo *relatorio.Rmd*, um arquivo *relatorio_completo.Rmd *, um arquivo *relatorio_verdadeiro_final.Rmd*, um arquivo *relatorio_final_20210304.Rmd*, um arquivo *relatorio_final_20210402.Rmd * e amaldiçoou suas habilidades de backup?

Git vai ajudar com tudo isso, e vale a pena aprender só por isso.

No entanto, ele se torna ainda mais poderoso quando usado com um repositório online para oferecer suporte a **projetos colaborativos**, como o Github. Isso facilita:
- Colaboração: outras pessoas podem revisar, comentar e aceitar/recusar as alterações;

- Compartilhar seu código, dados e resultados e solicitar feedback em público (ou em particular, com sua equipe).

E evita:

- "Opa, esqueci de enviar a última versão e agora você precisa refazer dois dias de trabalho neste novo arquivo";

- Patrícia, Ruanna e Nathalie trabalharam ao mesmo tempo em um script e precisam mesclar manualmente suas alterações;

- Duas pessoas tentam modificar o mesmo arquivo no Dropbox e no Sharepoint e isso cria um erro de sincronização.

### Isso parece complicado, não sou um programador {-}

Pode ser. Exemplos de usos avançados podem ser bastante assustadores. No entanto, assim como no R, ou mesmo no Excel, você não precisa se tornar um especialista para aproveitar os benefícios da ferramenta. Aprender um *pequeno número de funções e noções* permite rastrear suas alterações, sincronizar seus arquivos em um repositório online e colaborar com seus colegas em um período de tempo muito curto.

Devido à curva de aprendizado, o contexto de emergência pode não ser o melhor momento para aprender essas ferramentas. Mas o aprendizado pode ser alcançado por etapas. Depois de adquirir algumas noções, seu fluxo de trabalho pode ser bastante eficiente e rápido.

**Um bom momento para adquirir confiança no uso do Git**, na verdade, é quando você não está trabalhando em um projeto que precise dele, quando trabalhar em colaboração não é uma necessidade.

## Configuração

### Instale o Git {.unnumbered}

*Git* é o mecanismo por trás dos bastidores do seu computador, que rastreia alterações, ramos (versões), mesclagens e reversões. **Você deve primeiro instalar o *Git* em <https://git-scm.com/downloads>.**

### Instale uma interface (opcional, mas recomendado) {.unnumbered}

Git tem sua própria linguagem de comandos, que pode ser digitada em um terminal de linha de comando. No entanto, existem muitos clientes / interfaces e, não sendo um desenvolvedor, você raramente _precisará_ interagir diretamente com o Git na sua rotina. As interfaces geralmente fornecem boas ferramentas de visualização para modificações ou ramificações de arquivos.

Existem muitas opções, em todos os sistemas operacionais, desde iniciantes até os mais complexos. Boas opções para iniciantes incluem o painel RStudio Git e [Github Desktop](https://desktop.github.com/), que mostraremos neste capítulo. Opções intermediárias (mais poderosas, mas mais complexas) incluem Source Tree, Gitkracken, Smart Git e outras.

Explicação rápida sobre [Clientes Git](-%09https:/happygitwithr.com/git-client.html#git-client).

*Observação: como todas as interfaces usam o Git internamente, você pode tentar várias delas, alternar de uma para outra em um determinado projeto, usar o console pontualmente para uma ação que sua interface não suporta ou até mesmo realizar algumas ações online no Github.*

Conforme observado abaixo, você pode ocasionalmente ter que escrever comandos Git em um terminal, como o painel RStudio (uma aba do Console R) ou o terminal Git Bash.

### Conta Github {.unnumbered}

Inscreva-se para uma conta gratuita em [github.com](github.com).

Pode ser solicitado que você configure a autenticação de dois fatores com um aplicativo em seu telefone. Leia mais em [nos documentos de ajuda do Github](https://docs.github.com/en/github/authenticating-to-github/securing-your-account-with-two-factor-authentication-2fa).

Se você usa o Github Desktop, pode inserir suas credenciais do Gitub após a instalação seguindo estas [etapas](https://docs.github.com/en/desktop/installing-and-configuring-github-desktop/authenticating-to-github). Se você não fizer isso agora, as credenciais serão solicitadas mais tarde, quando você tentar clonar um projeto do Github.

## Vocabulário, conceitos e funções básicas

Assim como ao aprender R, há um pouco de vocabulário que você precisará lembrar para entender o Git. Aqui estão os [princípios básicos para você começar](https://www.freecodecamp.org/news/an-introduction-to-git-for-absolute-beginners-86fa1d32ff71/) e um [tutorial interativo](learngitbranching.js.org). Nas próximas seções, mostraremos como usar interfaces, mas é bom ter o vocabulário do Git e os conceitos em mente, para construir seu modelo mental. Você precisará deles ao usar interfaces de qualquer maneira.

### Repositório {.unnumbered}

Um *repositório* Git ("repo") é uma pasta que contém todas as subpastas e arquivos do seu projeto (dados, códigos, imagens etc.), além dos seus históricos de revisão. Quando você começar a rastrear as alterações no repositório com o Git, ele criará uma pasta oculta que contém todas as informações de rastreamento. Um repositório Git típico é a pasta *Projeto R* (consulte a página do manual em [Projetos R](#r-projects)).

Mostraremos como criar (_inicializar_) um repositório Git a partir do Github, Github Desktop ou Rstudio nas próximas seções.

### Commits () {.unnumbered}

Um *commit* é um **snapshot** do projeto, ou seja, uma foto  instantânea de um determinado momento. Ao fazer uma alteração no projeto, você fará um novo commit para rastrear as alterações (o delta) feitas em seus arquivos. Por exemplo, talvez você tenha editado algumas linhas de código e atualizado um conjunto de dados. Depois que suas alterações forem salvas, você pode agrupar essas alterações em um "commit".

Cada commit possui um ID exclusivo (um *hash*). Para fins de controle de versão, você pode recuperar seu projeto no tempo com base em commits, então é melhor mantê-los relativamente pequenos e coerentes. Você também anexará uma breve descrição das mudanças, chamada de "mensagem de confirmação".

*Mudanças graduais?* Preparar mudanças é adicioná-las à *área de teste*, em preparação para o próximo commit. A ideia é que você possa decidir com precisão quais alterações incluir em um determinado commit. Por exemplo, se você trabalhou na especificação do modelo em um script e, posteriormente, trabalhou em uma figura em outro script, faria sentido ter dois commits diferentes (seria mais fácil no caso de você querer reverter as mudanças na figura, mas não o modelo).

### Branches (Ramos) {.unnumbered}

Um branch representa uma *linha independente* de mudanças em seu repo, uma versão paralela e alternativa de seus arquivos de projeto.

Branches são úteis para testar mudanças antes de serem incorporadas ao branch *principal*, que geralmente é a versão primária / final / "ativa" do seu projeto. Quando você terminar de experimentar em um branch, você pode trazer as alterações para o seu branch *principal*, *mesclando*, ou excluí-lo, se as alterações não foram tão bem-sucedidas.

*Observação: você não precisa colaborar com outras pessoas para usar branches, nem precisa ter um repositório online remoto.*

### Repositórios locais e remotos {.unnumbered}

*Clonar* é criar uma cópia de um repositório Git em outro lugar.

Por exemplo, você pode *clonar* um repositório online _do_ Github localmente em seu computador, ou começar com um repositório local e cloná-lo online _para_ Github.

Quando você clona um repositório, os arquivos do projeto ficam em dois lugares:

- no repositório *LOCAL*, em seu computador físico. É aqui que você faz as mudanças reais nos arquivos / códigos.

- no repositório online *REMOTO*: versões dos seus arquivos de projeto no repositório Github (ou em qualquer outro site hospedeiro).
    
Para sincronizar esses repositórios, usaremos mais funções. Na verdade, ao contrário do Sharepoint, Dropbox ou outro software de sincronização, o Git não atualiza automaticamente seu repositório local baseado naquele que está online ou vice-versa. Você pode escolher quando e como sincronizar.

- `git fetch` baixa as novas mudanças do repositório remoto, mas não muda seu repositório local. Pense nela como uma verificação de estado do repositório remoto.

- `git pull` baixa as novas mudanças dos repositórios remotos e atualiza seu repositório local.

- Quando você tiver feito um ou vários commits localmente, você pode usar  `git push` para atualizar os commits no repositório remoto. Isso envia suas alterações no Github para que outras pessoas possam vê-las e acessá-las, se quiserem.

## Começar: crie um novo repositório

Existem muitas maneiras de criar novos repositórios. Você pode fazer isso no console, no Github, em uma interface.

Duas abordagens gerais são:

- Criar um novo Projeto R a partir de um repositório Github novo ou existente (*sugerido para iniciantes*);
- Criar um repositório Github para um projeto R existente.

### Arquivos iniciais {.unnumbered}

Ao criar um novo repositório, você pode opcionalmente criar todos os arquivos abaixo ou pode adicioná-los ao seu repositório em um estágio posterior. Eles normalmente ficam na pasta "raiz" do repositório.

-Um arquivo *README* é um arquivo que alguém pode ler para entender por que seu projeto existe e o que mais precisar saber para usá-lo. Ele estará vazio no início, mas você deve preenchê-lo mais tarde.

- Um arquivo *.gitignore* é um arquivo de texto em que cada linha contém pastas ou arquivos que o Git deve ignorar (não rastrear alterações). Leia mais sobre ele e veja exemplos [aqui](https://www.freecodecamp.org/news/gitignore-what-is-it-and-how-to-add-to-repo/).

- Você pode escolher uma *licença* para o seu trabalho, para que outras pessoas saibam em quais condições podem usar ou reproduzir ele. Para obter mais informações, consulte as [Licenças Creative Commons](https://creativecommons.org/licenses/).

### Criar um novo repositório no Githubb {.unnumbered}

Para criar um novo repositório, faça login no Github e procure o botão verde para criar um novo repositório. Este repositório agora vazio pode ser clonado localmente em seu computador (consulte a próxima seção).

```{r echo=F, fig.align = "center"}
knitr::include_graphics(here::here("images", "github_new.png"))
```

Você deve escolher se deseja que seu repositório seja **público**, ou seja, visível para todos na internet, ou **privado**, visível apenas para aqueles com permissão. Isso tem implicações importantes se seus dados forem confidenciais. Se o seu repositório for privado, você encontrará certas circunstâncias especiais avançadas, como se estiver usando as *actions* do Github para executar automaticamente o seu código na nuvem.
 
### Clonar de um repositório Github {.unnumbered}

Você pode *clonar* um repositório Github existente para criar um novo projeto R local em seu computador.

O repositório Github pode ser algum que já existe (com conteúdo) ou pode ser um repositório vazio que você acabou de criar. Neste último caso, você está essencialmente criando o repositório Github e o projeto R local ao mesmo tempo (consulte as instruções acima).

_Observação_: se você não possui direitos de contribuição em um repositório Github, é possível primeiro _bifurcar_ o repositório para o seu perfil, e então prosseguir com as outras ações. A bifurcação é explicada no final deste capítulo, mas recomendamos que você leia as outras seções primeiro.

Etapa 1: no Github, navegue até o repositório, clique no botão verde "**Code**" e copie a **URL clone HTTPS** (veja a imagem abaixo)

```{r echo=F, out.width = '100%', out.height='100%', fig.align = "center"}
knitr::include_graphics(here::here("images", "github_clone.png"))
```

A próxima etapa pode ser realizada em qualquer interface. Vamos ilustrar com o Rstudio desktop e com o Github.

#### No Rstudio {.unnumbered}

No RStudio, comece um novo projeto R clicando em *File\>New Project\>Version Control\>Git*

- Quando for solicitada a "URL do repositório", cole a URL HTTPS do Github\
- Atribua ao projeto R um nome curto e informativo\
- Escolha onde o novo Projeto R será salvo localmente\
- Marque "Abrir em nova sessão" e clique em "Criar projeto"

Agora você está em um novo projeto RStudio local que é um clone do repositório Github. O projeto local e o repositório Github agora estão vinculados.

#### No Github Desktop {.unnumbered}

- Clique em *Arquivo \> Clonar um repositório*

- Selecione a guia URL

- Cole a URL HTTPS do Github na primeira caixa

- Selecione a pasta na qual deseja ter seu repositório local

- Clique em "CLONE"

```{r echo=F, out.width = '100%', out.height='100%', fig.align = "center"}
knitr::include_graphics(here::here("images", "github_clone_desktop.png"))
```

### Novo repositório Github a partir de um projeto R existente {.unnumbered}

Outro cenário de configuração alternativo ocorre quando você tem um projeto R existente com conteúdo e deseja criar um repositório Github para ele.

1) Crie um novo repositório Github vazio para o projeto (consulte as instruções acima)\

2) Clone este repositório localmente (consulte as instruções HTTPS acima)\

3) Copie todo o conteúdo de seu projeto R pré-existente (códigos, dados, etc.) para este novo repositório vazio e local (Ex.: use copiar e colar).\

4) Abra seu novo projeto no RStudio e vá para o painel Git. Os novos arquivos devem estar registrados como alterações de arquivo, agora rastreados pelo Git. Portanto, você pode agrupar essas alterações como um *commit* e *enviar* para o Github. Uma vez *enviado*, o repositório no Github refletirá todos os arquivos. 

Consulte a seção de fluxo de trabalho do Github abaixo para obter detalhes sobre esse processo.

### Como aparecem agora? {.unnumbered}

#### No RStudio {-}

Depois de clonar um repositório Github para um novo projeto R, você verá no RStudio uma guia "Git". Esta guia aparece no mesmo painel RStudio que seu "ambiente"Environment" R:

```{r echo=F, out.width = "75%", out.height="75%", fig.align = "center"}
knitr::include_graphics(here::here("images", "Git_console.png"))
```

Observe os botões circulados na imagem acima, pois eles serão comentados a seguir (da esquerda para a direita):

-   Botão *commit* para confirmar as alterações do arquivo salvo no branch local (isso abrirá uma nova janela)
- Seta azul para *extrair* (atualize sua versão local do branch com quaisquer alterações feitas na versão Github (remota) desse branch)
- Seta verde para *enviar* (atualize quaisquer commits / alterações da sua versão local do branch para a versão Github (remota) desse branch)
- A guia Git no RStudio
- Botão para criar um NOVO branch usando qualquer branch local (mostrado à direita como base). *Quase sempre você criará um branch a partir do branch principal (depois de extrair pela primeira vez para atualizar o branch principal)*
- O branch que você está trabalhando no momento
- Alterações feitas no código ou em outros arquivos aparecerão abaixo

#### No Github Desktop {-}

Github Desktop é um aplicativo independente que permite gerenciar todos os seus repositórios. Ao abri-lo, a interface permite que você escolha o repositório no qual deseja trabalhar e, a seguir, executar ações básicas do Git a partir dele.

```{r echo=F, out.width = "75%", out.height="75%", fig.align = "center"}
knitr::include_graphics(here::here("images", "github_desktop_interface.png"))
```


## Fluxo de trabalho Git + Github

### Visão geral do processo {.unnumbered}

Depois de concluir a configuração (descrita acima), você terá um repositório Github conectado (*clonado*) a um projeto R local. O branch *principal* (criado por padrão) é a versão chamada "ao vivo" de *todos* os arquivos. Quando você quiser fazer modificações, é uma boa prática criar um *novo branch* a partir do branch *principal* ("Fazer uma cópia"). Este é um fluxo de trabalho típico no Git porque criar um branch é fácil e rápido. 

Um fluxo de trabalho típico é o seguinte:

1.  Certifique-se de que seu repositório local está atualizado e, se não estiver, atualize;

2.  Vá para o branch em que você estava trabalhando anteriormente ou crie um novo branch para testar algumas coisas

3.  Trabalhe nos arquivos localmente em seu computador, faça um ou vários commits para este branch

4.  Atualize a versão remota da filial com suas alterações (enviar)

5. Quando estiver satisfeito com seu branch, você pode mesclar a versão online do branch que trabalhou para o branch "principal" on-line e, assim, transferir suas alterações

Outros membros da equipe podem estar fazendo a mesma coisa com seus próprios branches, ou talvez contribuindo com commits no branch que você está trabalhando também. 

Vamos repassar passo a passo do processo acima com mais detalhes abaixo. Aqui está um esquema que desenvolvemos - está no formato de uma tabela dois-por-dois, portanto, deve ajudar os epidemiologistas a entender.

```{r echo=F, out.height='150%', out.width='100%', fig.align = "center"}
knitr::include_graphics(here::here("images", "github_table.png"))
```

Aqui está [outro diagrama](https://build5nines.com/introduction-to-git-version-control-workflow/).

*Observação: até recentemente, o termo branch "master" era usado, mas agora é chamado de branch "main" (principal).*

```{r echo=F, out.width = '100%', out.height='100%', fig.align = "center"}
knitr::include_graphics(here::here("images", "GitHub-Flow.png"))
```

Fonte da [imagem](https://build5nines.com/introduction-to-git-version-control-workflow/)

## Crie um novo branch

Quando você seleciona um branch para trabalhar, **Git redefine seu diretório de trabalho do jeito que estava da última vez que você esteve neste branch**.

### No painel Git no Rstudio {.unnumbered}

Certifique-se de que está no branch "principal" e clique no ícone roxo para criar um novo branch (veja a imagem acima).

- Você deverá nomear seu branch com uma única palavra (pode usar sublinhado, se necessário).
- Você verá que localmente está no mesmo projeto R, mas não está mais trabalhando no branch "main".
- Depois de criado, o novo branch também aparecerá no site do Github como um branch.
    
Você pode visualizar branches no painel Git no Rstudio depois de clicar em "Histórico"

```{r echo=F, out.width = '100%', out.height='100%', fig.align = "center"}
knitr::include_graphics(here::here("images", "github_rstudio_branchs.png"))
```


### No Github Desktop {.unnumbered}

O processo é muito semelhante, você deverá dar um nome ao seu branch. Depois, você será solicitado a "Publicar seu branch no Github" para fazer o novo branch aparecer no repositório remoto também.

```{r echo=F, out.width = '100%', out.height='100%', fig.align = "center"}
knitr::include_graphics(here::here("images", "github_desktop_new_branch.png"))
```

### No console {.unnumbered}

O que realmente está acontecendo nos bastidores é que você cria um novo branch com `git branch`, então vai para o branch com` git checkout` (_isto é, diga ao Git que seus próximos commits ocorrerão lá). Do seu repositório git:

```{bash, eval = FALSE}
git branch my-new-branch  # Cria o novo branch
git checkout my-new-branch # Vai para o branch
git checkout -b my-new-branch # Os dois ao mesmo tempo (atalho)
```

Para obter mais informações sobre como usar o console, consulte a seção sobre comandos Git no final.

## Confirmar alterações

Agora você pode editar o código, adicionar novos arquivos, atualizar conjuntos de dados, etc.

Cada uma de suas alterações será rastreada, *uma vez que o respectivo arquivo for salvo*. Os arquivos alterados irão aparecer na aba Git do RStudio, no Github , ou usando o comando `git status` no terminal (veja abaixo).

Sempre que você fizer alterações substanciais (Ex.:, adicionar ou atualizar uma seção de código), pare e *confirme* essas alterações (commit). Pense em um commit como um "lote" de mudanças relacionadas a um propósito comum. Você poderá continuar revisan um arquivo mesmo após ter confirmado as alterações nele.

*Conselhos sobre commits*: geralmente, é melhor fazer pequenos commits, que podem ser facilmente revertidos se um problema surgir, para confirmar modificações diferentes relacionadas a um mesmo propósito. Para isso, você descobrirá que *deve criar commits com frequência*. No início, você provavelmente vai esquecer, mas logo desenvolverá o hábito.

### No Rstudio {.unnumbered}

O exemplo abaixo mostra que, desde o último commit, o script R Markdown "Collaboration.Rmd" mudou, e várias imagens PNG foram adicionadas.

```{r echo=F, fig.align = "center"}
knitr::include_graphics(here::here("images", "github_tracking2.png"))
```

Você pode estar se perguntando o que representam os quadrados amarelos, azuis, verdes e vermelhos próximos aos nomes dos arquivos. Aqui está uma parte do [Cheatsheet RStudio](https://www.rstudio.com/wp-content/uploads/2016/01/rstudio-IDE-cheatsheet.pdf) que explica seu significado. Mudanças com o quadrado amarelo ("?") ainda podem ser preparadas, confirmadas e enviadas.

```{r echo=F, fig.align = "center"}
knitr::include_graphics(here::here("images", "github_tracking.png"))
```

- Pressione o botão "Commit" na guia Git, que abrirá uma nova janela (reproduzida abaixo)

- Clique no nome de um arquivo na caixa superior esquerda

- Revise as alterações feitas no arquivo (destacadas abaixo em verde ou vermelho)

- "Prepare" o arquivo, que incluirá essas mudanças no commit. Faça isso marcando a caixa ao lado do nome do arquivo. Como alternativa, você pode destacar vários nomes de arquivo e clicar em "Stage"

- Escreva uma mensagem de confirmação que seja curta, mas descritiva (obrigatório)

- Pressione o botão "Commit". Uma caixa pop-up aparecerá mostrando o sucesso ou uma mensagem de erro.

Agora você pode fazer mais alterações e mais commits, quantas vezes quiser 

```{r echo=F, out.width = '100%', out.height='200%', fig.align = "center"}
knitr::include_graphics(here::here("images", "github_commit.png"))
```

### No Github Desktop {.unnumbered}

Você pode ver a lista dos arquivos que foram alterados à esquerda. Se você selecionar um arquivo de texto, verá um resumo das modificações feitas no painel direito (a visualização não funcionará em arquivos mais complexos como .docs ou .xlsx).

Para fazer as alterações, basta marcar a caixa ao lado dos nomes dos arquivos. Quando você tiver selecionado os arquivos que deseja adicionar a este commit, dê um nome ao commit, uma descrição (opcional) e clique no botão **commit**.

```{r echo=F, fig.align = "center"}
knitr::include_graphics(here::here("images", "github_desktop_commit.png"))
```

### No console {.unnumbered}

São usadas as funções `git add` para selecionar / preparar arquivos e` git commit` para realmente fazer o commit.

```{bash, eval = FALSE}
git status #veja as mudanças 

git add new_pages/collaboration.Rmd  # selecione arquivos para o commit (= "stage" mudanças)

git commit -m "Describe commit from Github Desktop" # confirme mudanças com uma mensagem

git log  # veja informações sobre commits anteriores
```

### Corrigir um commit anterior {.unnumbered}

O que acontece se você fizer o commit de algumas alterações, continuar trabalhando e perceber que fez alterações que deveriam "pertencer" ao commit anterior (na sua opinião)? Está tudo bem! Você pode anexar essas alterações ao seu commit anterior.

No Rstudio há uma caixa "Corrigir commit anterior" na mesma linha do botão COMMIT. 

Por alguma razão, esta funcionalidade não foi implementada da mesma forma no Github Desktop, mas há uma maneira de contornar (estranha, mas fácil!). Se você tiver confirmado suas alterações **mas não enviado** ainda, um botão "UNDO" aparecerá logo abaixo do botão COMMIT. Clique nele e ele irá reverter seu commit (mas mantenha seus arquivos preparados e sua mensagem de commit). Salve suas mudanças, adicione novos arquivos ao commit se necessário e faça o commit novamente.

No console:  

```{bash, eval = FALSE}
git add [SEUS ARQUIVOS] # Prepare suas novas mudanças

git commit --amend  # Corrija o commit anteriororrigir o commit anterior

git commit --amend -m "An updated commit message"  # Corrija o commit anterior E atualize a mensagem de commit

```

_Observação: pense antes de modificar commits que já são públicos e compartilhados com seus colaboradores_.

## Pull (baixar/extrair) e Push (enviar/subir) alterações para o Github

"Primeiro PULL, depois PUSH"

É uma boa prática *fetch* (buscar) e *pull* (baixar) antes de começar a trabalhar no seu projeto, para atualizar a versão do branch em seu computador local com quaisquer alterações que tenham sido feitas na versão remota / Github.

PULL frequentemente. Não hesite. *Sempre faça um pull antes de fazer um push*.

Quando suas mudanças forem feitas e confirmadas e você estiver feliz com o seu projeto, você pode *fazer um push* dos seus commits para a versão remota / Github de seu branch.

**Observação:** é muito mais fácil desfazer alterações que foram confirmadas, mas não enviadas (ou seja, ainda são locais) do que alterações que foram enviadas para o repositório remoto (e talvez já extraídas por outra pessoa), por isso é melhor enviar quando terminar de introduzir mudanças no estava trabalhando.

#### No Rstudio {.unnumbered}

*PULL* - Primeiro, clique no ícone "Pull" (seta azul para baixo) que busca e extrai ao mesmo tempo.

*PUSH* - Clique no ícone "Pull" (seta verde para cima). Pode ser necessário inserir seu nome de usuário e senha do Github. Na primeira vez que você for solicitado, pode ser necessário inserir duas linhas de comando Git no *Terminal*:

-   **git config --global user.email "[voce\@exemplo.com](mailto:voce@exemplo.com){.email}"** (seu endereço de email Github), e\
-   **git config --global user.name "Seu nome de usuário Github"**

Para saber mais sobre como inserir esses comandos, consulte a seção abaixo sobre comandos Git.

***DICA:*** Sua senha está sendo solicitada com muita frequência? Veja os capítulos 10 e 11 deste [tutorial](https://happygitwithr.com/credential-caching.html#credential-caching) para se conectar a um repositório usando uma chave SSH (mais complicado)  

#### No Github Desktop {.unnumbered}

Clique no botão "Buscar origem" para verificar se há novos commits no repositório remoto.

```{r echo=F, fig.align = "center"}
knitr::include_graphics(here::here("images", "github_desktop_fetch_button.png"))
```

Se o Git encontrar novos commits no repositório remoto, o botão mudará para um botão "Pull". Como o mesmo botão é usado para fazer o pull (baixar/extrair) e fazer o push (subir/enviar), você não pode enviar suas alterações se não fizer o pull antes.

```{r echo=F, fig.align = "center"}
knitr::include_graphics(here::here("images", "github_desktop_pull_button.png"))
```

Você pode ir para a guia "Histórico" (perto da guia "Alterações") para ver todos os commits (seus e dos outros). Essa é uma ótima maneira de se familiarizar com o que seus colaboradores fizeram. Você pode ler a mensagem de confirmação, a descrição, se houver, e comparar o código dos dois arquivos usando o painel *diff*.

```{r echo=F, fig.align = "center"}
knitr::include_graphics(here::here("images", "github_desktop_history.png"))
```

Uma vez que todas as mudanças remotas tenham sido extraídas, e pelo menos uma mudança local tenha sido confirmada, você pode enviar clicando no mesmo botão.

```{r echo=F, fig.align = "center"}
knitr::include_graphics(here::here("images", "github_desktop_push_button.png"))
```

#### Console {.unnumbered}

Como esperado, os comandos são *fetch*, *pull* e *push *. 

```{bash, eval = FALSE}
git fetch  # Existem novos commits no diretório remoto?
git pull   # Traga commits remotos para seu branch local
git push   # Envie commits locais deste branch para o branch remoto
```

### Quero fazer um pull, mas tenho trabalho local {.unnumbered}

Isso pode acontecer às vezes: você fez algumas mudanças em seu repositório local, mas o repositório remoto tem commits que você não extraiu.


O Git se recusará a fazer um pull porque pode sobrescrever suas alterações. Existem várias estratégias para manter suas mudanças, bem descritas em [Happy Git with R](https://happygitwithr.com/pull-tricky.html), entre as quais as duas principais são:
 
- confirme suas alterações, busque alterações remotas, extraia elas, resolva conflitos, se necessário (consulte a seção abaixo), e coloque tudo online
- `stash` suas alterações, que meio que as armazena à parte, extrai, restaura ("unstash") e então efetua o commit, resolvendo quaisquer conflitos e envia.

Se não houver sobreposição entre os arquivos das mudanças remotas e os arquivos das mudanças locais, o Git pode resolver os conflitos automaticamente.

No Github Desktop, isso pode ser feito com botões. Para isso, vá até _Branch> Stash all changes_.

```{r echo=F, fig.align = "center"}
knitr::include_graphics(here::here("images", "github_desktop_stash.png"))
```

## Mesclar no branch principal 

Se você concluiu as alterações, pode iniciar o processo de mesclagem dessas alterações no branch principal. Dependendo da situação, isso pode ser rápido ou contemplar etapas acordadas de revisão e aprovação envolvendo colegas da sua equipe.

### Localmente no Github Desktop {.unnumbered}

É possível mesclar branches localmente usando o Github Desktop. Primeiro, vá até o branch que será o destinatário dos commits, ou seja, o branch que você deseja atualizar. Em seguida, clique em *Branch \> Merge into current branch*. Uma caixa permitirá que você selecione o branch que deseja importar.

```{r echo=F, fig.align = "center"}
knitr::include_graphics(here::here("images", "github_desktop_merge.png"))
```

### No console {.unnumbered}

Primeiro, volte para o branch que receberá as alterações. Geralmente é o *master*, mas pode ser outro branch. Em seguida, mescle seu branch de trabalho no master.

```{bash, eval = FALSE}
git checkout master  # Volte para o master (ou para o branch que você deseja mover)
git merge this_fancy_new_branch
```

[Esta página](https://git-scm.com/book/en/v2/Git-Branching-Basic-Branching-and-Merging) mostra um exemplo mais avançado de branching e explica um pouco como funciona nos bastidores.

### No Github: submeter uma requisição de pull {.unnumbered}

Embora seja totalmente possível mesclar dois branches localmente, ou sem informar ninguém, uma mesclagem pode ser discutida ou investigada por várias pessoas antes de ser integrada ao branch master. Para ajudar no processo, o Github oferece alguns recursos de discussão sobre a mesclagem: a **solicitação de pull**.

Uma solicitação de pull (um "PR", do inglês *pull request*) é uma solicitação para mesclar um branch em outro (em outras palavras, uma solicitação para que _seu branch de trabalho seja extraído para o branch "main"). Uma solicitação de extração geralmente envolve vários commits e inicia uma conversa, um processo de revisão, antes de ser aceita e o branch ser mesclado. Por exemplo, você pode ler as discussões de solicitação de extração no [github do dplyr](https://github.com/tidyverse/dplyr/pulls).

Você pode enviar uma solicitação de pull (PR) diretamente do site (conforme ilustrado abaixo) ou do Github Desktop.

- Vá para o repositório Github (online)
- Visualize a guia "Solicitações de pull" e clique no botão "Nova solicitação de pull"
- Selecione no menu suspenso para mesclar seu branch no branch principal (main)
- Escreva um comentário detalhado sobre o Pull Request e clique em "Criar Pull Request".

```{r echo=F, out.width = '100%', out.height='150%', fig.align = "center"}
knitr::include_graphics(here::here("images", "github_pull_request2.png"))
```

Agora você será capaz de ver a solicitação pull (exemplo na imagem abaixo):

- Revise a guia "Arquivos alterados" para ver como o branch "main" mudaria se o branch fosse mesclado. \
- À direita, você pode solicitar uma revisão dos colaboradores da sua equipe marcando seus IDs no Github. Se desejar, você pode definir as configurações do repositório para exigir uma revisão de aprovação antes de mesclar com o main.\
- Assim que a solicitação pull for aprovada, um botão para "Mesclar solicitação pull" ficará ativo. Clique nele.\
- Depois de concluído, exclua seu branch conforme explicado abaixo.

```{r echo=F, out.width = '100%', out.height='200%', fig.align = "center"}
knitr::include_graphics(here::here("images", "github_pull_request.png"))
```

### Resolvendo conflitos {.unnumbered}

Quando duas pessoas modificam a (s) mesma (s) linha (s) ao mesmo tempo, surge um conflito de mesclagem. Na verdade, o Git se recusa a tomar uma decisão sobre qual versão manter, mas ajuda a descobrir onde está o conflito. **NÃO ENTRE EM PÂNICO**. Na maioria das vezes, é muito simples de resolver.

Por exemplo, no Github:

```{r echo=F, out.width = '100%', out.height='200%', fig.align = "center"}
knitr::include_graphics(here::here("images", "github_conflict2.png"))
```

Após a mesclagem gerar um conflito, abra o arquivo em seu editor favorito. O conflito será indicado por uma série de caracteres:

```{r echo=F, out.width = '100%', out.height='200%', fig.align = "center"}
knitr::include_graphics(here::here("images", "github_conflict3.png"))
```

O texto entre *\<\<\<\<\<\<\<HEAD* e *=======* vem do seu repositório local, já o texto entre *=======* e *\>\>\>\>\>\>\>* vem do outro branch (que pode ser o original, o master ou qualquer branch de sua escolha).

Você precisa decidir qual versão do código prefere (ou até mesmo escrever uma terceira, incluindo alterações de ambos os lados, se pertinente), excluir o resto e remover todas as marcas que o Git adicionou *(\<\<\<\<\<\<\<HEAD,=======,\>\>\>\>\>\>\>origin/master/your_branch_name*).

Então, salve, prepare e submeta o arquivo: este é o commit que torna a versão mesclada "oficial". Não se esqueça de enviar depois.

Quanto mais você e seus colaboradores puxarem e empurrarem, menores serão os conflitos.

*Observação: se você se sentir à vontade com o console, há mais [opções avançadas de mesclagem](https://git-scm.com/book/en/v2/Git-Tools-Advanced-Merging) (Ex.: ignorando espaços em branco, dando prioridade a um colaborador, etc.). *

### Delete seu branch {.unnumbered}

Depois que um branch foi mesclado com o master e não for mais necessário, você pode excluí-lo.

#### Github + Rstudio

Vá até o repositório no Github e clique no botão para ver todos os branches (próximo ao menu suspenso para selecionar branches). Agora encontre seu branch e clique no ícone de lixeira próximo a ele. Leia mais detalhes sobre como excluir um branch [aqui](https://docs.github.com/en/free-pro-team@latest/github/collaborating-with-issues-and-pull-requests/creating-and-deleting-branches-within-your-repository#deleting-a-branch).

Certifique-se de excluir também o branch local no seu computador. Isso não acontecerá automaticamente.

- No RStudio, certifique-se de estar no branch principal
- Passe a digitar comandos Git no "Terminal" do RStudio (a guia adjacente ao console R) e digite: **git branch -d nome_do_branch **, onde "nome_do_branch" é o nome do seu branch a ser excluído
- Atualize sua guia Git e o branch terá desaparecido

#### No Github Desktop

Basta verificar o branch que deseja excluir e ir até o menu *Branch\>Delete*.

### Forking {.unnumbered}

Você pode bifurcar um projeto (fork) se desejar contribuir com ele mas não tiver os direitos ou se desejar modificá-lo apenas para seu uso pessoal. Uma breve descrição da bifurcação pode ser encontrada [aqui](https://guides.github.com/activities/forking/).

No Github, clique no botão "Fork":  

```{r echo=F, out.width = '100%', out.height='200%', fig.align = "center"}
knitr::include_graphics(here::here("images", "github_fork_1.png"))
```

Isso irá clonar o repositório original no seu próprio perfil. Agora, existem duas versões do repositório **no Github**: a original, que você não pode modificar, e a versão clonada no seu perfil.

Em seguida, você pode clonar sua versão do repositório online localmente no seu computador, usando qualquer um dos métodos descritos nas seções anteriores. A partir de então, você poderá criar um novo branch, fazer mudanças, submetê-las e enviá-las _para o seu repositório remoto_.

Quando estiver satisfeito com o resultado, você pode criar um "Pull Request" do Github ou Github Desktop para iniciar a conversa com os proprietários / responsáveis pelo repositório original.

**E se você precisar de alguns commits mais recentes do repositório original?**

Imagine que alguém faça uma modificação substancial no repositório oficial, que você deseja incluir em sua versão clonada. É possível sincronizar sua bifurcação (fork) com o repositório oficial. Envolve o uso do terminal, mas não é tão complicado. Você precisa se lembrar principalmente que: - _upstream_ = repositório oficial, aquele que você não pode modificar - _origin_ = sua versão do repositório em seu perfil Github

Você pode ler [este tutorial](https://docs.github.com/en/github/collaborating-with-issues-and-pull-requests/syncing-a-fork) ou seguir o caminho abaixo:

Primeiro, digite seu terminal Git (dentro de seu reposositório): 

```{bash, eval = FALSE}
git remote -v
```
 
Se você ainda não configurou o repositório upstream, deverá ver duas linhas, começando por _origin_. Eles mostram o repositório remoto para o qual `fetch` e` push` estão direcionados. Lembre-se, por convenção, _origin_ é sua própria versão do repositório no Github. Por exemplo: 

```{r echo=F, out.width = '100%', out.height='200%', fig.align = "center"}
knitr::include_graphics(here::here("images", "github_fork_2.png"))
```

Agora, adicione um novo repositório remoto:  

```{bash, eval = FALSE}
git remote add upstream https://github.com/appliedepi/epirhandbook_eng.git
```
 
Aqui, o site é o endereço que o Github gera quando você clona um repositório (consulte a seção sobre clonagem). Agora você terá quatro ponteiros remotos:

```{r echo=F, out.width = '100%', out.height='200%', fig.align = "center"}
knitr::include_graphics(here::here("images", "github_fork_3.png"))
```

Agora que a configuração está feita, sempre que você quiser obter as alterações do repositório original (_upstream_), você só precisa ir (_checkout_) ao branch que deseja atualizar e digitar:

```{bash, eval = FALSE}
git fetch upstream # Para obter os novos commits do repositório remoto
git checkout the_branch_you_want_to_update
git merge upstream/the_branch_you_want_to_update  # Para mesclar o branch upstream em seu branch
git push # Para atualizar sua própria versão do repositório remoto
```

Se houver conflitos, você terá que resolvê-los, conforme explicado na seção Resolvendo conflitos.

**Resumo**: bifurcar é clonar, mas no servidor Github. O restante das ações são ações típicas do fluxo de trabalho de colaboração (clonar, enviar, puxar, confirmar, mesclar, enviar solicitações pull ...).

_Observação: a bifurcação é um conceito, não um comando Git, e também existe em outros sites de hospedagem, como [Bitbucket](https://www.atlassian.com/git/tutorials/comparing-workflows/forking-workflow)._

```{r echo=F, out.width = '100%', out.height='200%', fig.align = "center"}
knitr::include_graphics(here::here("images", "github_fork_4.png"))
```

## O que aprendemos

Você aprendeu como:  

- configurar o Git para rastrear modificações em suas pastas,
- conectar seu repositório local a um repositório online remoto,
- confirmar alterações,
- sincronizar seus repositórios locais e remotos.  

Isso deve ajudá-lo e ser suficiente para a maioria de suas demandas como epidemiologista. Normalmente não temos um uso tão avançado quanto os desenvolvedores. 

No entanto, se você quiser (ou precisar) ir além, o Git oferece funcionalidades para simplificar históricos de commits, reverter um ou vários commits, selecionar commits, etc. Alguns deles podem soar como pura magia, mas agora que você já sabe o básico, será mais fácil avançar.

Observe que embora o painel Git no Rstudio e no Github Desktop sejam bons para iniciantes ou para uso diário no trabalho, eles não oferecem interface para algumas das funções intermediárias e avançadas do Git. Algumas interfaces mais completas permitem fazer mais com cliques (geralmente ao custo de um layout mais complexo). 

Lembre-se que você pode usar qualquer ferramenta para rastrear seu repositório, então pode instalar uma outra interface para experimentá-la algumas vezes, ou para realizar alguma tarefa complexa não tão comum no seu trabalho, e continuar usando uma interface simplificada para o resto do tempo (por exemplo, usando Github Desktop na maioria das vezes e mudando para SourceTree ou Gitbash para algumas tarefas específicas).

## Comandos Git {#git}

### Aprendizados recomendados {.unnumbered}

Para aprender os comandos Git em um tutorial interativo, consulte [este site](https://learngitbranching.js.org/).

### Onde inserir comandos {.unnumbered}

Você insere comandos em um shell Git.

*Opção 1* Você pode abrir um novo Terminal no RStudio. Esta guia está ao lado do R Console. Se você não conseguir digitar nenhum texto nele, clique no menu suspenso abaixo de "Terminal" e selecione "Novo terminal". Digite os comandos no espaço  em frente do cifrão "\$".

```{r echo=F, out.width = '100%', out.height='200%', fig.align = "center"}
knitr::include_graphics(here::here("images", "github_terminal.png"))
```

*Opção 2* Você também pode abrir um *shell* (um terminal para inserir comandos) clicando no ícone azul "engrenagens" na guia Git (próximo ao ambiente RStudio). Selecione "Shell" no menu suspenso. Uma nova janela será aberta onde você pode digitar os comandos após o cifrão "\$".

*Opção 3* Clique com o botão direito para abrir o "Git Bash aqui", que abrirá o mesmo tipo de terminal, ou abra o *Git Bash* da sua lista de aplicativos. [Mais informações para iniciantes no Git Bash](https://happygitwithr.com/shell.html), como encontrá-lo e alguns comandos bash que você precisará.

### Amostra de comandos {.unnumbered}

Abaixo, apresentamos alguns comandos git comuns. Ao usá-los, lembre-se de qual branch está ativo (com check-out), pois isso mudará a ação!

Nos comandos abaixo, <nome> representa o nome de um branch. <commit_hash> representa o ID de hash de um commit específico. <num> representa um número. Não digite os símbolos \< ou \>.

| Comando Git              | Ação                                                                            |
|--------------------------|---------------------------------------------------------------------------------|
| `git branch <nome>`      | Crie uma nova ramificação com o nome <nome>                                     |
| `git checkout <nome>`    | Mude o branch (ramificação) atual para <nome>                                   |
| `git checkout -b <nome>` | Atalho para criar um novo branch *e* mudar para ele                             |
| `git status`             | Veja as alterações não rastreadas                                               |
| `git add <file>`         | Prepare um arquivo                                                              |
| `git commit -m <message>`| Confirme as alterações (commit) preparadas para o branch atual com a mensagem   |
| `git fetch`              | Obter commits do repositório remoto                                             |
| `git pull`               | Extraia commits do repositório remoto no branch atual                           |
| `git push`               | Envie commits locais para o diretório remoto                                    |
| `git switch`             | Uma alternativa ao `git checkout` que está sendo implementado no Git            |
| `git merge <nome>`       | Mescle o branch <nome> no branch atual                                          |
| `git rebase <nome>`      | Anexar commits do branch atual para o branch <nome>                             |

<!-- ======================================================= -->

## Recursos

Grande parte desta página foi baseada [no site "Happy Git with R"](https://happygitwithr.com/) de Jenny Bryan. Há uma seção muito útil neste site que ajuda a solucionar erros comuns relacionados ao Git e ao R.

[Documentação do Github.com e guia de inicialização](https://docs.github.com/en/github).

["IDE" cheatsheet do RStudio](https://www.rstudio.com/wp-content/uploads/2016/01/rstudio-IDE-cheatsheet.pdf) que inclui dicas sobre o uso do Git com RStudio.

<https://ohi-science.org/news/github-going-back-in-time>

**Comandos Git para iniciantes**

Um [tutorial interativo](learngitbranching.js.org) para aprender os comandos Git.

<https://www.freecodecamp.org/news/an-introduction-to-git-for-absolute-beginners-86fa1d32ff71/>: "básico do básico" para rastrear alterações em uma pasta no seu próprio computador.

Esquemas legais para entender os branches: <https://speakerdeck.com/alicebartlett/git-for-humans>

**Tutoriais de assuntos básicos e avançados**

<https://tutorialzine.com/2016/06/learn-git-in-30-minutes>\
<https://dzone.com/articles/git-tutorial-commands-and-operations-in-git>\
<https://swcarpentry.github.io/git-novice/> (short course)\
<https://rsjakob.gitbooks.io/git/content/chapter1.html>\

O [livro Pro Git](https://git-scm.com/book/en/v2) é considerado uma referência oficial. Mas embora alguns capítulos estejam ok, ele pode parecer um pouco _técnico_. Certamente será um bom recurso se você já tiver usado um pouco o Git e quiser aprender um pouco mais precisamente sobre o que acontece e como ir mais longe.
```{r include=FALSE, cache=FALSE}

# clear workspace
rm(list = ls(all = TRUE))

# clear all packages except base
#lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))

# to ensure that tidyverse packages prevail
filter <- dplyr::filter
select <- dplyr::select
summarise <- dplyr::summarise
summary <- base::summary
incidence <- incidence2::incidence

#load core packages
pacman::p_load(
     rio,
     here,
     DT,
     stringr,
     lubridate,
     tidyverse
)

# import the cleaned ebola linelist
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

# import the count data - facility level
#count_data <- rio::import(here::here("data", "facility_count_data.rds"))

# Settings

options(scipen=1, digits=7)

# print only text (not code)
# library(knitr)
# opts_chunk$set(list(echo = FALSE, eval = FALSE))
```

<!--chapter:end:new_pages/collaboration.Rmd-->

# Erros comuns  {#errors}

Esta página inclui uma lista de erros comuns e sugere soluções para solucioná-los.

## Interpretando mensagens de erro

Os erros no R podem ser enigmáticos às vezes, então use o Google como seu amigo. Pesquise a mensagem de erro com "R" e procure as postagens recentes em [StackExchange.com](StackExchange.com), [stackoverflow.com](stackoverflow.com), [community.rstudio.com](community.rstudio.com), twitter (#rstats) e outros fóruns de perguntas e respostas usados por programadores. Tente encontrar postagens recentes que resolveram problemas semelhantes.

Se você não conseguir encontrar uma resposta para o seu problema, mesmo depois de pesquisar muito, considere criar um *exemplo reprodutível* ("reprex", ou um MRE para *Minimal Reproducible Exemple* ) e postar a pergunta você mesmo. Consulte a página [Obtendo ajuda](#help) para dicas sobre como criar e postar um exemplo reprodutível em fóruns.

## Erros comuns  

Abaixo, listamos alguns erros comuns e potenciais explicações / soluções. Some of these are borrowed from Noam Ross who analyzed the most common forum posts on Stack Overflow about R error messages (see analysis [here](https://github.com/noamross/zero-dependency-problems/blob/master/misc/stack-overflow-common-r-errors.md))  


### Erros de digitação {.unnumbered}  

```
Error: unexpected symbol in:
"  geom_histogram(stat = "identity")+
  tidyquant::geom_ma(n=7, size = 2, color = "red" lty"
```
Se você vir um "unexpected symbol" (símbolo inesperado), verifique se há vírgulas faltando  

### Erros de pacote {.unnumbered}  

```
could not find function "x"...
```
Isso provavelmente significa que você digitou o nome da função incorretamente ou esqueceu de instalar / carregar um pacote.

```
Error in select(data, var) : unused argument (var)
```
Você acha que está usando `dplyr :: select ()` mas a função `select ()` foi mascarada por `MASS::select ()` - especifique `dplyr ::` ou reorganize o carregamento do pacote para que dplyr venha depois de todos os outros.

Outros erros comuns de mascaramento vêm de: `plyr::summarise()` and `stats::filter()`. Considere usar o pacote [**conflicted** package](https://www.tidyverse.org/blog/2018/06/conflicted/).

```
Error in install.packages : ERROR: failed to lock directory ‘C:\Users\Name\Documents\R\win-library\4.0’ for modifying
Try removing ‘C:\Users\Name\Documents\R\win-library\4.0/00LOCK’
```

Se você receber um erro dizendo que precisa remover um arquivo "00LOCK", vá para a biblioteca "R" no diretório do seu computador (por exemplo, R/win-library/) e procure uma pasta chamada "00LOCK". Exclua isso manualmente e tente instalar o pacote novamente. Provavelmente isso aconteceu porque um processo de instalação anterior foi interrompido.

### Erros de objeto {.unnumbered}  

```
No such file or directory:
```
Se você encontrar um erro como este na exportação ou importação: Verifique a ortografia do arquivo e do caminho do arquivo. Se o caminho contém barras, certifique-se de que estão para frente `/` e não para trás `\`. Certifique-se também de usar a extensão de arquivo correta (por exemplo, .csv, .xlsx).

```
object 'x' not found 
```
Isso significa que o objeto não existe. Talvez o código acima não tenha funcionado corretamente?

```
Error in 'x': subscript out of bounds
```
Isso significa que você tentou acessar algo (um elemento de um vetor ou uma lista) que não estava lá.

### Erros de sintaxe de função {.unnumbered}

```
# ran recode without re-stating the x variable in mutate(x = recode(x, OLD = NEW)
Error: Problem with `mutate()` input `hospital`.
x argument ".x" is missing, with no default
i Input `hospital` is `recode(...)`.
```
O erro acima (`argument ".x" is missing, with no default`) é comum em `mutate()` se você estiver fornecendo uma função como `recode ()` ou `replace_na()`, pois espera-se que você forneça a coluna nome como  primeiro argumento. Isso é fácil de esquecer.

### Erros lógicos {.unnumbered}  

```
Error in if
```

Isso provavelmente significa que uma instrução `if` foi aplicada a algo que não era VERDADEIRO ou FALSO.

### Erros de fator {.unnumbered}  

```
#Tried to add a value ("Missing") to a factor (with replace_na operating on a factor)
Problem with `mutate()` input `age_cat`.
i invalid factor level, NA generated
i Input `age_cat` is `replace_na(age_cat, "Missing")`.invalid factor level, NA generated
```
Se você encontrar este erro sobre níveis de fator inválidos, provavelmente tem uma coluna com uma variável do tipo fator (níveis predefinidos) e tentou adicionar um novo valor a ela. Converta-o para o tipo caracter antes de adicionar um novo valor.

### Erros de plotagem {.unnumbered}  

`Error: Insufficient values in manual scale. 3 needed but only 2 provided.`
ggplot() scale_fill_manual() values = c("orange", "purple") ... insufficient for number of factor levels ... consider whether NA is now a factor level...

```
Can't add x object
```
Provavelmente tem um `+` extra no final de um comando ggplot que você precisa excluir.

### Erros de R Markdown {.unnumbered}  

Se a mensagem de erro contiver algo como `Error in options[[sprintf("fig.%s", i)]]`, verifique se as opções do knitr no topo de cada bloco usam adequadamente `out.width = ` ou `out.height = ` e *não* `fig.width=` e `fig.height=`.

### Diversos {.unnumbered}  

Considere se você reorganizou os verbos **dplyr** e esqueceu de substituir um *pipe* (%>%) no meio do código ou se esqueceu um pipe na extremidade após reorganizar.

<!-- ======================================================= -->
## Recursos { }

Esta é outra postagem do blog que lista [erros de programação R enfrentados por iniciantes](https://www.r-bloggers.com/2016/06/common-r-programming-errors-faced-by-beginners/)
```{r include=FALSE, cache=FALSE}

# clear workspace
rm(list = ls(all = TRUE))

# clear all packages except base
#lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))

# to ensure that tidyverse packages prevail
filter <- dplyr::filter
select <- dplyr::select
summarise <- dplyr::summarise
summary <- base::summary
incidence <- incidence2::incidence

#load core packages
pacman::p_load(
     rio,
     here,
     DT,
     stringr,
     lubridate,
     tidyverse
)

# import the cleaned ebola linelist
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

# import the count data - facility level
#count_data <- rio::import(here::here("data", "facility_count_data.rds"))

# Settings

options(scipen=1, digits=7)

# print only text (not code)
# library(knitr)
# opts_chunk$set(list(echo = FALSE, eval = FALSE))
```

<!--chapter:end:new_pages/errors.Rmd-->


# Conseguindo ajuda  {#help}

Esta página aborda sobre como obter ajuda postando um problema (issue) no Github ou postando um exemplo reprodutível ("reprex" ou MRE para *Minimal reprodutible exemple*) em um fórum online.

## Issues (problemas) do Github

Muitos pacotes e projetos R têm seu código hospedado no site Github.com. Você pode se comunicar diretamente com os autores através do site, postando um "Problema".

Leia mais sobre como armazenar seu trabalho no Github na página [Colaboração e Github](#collaboration). 

No Github, cada projeto está contido em um *repositório*. Cada repositório contém código, dados, saídas, documentação de ajuda etc. Existe também um veículo de comunicação com os autores denominado "Problemas".  

Veja abaixo a página do Github para o pacote **incidence2** (usado para fazer curvas epidêmicas). Você pode ver a guia "Issues" (Problemas, em imglês) destacada em amarelo. Você pode ver que existem 5 questões em aberto.

```{r, warning=F, message=F, echo=F}
knitr::include_graphics(here::here("images", "errors_Github_issues.png"))
```

Nesta guia *Issues* você pode ver os problemas em aberto. Revise-os para garantir que seu problema não foi resolvido ainda. Você pode abrir um novo problema clicando no botão verde à direita. Para fazer isso, será necessário ter uma conta Github.

```{r, warning=F, message=F, echo=F}
knitr::include_graphics(here::here("images", "errors_Github_issues2.png"))
```

Siga as instruções abaixo para fornecer um exemplo mínimo e reproduzível do seu problema. Por favor, seja educado(a)! A maioria das pessoas que desenvolve pacotes e projetos R estão fazendo isso no seu tempo livre (como este manual!).

Para ler materiais mais avançados sobre como lidar com problemas no seu  repositório, verifique a [documentação sobre problemas do Github](https://guides.github.com/features/issues/).

## Exemplo reprodutível  

Fornecer um exemplo reprodutível ("reprex") é a chave para obter ajuda com sua postagem ou problema no Github. As pessoas querem ajudá-lo, mas você precisa dar um exemplo com o qual elas possam trabalhar em seus próprios computadores. O exemplo deve:

* Demonstrar o problema que você encontrou  
* Ser *o mais curto possível*, incluindo apenas os dados e o código necessário para reproduzir o seu problema
* Ser *reprodutível*, de modo que todos os objetos (por exemplo, dados), e pacotes sejam incluídos (por exemplo, `library()` ou `p_load()`)

*Além disso, certifique-se de não postar nenhum dado sensível com o reprex!* Você pode criar dataframes de exemplo ou usar um dos dataframes embutidos no R (insira `data()` para abrir uma lista desses conjuntos de dados).

### O pacote **reprex** {.unnumbered}  

O pacote **reprex** pode ajudá-lo a fazer um exemplo reprodutível: 

1) **reprex** é instalado com **tidyverse**, então carregue qualquer um dos pacotes  

```{r, eval=F}
# intale/carregue o tidyverse (que inclui o reprex)
pacman::p_load(tidyverse)
```

2) Inicie um script R que gere seu problema, passo a passo, começando com o carregamento de pacotes e dados.

```{r, eval=F}
# carregar pacotes
pacman::p_load(
     tidyverse,  # manipulação de dados e visualização
     outbreaks)  # exemplos de dados de surtos 

# linelist lista dos casos da epidemia de gripe
outbreak_raw <- outbreaks::fluH7N9_china_2013  #recuperar conjunto de dados do pacote de surtos

# Limpar conjunto de dados
outbreak <- outbreak_raw %>% 
     mutate(across(contains("date"), as.Date))

# Visualizar epidemia
ggplot(data = outbreak)+
     geom_histogram(
          mapping = aes(x = date_of_onset),
          binwidth = 7
     )+
  scale_x_date(
    date_format = "%d %m"
  )

```
*Copie* todo o código para a área de transferência e execute o seguinte comando:  

```{r, eval=F}
reprex::reprex()
```

Você verá uma saída HTML aparecer no painel RStudio Viewer. Ele conterá todo o seu código e quaisquer avisos, erros ou resultados de plotagem. Essa saída também é copiada para sua área de transferência, para que você possa publicá-la diretamente em um problema do Github ou em uma postagem do fórum.

```{r, out.width=c('100%', '100%'), warning=F, message=F, echo=F}
knitr::include_graphics(here::here("images", "errors_reprex_RStudio1.png"))
```

* Se você definir `session_info = TRUE`, a saída de `sessioninfo ::session_info()` incluírá suas versões do R e dos pacotes R
* Você pode fornecer um diretório de trabalho para `wd =`
* Você pode ler mais sobre os argumentos e possíveis variações em [documentation]() ou inserindo `?Reprex`

No exemplo acima, o comando `ggplot()` não rodou porque o argumento `date_format =` não está correto - deveria ser `date_labels =`. 

### Dados mínimos {.unnumbered}  

As pessoas que vão te ajudar precisam ser capazes de usar seus dados - de preferência, eles precisam ser capazes de criá-los *com código*.

Para criar um conjunto de dados mínimos, considere anonimizar e usar apenas um subconjunto das observações.

EM CONSTRUÇÃO - você também pode usar a função `dput()` para criar um conjunto mínimo de dados.

## Postar em um fórum  

Leia muitas postagens do fórum. Entenda quais postagens são bem escritas e quais não são.

1) Primeiro, decida se deseja fazer a pergunta. Você revisou *extensivamente* o site do fórum, tentando vários termos de pesquisa, para ver se sua pergunta já foi feita?

2) Dê um título informativo à sua pergunta (não algo como "Socorro! Isso não está funcionando!").

3) Escreva sua pergunta:

* Apresente sua situação e problema
* Faça um link com postagens de problemas semelhantes e explique porque eles não responderam à sua pergunta
* Inclua qualquer informação relevante para ajudar alguém que não conhece o contexto do seu trabalho
* Dê um exemplo reprodutível mínimo com as informações do seu trabalho
* Use ortografia, gramática e pontuação adequadas e divida sua pergunta em parágrafos para que seja mais fácil de ler

4) Depois de postar, monitore sua pergunta para responder a qualquer pedido de esclarecimento. Seja educado(a) e cortês - muitas vezes as pessoas que respondem estão oferecendo seu tempo para ajudá-lo. Se você tiver uma pergunta de acompanhamento, considere se deve ser uma pergunta postada separada.

5) Marque a pergunta como respondida, *se* obtiver uma resposta que atenda à solicitação *original*. Isso ajuda outras pessoas a reconhecerem rapidamente a solução mais tarde.  

Leia estas postagens sobre [como fazer uma boa pergunta](https://stackoverflow.com/help/how-to-ask) e sobre o[código de conduta do Stack overflow](https://stackoverflow.com/conduct).  

<!-- ======================================================= -->
## Recursos { }

Página do Tidyverse sobre como [obter ajuda!](https://www.tidyverse.org/help/#:~:text=When%20you%20want%20to%20make,to%20load%20the%20reprex%20package.&text=Enter%20reprex()%20in%20the,preview%20of%20your%20rendered%20reprex.)

Dicas para [produzir um conjunto mínimo de dados](https://xiangxing98.github.io/R_Learning/R_Reproducible.nb.html#producing-a-minimal-dataset)

Documentação para a [função dput](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/dput)
```{r include=FALSE, cache=FALSE}

# clear workspace
rm(list = ls(all = TRUE))

# clear all packages except base
#lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))

# to ensure that tidyverse packages prevail
filter <- dplyr::filter
select <- dplyr::select
summarise <- dplyr::summarise
summary <- base::summary
incidence <- incidence2::incidence

#load core packages
pacman::p_load(
     rio,
     here,
     DT,
     stringr,
     lubridate,
     tidyverse
)

# import the cleaned ebola linelist
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

# import the count data - facility level
#count_data <- rio::import(here::here("data", "facility_count_data.rds"))

# Settings

options(scipen=1, digits=7)

# print only text (not code)
# library(knitr)
# opts_chunk$set(list(echo = FALSE, eval = FALSE))
```

<!--chapter:end:new_pages/help.Rmd-->

# R em drives (pastas) na rede {#network-drives}

<!-- ======================================================= -->

## Visão geral

O uso do R em rede ou em pastas compartilhadas de uma instituição pode apresentar desafios adicionais. Esta página contém abordagens, erros comuns e sugestões sobre a solução de problemas obtidos a partir da nossa experiência de trabalho com estas questões. Isto inclui dicas para as situações particularmente delicadas envolvendo o R Markdown.  

**Usando R em drives na rede: Princípios gerais**

1) Você deve obter acesso de administrador para seu computador. Configure o RStudio especificamente para ser executado como administrador.  
2) Salve os pacotes em uma biblioteca (drive, pasta) com letras sempre que possível (por exemplo, "C:"). Evite usar uma biblioteca de pacotes cujo caminho comece com "\\".  
3) O pacote **rmarkdown não deve** estar em uma biblioteca de pacotes "\\", pois assim não poderá se conectar ao TinyTex ou ao Pandoc.  

## RStudio como administrador  

Para abrir o RStudio, clique no ícone com o botão direito do mouse. Dependendo de sua máquina, você verá uma opção para "Run as Administrator" (Executar como administrador). Caso contrário, você verá uma opção para selecionar as Properties (Propriedades), e então deverá aparecer uma janela com a opção "Compatibility" (Compatibilidade), e você poderá selecionar uma caixa de seleção "Run as Administrator" (Executar como Administrador).  

## Comandos úteis

Abaixo estão alguns comandos úteis ao tentar solucionar problemas usando R em drives de rede.  

Você pode retornar o(s) caminho(s) para as bibliotecas de pacotes que o R está usando. Eles serão listados na ordem em que R estiver usando para instalar/carregar/buscar por pacotes. Assim, se você quiser que R use uma biblioteca padrão diferente, você pode mudar a ordem destes caminhos (veja abaixo).

```{r, eval=F}
# Encontrar bibliotecas
.libPaths()                   #  Os caminhos de sua biblioteca, listados para que o R instale/selecione.. 
                              # Nota: todas as bibliotecas serão listadas, mas para instalar em algumas 
                              # (por exemplo, C:) você pode precisar executar o RStudio como administrador 
                              # (não aparecerá no menu suspenso de install.packages) 
```

Você pode querer mudar a ordem das bibliotecas de pacotes usadas pelo R. Por exemplo, se o R estiver pegando um local de biblioteca que começa com "\\" e um que começa com uma letra, por exemplo, "D:". Você pode ajustar a ordem de `.libPaths()` com o seguinte código.

```{r, eval=F}
# Troca a ordem das bibliotecas
# Isto pode afetar a prioridade do R encontrar um pacote. Por exemplo, você pode querer que sua biblioteca C: seja listada primeiro
myPaths <- .libPaths() # obter os caminhos
myPaths <- c(myPaths[2], myPaths[1]) # trocar os caminhos
.libPaths(myPaths) # realocar os caminhos
```

Se você estiver com dificuldades no para conectar o R Markdown ao Pandoc, comece com este código para descobrir onde RStudio entende que está sua instalação Pandoc. 

```{r, eval=F}
#Encontrar o Pandoc
Sys.getenv("RSTUDIO_PANDOC")  # Descubra onde o RStudio entende que está sua instalação Pandoc
```

Se você quiser ver de qual biblioteca um pacote está sendo carregado, tente o código abaixo: 

```{r, eval=F}
# Encontrar um pacote
# Indica a primeira localização do pacote (Note a ordem de suas bibliotecas)
find.package("rmarkdown", lib.loc = NULL, quiet = FALSE, verbose = getOption("verbose")) 
```

<!-- ======================================================= -->

## Resolução de problemas e erros comuns

**"Failed to compile...tex in rmarkdown"**

-   Verifique a instalação de TinyTex, ou instale TinyTex em C:. Veja na página [Introdução ao R](#basics) sobre como instalar o TinyTex. 

```{r, eval=F}
# Verificar/instalar tinytex em C:
tinytex::install_tinytex()
tinytex:::is_tinytex() # deve retornar TRUE (VERDADEIRO)
```

**As rotinas da Internet não podem ser carregadas**

Por exemplo, `Error in tools::startDynamicHelp() : internet routines cannot be loaded`

-   Tente selecionar a versão de 32 bits do RStudio em Tools/Global Options (Ferramentas/Opções Globais).

    -   nota: se a versão de 32 bits não aparecer no menu, certifique-se de não estar usando o RStudio v1.2

-   Alternativamente, tente desinstalar R e reinstalar com versão de bit diferente (32 em vez de 64).

**C: o pacote não aparece como opção quando tento instalar pacotes manualmente**

- Execute o RStudio como administrador que esta opção vai aparecer  
- Para executar o RStudio sempre como administrador, clique com o botão direito do mouse no ícone do Rstudio (opção vantajosa ao usar um projeto R, em que você não clica no ícone do RStudio para abrir).  

A imagem abaixo mostra como você pode selecionar manualmente a biblioteca para a instalação de um pacote. Esta janela aparece quando você abre o painel Packages (Pacotes) no RStudio e clica em "Install" (Instalar).  

```{r, warning=F, message=F, echo=F}
knitr::include_graphics(here::here("images", "network_install.png"))
```

**Erro Pandoc 1**

Se você estiver recebendo "pandoc error 1" ao criar scripts R Markdowns em drives de rede:

-   Dentre as muitas bibliotecas, tenha uma com letras listadas primeiro (ver códigos acima)\
-   A solução acima funcionou ao programar em uma unidade local, mas em uma conexão de Internet em rede\
-   Veja mais dicas aqui: <https://ciser.cornell.edu/rmarkdown-knit-to-html-word-pdf/>

**Erro Pandoc 83**

O erro será algo parecido com:  `can't find file...rmarkdown...lua...`. Isto significa que não foi possível encontrar este arquivo.

Veja <https://stackoverflow.com/questions/58830927/rmarkdown-unable-to-locate-lua-filter-when-knitting-to-word>

Possibilidades:

1)  O pacote Rmarkdown não está instalado\
2)  O pacote Rmarkdown não pode ser encontrado\
3)  Uma questão de direitos do administrador.

É possível que o R não seja capaz de encontrar o arquivo do pacote **rmarkdown**, portanto verifique qual biblioteca (pasta) o pacote **rmarkdown** se encontra (veja o código acima). Se o pacote foi instalado em uma biblioteca inacessível (por exemplo, que comece com "\\"), considere movê-lo manualmente para C: ou outra biblioteca que comece com uma letra. Esteja ciente de que o pacote **rmarkdown** tem que ser capaz de se conectar à instalação do TinyTex, portanto não pode estar em uma biblioteca em uma unidade de rede.

**Erro Pandoc 61**

Por exemplo: `Error: pandoc document conversion failed with error 61` ou `Could not fetch...`

-   Tente executar o RStudio como administrador (clique com o botão direito do mouse, selecione executar como administrador, veja as instruções acima)\
-   Veja também se o pacote específico que não pôde ser carregado pode ser movido para biblioteca C:.

**LaTex error (ver abaixo)**

Um erro como: `! Package pdftex.def Error: File 'cict_qm2_2020-06-29_files/figure-latex/unnamed-chunk-5-1.png' not found: using draft setting.` ou `Error: LaTeX failed to compile file_name.tex.`

-   Veja <https://yihui.org/tinytex/r/#debugging> para dicas de correção.\
-   Veja file_name.log para mais informações.

**Erro Pandoc 127**

Isto pode ser uma questão de RAM (espaço). Reinicie novamente sua sessão R e tente novamente.

**Mapeamento de drives na rede**

Mapear uma unidade de rede pode ser arriscado. Consulte seu departamento de TI antes de tentar fazer isso.

Uma dica emprestada deste [fórum de discussão](https://stackoverflow.com/questions/48161177/r-markdown-openbinaryfile-does-not-exist-no-such-file-or-directory/55616529?noredirect=1#comment97966859_55616529):

Como se abre um arquivo "através de uma unidade de rede mapeada"?

-   Primeiro, você precisará saber a localização da rede à qual está tentando acessar.\
-   Em seguida, no gerenciador de arquivos do Windows, você precisará clicar com o botão direito do mouse em "Este Computador" no painel à esquerda (ou direita, dependendo da sua configuração), e selecionar "Mapear uma unidade de rede".\
-   Passe pelo diálogo para definir a localização da rede desde o início como um drive com letras de forma.\
-   Agora você tem duas maneiras de chegar ao arquivo que você está abrindo. O uso do caminho com letras deve funcionar.

**Erro em install.packages()**

Se você receber um erro que inclua a menção de um diretório "lock", por exemplo: `Error in install.packages : ERROR: failed to lock directory...`

Procure em sua biblioteca de pacotes e verá uma pasta cujo nome começa com "00LOCK". Tente as seguintes dicas:

-   Apague manualmente o diretório da pasta "00LOCK" de sua biblioteca de pacotes. Tente instalar o pacote de novo.\
-   Você também pode tentar o comando `pacman::p_unlock()` (você também pode colocar este comando no Rprofile para que ele seja executado toda vez que o projeto abrir). Tente então instalar o pacote novamente. Pode ser necessário várias tentativas.\
-   Tente executar o RStudio no modo administrador, e tente instalar os pacotes um a um.\
-   e tudo isso falhar, instale o pacote em outra biblioteca ou pasta (por exemplo, Temp) e depois copie manualmente a pasta do pacote para a biblioteca desejada.
```{r include=FALSE, cache=FALSE}

# clear workspace
rm(list = ls(all = TRUE))

# clear all packages except base
#lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))

# to ensure that tidyverse packages prevail
filter <- dplyr::filter
select <- dplyr::select
summarise <- dplyr::summarise
summary <- base::summary
incidence <- incidence2::incidence

#load core packages
pacman::p_load(
     rio,
     here,
     DT,
     stringr,
     lubridate,
     tidyverse
)

# import the cleaned ebola linelist
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

# import the count data - facility level
#count_data <- rio::import(here::here("data", "facility_count_data.rds"))

# Settings

options(scipen=1, digits=7)

# print only text (not code)
# library(knitr)
# opts_chunk$set(list(echo = FALSE, eval = FALSE))
```

<!--chapter:end:new_pages/network_drives.Rmd-->


# Data Table {#data-table}  
     
Este livro centra-se nos "verbos" (funções) do pacote **dplyr** e no operador pipe `%>%` do pacote **magrittr** como método para limpar e agrupar dados, mas o pacote **data.table** oferece um método alternativo que você poderá incorporar em seu uso do R.  



<!-- ======================================================= -->
## Introdução ao Data Table {  }

Uma tabela de dados (data table) é uma estrutura de dados bidimensional como um data frame, que permite a realização de operações complexas de agrupamento. A sintaxe data.table é estruturada para que as operações possam ser realizadas em linhas, colunas e grupos. 

A estrutura é **DT[i, j, by]**, separada por 3 partes; os argumentos **i, j** e **by**. O argumento **i** permite filtrar linhas, o argumento **j** permite operar em colunas e o argumento **by** permite operar em colunas por grupos.
  
Esta página abordará os seguintes tópicos:  

* Importação de dados e uso das funções `fread()` e `fwrite()`
* Filtragem de linhas utilizando o argumento **i**
* Utilização das funções de ajuda `%like%`, `%chin%` e `%between%` 
* Seleção e operação com colunas utilizando o argumento **j**
* Operar por grupos utilizando o argumento **by**
* Adição de dados e atualização de data tables (tabelas de dados) utilizando `:=`

<!-- ======================================================= -->
## Carregar pacotes e importar dados { }

### Carregar pacotes {.unnumbered}  

Utilizando a função `p_load()` de **pacman**, carregamos (e instalamos, se necessário) os pacotes necessários para esta análise.

```{r}
pacman::p_load(
  rio,        # para importar dados
  data.table, # para agrupar e limpar dados
  tidyverse,  # permite o uso da função pipe (%>%) neste capítulo
  here 
  ) 
```


### Importar dados {.unnumbered}

Esta página vai explorar algumas das funções centrais do pacote **data.table** recorrendo à mesma linelist de casos utilizada ao longo do manual.

Importamos o conjunto de dados dos casos de uma epidemia simulada de Ébola. Se você quiser baixar os dados para seguir passo a passo, veja as instruções na página [Baixar livro e dados](#data-used). O conjunto de dados é importado utilizando a função `import()` do pacote **rio**. Veja a página em [Importar e exportar](#importing) para várias formas de importação de dados. Em seguida, utilizamos `data.table()` para converter o quadro de dados em um data table.

```{r}
linelist <- rio::import(here("data", "linelist_cleaned.xlsx")) %>% data.table()
```

A função `fread()` é utilizada para importar arquivos delimitados por caracteres, como arquivos .csv, diretamente para um formato de data table. Esta função, e sua contraparte `fwrite()`, utilizada para escrever data.tables como arquivos delimitados, são opções muito rápidas e computacionalmente eficientes para grandes bancos de dados.

As primeiras 20 linhas da `linelist`:  

```{r message=FALSE, echo=F, eval=FALSE}
DT::datatable(head(linelist,20), rownames = FALSE, filter="top", options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```

Comandos do R Base como `dim()` que são utilizados para data frames também podem ser utilizados para data tables (tabelas de dados).

```{r}
dim(linelist) #dispõe o número de linhas e colunas na tabela de dados
```

<!-- ======================================================= -->
## O argumento i: selecionando e filtrando linhas{ }
     
Relembrando a estrutura **DT[i, j, by]**, podemos filtrar linhas usando números de linha ou expressões lógicas. O argumento i é o primeiro; portanto, a sintaxe **DT[i]** ou **DT[i,]** pode ser usada. 

O primeiro exemplo recupera as primeiras 5 linhas do data table, o segundo exemplo retorna casos com 18 anos ou mais, e o terceiro exemplo gera um subconjunto de casos com 18 anos ou mais, mas não diagnosticados no Hospital Central:


```{r, eval=F}
linelist[1:5] # retorna da 1ª à 5ª fileira
linelist[age >= 18] # subconjunto de casos com 18 anos ou mais
linelist[age >= 18 & hospital != "Central Hospital"] # conjunto de casos com idade igual ou superior a 18 anos, mas não diagnosticados no Hospital Central
```

O uso de .N no argumento i representa o número total de linhas no data table. Isto pode ser usado para criar subconjuntos com base nos números das linhas:  

```{r, eval=F}
linelist[.N] # retorna a última linha
linelist[15:.N] # retorna da 15ª à última linha
```


### Funções de ajuda para filtragem {.unnumbered}  

Data tables (tabelas de dados) utilizam funções de auxílio que facilitam a filtragem linhas. A função `%like%` é utilizada para corresponder a um padrão em uma coluna, `%chin%` é utilizada para corresponder a um caractere específico, e a função `%between%` é utilizada para corresponder a colunas numéricas dentro de uma faixa pré-especificada.

Nos exemplos a seguir, nós:
* filtramos linhas em que a variável hospital contém "Hospital"
* filtramos linhas em que o resultado é "Recover" ou "Death"
* filtramos linhas em que a faixa etária (age) é 40-60 anos

```{r, eval=F}
linelist[hospital %like% "Hospital"] # filtrar linhas em que a variável hospital contém "Hospital"
linelist[outcome %chin% c("Recover", "Death")] # filtrar linhas em que o resultado (outcome) é "Recover" ou "Death"
linelist[age %between% c(40, 60)] # filtrar linhas em que a faixa etária (age) é de 40-60 anos

#%between% deve receber um vetor de comprimento 2, enquanto %chin% pode receber vetores de comprimento >= 1

```

## O argumento j: seleção e cálculo nas colunas{ }

Usando a estrutura **DT[i, j, by]**, podemos selecionar colunas usando números ou nomes. O argumento **j** é o segundo; portanto, a sintaxe **DT[, j]** é usada. Para facilitar os cálculos no argumento **j**, a coluna é envolvida utilizando `list()` ou `.()`. 

### Seleção de colunas {.unnumbered} 

O primeiro exemplo recupera a primeira, terceira e quinta colunas do data table, o segundo exemplo seleciona todas as colunas, exceto as colunas gender, age, wt_kg e ht_cm. O terceiro exemplo utiliza o envelope `.()` para selecionar as colunas **case_id** e **outcome**.


```{r, eval=F}
linelist[ , c(1,3,5)]
linelist[ , -c("gender", "age", "wt_kg", "ht_cm")]
linelist[ , list(case_id, outcome)] #linelist[ , .(case_id, outcome)] funciona tão bem quanto

```

### Cálculo nas colunas {.unnumbered} 

Combinando os argumentos **i** e **j** é possível filtrar linhas e calcular colunas. Usar **.N** no argumento **j** também representa o número total de linhas no data table e pode ser útil para retornar o número de linhas após a filtragem.

Nos exemplos a seguir, nós:
* contamos o número de casos que permaneceram mais de 7 dias no hospital
* calculamos a idade média dos casos que vieram a óbito no hospital militar
* calculamos o desvio padrão, mediana, e média da idade dos casos que se recuperaram no hospital central

```{r}
linelist[days_onset_hosp > 7 , .N]
linelist[hospital %like% "Military" & outcome %chin% "Death", .(mean(age, na.rm = T))] #na.rm = T remove valores N/A
linelist[hospital == "Central Hospital" & outcome == "Recover", 
                 .(mean_age = mean(age, na.rm = T),
                   median_age = median(age, na.rm = T),
                   sd_age = sd(age, na.rm = T))] # esta sintaxe não utiliza as funções de ajuda, mas funciona tão bem quanto

```

Lembre-se que usar o envelope .() no argumento j facilita o cálculo, retorna um data table e permite a nomeação de colunas.

## The by argument: computing by groups{ }

O argumento **by** é o terceiro argumento na estrutura **DT[i, j, by]**. Ele aceita tanto um vetor de caracteres quanto a sintaxe `list()` ou `.()`. A utilização da sintaxe `.()` no argumento **by** permite renomear a coluna imediatamente.

Nos exemplos a seguir, nós:	
* agrupamos o número de casos por hospital
* calculamos a altura média e o peso dos casos com 18 anos ou mais, de acordo com o sexo e desfecho (se eles se recuperaram ou vieram a óbito)
* contamos o número de casos com tempo de internação > 7 dias, de acordo com o mês e o hospital em que foram admitidos

```{r}
linelist[, .N, .(hospital)] # número de casos por hospital
linelist[age > 18, .(mean_wt = mean(wt_kg, na.rm = T),
                             mean_ht = mean(ht_cm, na.rm = T)), .(gender, outcome)] #NAs representam as categorias em que os dados estão faltando
linelist[days_onset_hosp > 7, .N, .(month = month(date_hospitalisation), hospital)]

```

Data.table também permite expressões em serquência:

```{r}

linelist[, .N, .(hospital)][order(-N)][1:3] #1º seleciona todos os casos por hospital, 2º ordena os casos em ordem decrescente, 3º seleciona um subconjunto dos 3 hospitais com o maior número de casos


```

Nestes exemplos, estamos seguindo a suposição de que uma linha no data table é igual a um novo caso, e assim podemos usar o **.N** para representar o número de linhas no data table. Outra função útil para representar o número de casos únicos é `uniqueN()`, que retorna o número de valores únicos em uma determinada entrada. Como ilustrado aqui:

```{r}

linelist[, .(uniqueN(gender))] # lembre que o envelope .() no argumento j retorna um data table

```

A resposta é 3, pois os valores únicos na coluna de gênero são m, f e N/A. Compare com a função `unique()` do R Base, que retorna todos os valores únicos em uma determinada entrada:

```{r}

linelist[, .(unique(gender))]
```

Para encontrar o número de casos únicos em um determinado mês, escrevemos o seguinte:

```{r}

linelist[, .(uniqueN(case_id)), .(month = month(date_hospitalisation))]

```

## Adicionar e atualizar data tables (tabelas de dados) { }

O operador `:=` é utilizado para adicionar ou atualizar dados em um data table. A adição de colunas pode ser feita das seguintes maneiras:

```{r}

linelist[, adult := age >= 18] # adiciona uma coluna
linelist[, c("child", "wt_lbs") := .(age < 18, wt_kg*2.204)] #para adicionar múltiplas colunas é necessário usar as sintaxes c(""), list() ou .() syntax
linelist[, `:=` (bmi_in_range = (bmi > 16 & bmi < 40),
                         no_infector_source_data = is.na(infector) | is.na(source))] #Este método utiliza `:=` como um operador funcional 
linelist[, adult := NULL] # deleta a coluna

```


Outras agregações complexas estão além do objetivo deste capítulo introdutório, mas a ideia é fornecer uma alternativa popular e viável ao **dplyr** para agrupamento e limpeza de dados. O pacote **data.table** é um grande pacote que permite um código limpo e legível.


## Recursos {  }

Aqui estão alguns recursos úteis para maiores informações:
* https://cran.r-project.org/web/packages/data.table/vignettes/datatable-intro.html
* https://github.com/Rdatatable/data.table
* https://s3.amazonaws.com/assets.datacamp.com/img/blog/data+table+cheat+sheet.pdf
* https://www.machinelearningplus.com/data-manipulation/datatable-in-r-complete-guide/
* https://www.datacamp.com/community/tutorials/data-table-r-tutorial

Você pode realizar qualquer função de resumo sobre dados agrupados; veja a Cheat Sheet para mais informações:
https://s3.amazonaws.com/assets.datacamp.com/blog_assets/datatable_Cheat_Sheet_R.pdf
```{r include=FALSE, cache=FALSE}

# clear workspace
rm(list = ls(all = TRUE))

# clear all packages except base
#lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))

# to ensure that tidyverse packages prevail
filter <- dplyr::filter
select <- dplyr::select
summarise <- dplyr::summarise
summary <- base::summary
incidence <- incidence2::incidence

#load core packages
pacman::p_load(
     rio,
     here,
     DT,
     stringr,
     lubridate,
     tidyverse
)

# import the cleaned ebola linelist
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

# import the count data - facility level
#count_data <- rio::import(here::here("data", "facility_count_data.rds"))

# Settings

options(scipen=1, digits=7)

# print only text (not code)
# library(knitr)
# opts_chunk$set(list(echo = FALSE, eval = FALSE))
```

<!--chapter:end:new_pages/data_table.Rmd-->

